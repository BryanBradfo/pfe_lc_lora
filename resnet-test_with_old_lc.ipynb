{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-50 Implementation with Old LC on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bradf\\anaconda3\\envs\\py310\\lib\\site-packages\\transformers\\utils\\generic.py:485: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy as spy\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import ssl\n",
    "import pickle, json\n",
    "import src.main as lc\n",
    "import old_lc.main as olc\n",
    "from src.models.ResNet50 import ResNet50\n",
    "import src.compression.deltaCompress as lc_compress\n",
    "from src.models.ResNet50_LowRank import getBase, ResNet50_LowRank, load_sd_decomp\n",
    "from src.utils.utils import evaluate_accuracy, lazy_restore, evaluate_compression\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 5253578\n",
      "Linear parameters (excluding the last nn.Linear): 20490\n"
     ]
    }
   ],
   "source": [
    "# Function to count the number of parameters\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    # Exclude the last nn.Linear layer\n",
    "    linear_params = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            linear_params += sum(p.numel() for p in module.parameters())\n",
    "\n",
    "    return total_params, linear_params\n",
    "\n",
    "model = ResNet50()\n",
    "# Get the total and linear parameters\n",
    "total_params, linear_params = count_parameters(model)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Linear parameters (excluding the last nn.Linear): {linear_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Data Loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDFP = \"./volumes/Ultra Touch\" # Load HHD\n",
    "\n",
    "def data_loader():\n",
    "    # transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(32, antialias=True)])\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize(32, antialias=True),  # ou (32, 32), redimensionne les images à 32x32\n",
    "    transforms.ToTensor(),  # Convertit les images PIL ou numpy.ndarray en Tensors.\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))  # Normalise les données\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                          download=True, transform=transform)\n",
    "    # Reintroduce the 2000 datapoints model has not seen before.\n",
    "    trainset.data = trainset.data.clone()[-2000:-1000]\n",
    "    trainset.targets = trainset.targets.clone()[-2000:-1000]\n",
    "    # trainset.data = trainset.data.clone()[:58000]\n",
    "    # trainset.targets = trainset.targets.clone()[:58000]\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size = 32,\n",
    "                                              shuffle=False, num_workers=2)\n",
    "\n",
    "    testset = datasets.MNIST(root='./data', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "\n",
    "    # testset.data = testset.data[:2000]\n",
    "    # testset.targets = testset.targets[:2000]\n",
    "    testset.data = trainset.data[-1000:]\n",
    "    testset.targets = trainset.targets[-1000:]\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bypass using SSL unverified\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# MNIST dataset \n",
    "train_loader, test_loader = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bypass the matplotlib error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing some images of the dataset we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) tensor(3) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# Adjust these values to match the normalization values used during the loading of your dataset\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    # Adjusting unnormalization for potentially 3-channel images\n",
    "    img = img * std + mean  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Assuming train_loader is defined and loaded as before\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images[:3]))\n",
    "# Print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of folder to save the results (for plots and compression rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch\"\n",
    "if not os.path.exists(SAVE_LOC):\n",
    "    os.makedirs(SAVE_LOC)\n",
    "\n",
    "SAVE_LOC_OLC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc\"\n",
    "if not os.path.exists(SAVE_LOC_OLC):\n",
    "    os.makedirs(SAVE_LOC_OLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binary(model, evaluation_set):\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for input, label in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            output = torch.sigmoid(model(input))  # Apply sigmoid to model output to get probabilities.\n",
    "            output = torch.where(output > 0.5, 1, 0)  # Threshold probabilities at 0.5 to decide between classes 0 and 1.\n",
    "            no_seen += label.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += (output == label).sum().item()  # Increment correct predictions by the number of matches in the batch.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n",
    "\n",
    "def accuracy_multiclass(model, evaluation_set):\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for input, label in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            output = model(input)  # Get the raw logits from the model.\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit which represents the predicted class.\n",
    "            no_seen += label.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += pred.eq(label.view_as(pred)).sum().item()  # Compare predictions with true labels and sum up correct predictions.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special function for the accuracy of the model on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multiclass_gpu(model, evaluation_set):\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for inputs, labels in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device of the model\n",
    "            output = model(inputs)  # Get the raw logits from the model.\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit which represents the predicted class.\n",
    "            no_seen += labels.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += pred.eq(labels.view_as(pred)).sum().item()  # Compare predictions with true labels and sum up correct predictions.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On GPU (Testing if it works with loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the base model (ResNet50)\n",
    "\n",
    "model_for_checkpoint = ResNet50()\n",
    "\n",
    "\n",
    "# train model_for_checkpoint such that we compute the loss for the validation dataset and the training dataset (just for the sake of it), et take the checkpoint at the minimum validation loss\n",
    "\n",
    "# define the loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the optimizer\n",
    "\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.1)\n",
    "\n",
    "# define the number of epochs\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "# define the validation loss\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# GPU check with print\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU available\")\n",
    "\n",
    "else:\n",
    "    print(\"GPU not available\")\n",
    "\n",
    "    \n",
    "# move the model to the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# move the model to the GPU\n",
    "\n",
    "model_for_checkpoint.to(device)\n",
    "\n",
    "# train the model\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    model_for_checkpoint.train()\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model_for_checkpoint(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    model_for_checkpoint.eval()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model_for_checkpoint(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(test_loader.sampler)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "        # torch.save(model_for_checkpoint.state_dict(), 'model_for_checkpoint.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On CPU (Testing if it works with loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the base model (VGG16)\n",
    "\n",
    "# model_for_checkpoint = VGG16()\n",
    "\n",
    "\n",
    "# # train model_for_checkpoint such that we compute the loss for the validation dataset and the training dataset (just for the sake of it), et take the checkpoint at the minimum validation loss\n",
    "\n",
    "# # define the loss function\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # define the optimizer\n",
    "\n",
    "# optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.1)\n",
    "\n",
    "# # define the number of epochs\n",
    "\n",
    "# n_epochs = 10\n",
    "\n",
    "# # define the validation loss\n",
    "\n",
    "# valid_loss_min = np.Inf\n",
    "\n",
    "# # GPU check with print\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"GPU available\")\n",
    "\n",
    "# else:\n",
    "#     print(\"GPU not available\")\n",
    "\n",
    "    \n",
    "# # move the model to the GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# # move the model to the GPU\n",
    "\n",
    "# model_for_checkpoint.to(device)\n",
    "\n",
    "# # train the model\n",
    "\n",
    "# for epoch in range(1, n_epochs+1):\n",
    "#     train_loss = 0.0\n",
    "#     valid_loss = 0.0\n",
    "\n",
    "#     model_for_checkpoint.train()\n",
    "\n",
    "#     for data, target in train_loader:\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         output = model_for_checkpoint(data)\n",
    "\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "\n",
    "#         train_loss += loss.item()*data.size(0)\n",
    "\n",
    "#     model_for_checkpoint.eval()\n",
    "\n",
    "#     for data, target in test_loader:\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "\n",
    "#         output = model_for_checkpoint(data)\n",
    "\n",
    "#         loss = criterion(output, target)\n",
    "\n",
    "#         valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "#     train_loss = train_loss/len(train_loader.sampler)\n",
    "#     valid_loss = valid_loss/len(test_loader.sampler)\n",
    "\n",
    "#     print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "\n",
    "#     if valid_loss <= valid_loss_min:\n",
    "#         print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "#         # torch.save(model_for_checkpoint.state_dict(), 'model_for_checkpoint.pt')\n",
    "#         valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual training on GPU (Creating branchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch : [0/10], Training Loss: 24.46287727355957\n",
      "Length of train_loader is:  32\n",
      "Epoch : [1/10], Training Loss: 13.958986282348633\n",
      "Length of train_loader is:  32\n",
      "Epoch : [2/10], Training Loss: 20.612934112548828\n",
      "Length of train_loader is:  32\n",
      "Epoch : [3/10], Training Loss: 18.17078399658203\n",
      "Length of train_loader is:  32\n",
      "Epoch : [4/10], Training Loss: 10.120857238769531\n",
      "Length of train_loader is:  32\n",
      "Epoch : [5/10], Training Loss: 14.014628410339355\n",
      "Length of train_loader is:  32\n",
      "Epoch : [6/10], Training Loss: 14.129121780395508\n",
      "Length of train_loader is:  32\n",
      "Epoch : [7/10], Training Loss: 8.15334701538086\n",
      "Length of train_loader is:  32\n",
      "Epoch : [8/10], Training Loss: 5.082653999328613\n",
      "Length of train_loader is:  32\n",
      "Model saved at accuracy:  0.74\n",
      "Epoch : [9/10], Training Loss: 3.467045783996582\n",
      "Length of train_loader is:  32\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# get the base model (ResNet50) and move it to the chosen device\n",
    "model_for_checkpoint = ResNet50().to(device)\n",
    "\n",
    "# creating branchpoints\n",
    "epochs = 10\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.1) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        # data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        # output = model_for_checkpoint(data)\n",
    "\n",
    "        # loss = criterion(output, target)\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_for_checkpoint(inputs)\n",
    "\n",
    "        # Here assuming your loss function and any other operation are compatible with CUDA tensors\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        if iter % 20 == 0:\n",
    "            # print(\"Running validation for {} Epoch, {} Iteration...\".format(epoch, iter))\n",
    "            res = accuracy_multiclass_gpu(model_for_checkpoint, test_loader)  # Ensure this function also handles data on GPU\n",
    "\n",
    "            # print(\"ACCURACY: {}\".format(res))\n",
    "            if res > 0.7:\n",
    "                # Move model to CPU before saving\n",
    "                model_for_checkpoint.to('cpu')\n",
    "                torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/resnet50/branch_{}.pt\".format(res))\n",
    "                # Optionally, move model back to the original device (GPU) if further computation is needed\n",
    "                model_for_checkpoint.to(device)\n",
    "                print(\"Model saved at accuracy: \", res)\n",
    "\n",
    "            if res > 0.9:\n",
    "                isLoop = False\n",
    "                print(\"Model saved at accuracy: \", res)\n",
    "                break\n",
    "        \n",
    "    print(\"Epoch : [{}/{}], Training Loss: {}\".format(epoch, epochs, loss.item()))\n",
    "    if not isLoop:\n",
    "        break\n",
    "    print(\"Length of train_loader is: \", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual training on CPU (Creating branchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the base model (ResNet50)\n",
    "\n",
    "model_for_checkpoint = ResNet50()\n",
    "\n",
    "# creating branchpoints : \n",
    "\n",
    "epochs = 10\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.1) # momentum=0.9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}/{}\".format(epoch, epochs))\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_for_checkpoint(inputs)\n",
    "\n",
    "        # if self.config.loss_function == \"binary_cross_entropy\":\n",
    "        #     outputs = torch.sigmoid(outputs)\n",
    "        \n",
    "        # loss = loss_function(outputs, labels)\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(\"Epoch {} | Iteration {} : Loss {}\".format(epoch, iter, loss.item()))\n",
    "        if iter % 20 == 0:\n",
    "            # print(\"Running validation for {} Epoch, {} Iteration...\".format(epoch, iter))\n",
    "            # Previously: res = accuracy_binary(model_for_checkpoint, test_loader)\n",
    "            res = accuracy_multiclass(model_for_checkpoint, test_loader)\n",
    "\n",
    "            # res = accuracy_binary(model_for_checkpoint, test_loader)\n",
    "            \n",
    "            print(\"ACCURACY: {}\".format(res))\n",
    "            if res > 0.7:\n",
    "                torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/resnet50/branch_{}.pt\".format(res))\n",
    "                print(\"Model saved at accuracy: \", res)\n",
    "            if res > 0.9:\n",
    "                isLoop = False\n",
    "                print(\"Model saved at accuracy: \", res)\n",
    "                break\n",
    "\n",
    "    print(\"Epoch : [{}/{}], Training Loss: {}\".format(epoch, epochs, loss.item()))\n",
    "\n",
    "    if not isLoop:\n",
    "        break\n",
    "    print(\"Length of train_loader is: \", len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploiting branchpoints of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call of the different models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.weight', 'layer1.1.weight', 'layer1.1.bias', 'layer1.1.running_mean', 'layer1.1.running_var', 'layer1.1.num_batches_tracked', 'layer1.3.weight', 'layer1.4.weight', 'layer1.4.bias', 'layer1.4.running_mean', 'layer1.4.running_var', 'layer1.4.num_batches_tracked', 'layer1.6.weight', 'layer1.7.weight', 'layer1.7.bias', 'layer1.7.running_mean', 'layer1.7.running_var', 'layer1.7.num_batches_tracked', 'layer2.0.weight', 'layer2.1.weight', 'layer2.1.bias', 'layer2.1.running_mean', 'layer2.1.running_var', 'layer2.1.num_batches_tracked', 'layer2.3.weight', 'layer2.4.weight', 'layer2.4.bias', 'layer2.4.running_mean', 'layer2.4.running_var', 'layer2.4.num_batches_tracked', 'layer2.6.weight', 'layer2.7.weight', 'layer2.7.bias', 'layer2.7.running_mean', 'layer2.7.running_var', 'layer2.7.num_batches_tracked', 'layer3.0.weight', 'layer3.1.weight', 'layer3.1.bias', 'layer3.1.running_mean', 'layer3.1.running_var', 'layer3.1.num_batches_tracked', 'layer3.3.weight', 'layer3.4.weight', 'layer3.4.bias', 'layer3.4.running_mean', 'layer3.4.running_var', 'layer3.4.num_batches_tracked', 'layer3.6.weight', 'layer3.7.weight', 'layer3.7.bias', 'layer3.7.running_mean', 'layer3.7.running_var', 'layer3.7.num_batches_tracked', 'layer4.0.weight', 'layer4.1.weight', 'layer4.1.bias', 'layer4.1.running_mean', 'layer4.1.running_var', 'layer4.1.num_batches_tracked', 'layer4.3.weight', 'layer4.4.weight', 'layer4.4.bias', 'layer4.4.running_mean', 'layer4.4.running_var', 'layer4.4.num_batches_tracked', 'layer4.6.weight', 'layer4.7.weight', 'layer4.7.bias', 'layer4.7.running_mean', 'layer4.7.running_var', 'layer4.7.num_batches_tracked', 'fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "DECOMPOSED_LAYERS = ['fc.weight']\n",
    "RANK = -1\n",
    "SCALING = -1\n",
    "BRANCH_ACC = \"0.74\"\n",
    "\n",
    "# Set up weights for original AlexNet model\n",
    "original = ResNet50()\n",
    "model_original = ResNet50()\n",
    "\n",
    "# Load from \"branch point\"\n",
    "BRANCH_LOC = HDFP + \"/lobranch-snapshot/branchpoints/resnet50/branch_{}.pt\".format(BRANCH_ACC)\n",
    "original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "model_original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "print(model_original.state_dict().keys())\n",
    "w, b = getBase(model_original)\n",
    "model = ResNet50_LowRank(w, b, rank = RANK)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification of the bias shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for bias in b:\n",
    "    print(bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and updating model state dictionary from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('conv1.weight', tensor([[[[ 7.0657e-02, -9.3932e-04, -8.1914e-02,  ...,  9.0858e-03,\n",
      "           -5.0250e-02,  1.5766e-01],\n",
      "          [-1.9712e-01, -1.4861e-01,  1.8126e-01,  ...,  3.6887e-02,\n",
      "            1.4188e-01,  1.9933e-01],\n",
      "          [ 4.7084e-02, -7.8152e-02,  3.0579e-01,  ...,  2.2811e-01,\n",
      "            1.4665e-01,  1.7445e-04],\n",
      "          ...,\n",
      "          [-1.7783e-01, -4.4653e-02,  2.9276e-01,  ...,  3.6733e-01,\n",
      "            6.3442e-02, -1.1060e-01],\n",
      "          [-1.5022e-01,  1.0597e-02,  1.1430e-01,  ...,  2.8658e-01,\n",
      "            6.2240e-02,  1.4002e-01],\n",
      "          [ 1.7834e-01,  1.7027e-02,  1.1621e-01,  ...,  2.6999e-01,\n",
      "            7.5279e-02,  2.1835e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5639e-01, -6.6211e-02, -1.4586e-01,  ..., -1.6506e-01,\n",
      "            1.3944e-01,  1.9599e-01],\n",
      "          [ 3.4227e-02, -5.3393e-02, -3.2388e-02,  ..., -1.2906e-01,\n",
      "            3.2676e-02, -6.2539e-03],\n",
      "          [ 1.7218e-02, -2.1605e-02, -1.8425e-01,  ..., -1.3701e-02,\n",
      "           -1.9043e-01, -1.0096e-01],\n",
      "          ...,\n",
      "          [-3.4494e-02,  1.1025e-01, -4.3901e-02,  ..., -1.2112e-02,\n",
      "           -1.9372e-01, -2.5754e-01],\n",
      "          [ 1.6287e-01,  1.2834e-01,  7.9966e-02,  ..., -5.3115e-02,\n",
      "           -7.5655e-02, -1.7863e-01],\n",
      "          [ 2.3388e-01,  3.6503e-01,  1.8625e-01,  ..., -1.4849e-02,\n",
      "            1.2478e-01,  2.2715e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3460e-02, -7.6496e-03,  7.0992e-02,  ..., -1.2646e-01,\n",
      "            2.0837e-02,  4.1390e-02],\n",
      "          [-1.7634e-01, -1.5307e-01, -1.5883e-01,  ...,  3.1443e-02,\n",
      "           -3.1571e-02,  8.8432e-04],\n",
      "          [-9.8883e-02, -1.8929e-02, -3.8564e-02,  ..., -1.7884e-02,\n",
      "            7.6606e-02, -1.4961e-01],\n",
      "          ...,\n",
      "          [-3.3912e-02, -6.8996e-02, -1.0336e-01,  ...,  2.1536e-02,\n",
      "           -8.0107e-02, -1.1870e-01],\n",
      "          [ 5.1878e-02, -4.3267e-02,  8.1588e-02,  ..., -6.3073e-02,\n",
      "            5.2204e-02, -1.5026e-01],\n",
      "          [ 1.4846e-02, -1.1815e-02,  1.7934e-01,  ..., -5.5204e-02,\n",
      "           -9.6528e-02,  2.8930e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.6099e-02, -1.8225e-01,  1.7070e-02,  ...,  1.4393e-02,\n",
      "           -6.6126e-02, -5.2265e-02],\n",
      "          [-1.3674e-02, -1.4694e-01, -8.4851e-02,  ...,  5.5378e-02,\n",
      "           -2.3198e-02, -7.5485e-02],\n",
      "          [-1.9717e-01, -1.5629e-01,  6.2468e-03,  ..., -1.1675e-02,\n",
      "           -9.7464e-02, -9.3824e-02],\n",
      "          ...,\n",
      "          [ 4.3978e-02, -1.9573e-01,  5.2412e-02,  ..., -7.6627e-02,\n",
      "            4.2849e-02, -1.0092e-01],\n",
      "          [-1.2249e-01, -1.4067e-01, -7.8899e-02,  ...,  1.6123e-01,\n",
      "           -6.6737e-02,  1.4643e-02],\n",
      "          [-9.1982e-02,  4.2845e-02,  1.1378e-03,  ...,  6.7411e-02,\n",
      "            1.0237e-01,  1.2970e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5779e-01, -3.3763e-02,  1.1787e-01,  ..., -3.5564e-02,\n",
      "            5.9120e-02,  8.5526e-02],\n",
      "          [-1.6056e-01,  7.2687e-02,  1.5948e-01,  ...,  1.8860e-02,\n",
      "            2.1623e-01,  1.6678e-01],\n",
      "          [-1.7804e-01, -2.9164e-02,  8.2720e-03,  ...,  2.9408e-01,\n",
      "            3.0523e-01,  5.7809e-02],\n",
      "          ...,\n",
      "          [-5.4274e-02,  2.4188e-01,  2.2174e-01,  ...,  1.1314e-01,\n",
      "            9.8752e-02, -1.1512e-01],\n",
      "          [-1.9550e-01,  1.6164e-01,  1.6706e-01,  ...,  1.3372e-01,\n",
      "            7.0887e-02,  6.7844e-03],\n",
      "          [-7.2008e-02,  1.3065e-01,  9.6773e-02,  ...,  1.0717e-01,\n",
      "            2.2038e-02,  7.3464e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.9904e-03, -7.0834e-02, -1.1584e-01,  ..., -1.7646e-01,\n",
      "           -1.1662e-01, -8.3018e-02],\n",
      "          [-2.5517e-01, -2.4235e-01, -1.5453e-01,  ..., -2.5381e-01,\n",
      "           -3.3314e-02,  3.1756e-03],\n",
      "          [-2.3855e-01, -1.5751e-01, -1.6242e-01,  ..., -5.9439e-02,\n",
      "            8.2953e-02,  9.2215e-02],\n",
      "          ...,\n",
      "          [ 5.2029e-02,  5.4754e-02, -4.9019e-02,  ...,  1.3215e-01,\n",
      "           -1.1550e-01, -3.9856e-02],\n",
      "          [-1.9971e-01,  3.5190e-02, -1.0590e-02,  ..., -7.4479e-02,\n",
      "            1.6119e-01,  2.1304e-01],\n",
      "          [-1.0221e-01, -1.3052e-01, -1.6267e-01,  ...,  1.6796e-01,\n",
      "            1.5465e-01,  1.9068e-01]]]])), ('bn1.weight', tensor([0.9855, 0.9554, 0.9879, 0.9925, 0.8916, 1.0863, 1.3131, 0.9971, 0.9482,\n",
      "        1.0017, 1.0379, 1.0570, 0.8943, 0.9892, 0.8779, 0.8810, 0.9715, 0.8747,\n",
      "        1.0076, 0.8456, 1.1952, 1.2985, 0.9474, 0.8628, 1.3331, 1.0822, 1.0120,\n",
      "        1.1513, 0.9012, 0.9845, 0.9578, 1.0006, 1.0198, 0.9771, 0.9723, 1.0470,\n",
      "        0.9815, 0.9609, 1.1782, 1.0062, 0.9823, 0.9581, 0.9547, 0.9730, 0.9638,\n",
      "        1.0715, 1.0472, 1.0165, 0.9362, 0.9964, 1.0349, 0.8449, 0.9096, 0.9542,\n",
      "        1.0859, 0.9681, 1.1975, 0.8870, 1.0237, 1.0287, 0.9981, 0.9750, 0.9260,\n",
      "        0.9109])), ('bn1.bias', tensor([ 0.0519,  0.0068,  0.0031, -0.0233,  0.0394,  0.0118,  0.0583,  0.0225,\n",
      "        -0.0935,  0.0239,  0.0395,  0.0575, -0.0183, -0.0368,  0.0037,  0.0029,\n",
      "        -0.0347,  0.0104,  0.0041, -0.0616, -0.0087,  0.1447,  0.0149, -0.0039,\n",
      "         0.1291, -0.0136,  0.0471,  0.0479,  0.0470,  0.0493,  0.0704,  0.0135,\n",
      "         0.0301, -0.0062, -0.0133, -0.0240,  0.0272,  0.0329,  0.0265, -0.0142,\n",
      "         0.0111, -0.0083,  0.0273,  0.0203, -0.0063,  0.0540,  0.0547,  0.0768,\n",
      "         0.0234, -0.0069,  0.1225,  0.0026,  0.0428, -0.0005,  0.0693,  0.0708,\n",
      "         0.1319,  0.0247,  0.0424,  0.0552,  0.0369, -0.0447,  0.0033,  0.0291])), ('bn1.running_mean', tensor([ 0.5410, -0.0471, -0.1767, -0.1715,  0.3583,  0.0559,  0.3290,  0.3515,\n",
      "        -0.5084,  0.0763,  0.3561, -0.3069,  0.6516, -0.1027,  0.5449,  0.2637,\n",
      "        -0.2047,  0.4810,  0.0480,  0.1284, -0.3078,  0.1018,  0.6128,  0.5573,\n",
      "         0.9046,  0.0190,  0.2234,  0.6459,  0.5597,  0.3201,  0.6824,  0.7076,\n",
      "         0.2509, -0.2449, -0.2126, -0.1961,  0.4970,  0.4075,  0.2817, -0.0826,\n",
      "        -0.1641, -0.1839,  0.2780, -0.0331,  0.1291,  0.5894,  0.5653,  0.4023,\n",
      "         0.4497, -0.0931, -0.2591,  0.0948,  0.0341, -0.1971,  0.4229,  0.1326,\n",
      "         0.5449,  0.1616, -0.0282,  0.2435,  0.4674, -0.2660,  0.4545, -0.3006])), ('bn1.running_var', tensor([0.8518, 0.1441, 0.0825, 0.0754, 0.4484, 0.3428, 0.6235, 0.4412, 0.6381,\n",
      "        0.2758, 0.5809, 0.4745, 1.0509, 0.0743, 0.7297, 0.2587, 0.1550, 0.5963,\n",
      "        0.1810, 0.1371, 0.5450, 0.1561, 0.9069, 0.8035, 2.0932, 0.4703, 0.4205,\n",
      "        1.3402, 0.7885, 0.4326, 1.0726, 1.1558, 0.3821, 0.1226, 0.1241, 0.3091,\n",
      "        0.7476, 0.5105, 0.5205, 0.0415, 0.0987, 0.1380, 0.4303, 0.3198, 0.2743,\n",
      "        1.0294, 0.6751, 0.4713, 0.5959, 0.0694, 0.6808, 0.3458, 0.2810, 0.2549,\n",
      "        0.6343, 0.3338, 1.0055, 0.2096, 0.3599, 0.3622, 0.5971, 0.2188, 0.7481,\n",
      "        0.4483])), ('bn1.num_batches_tracked', tensor(309)), ('layer1.0.weight', tensor([[[[-0.0511]],\n",
      "\n",
      "         [[ 0.1430]],\n",
      "\n",
      "         [[-0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0452]],\n",
      "\n",
      "         [[-0.0277]],\n",
      "\n",
      "         [[ 0.0657]]],\n",
      "\n",
      "\n",
      "        [[[-0.1111]],\n",
      "\n",
      "         [[ 0.0792]],\n",
      "\n",
      "         [[-0.1174]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1238]],\n",
      "\n",
      "         [[ 0.0336]],\n",
      "\n",
      "         [[ 0.0627]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1097]],\n",
      "\n",
      "         [[ 0.1334]],\n",
      "\n",
      "         [[-0.0633]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1456]],\n",
      "\n",
      "         [[ 0.1329]],\n",
      "\n",
      "         [[-0.1549]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0726]],\n",
      "\n",
      "         [[ 0.0250]],\n",
      "\n",
      "         [[ 0.1101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1016]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[ 0.1659]]],\n",
      "\n",
      "\n",
      "        [[[-0.0619]],\n",
      "\n",
      "         [[ 0.0936]],\n",
      "\n",
      "         [[ 0.0758]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0216]],\n",
      "\n",
      "         [[ 0.0075]],\n",
      "\n",
      "         [[ 0.0124]]],\n",
      "\n",
      "\n",
      "        [[[-0.0213]],\n",
      "\n",
      "         [[ 0.1357]],\n",
      "\n",
      "         [[-0.0927]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0792]],\n",
      "\n",
      "         [[-0.0665]],\n",
      "\n",
      "         [[-0.0445]]]])), ('layer1.1.weight', tensor([1.0613, 1.0490, 0.7434, 0.9210, 0.9992, 0.9928, 1.4389, 1.0004, 1.0224,\n",
      "        0.8911, 1.0328, 0.9272, 0.7899, 0.9526, 1.0789, 1.0064, 1.2432, 1.0525,\n",
      "        1.1195, 0.7230, 1.0225, 0.9120, 0.9739, 1.0203, 1.1049, 1.0694, 0.9379,\n",
      "        1.0515, 0.8359, 1.0025, 1.1673, 0.8755, 1.0010, 1.0303, 0.9833, 0.9830,\n",
      "        0.8690, 0.9779, 0.8386, 1.0900, 1.0213, 1.0177, 1.0461, 1.0144, 0.9851,\n",
      "        0.9409, 1.0673, 1.0230, 0.9909, 0.9997, 1.0080, 0.9108, 1.0251, 1.2052,\n",
      "        1.0706, 0.8622, 0.9868, 1.0457, 0.9082, 1.0380, 1.0407, 0.8534, 1.0974,\n",
      "        1.0308])), ('layer1.1.bias', tensor([ 0.0452,  0.0216, -0.0065,  0.0956,  0.3011,  0.0358,  0.1845, -0.0260,\n",
      "         0.0034,  0.1211,  0.0159,  0.0380,  0.0124, -0.0163,  0.0212,  0.2525,\n",
      "         0.0695,  0.0192, -0.0279,  0.0477,  0.1092,  0.1843,  0.0577,  0.0093,\n",
      "         0.0366,  0.0815,  0.1022, -0.1008,  0.0086,  0.0013,  0.1500,  0.0145,\n",
      "        -0.0146,  0.0314, -0.0383, -0.1536,  0.0864,  0.0058, -0.0346,  0.2385,\n",
      "         0.0157, -0.0317,  0.0965, -0.0265,  0.0386,  0.0261,  0.0694,  0.0870,\n",
      "        -0.1582, -0.0131,  0.0122, -0.0966, -0.0480,  0.0528,  0.0473, -0.1426,\n",
      "        -0.0245,  0.0173,  0.0398,  0.0537,  0.0365,  0.1253,  0.0799, -0.0237])), ('layer1.1.running_mean', tensor([-1.2563, -2.3978,  2.1154,  3.7008,  5.0143, -2.0797,  1.0465, -1.6907,\n",
      "        -1.7588,  3.3704, -1.4809,  2.4023,  1.8106, -2.1742,  1.3590,  4.2878,\n",
      "        -0.3646,  1.9986, -2.5494,  3.4706,  2.3330,  5.2536,  2.3095, -1.6813,\n",
      "        -0.8619, -1.7263,  4.9087, -2.4813,  1.2705, -4.3824,  2.1610,  3.3840,\n",
      "        -1.8700, -1.9016, -1.9468, -4.0660,  3.0585, -2.7372,  1.9633,  5.6039,\n",
      "        -2.3416, -2.3243,  3.5689, -1.4691, -1.8293,  2.2986, -1.4356, -2.5261,\n",
      "        -6.3731,  3.1567, -1.6794, -3.4627, -0.9062,  1.7301, -2.2165, -7.3943,\n",
      "        -1.5644, -2.0554,  3.1115, -1.7338, -2.3764,  2.9232, -1.3163, -1.9114])), ('layer1.1.running_var', tensor([ 2.1310,  4.8027,  6.9165, 16.9298, 38.3100,  7.1941, 11.6610,  4.5742,\n",
      "         4.1287, 19.0019,  2.9450,  9.5146,  5.9957,  5.6984,  4.0490, 33.1989,\n",
      "         2.8056,  4.7992,  8.5380, 19.6418, 11.7420, 33.5265,  5.3595,  3.0737,\n",
      "         4.6808,  7.6521, 28.9105,  6.3461,  4.5018, 21.3794,  5.6894, 14.1845,\n",
      "         2.8583,  3.1723,  3.3338, 18.6943, 16.7093,  6.4328,  6.5313, 45.3006,\n",
      "         4.5988,  3.8173, 14.4420,  2.1056,  6.1127, 10.8726,  2.8526,  7.8009,\n",
      "        46.8530, 10.2886,  3.1239, 11.6526,  0.8341,  8.0850,  4.9672, 67.3134,\n",
      "         3.8764,  3.2552, 10.3850,  5.0243,  4.9896, 12.6673,  1.8005,  5.5064])), ('layer1.1.num_batches_tracked', tensor(309)), ('layer1.3.weight', tensor([[[[ 2.4967e-02,  3.7084e-02,  2.7881e-02],\n",
      "          [ 2.3584e-02,  4.3217e-02, -2.4693e-02],\n",
      "          [ 2.3752e-02, -2.1586e-02, -4.0997e-02]],\n",
      "\n",
      "         [[ 2.2008e-02,  4.6812e-03, -4.6706e-02],\n",
      "          [ 5.3392e-02,  2.5293e-02, -4.2807e-02],\n",
      "          [ 4.3407e-02, -1.4602e-03, -1.5613e-02]],\n",
      "\n",
      "         [[-1.5325e-02, -3.3892e-02, -5.2228e-03],\n",
      "          [-5.0857e-02, -4.4772e-03,  1.5866e-02],\n",
      "          [-5.8586e-02, -4.4034e-02, -2.3156e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1303e-02, -2.9028e-02, -2.0026e-03],\n",
      "          [-1.4497e-02,  6.0869e-03,  3.7556e-02],\n",
      "          [ 2.5244e-03,  2.3727e-02,  8.4761e-03]],\n",
      "\n",
      "         [[-9.3404e-03, -5.1767e-03, -4.1867e-02],\n",
      "          [ 4.2465e-02,  5.4362e-03,  3.3463e-02],\n",
      "          [-1.2388e-02, -4.8247e-02,  2.6566e-02]],\n",
      "\n",
      "         [[-8.4331e-03,  1.3181e-02, -5.4218e-02],\n",
      "          [-4.3663e-02,  1.9527e-02, -3.8373e-03],\n",
      "          [ 2.2698e-02, -1.2090e-02, -4.1803e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2519e-02, -2.8189e-02,  1.0149e-02],\n",
      "          [-4.0506e-02,  5.9960e-03,  3.6334e-02],\n",
      "          [-1.0705e-01, -4.9789e-02, -3.2245e-02]],\n",
      "\n",
      "         [[ 1.6291e-03, -2.4713e-02,  2.2957e-02],\n",
      "          [-5.4428e-02,  4.1678e-04, -2.3703e-02],\n",
      "          [-3.9343e-02,  2.6091e-02, -1.3814e-02]],\n",
      "\n",
      "         [[ 5.1785e-02,  3.2875e-03,  7.6843e-02],\n",
      "          [ 7.5911e-02,  1.2271e-01, -3.1262e-02],\n",
      "          [ 2.5577e-02, -7.3149e-04, -4.1629e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4647e-02,  4.5148e-03,  6.9801e-02],\n",
      "          [ 6.9921e-02,  7.1061e-02,  2.3577e-02],\n",
      "          [ 7.2153e-02,  3.2444e-02, -3.7325e-02]],\n",
      "\n",
      "         [[-5.3986e-02,  4.6460e-02, -7.2887e-03],\n",
      "          [-4.6713e-02, -1.1063e-02,  3.6915e-03],\n",
      "          [-4.2851e-02, -2.4682e-02,  1.5737e-02]],\n",
      "\n",
      "         [[-1.0310e-03, -1.0302e-03,  9.6019e-03],\n",
      "          [-6.7412e-02, -2.1288e-03,  6.5942e-03],\n",
      "          [-5.4375e-02,  6.1762e-02, -3.2089e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5466e-02,  3.1726e-02,  1.8191e-02],\n",
      "          [-6.1240e-02,  7.7952e-03,  2.5785e-02],\n",
      "          [-3.6147e-02, -4.1700e-02,  1.8398e-02]],\n",
      "\n",
      "         [[-3.0830e-02, -2.3931e-02,  6.6250e-03],\n",
      "          [-2.9208e-02, -1.9693e-03,  6.1734e-02],\n",
      "          [-6.0109e-02,  1.1398e-02,  4.8769e-03]],\n",
      "\n",
      "         [[-5.7529e-02, -5.4104e-02, -4.6582e-02],\n",
      "          [-8.1526e-02, -1.5935e-02, -6.5883e-02],\n",
      "          [-6.6380e-02,  1.1075e-01, -7.2078e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.4790e-03, -4.7029e-02, -6.4746e-02],\n",
      "          [-1.1244e-02, -4.0540e-02, -5.1987e-02],\n",
      "          [-1.0082e-02,  1.3399e-01, -4.8443e-02]],\n",
      "\n",
      "         [[-1.5455e-02,  9.0361e-03, -1.3241e-02],\n",
      "          [-6.3055e-02, -2.3436e-02,  3.4126e-02],\n",
      "          [-1.2320e-01,  4.5886e-02,  7.7929e-02]],\n",
      "\n",
      "         [[-7.3206e-03, -1.9743e-02,  2.7302e-02],\n",
      "          [-3.8410e-02,  2.5177e-02,  1.2921e-02],\n",
      "          [-9.7872e-03, -3.5866e-03, -1.2328e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.1465e-02, -2.5166e-02,  1.4895e-03],\n",
      "          [ 2.1160e-02,  1.2120e-01,  1.0208e-01],\n",
      "          [ 2.7164e-03,  6.7156e-02,  1.5665e-02]],\n",
      "\n",
      "         [[ 3.9721e-02,  3.6874e-02,  2.5381e-02],\n",
      "          [ 7.4187e-02,  8.7279e-02,  1.5151e-02],\n",
      "          [ 4.6394e-02,  2.3807e-02,  1.7883e-03]],\n",
      "\n",
      "         [[-5.6660e-02, -3.7152e-02,  1.6705e-02],\n",
      "          [-3.3867e-02, -2.7754e-02, -6.2936e-02],\n",
      "          [-5.9230e-03,  1.3804e-02, -2.7352e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.0810e-02, -2.5290e-03, -2.8922e-02],\n",
      "          [-4.9192e-02, -2.3202e-02, -6.8460e-02],\n",
      "          [-7.0288e-02, -4.4697e-02, -3.5267e-02]],\n",
      "\n",
      "         [[ 1.1912e-02,  6.0600e-02,  7.7264e-03],\n",
      "          [ 1.0618e-01,  4.0539e-02,  4.1874e-02],\n",
      "          [ 7.3176e-02,  9.6097e-02, -1.0111e-01]],\n",
      "\n",
      "         [[-1.4045e-02,  3.1537e-03, -4.3987e-02],\n",
      "          [ 4.2523e-02,  7.1645e-02,  6.7099e-02],\n",
      "          [-2.1246e-02,  3.1681e-02, -3.2201e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.7868e-02, -1.4569e-02, -3.2261e-02],\n",
      "          [-6.8890e-02, -2.5577e-02,  3.3224e-02],\n",
      "          [-3.8901e-03,  1.2177e-02, -6.9582e-03]],\n",
      "\n",
      "         [[-8.2051e-02,  1.0338e-02,  4.8862e-02],\n",
      "          [-6.6443e-02,  1.8416e-02,  2.8591e-02],\n",
      "          [-2.3291e-02,  2.7394e-02,  8.1868e-02]],\n",
      "\n",
      "         [[-1.1072e-03,  8.3449e-03, -2.3116e-02],\n",
      "          [ 1.1130e-02, -7.2891e-02, -6.2037e-02],\n",
      "          [-2.2928e-02, -1.2627e-02, -8.0961e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9722e-02, -9.4190e-03, -4.7398e-02],\n",
      "          [-1.3465e-02,  3.1280e-03,  2.1735e-03],\n",
      "          [-1.1985e-02,  3.8567e-02, -6.7591e-02]],\n",
      "\n",
      "         [[-5.4541e-02,  2.6906e-02,  2.7797e-02],\n",
      "          [-9.4702e-02,  2.6308e-02,  5.6231e-02],\n",
      "          [-8.7807e-02,  1.7786e-02,  1.3883e-01]],\n",
      "\n",
      "         [[-9.4551e-02,  3.9452e-02, -1.9425e-06],\n",
      "          [-8.0116e-02,  3.9676e-04,  7.0600e-02],\n",
      "          [ 9.7730e-03,  2.0797e-02,  4.7364e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5604e-02,  3.5841e-02,  1.2350e-02],\n",
      "          [-1.9904e-02,  4.2537e-03, -9.0224e-03],\n",
      "          [ 2.3452e-02, -5.6914e-02, -1.9197e-02]],\n",
      "\n",
      "         [[-1.2546e-02,  7.5112e-02, -3.8007e-03],\n",
      "          [-2.2074e-02,  4.9298e-03,  2.2684e-02],\n",
      "          [ 9.3512e-03, -7.5262e-03, -3.9267e-02]],\n",
      "\n",
      "         [[ 2.0393e-03, -3.4981e-02, -1.7221e-02],\n",
      "          [ 3.1918e-03, -2.3234e-02,  4.2047e-02],\n",
      "          [-3.0864e-02,  5.2815e-02,  6.2811e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4101e-02, -5.8201e-02, -6.0138e-02],\n",
      "          [-7.0546e-03, -4.0131e-02,  6.1729e-02],\n",
      "          [-1.6785e-02,  1.1723e-02,  5.4104e-02]],\n",
      "\n",
      "         [[-6.4721e-04,  5.7128e-02,  1.6163e-02],\n",
      "          [ 1.8388e-02, -5.8481e-03, -3.3316e-02],\n",
      "          [-2.0609e-02, -2.9371e-02,  5.0015e-02]],\n",
      "\n",
      "         [[-3.1435e-02,  6.6384e-03, -1.6508e-02],\n",
      "          [-6.6813e-02,  3.8233e-02, -3.4953e-02],\n",
      "          [ 1.4889e-02,  3.0782e-02,  1.7032e-02]]]])), ('layer1.4.weight', tensor([0.9463, 0.8775, 1.0954, 0.9083, 0.8308, 0.9928, 0.9126, 0.9340, 1.0111,\n",
      "        1.0668, 0.9768, 0.9028, 1.1421, 1.0204, 0.7957, 0.9640, 0.9680, 0.9718,\n",
      "        0.9244, 1.1141, 0.9648, 1.1142, 1.1922, 1.0677, 0.9900, 1.0052, 1.0691,\n",
      "        0.9260, 0.9145, 0.9814, 1.0773, 1.0139, 0.9334, 0.9574, 1.0317, 0.9435,\n",
      "        1.0394, 0.9904, 1.0048, 0.9500, 1.0098, 1.1350, 0.8434, 1.0327, 1.0169,\n",
      "        1.0036, 1.0651, 0.9631, 1.0932, 1.0762, 0.9690, 0.9098, 0.9603, 0.9825,\n",
      "        0.9727, 1.2729, 0.9380, 1.0615, 1.0216, 0.9011, 1.0439, 1.0326, 1.0790,\n",
      "        1.0229])), ('layer1.4.bias', tensor([ 0.0265, -0.0249,  0.0126, -0.0647,  0.3519,  0.0413,  0.1423,  0.1211,\n",
      "         0.0069, -0.1298, -0.1570, -0.0120,  0.0120,  0.0530, -0.1681,  0.0011,\n",
      "         0.0224,  0.0237,  0.0624,  0.0192, -0.0018,  0.2801, -0.1113,  0.0407,\n",
      "        -0.0845, -0.0411, -0.0183,  0.0100, -0.0575, -0.0308, -0.0603, -0.0061,\n",
      "        -0.0326, -0.0922, -0.0099,  0.0042,  0.0396,  0.0740,  0.0020, -0.0323,\n",
      "         0.1858,  0.0936,  0.1655, -0.0117, -0.0077,  0.0006,  0.1859, -0.1420,\n",
      "        -0.0008,  0.3060,  0.0748, -0.3238,  0.0295, -0.0596, -0.0838,  0.2239,\n",
      "         0.2106,  0.0711,  0.0142,  0.0315, -0.0795, -0.0929,  0.0544,  0.0574])), ('layer1.4.running_mean', tensor([-1.5318,  0.6544, -2.6398, -1.1028,  1.6677, -1.1145,  0.1840,  3.5547,\n",
      "        -1.5478, -1.9652, -1.6312,  1.2521,  1.0657,  1.9806,  0.5490,  1.2071,\n",
      "         1.4466,  2.6277,  2.8855,  0.9981, -0.5890,  1.8050,  1.0812,  0.8089,\n",
      "         3.5306,  1.8593,  3.9735,  4.1768,  2.4709,  4.6592, -2.4254,  3.2677,\n",
      "        -2.2495, -6.0059,  0.0662,  2.4672, -2.7672, -0.9033, -0.7017,  2.9785,\n",
      "         1.1602, -0.5452,  3.2621,  3.5166, -1.6360,  2.1991,  2.3174, -1.2536,\n",
      "        -0.0783,  0.0493,  1.4542,  0.7144,  0.0078, -0.5517, -0.6596, -2.5087,\n",
      "         0.1678, -0.6400,  3.2997,  4.1789, -1.6136, -0.9314, -1.4076, -1.9507])), ('layer1.4.running_var', tensor([ 5.7003,  9.4870,  9.5898,  4.8215, 26.0407,  7.6457,  3.7479, 18.1836,\n",
      "         5.6768, 24.7921,  6.5578,  6.1117, 20.9327, 21.3460, 11.7428,  6.8832,\n",
      "        11.5021, 17.9170, 22.7590, 32.2778, 11.2888, 23.6407, 18.3091, 24.0456,\n",
      "        26.4678,  7.1968, 35.2520, 20.2583, 14.0063, 32.4436,  7.2141, 21.0472,\n",
      "         2.4678, 38.8949,  7.4697, 11.4534,  4.9366,  7.2627,  5.6262, 16.7994,\n",
      "        24.1056, 11.9223,  7.2757, 15.6520,  7.0189, 15.5809,  5.3239, 13.4620,\n",
      "        12.4549, 23.9499,  5.7018, 11.1254,  5.4999,  3.9042,  1.0216, 23.1279,\n",
      "         4.8123, 10.8116, 24.0605, 15.0578,  5.9487,  8.6737,  7.2688,  7.4979])), ('layer1.4.num_batches_tracked', tensor(309)), ('layer1.6.weight', tensor([[[[ 0.0282]],\n",
      "\n",
      "         [[-0.0402]],\n",
      "\n",
      "         [[-0.1613]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0571]],\n",
      "\n",
      "         [[-0.0124]],\n",
      "\n",
      "         [[ 0.0430]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0478]],\n",
      "\n",
      "         [[-0.0884]],\n",
      "\n",
      "         [[ 0.1542]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0101]],\n",
      "\n",
      "         [[-0.0228]],\n",
      "\n",
      "         [[-0.0740]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0905]],\n",
      "\n",
      "         [[-0.0019]],\n",
      "\n",
      "         [[-0.0861]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1135]],\n",
      "\n",
      "         [[-0.0283]],\n",
      "\n",
      "         [[-0.0051]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0490]],\n",
      "\n",
      "         [[-0.0256]],\n",
      "\n",
      "         [[ 0.0841]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0842]],\n",
      "\n",
      "         [[-0.0528]],\n",
      "\n",
      "         [[ 0.0406]]],\n",
      "\n",
      "\n",
      "        [[[-0.0700]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         [[ 0.1389]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0211]],\n",
      "\n",
      "         [[ 0.0381]],\n",
      "\n",
      "         [[ 0.1296]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0448]],\n",
      "\n",
      "         [[ 0.1338]],\n",
      "\n",
      "         [[-0.0389]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0090]],\n",
      "\n",
      "         [[-0.0857]],\n",
      "\n",
      "         [[ 0.0209]]]])), ('layer1.7.weight', tensor([0.9902, 1.0028, 0.9940, 0.9822, 1.0051, 1.0304, 1.0089, 1.0164, 0.9806,\n",
      "        0.9876, 0.9818, 1.0022, 1.0015, 1.0102, 1.0539, 1.0139, 0.9707, 1.0093,\n",
      "        0.9999, 0.9975, 1.0034, 0.9932, 1.0046, 1.0179, 1.0032, 1.0106, 0.9949,\n",
      "        1.0238, 1.0319, 1.0180, 1.0037, 0.9936, 1.0111, 1.0153, 0.9902, 1.0013,\n",
      "        1.0213, 0.9819, 0.9849, 0.9919, 1.0078, 0.9945, 0.9953, 0.9939, 1.0132,\n",
      "        0.9813, 0.9938, 0.9677, 0.9946, 0.9903, 0.9921, 1.0478, 1.0035, 1.0148,\n",
      "        1.0091, 0.9920, 0.9772, 1.0117, 1.0033, 1.0106, 1.0070, 1.0151, 0.9895,\n",
      "        0.9960, 1.0093, 0.9972, 1.0098, 0.9866, 1.0095, 1.0192, 1.0262, 0.9915,\n",
      "        1.0076, 0.9919, 1.0017, 0.9892, 0.9777, 0.9944, 1.0283, 1.0096, 0.9720,\n",
      "        0.9875, 0.9793, 0.9643, 1.0418, 1.0356, 0.9852, 0.9958, 0.9876, 0.9773,\n",
      "        0.9689, 0.9997, 1.0175, 0.9838, 1.0438, 1.0073, 0.9888, 1.0064, 0.9840,\n",
      "        1.0056, 0.9926, 0.9989, 1.0053, 1.0097, 0.9981, 0.9874, 0.9717, 1.0079,\n",
      "        1.0113, 0.9825, 0.9962, 0.9831, 1.0029, 0.9878, 0.9873, 0.9836, 1.0166,\n",
      "        0.9864, 1.0009, 1.0129, 1.0002, 0.9645, 1.0002, 1.0207, 0.9836, 1.0001,\n",
      "        0.9921, 0.9763, 1.0142, 1.0027, 1.0320, 0.9816, 1.0052, 0.9864, 0.9898,\n",
      "        1.0056, 0.9841, 0.9777, 0.9937, 1.0186, 0.9972, 1.0062, 0.9991, 1.0061,\n",
      "        1.0074, 1.0382, 1.0063, 1.0093, 0.9880, 0.9769, 0.9952, 1.0056, 1.0137,\n",
      "        1.0027, 1.0044, 1.0032, 1.0130, 0.9615, 1.0147, 0.9962, 0.9899, 0.9782,\n",
      "        0.9677, 1.0323, 0.9875, 0.9928, 1.0160, 0.9934, 0.9965, 1.0147, 0.9877,\n",
      "        1.0171, 0.9900, 0.9983, 1.0087, 1.0177, 0.9865, 1.0445, 0.9914, 0.9872,\n",
      "        1.0081, 0.9889, 1.0105, 1.0079, 0.9979, 0.9951, 1.0126, 0.9880, 0.9865,\n",
      "        1.0047, 1.0025, 1.0084, 0.9597, 0.9837, 1.0277, 0.9820, 0.9653, 1.0150,\n",
      "        1.0032, 1.0013, 1.0215, 0.9931, 1.0008, 1.0335, 1.0244, 0.9827, 0.9839,\n",
      "        1.0093, 0.9726, 1.0102, 0.9743, 0.9905, 0.9892, 1.0022, 0.9853, 0.9809,\n",
      "        0.9911, 1.0037, 1.0274, 1.0195, 1.0077, 0.9859, 1.0374, 0.9648, 0.9919,\n",
      "        1.0145, 0.9907, 0.9857, 1.0279, 1.0045, 0.9973, 0.9751, 0.9902, 1.0103,\n",
      "        0.9955, 1.0174, 1.0177, 1.0331, 0.9467, 1.0272, 1.0177, 1.0010, 0.9921,\n",
      "        0.9935, 1.0233, 0.9872, 1.0266, 1.0071, 0.9746, 1.0299, 0.9933, 1.0249,\n",
      "        0.9875, 0.9543, 1.0239, 0.9975])), ('layer1.7.bias', tensor([-1.4937e-07, -2.7699e-06,  4.6897e-06,  5.4465e-06,  9.6323e-06,\n",
      "        -2.7302e-06,  7.5651e-06, -3.5723e-07,  1.5300e-06, -9.1878e-06,\n",
      "         4.2411e-06, -5.1719e-06,  1.9099e-06, -2.6024e-06, -1.6974e-06,\n",
      "        -1.3744e-06, -5.2926e-06, -7.3796e-06, -1.5617e-07,  2.8413e-06,\n",
      "        -3.6443e-06, -3.5348e-06, -4.9006e-06, -7.6322e-06,  1.6756e-06,\n",
      "        -3.7419e-06,  3.5023e-06, -2.9078e-06,  1.5204e-06,  1.0989e-06,\n",
      "        -4.7800e-07,  2.8965e-06,  5.4404e-07, -3.4086e-06, -4.9980e-06,\n",
      "         2.4683e-06,  2.8688e-07, -3.1671e-06,  2.8743e-06,  9.2349e-06,\n",
      "        -1.5974e-06,  6.4390e-06, -2.6927e-06,  1.6496e-06, -3.0524e-06,\n",
      "        -5.2628e-06,  2.2953e-06,  3.2785e-06, -8.4880e-07, -5.2227e-06,\n",
      "        -1.2238e-06, -9.3969e-06,  5.5014e-07,  1.0005e-06,  3.1996e-06,\n",
      "        -5.2515e-06, -3.3956e-06, -3.9383e-06,  1.0312e-06, -1.3028e-06,\n",
      "        -1.7562e-06, -1.3625e-07,  2.1666e-06,  1.7096e-07, -4.3951e-06,\n",
      "         2.5266e-06, -3.2029e-06,  1.4941e-08, -6.9200e-07,  6.0419e-06,\n",
      "         4.5955e-06, -1.2870e-06, -7.4158e-07,  2.4092e-06, -2.4095e-06,\n",
      "        -9.4527e-07, -2.4300e-07,  2.4858e-07, -1.0783e-06, -5.0572e-06,\n",
      "         7.3102e-06,  7.2193e-06, -4.6003e-06,  4.5550e-06, -3.1387e-06,\n",
      "        -3.4396e-06, -9.3834e-07,  2.4199e-06,  7.9353e-06, -2.0328e-06,\n",
      "        -1.8799e-06,  6.5622e-06,  3.5298e-06, -2.1814e-06,  3.8428e-06,\n",
      "        -3.2754e-06, -6.6541e-06,  2.0982e-06,  1.6761e-06, -5.6279e-06,\n",
      "        -4.2230e-06, -2.8715e-06, -1.5446e-05, -1.3688e-06, -2.0894e-06,\n",
      "        -5.7200e-06, -2.3001e-06,  4.0927e-06,  1.1863e-06, -1.7404e-06,\n",
      "         4.7781e-06, -2.1497e-06, -3.5793e-06,  8.1805e-06, -2.7844e-06,\n",
      "         4.4542e-07, -4.0279e-07, -3.4627e-06,  2.1649e-06, -9.4846e-07,\n",
      "        -1.0346e-05,  4.5769e-07, -2.0607e-07,  4.6910e-07, -1.4687e-06,\n",
      "         3.0252e-06,  1.0681e-05, -2.4314e-06, -6.0075e-06,  4.0527e-07,\n",
      "         1.6778e-07,  5.3046e-06,  2.1284e-06,  5.4628e-06, -7.4071e-07,\n",
      "         3.6774e-06,  2.6153e-06, -1.5762e-07,  4.1685e-07,  2.2085e-06,\n",
      "         5.2626e-06, -9.1250e-06,  1.4503e-07,  2.0691e-07, -3.7233e-06,\n",
      "        -4.5599e-06, -1.9630e-07, -1.5802e-06,  4.6975e-06,  2.4198e-06,\n",
      "         4.9618e-07, -3.6909e-06, -1.7740e-07,  1.7441e-06, -2.7536e-06,\n",
      "        -8.3784e-07, -5.8215e-06,  2.5132e-06, -1.2927e-05,  3.0209e-08,\n",
      "         8.7163e-07,  4.7211e-06, -2.2792e-06, -3.3572e-06, -2.5147e-06,\n",
      "        -3.4774e-06,  3.3392e-06,  1.7787e-06, -9.8680e-06, -5.4590e-07,\n",
      "         1.8407e-06, -3.4722e-06,  2.8140e-06,  6.2589e-06,  5.7440e-06,\n",
      "         2.0141e-06,  6.6185e-06,  4.0871e-06, -7.9044e-06,  1.7573e-06,\n",
      "         4.6411e-06, -2.7270e-06, -4.4820e-06,  6.9798e-07, -7.4194e-06,\n",
      "        -1.0483e-06,  1.8474e-06, -1.1715e-06, -4.7644e-08, -7.0318e-07,\n",
      "        -3.5755e-07, -8.5900e-06,  2.5118e-06,  5.0186e-06,  1.0858e-05,\n",
      "         2.2289e-06,  2.7373e-06, -3.1284e-09,  4.3988e-06,  4.4319e-08,\n",
      "         7.3678e-07,  6.3502e-06, -1.1077e-05, -6.5373e-06, -3.0496e-06,\n",
      "         2.0406e-06, -6.1519e-06,  9.8679e-07,  6.3382e-06,  1.1251e-06,\n",
      "        -5.0879e-07,  3.3443e-06,  4.5465e-06,  3.8062e-06, -1.3355e-06,\n",
      "         6.7525e-06,  8.0821e-06,  5.9779e-08,  3.2810e-06, -3.8610e-06,\n",
      "         9.4750e-07,  7.7336e-06,  3.5274e-06, -3.6375e-06, -3.3363e-06,\n",
      "        -9.1947e-06,  6.5676e-06,  4.9994e-06,  3.1988e-06, -1.5734e-06,\n",
      "         1.4283e-06,  1.9263e-06, -7.2257e-07,  8.7458e-06,  1.5245e-07,\n",
      "         5.5665e-06, -3.3462e-07,  5.7748e-06,  2.3426e-06,  4.1621e-07,\n",
      "        -3.6775e-06, -2.2997e-06, -9.0811e-06,  8.8666e-06, -3.4711e-06,\n",
      "        -4.5662e-06,  3.0327e-06, -5.2701e-06,  6.5191e-06, -4.6379e-06,\n",
      "         1.9710e-06, -1.7254e-08, -3.0893e-06,  3.9095e-07,  4.2576e-06,\n",
      "        -9.0213e-07])), ('layer1.7.running_mean', tensor([-4.0306e-01, -2.4398e-01, -3.2270e-01,  1.5467e-01, -6.3547e-01,\n",
      "         8.6147e-02,  4.8190e-01, -2.2393e-02,  2.4689e-01, -1.3937e-01,\n",
      "        -2.0061e-01,  7.8569e-01,  2.4580e-01, -1.1550e-01,  5.2197e-01,\n",
      "         6.0641e-01,  5.0987e-01,  2.3183e-01, -4.9555e-01, -3.1438e-01,\n",
      "        -7.7251e-01,  5.5731e-01,  2.9120e-01, -1.4760e-01, -6.2803e-01,\n",
      "        -2.1433e-01, -1.4760e-01,  3.7377e-01,  2.0282e-01,  2.7538e-01,\n",
      "         5.9289e-01,  5.4618e-01,  5.8148e-02,  5.3240e-02,  1.4854e-01,\n",
      "        -6.1877e-01,  4.1606e-02,  7.0845e-01,  2.4110e-01, -4.9915e-01,\n",
      "         4.6413e-01, -5.1500e-01,  5.3592e-01,  1.2384e-01,  7.0974e-01,\n",
      "         3.1094e-01, -5.1696e-01, -3.7836e-01, -1.5244e-01,  2.3442e-01,\n",
      "        -5.7695e-01,  3.2944e-01,  1.6474e-01,  3.1861e-01, -4.5322e-01,\n",
      "         5.1590e-01,  7.4985e-01,  3.1039e-04, -3.1461e-01, -2.0650e-02,\n",
      "        -3.5702e-03, -1.0578e-01,  3.0813e-02,  2.4049e-01, -5.3891e-01,\n",
      "        -1.6310e-01,  5.1674e-01, -4.4916e-01, -3.9119e-02,  2.4291e-01,\n",
      "        -1.0024e+00,  1.9427e-01,  3.4882e-02, -1.7921e-02,  1.1019e-01,\n",
      "         8.3836e-01, -1.9171e-01,  1.3054e-01, -1.5414e-01,  7.1525e-01,\n",
      "        -7.6752e-01, -2.7969e-01, -1.7552e-02,  4.7752e-01, -6.0216e-01,\n",
      "         9.0604e-02, -3.8858e-01,  3.6704e-01,  2.0825e-01, -3.8481e-01,\n",
      "        -1.0371e-01, -7.5218e-01, -4.3635e-01,  7.2280e-02, -3.4012e-01,\n",
      "         1.8100e-02,  2.6115e-01,  7.0604e-02, -9.0825e-01, -6.6541e-02,\n",
      "         1.7174e-01, -1.6846e-01,  8.0016e-01, -1.6429e-01, -3.2675e-02,\n",
      "         1.5852e-01,  1.3116e-01, -3.1913e-01,  7.1760e-02,  2.6316e-01,\n",
      "        -1.7315e-01,  1.0033e-01, -4.4064e-02, -4.8438e-01,  4.4670e-01,\n",
      "         2.7534e-01,  2.7091e-01,  4.9305e-02, -1.6432e-01,  1.6743e-01,\n",
      "         4.8016e-01,  1.6669e-01,  6.1896e-01, -5.3713e-01, -7.2932e-01,\n",
      "        -1.1706e-01, -8.7255e-02, -5.5644e-02,  3.7830e-01,  3.0592e-01,\n",
      "        -2.7942e-01, -5.6267e-01, -2.1730e-01,  9.6523e-02, -2.0605e-01,\n",
      "        -2.7714e-01,  2.2841e-01, -4.2728e-01,  1.6777e-01, -2.9225e-01,\n",
      "        -5.0368e-01,  4.5574e-01, -4.4671e-01, -2.2808e-01, -3.4993e-02,\n",
      "         7.7724e-02,  4.3765e-01,  2.0809e-01, -1.0746e+00, -6.7079e-01,\n",
      "        -1.7968e-01,  3.9112e-01,  4.0544e-01, -3.4040e-01, -5.8848e-01,\n",
      "         1.1441e-01,  3.6224e-01, -4.1122e-01,  4.9572e-01, -2.6821e-01,\n",
      "         8.6499e-01,  2.5453e-01,  1.2730e-01, -2.2694e-01, -2.0861e-01,\n",
      "         1.9045e-01, -4.2877e-01,  4.3035e-03,  6.1190e-01, -2.1809e-01,\n",
      "        -1.6990e-01,  4.8394e-01, -4.0711e-01,  3.9282e-03, -7.2530e-01,\n",
      "         2.6837e-01, -2.4094e-01, -2.7241e-01,  1.6115e-01, -1.8133e-01,\n",
      "        -3.2323e-01, -4.0357e-01,  6.0086e-01,  6.9368e-02,  3.0441e-01,\n",
      "         5.2801e-02, -1.8407e-01, -1.8712e-01, -1.0932e-01,  3.2509e-02,\n",
      "        -2.3770e-02,  6.9269e-02, -3.9388e-01, -1.2747e-01, -3.3864e-01,\n",
      "        -6.3735e-01, -4.6473e-01, -1.4168e-01, -1.2211e-01, -3.5135e-01,\n",
      "         2.2756e-04, -1.9866e-01,  4.6943e-01,  5.1472e-02,  3.8268e-01,\n",
      "        -3.9785e-01,  1.5825e-01, -4.5380e-01,  8.9666e-02,  4.7452e-01,\n",
      "         1.4834e-01,  6.0322e-01, -3.8310e-01, -6.4176e-01, -8.2728e-01,\n",
      "        -5.8759e-01, -3.7879e-01, -5.5668e-01, -4.7375e-01, -3.0764e-01,\n",
      "        -1.4210e-01, -6.0290e-01,  2.6016e-01,  2.3967e-01, -2.7014e-01,\n",
      "        -5.8866e-02,  2.4695e-01, -3.8294e-01,  4.4553e-01,  2.5375e-02,\n",
      "        -5.5899e-01, -2.8590e-01, -3.7158e-01, -1.9248e-01,  3.4520e-01,\n",
      "        -9.8989e-02,  9.2469e-01, -2.7691e-01, -7.7514e-01, -4.6520e-01,\n",
      "        -1.7523e-01,  2.4218e-02,  4.8727e-01, -3.5343e-01,  4.1827e-01,\n",
      "         2.8466e-01, -2.2377e-01, -2.6234e-01,  2.5898e-01, -1.2246e-01,\n",
      "         5.3183e-01,  4.0751e-01,  4.8836e-01, -6.4827e-02,  1.4333e-01,\n",
      "         7.1933e-01])), ('layer1.7.running_var', tensor([0.4643, 0.1930, 0.5553, 0.1761, 1.1153, 0.2305, 0.1127, 0.4880, 0.7021,\n",
      "        0.4289, 0.3598, 1.1987, 0.5844, 0.1958, 0.3966, 0.7315, 0.5217, 0.1991,\n",
      "        0.8870, 0.2372, 0.6426, 0.7965, 0.6110, 0.2050, 0.4099, 0.1311, 0.3738,\n",
      "        0.3706, 0.8146, 0.4171, 0.5176, 0.7345, 0.2472, 0.5997, 0.3565, 0.6353,\n",
      "        0.2881, 0.6409, 0.0827, 0.8412, 0.3737, 0.6201, 0.6352, 0.1651, 1.2868,\n",
      "        0.2588, 0.7079, 0.5773, 0.1960, 0.3427, 1.2239, 0.3772, 0.2772, 0.0810,\n",
      "        0.9519, 0.1290, 0.8230, 0.2090, 0.2868, 0.3267, 0.2854, 0.3307, 0.2584,\n",
      "        0.3375, 0.3853, 0.3206, 0.7294, 0.5387, 0.2193, 0.2313, 0.8800, 0.4010,\n",
      "        0.1840, 0.3336, 0.5348, 0.6806, 0.7192, 0.5570, 0.2082, 0.6999, 0.3683,\n",
      "        0.7648, 0.4978, 0.1453, 0.2041, 0.5028, 0.3299, 0.1934, 0.1102, 0.3384,\n",
      "        0.2169, 0.8773, 0.3215, 0.1218, 0.1141, 0.1604, 0.5154, 0.1201, 0.5292,\n",
      "        0.2480, 0.6366, 0.1420, 1.3490, 0.1882, 0.1180, 0.1164, 0.2663, 0.5391,\n",
      "        0.0729, 0.1284, 0.1635, 0.2842, 0.2842, 0.4560, 0.5503, 0.1922, 0.5168,\n",
      "        0.6426, 0.4308, 0.1876, 0.6090, 0.3990, 0.6275, 0.2100, 0.2421, 0.1612,\n",
      "        0.2196, 0.1295, 0.2799, 0.3488, 0.2634, 0.6160, 0.4818, 0.0705, 0.4040,\n",
      "        0.3712, 0.6086, 0.1648, 0.3037, 0.7247, 0.1485, 0.7931, 0.3317, 0.4915,\n",
      "        0.2953, 0.3624, 0.1836, 0.8997, 1.0620, 0.5658, 0.3541, 0.3458, 0.4861,\n",
      "        0.4245, 0.5314, 0.3181, 0.8023, 0.2255, 0.7523, 0.4126, 0.6009, 0.3114,\n",
      "        0.2133, 0.3092, 0.3108, 0.4921, 0.3365, 0.1336, 0.8581, 0.7476, 0.2474,\n",
      "        0.3050, 0.2246, 0.3158, 0.9638, 0.1460, 0.9611, 0.4093, 0.3485, 0.5216,\n",
      "        0.4799, 0.5282, 0.7035, 0.1915, 0.6371, 0.2009, 0.3124, 0.3104, 0.2426,\n",
      "        0.3283, 0.2323, 0.2117, 0.2565, 0.1028, 0.4880, 0.5054, 0.1247, 0.4838,\n",
      "        0.3746, 0.5801, 0.1834, 0.3097, 0.6964, 0.6737, 0.6421, 0.7732, 0.4297,\n",
      "        0.5096, 0.9538, 0.6219, 0.1272, 0.7420, 0.8860, 0.6918, 0.6552, 0.5700,\n",
      "        0.2116, 0.7149, 0.3168, 0.1775, 0.1864, 0.4457, 0.2817, 0.2211, 0.3593,\n",
      "        0.1594, 0.4087, 0.4308, 0.5972, 0.5413, 0.7693, 0.5272, 0.0380, 0.2866,\n",
      "        0.3838, 0.2709, 1.9174, 1.1956, 0.2313, 0.6918, 0.2472, 0.2599, 0.7015,\n",
      "        0.5199, 0.7392, 0.6329, 1.0311, 1.1010, 0.1967, 0.3088, 0.2497, 0.5428,\n",
      "        0.4251, 0.3065, 0.2593, 0.2554])), ('layer1.7.num_batches_tracked', tensor(309)), ('layer2.0.weight', tensor([[[[-0.0657]],\n",
      "\n",
      "         [[ 0.0450]],\n",
      "\n",
      "         [[-0.0661]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0615]],\n",
      "\n",
      "         [[-0.0028]],\n",
      "\n",
      "         [[-0.0605]]],\n",
      "\n",
      "\n",
      "        [[[-0.0545]],\n",
      "\n",
      "         [[-0.0197]],\n",
      "\n",
      "         [[ 0.0087]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0370]],\n",
      "\n",
      "         [[-0.1045]],\n",
      "\n",
      "         [[-0.0016]]],\n",
      "\n",
      "\n",
      "        [[[-0.0431]],\n",
      "\n",
      "         [[-0.0112]],\n",
      "\n",
      "         [[ 0.0559]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0520]],\n",
      "\n",
      "         [[-0.1014]],\n",
      "\n",
      "         [[ 0.0752]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0501]],\n",
      "\n",
      "         [[-0.0039]],\n",
      "\n",
      "         [[ 0.0463]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0365]],\n",
      "\n",
      "         [[-0.0573]],\n",
      "\n",
      "         [[-0.0241]]],\n",
      "\n",
      "\n",
      "        [[[-0.1005]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[ 0.0323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0401]],\n",
      "\n",
      "         [[-0.0247]],\n",
      "\n",
      "         [[-0.1149]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0708]],\n",
      "\n",
      "         [[ 0.0391]],\n",
      "\n",
      "         [[ 0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0262]],\n",
      "\n",
      "         [[ 0.0279]],\n",
      "\n",
      "         [[ 0.0246]]]])), ('layer2.1.weight', tensor([0.9176, 1.0381, 1.0169, 0.9999, 0.9641, 0.9745, 1.0052, 0.9814, 0.9916,\n",
      "        1.0208, 0.9760, 0.9987, 0.9680, 0.9461, 0.9853, 0.9869, 1.0315, 0.9386,\n",
      "        1.0415, 1.0059, 0.9193, 0.9571, 0.9829, 1.0063, 1.0262, 0.9658, 0.8689,\n",
      "        0.9623, 1.0031, 0.9438, 1.0292, 1.0199, 1.1142, 1.0246, 1.0809, 0.9615,\n",
      "        1.0073, 0.9777, 1.0407, 0.9812, 1.0205, 1.0318, 1.0202, 1.1257, 0.9688,\n",
      "        1.0005, 0.9667, 1.0170, 0.9939, 0.9153, 0.9179, 1.1201, 1.0071, 1.1082,\n",
      "        1.0421, 0.9577, 1.0723, 1.0033, 0.9229, 0.9814, 1.0653, 1.0686, 0.9882,\n",
      "        0.9482, 1.0197, 0.9312, 1.0075, 0.8854, 0.9954, 1.0104, 1.0400, 0.9639,\n",
      "        1.0130, 0.9958, 1.0413, 1.0513, 1.0334, 0.9860, 1.0428, 0.9833, 0.9329,\n",
      "        1.0497, 1.0019, 0.9928, 1.0001, 0.9649, 0.9916, 0.9928, 1.0764, 1.0640,\n",
      "        1.0826, 1.0174, 0.9430, 0.9390, 1.0063, 1.0150, 1.0046, 0.9768, 1.0496,\n",
      "        1.0141, 0.9508, 0.9703, 0.9897, 1.0051, 0.9880, 1.0357, 0.9953, 0.9741,\n",
      "        1.0240, 0.9807, 0.9994, 0.9956, 1.0113, 1.0144, 1.0217, 1.0197, 1.0472,\n",
      "        1.0278, 1.0133, 0.9501, 1.0318, 1.1035, 1.0326, 1.0230, 1.0167, 1.0009,\n",
      "        0.9242, 0.9968])), ('layer2.1.bias', tensor([-0.0671,  0.0020,  0.0656,  0.0120, -0.0467,  0.0167,  0.0817,  0.0404,\n",
      "        -0.0264, -0.0072, -0.0519,  0.0384, -0.0411,  0.0596, -0.0526,  0.0471,\n",
      "         0.0810, -0.0603,  0.0722,  0.0270, -0.0166, -0.0291, -0.0311,  0.0347,\n",
      "         0.0545,  0.0097, -0.0323,  0.0214,  0.0327, -0.0055, -0.0008,  0.0832,\n",
      "         0.0122, -0.0084,  0.0525, -0.0268, -0.0269, -0.0030,  0.0321,  0.0020,\n",
      "        -0.0210,  0.0347,  0.0694,  0.1071,  0.0756,  0.0175,  0.0091,  0.0556,\n",
      "        -0.0308,  0.0239, -0.0283,  0.1482, -0.0175,  0.0908,  0.1092,  0.0225,\n",
      "        -0.0012, -0.0899, -0.0731,  0.0105, -0.0867, -0.0063,  0.0590,  0.0134,\n",
      "         0.0291,  0.0269, -0.0178,  0.0002,  0.0048,  0.0362,  0.0344,  0.0264,\n",
      "         0.0478,  0.0526,  0.0337,  0.1111,  0.0647,  0.0115,  0.0960, -0.0206,\n",
      "        -0.0430,  0.1304,  0.0273, -0.0279,  0.0699,  0.0336,  0.0125, -0.0389,\n",
      "         0.0075,  0.0856,  0.0599,  0.0180,  0.0237,  0.0146,  0.0517,  0.0707,\n",
      "         0.0479,  0.0444, -0.0342, -0.0063, -0.0189,  0.0116,  0.0090,  0.0017,\n",
      "         0.0475,  0.0167, -0.0122,  0.0592, -0.0185,  0.0788, -0.0296, -0.0270,\n",
      "         0.0036,  0.0544,  0.0421,  0.0337,  0.0415,  0.0645,  0.0520, -0.0931,\n",
      "         0.0878,  0.0324,  0.0078, -0.0056,  0.0473, -0.0412, -0.0954,  0.0242])), ('layer2.1.running_mean', tensor([-0.4272,  0.2621, -0.8681,  0.6422,  0.6346, -0.2437,  0.1992, -0.6489,\n",
      "        -0.4560,  0.3462,  0.4282, -0.8169, -0.0645, -0.5010,  0.8123, -0.4678,\n",
      "        -0.0258, -0.1267, -0.4708, -0.6263, -0.6253,  0.1380,  0.3435,  0.6923,\n",
      "         0.0935, -0.3907, -0.4592, -0.2754, -0.4834, -0.2877,  0.0997, -0.6795,\n",
      "         0.0685,  0.4256, -0.7129, -0.4296,  0.6487, -0.4046, -0.6282, -0.4295,\n",
      "        -0.4625, -0.4761, -0.4100, -0.8709, -0.6765, -0.0507, -0.2707, -0.1385,\n",
      "         0.0950, -0.6178, -0.3602, -0.8657,  0.6003, -0.9275, -0.8318, -0.5511,\n",
      "        -0.6743,  0.8175,  0.5537, -0.7907, -0.1636, -0.0925, -0.1509, -0.6879,\n",
      "         0.2378, -0.2209,  0.5746, -0.2080, -0.4873,  0.2863, -0.1345, -0.9289,\n",
      "         0.4091, -0.7060, -0.7852, -0.8865, -0.7101,  0.2376,  0.0123,  0.5203,\n",
      "        -0.5325, -0.6206, -0.7523,  0.6498,  0.4736, -0.4299,  0.1005,  0.0421,\n",
      "        -0.7095, -0.5871,  0.0613,  0.1535, -0.4717, -0.3482,  0.4166, -0.6740,\n",
      "         0.2820, -0.5495, -0.2648,  0.5677, -0.2313, -0.6484, -0.0932, -0.1809,\n",
      "        -0.8228,  0.2037,  0.5963, -0.6105,  0.3720, -1.1126, -0.3264, -0.3611,\n",
      "         0.2180,  0.3095, -0.3183, -0.7964, -0.5845, -0.9975, -0.4589,  0.7726,\n",
      "         0.5269, -0.4672,  0.4184,  0.5438,  0.4297,  0.3387,  0.7483, -0.5159])), ('layer2.1.running_var', tensor([25.9962,  9.2460, 13.4437,  6.6983, 11.9928, 11.2697,  5.2160,  6.7283,\n",
      "        30.7925, 11.7637, 11.5508,  4.4561,  9.6630, 17.1110,  6.1720,  4.8932,\n",
      "         4.4445, 29.4832, 35.4602,  7.1237, 19.6957,  3.0657,  3.4574,  8.3316,\n",
      "        13.8992, 13.9336, 17.5489,  5.5747, 41.1231, 37.1097,  5.8671, 31.4663,\n",
      "        48.2873,  2.6983, 12.9548, 28.9575,  9.5728,  1.7811, 11.9735, 12.3998,\n",
      "        48.3285, 28.2138,  9.6640, 12.0913, 24.0480, 11.4919, 19.1563, 12.5588,\n",
      "         9.1937, 10.5263, 20.4754, 13.5051,  4.8770, 13.1079, 10.7620, 13.3898,\n",
      "         8.7302, 16.6474,  3.4027,  6.7039,  6.8681, 32.1381,  3.6175, 34.2834,\n",
      "         7.0071, 14.3047,  5.3448, 32.3113, 30.7140,  8.4791,  3.4748,  7.3444,\n",
      "         6.7160, 27.7856, 30.3431,  8.7652,  4.9864, 13.0046,  4.6586,  3.1757,\n",
      "         3.4726,  6.5756, 25.7077,  4.4703,  7.6976, 23.7000,  6.8262, 20.5727,\n",
      "         8.8182, 15.2393,  5.8167,  8.6878, 43.3895, 73.5136,  8.1287, 33.6414,\n",
      "         5.5834, 24.3496, 28.9462,  4.9212, 43.8950, 32.9594,  2.6675,  9.3265,\n",
      "        22.6642, 15.5809,  4.5082,  4.3282,  8.6240, 10.1515,  7.7121, 35.1225,\n",
      "        10.1124,  9.7318,  3.7687,  9.7359,  4.2877,  7.2696,  6.5028,  8.0660,\n",
      "         7.1883, 58.3657,  3.8249,  4.1564,  5.7612,  1.6293,  7.2558,  3.6696])), ('layer2.1.num_batches_tracked', tensor(309)), ('layer2.3.weight', tensor([[[[-2.0209e-02,  5.0658e-02,  3.0842e-02],\n",
      "          [ 2.3897e-02, -5.9993e-02,  2.9118e-02],\n",
      "          [-5.8646e-02,  2.4845e-02,  1.6512e-02]],\n",
      "\n",
      "         [[-4.1976e-03,  6.2613e-03, -2.1717e-03],\n",
      "          [-1.9821e-02, -2.2785e-02,  2.2516e-02],\n",
      "          [-2.4412e-02,  9.9905e-03,  1.1331e-02]],\n",
      "\n",
      "         [[ 3.2440e-03,  2.9947e-02, -1.6244e-02],\n",
      "          [-1.3586e-02, -6.9227e-02,  6.7606e-02],\n",
      "          [-2.6082e-03, -1.3191e-02, -5.9831e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2075e-02,  2.9541e-02, -2.9089e-03],\n",
      "          [ 3.1393e-04,  1.6826e-02, -2.8263e-03],\n",
      "          [-1.7513e-02,  2.7337e-02,  4.9737e-03]],\n",
      "\n",
      "         [[-3.1556e-03,  4.8813e-02, -1.8288e-02],\n",
      "          [-1.0841e-02, -1.6360e-02, -5.7694e-02],\n",
      "          [-2.4199e-02, -2.2472e-02,  2.3179e-02]],\n",
      "\n",
      "         [[-1.7142e-02,  5.5358e-02,  4.6844e-02],\n",
      "          [ 1.1685e-02, -6.5368e-02, -9.3024e-04],\n",
      "          [ 4.2915e-02,  1.8404e-02,  1.0431e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1743e-02, -8.4258e-02,  1.6213e-02],\n",
      "          [-8.6990e-03, -5.7838e-02,  3.6809e-02],\n",
      "          [ 1.1222e-02,  5.0654e-03,  8.6242e-03]],\n",
      "\n",
      "         [[ 5.2417e-03, -8.8771e-02,  1.7802e-02],\n",
      "          [ 3.0915e-02, -3.4480e-02,  1.2840e-03],\n",
      "          [ 8.8659e-03,  1.2150e-01, -4.3587e-02]],\n",
      "\n",
      "         [[-1.1994e-02,  1.6391e-02,  2.1846e-02],\n",
      "          [-3.9282e-02, -2.5399e-03, -3.5038e-02],\n",
      "          [ 1.5456e-02,  1.3422e-02,  1.2875e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2045e-02,  1.3576e-02, -1.0757e-05],\n",
      "          [ 2.0241e-02,  3.6928e-03, -3.3889e-02],\n",
      "          [-2.3740e-02,  2.1308e-02,  2.0513e-02]],\n",
      "\n",
      "         [[-4.6701e-02, -4.4405e-02,  4.1238e-02],\n",
      "          [ 1.8171e-02, -4.3239e-02,  7.3397e-03],\n",
      "          [ 2.1222e-02, -2.2892e-02,  2.6650e-02]],\n",
      "\n",
      "         [[-7.1668e-03,  3.2663e-02,  7.7218e-04],\n",
      "          [-2.8723e-02,  2.2245e-02,  2.1967e-02],\n",
      "          [ 6.6679e-03,  8.1686e-03,  4.4279e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.1995e-02,  4.6006e-02,  1.0378e-02],\n",
      "          [ 6.8065e-02,  1.9963e-02,  4.7955e-02],\n",
      "          [ 6.7784e-02,  3.1572e-02,  5.6792e-02]],\n",
      "\n",
      "         [[ 5.6166e-03,  3.5387e-02, -4.5472e-03],\n",
      "          [-1.2720e-02,  1.7357e-03,  2.5574e-02],\n",
      "          [ 2.1013e-02, -2.5632e-02, -7.5150e-03]],\n",
      "\n",
      "         [[-2.5716e-02,  5.3285e-02, -1.3135e-02],\n",
      "          [ 1.0590e-02, -7.4686e-02, -8.6099e-03],\n",
      "          [-2.5166e-02,  7.4399e-03, -2.8799e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7202e-02,  1.7589e-02,  2.0956e-02],\n",
      "          [ 1.8119e-02, -1.9984e-02, -5.2524e-03],\n",
      "          [ 6.1074e-03, -5.7202e-02,  1.3416e-02]],\n",
      "\n",
      "         [[-7.3543e-04, -1.4256e-02, -9.9542e-03],\n",
      "          [-1.4900e-02,  3.1585e-02,  3.3202e-02],\n",
      "          [ 2.4327e-02,  7.7881e-03,  2.9987e-02]],\n",
      "\n",
      "         [[-5.9845e-03,  2.8899e-02,  4.5377e-02],\n",
      "          [ 1.7928e-02, -4.6715e-02,  1.6010e-02],\n",
      "          [ 1.4218e-02,  4.5014e-02, -2.5497e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.0843e-02, -2.0168e-02, -1.1036e-02],\n",
      "          [-1.6927e-02, -3.0519e-03, -5.3963e-02],\n",
      "          [-1.2852e-02, -4.6636e-02,  3.6849e-02]],\n",
      "\n",
      "         [[-2.1012e-02, -7.5797e-03,  1.7657e-02],\n",
      "          [-1.8861e-02,  1.4553e-02,  5.4622e-02],\n",
      "          [-1.1558e-02, -2.3634e-02,  4.3112e-02]],\n",
      "\n",
      "         [[-3.7564e-02, -1.9190e-02, -3.5750e-02],\n",
      "          [-2.9980e-02,  1.3204e-02,  3.1887e-02],\n",
      "          [-3.1850e-02, -3.5954e-02,  2.7393e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0860e-02, -8.3927e-03,  2.6646e-02],\n",
      "          [-2.1735e-02,  1.3389e-02,  2.7447e-02],\n",
      "          [-2.4650e-02,  3.7334e-02, -4.5223e-02]],\n",
      "\n",
      "         [[-3.5778e-02, -4.0448e-02,  1.2478e-02],\n",
      "          [ 2.0720e-02, -3.7933e-02, -4.0665e-03],\n",
      "          [-1.2029e-02,  4.0479e-03,  3.4059e-02]],\n",
      "\n",
      "         [[ 1.4627e-02, -1.9815e-02,  1.9022e-02],\n",
      "          [-1.2886e-02, -2.7792e-02,  1.5085e-02],\n",
      "          [-3.3768e-03,  4.6106e-03,  2.3756e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2242e-05,  6.3504e-02,  1.0675e-02],\n",
      "          [ 5.2788e-02, -6.7143e-02, -1.5576e-02],\n",
      "          [-6.7080e-02,  8.7329e-03,  3.5727e-02]],\n",
      "\n",
      "         [[ 5.9721e-03,  3.4089e-02,  7.3320e-03],\n",
      "          [ 7.8736e-04,  1.8997e-02, -4.6093e-02],\n",
      "          [-1.8975e-02,  8.3176e-03, -2.6437e-02]],\n",
      "\n",
      "         [[-1.9551e-02,  1.9701e-02, -7.8207e-03],\n",
      "          [ 2.8750e-02, -1.9606e-02,  4.5129e-02],\n",
      "          [-5.4568e-02,  9.8098e-03, -3.4329e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4448e-02,  3.1904e-02, -1.5277e-02],\n",
      "          [-2.8998e-02,  1.3828e-02, -1.7118e-02],\n",
      "          [ 6.4757e-03,  2.0703e-02, -2.8938e-02]],\n",
      "\n",
      "         [[ 4.3717e-02, -3.1117e-02, -2.7862e-02],\n",
      "          [-9.1736e-04, -2.2872e-02, -3.0188e-02],\n",
      "          [-2.7873e-02, -6.5385e-02, -3.2444e-02]],\n",
      "\n",
      "         [[-3.0882e-02,  4.9184e-02,  2.4211e-02],\n",
      "          [ 2.8292e-02, -8.3321e-02,  3.6722e-02],\n",
      "          [ 3.0699e-02,  2.4206e-02,  4.7992e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7054e-02,  4.3748e-02,  7.1704e-03],\n",
      "          [ 5.5255e-02,  1.2861e-02,  6.0486e-02],\n",
      "          [-4.9156e-02,  4.0345e-02, -2.2215e-02]],\n",
      "\n",
      "         [[ 3.5514e-03, -2.6536e-02, -2.3133e-02],\n",
      "          [ 1.6854e-03,  5.0478e-02,  1.5529e-04],\n",
      "          [-6.9573e-03, -1.2834e-02,  4.0527e-02]],\n",
      "\n",
      "         [[-1.7438e-02, -8.3631e-03, -4.1145e-03],\n",
      "          [-1.6747e-02,  5.3326e-02, -1.2755e-02],\n",
      "          [-5.5264e-02, -1.3435e-02,  3.3224e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5676e-02, -2.3281e-02, -2.5620e-02],\n",
      "          [-2.7873e-03,  9.8364e-03, -2.4817e-02],\n",
      "          [ 2.2678e-02,  6.5564e-02, -1.3140e-02]],\n",
      "\n",
      "         [[ 5.2095e-02, -1.3075e-02, -1.8765e-02],\n",
      "          [ 5.4825e-02, -9.2270e-03, -6.5029e-02],\n",
      "          [-2.4616e-02,  1.8233e-02,  7.7441e-03]],\n",
      "\n",
      "         [[-2.3184e-02,  3.6355e-02, -3.6614e-02],\n",
      "          [ 4.6507e-03,  2.9381e-02,  3.7488e-02],\n",
      "          [-1.6084e-02,  3.7913e-02, -2.1578e-02]]]])), ('layer2.4.weight', tensor([1.0099, 0.9497, 1.0230, 1.0329, 1.1293, 1.0240, 1.0067, 1.0426, 0.9253,\n",
      "        1.0585, 0.9857, 1.1230, 1.1086, 0.9937, 1.0063, 0.9622, 1.0746, 0.9927,\n",
      "        1.0792, 0.8378, 1.0361, 0.8758, 0.9977, 1.0985, 1.0320, 0.9993, 0.9959,\n",
      "        1.1000, 0.9757, 1.0979, 0.9963, 1.0065, 0.8815, 0.9696, 0.9738, 0.9954,\n",
      "        0.8849, 0.9888, 1.0838, 1.0238, 0.9001, 1.0313, 1.0417, 0.9788, 0.9273,\n",
      "        1.0799, 0.9582, 0.9264, 1.1010, 1.0000, 0.9826, 0.9809, 1.1435, 0.8672,\n",
      "        0.8684, 0.8327, 0.9516, 1.0566, 1.1247, 0.9858, 1.1524, 1.0292, 0.8478,\n",
      "        0.9499, 0.9866, 1.0265, 1.1201, 1.0463, 0.8758, 0.9691, 1.0086, 1.0280,\n",
      "        0.9886, 1.0355, 0.9763, 0.9530, 1.0574, 0.7958, 0.9965, 0.9136, 1.1630,\n",
      "        0.9241, 0.8440, 0.8876, 1.1058, 0.9658, 0.9462, 0.9038, 1.1543, 1.0112,\n",
      "        1.0266, 0.9833, 1.1388, 0.9792, 1.0605, 0.9976, 1.0671, 0.8490, 1.0287,\n",
      "        1.1371, 0.9399, 1.0864, 0.8486, 0.9501, 0.9571, 1.0146, 1.0210, 0.9823,\n",
      "        1.1028, 1.0227, 0.8826, 0.9773, 1.0263, 1.0480, 0.9545, 0.9906, 1.0148,\n",
      "        0.9754, 1.0429, 0.9546, 1.0676, 1.0329, 1.0112, 1.0283, 1.0111, 1.0435,\n",
      "        1.0741, 0.9726])), ('layer2.4.bias', tensor([-1.8683e-02,  3.9542e-03, -1.1044e-01, -7.9179e-03,  6.0252e-02,\n",
      "        -2.6070e-01, -3.8726e-02,  1.5395e-02, -4.8576e-02, -7.7534e-02,\n",
      "        -1.1489e-01,  9.4961e-02,  1.1356e-01, -1.1193e-01,  2.5728e-01,\n",
      "        -1.0513e-01, -1.4199e-01, -1.5980e-02, -1.2120e-01,  7.9045e-02,\n",
      "        -7.6329e-02,  7.2287e-02, -6.3901e-02, -1.8658e-01, -2.2264e-02,\n",
      "        -6.5653e-02,  2.8967e-02,  1.0488e-01, -2.6199e-02, -2.7909e-02,\n",
      "        -1.8019e-01, -1.5579e-01, -7.5854e-02, -1.6721e-02, -7.2744e-02,\n",
      "        -1.4988e-03, -2.6664e-02,  8.8856e-02,  2.1765e-02,  6.4440e-04,\n",
      "        -4.0059e-02,  1.1596e-02,  4.5314e-02, -8.3928e-02,  1.4651e-01,\n",
      "         7.0891e-02,  2.2504e-02,  1.1009e-02, -7.4924e-02, -7.5700e-02,\n",
      "        -5.3633e-02, -7.0272e-02,  8.6456e-03,  6.4327e-02,  8.6451e-02,\n",
      "         8.5274e-02,  8.6089e-02, -1.0771e-01,  1.0177e-02,  3.8677e-02,\n",
      "         3.9408e-02,  3.6590e-03, -1.1697e-01, -8.5543e-02,  6.7009e-02,\n",
      "         2.7463e-02, -2.1160e-01, -2.6107e-02, -9.9496e-02, -8.1588e-03,\n",
      "         5.1857e-02, -2.0946e-03,  1.4422e-02, -4.7244e-02,  2.5221e-02,\n",
      "        -3.4037e-02,  3.0437e-02,  3.5170e-02,  2.1692e-03,  1.5071e-01,\n",
      "        -3.0945e-02, -5.8556e-02, -3.1721e-02,  1.5206e-01,  9.2669e-02,\n",
      "        -1.1233e-02,  4.1323e-02,  7.8695e-02, -4.2666e-02,  1.0791e-02,\n",
      "        -1.0958e-01,  1.7774e-02, -4.9088e-02,  1.2083e-02,  2.1198e-03,\n",
      "        -1.9019e-02, -1.7773e-01, -1.6497e-02, -2.2479e-02,  1.0367e-01,\n",
      "         5.3441e-02, -2.7853e-02,  1.0620e-01, -4.8776e-02, -7.2505e-02,\n",
      "        -8.4959e-02, -1.2693e-01,  2.7693e-02, -1.5905e-02,  2.5666e-02,\n",
      "         3.2141e-02,  4.9935e-02, -7.7742e-02, -4.9906e-02,  5.7241e-03,\n",
      "        -6.9833e-03,  1.0351e-04,  5.0169e-02,  3.4240e-02, -7.8292e-03,\n",
      "         6.3782e-03,  7.1011e-02,  1.3281e-02,  8.1658e-02, -1.4619e-01,\n",
      "         6.9438e-02,  4.3438e-02, -4.3031e-02])), ('layer2.4.running_mean', tensor([-0.4265,  0.4950,  2.2606, -1.8999,  0.5516,  0.7868, -1.3862,  0.2522,\n",
      "        -0.4422,  2.3483,  2.7479,  0.7049,  3.6696,  2.0257,  1.5905,  1.3779,\n",
      "         2.3207, -3.2559, -0.2470,  2.0208,  3.6886,  1.4644,  3.6118,  2.7500,\n",
      "        -1.3485, -0.6259, -1.8857, -3.0646, -0.1204,  1.0137,  3.4674,  2.7468,\n",
      "         2.7183,  0.3484,  1.0097, -0.7685, -0.8300, -0.3593, -1.1997, -0.8813,\n",
      "         2.6457, -1.4515, -0.9013, -0.5937,  0.8450, -1.8441, -1.6603,  3.3494,\n",
      "        -0.4702,  3.1337, -0.4474,  0.1360, -0.3588,  0.3919,  1.1040,  0.9967,\n",
      "        -1.2871,  0.8793, -0.2688, -1.2872, -1.8742, -2.2435,  1.7868,  2.3382,\n",
      "         1.9269,  1.6943,  5.3824, -0.4918,  3.9396, -0.7845, -0.1428, -1.4391,\n",
      "        -1.8731, -0.9064, -1.4253,  1.2854, -1.7685,  0.9275, -1.6392,  1.3114,\n",
      "        -0.1669,  2.3741,  1.6666,  1.6415, -2.0540, -1.3343,  1.0043,  0.7773,\n",
      "         0.6322,  0.2283,  1.9943, -0.3514, -1.5217, -0.2726, -1.9392, -2.2187,\n",
      "         2.0617,  2.1753, -1.3141,  4.2441,  1.2308,  0.3383,  1.7945,  1.1858,\n",
      "        -0.6228,  2.4569,  3.5406, -1.3911, -2.0800,  0.6608, -0.7526,  0.5089,\n",
      "        -1.0165, -1.8093, -0.0278, -1.7465, -0.9180, -3.0348,  0.6312,  0.1086,\n",
      "        -0.7282,  1.2161,  0.4426, -1.2432,  4.2332, -2.1990, -1.3460,  1.8341])), ('layer2.4.running_var', tensor([ 7.7906,  5.7178, 10.1602,  4.4509,  9.7971, 10.6481,  6.1099,  4.6056,\n",
      "         2.6940, 14.6871,  8.2231,  7.4348, 53.2740, 10.3935, 12.4842,  4.9911,\n",
      "        12.0637,  3.1922,  9.8538,  9.5590, 17.4428, 10.8383, 15.0271, 15.3960,\n",
      "         4.1140,  9.6653,  5.7769, 18.6494, 10.7079,  8.4235, 14.1061, 12.1335,\n",
      "         6.8076,  2.4665, 10.0309,  4.2960,  4.9351, 19.1625,  7.9728,  2.7670,\n",
      "        10.7807,  4.9327,  5.7447,  4.8593, 12.3328,  8.0553,  5.6784,  7.6643,\n",
      "         4.2720, 16.0011,  4.7689,  4.5930, 23.4261,  8.1173,  7.2777,  9.5370,\n",
      "         8.8094, 12.8077,  9.7479,  5.2491,  8.0531,  6.8650, 12.7043,  7.4040,\n",
      "        19.2330, 20.2340, 26.2767, 12.0695,  7.7440,  1.9403, 20.1352, 13.5473,\n",
      "         4.6342, 14.3025,  6.8500,  3.4834,  7.6108,  6.9793,  4.6019, 10.3268,\n",
      "         5.7710,  5.9293, 11.0207, 13.0155, 13.6138,  4.1809,  7.1169,  4.0227,\n",
      "        26.9000, 21.4881, 12.0002,  6.0371, 13.4891,  9.7360, 20.3210,  5.4870,\n",
      "        18.3836, 11.8754,  3.6990, 47.9674,  6.2574,  7.1261,  9.9933,  1.0737,\n",
      "         2.6366, 14.6984, 14.0982,  5.7570,  6.1068,  3.5291,  5.8644, 17.1238,\n",
      "         4.9840,  6.1311,  9.3117,  3.7116,  4.4994,  7.8750,  5.8150,  3.5867,\n",
      "         6.8376,  9.5113,  3.8766,  6.8095, 15.8995,  7.2389, 17.4930,  2.9944])), ('layer2.4.num_batches_tracked', tensor(309)), ('layer2.6.weight', tensor([[[[-0.0750]],\n",
      "\n",
      "         [[-0.0127]],\n",
      "\n",
      "         [[-0.0474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0606]],\n",
      "\n",
      "         [[-0.0583]],\n",
      "\n",
      "         [[ 0.0515]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0647]],\n",
      "\n",
      "         [[ 0.0633]],\n",
      "\n",
      "         [[-0.0037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0336]],\n",
      "\n",
      "         [[ 0.0358]],\n",
      "\n",
      "         [[-0.0469]]],\n",
      "\n",
      "\n",
      "        [[[-0.0881]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         [[ 0.0566]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0096]],\n",
      "\n",
      "         [[ 0.0395]],\n",
      "\n",
      "         [[-0.0534]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0139]],\n",
      "\n",
      "         [[-0.0124]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0767]],\n",
      "\n",
      "         [[-0.0556]],\n",
      "\n",
      "         [[-0.0577]]],\n",
      "\n",
      "\n",
      "        [[[-0.0409]],\n",
      "\n",
      "         [[ 0.0809]],\n",
      "\n",
      "         [[ 0.0826]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0315]],\n",
      "\n",
      "         [[ 0.0548]],\n",
      "\n",
      "         [[-0.0811]]],\n",
      "\n",
      "\n",
      "        [[[-0.0684]],\n",
      "\n",
      "         [[ 0.0206]],\n",
      "\n",
      "         [[ 0.0446]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0061]],\n",
      "\n",
      "         [[ 0.0418]],\n",
      "\n",
      "         [[-0.0608]]]])), ('layer2.7.weight', tensor([1.0076, 0.9991, 0.9816, 0.9960, 0.9900, 1.0059, 1.0135, 0.9966, 1.0064,\n",
      "        1.0068, 1.0039, 1.0113, 0.9912, 0.9998, 1.0019, 0.9765, 1.0089, 0.9791,\n",
      "        0.9895, 1.0020, 0.9848, 0.9874, 1.0041, 0.9818, 0.9980, 1.0088, 1.0024,\n",
      "        1.0396, 1.0104, 1.0039, 1.0042, 1.0249, 0.9968, 0.9719, 0.9978, 0.9917,\n",
      "        0.9841, 0.9876, 0.9720, 0.9933, 1.0096, 0.9908, 1.0182, 1.0061, 0.9954,\n",
      "        1.0010, 1.0073, 0.9880, 1.0383, 0.9926, 1.0159, 0.9886, 0.9902, 1.0084,\n",
      "        0.9900, 0.9942, 0.9775, 1.0129, 1.0008, 0.9866, 0.9839, 0.9825, 0.9852,\n",
      "        0.9983, 0.9952, 1.0045, 0.9903, 1.0055, 0.9958, 1.0303, 1.0075, 1.0310,\n",
      "        1.0025, 1.0129, 0.9995, 1.0238, 0.9810, 0.9999, 1.0075, 0.9988, 1.0060,\n",
      "        0.9904, 1.0101, 0.9981, 0.9855, 1.0113, 0.9947, 1.0004, 0.9888, 0.9981,\n",
      "        0.9645, 1.0075, 0.9864, 1.0016, 1.0005, 0.9996, 1.0249, 0.9995, 0.9918,\n",
      "        0.9901, 0.9875, 0.9986, 1.0061, 1.0132, 1.0021, 1.0036, 1.0026, 0.9909,\n",
      "        0.9969, 0.9998, 1.0080, 0.9965, 0.9905, 0.9891, 0.9934, 1.0319, 0.9989,\n",
      "        0.9945, 0.9784, 1.0131, 0.9969, 1.0183, 0.9781, 1.0005, 0.9924, 1.0178,\n",
      "        1.0047, 0.9825, 0.9976, 0.9869, 1.0118, 0.9898, 1.0120, 1.0009, 0.9949,\n",
      "        0.9939, 0.9831, 1.0142, 0.9912, 1.0020, 1.0183, 0.9902, 0.9930, 0.9959,\n",
      "        1.0251, 0.9769, 0.9938, 1.0326, 0.9878, 1.0098, 0.9949, 1.0046, 1.0091,\n",
      "        1.0149, 1.0015, 1.0353, 0.9872, 1.0069, 0.9936, 0.9940, 0.9889, 0.9860,\n",
      "        1.0023, 1.0171, 0.9797, 1.0020, 0.9738, 1.0058, 1.0005, 0.9877, 0.9858,\n",
      "        0.9930, 1.0061, 0.9914, 1.0030, 0.9992, 1.0403, 0.9985, 0.9953, 0.9866,\n",
      "        0.9938, 1.0114, 0.9997, 1.0067, 0.9947, 1.0117, 0.9941, 0.9935, 0.9780,\n",
      "        1.0153, 1.0236, 1.0119, 0.9825, 0.9939, 0.9983, 1.0119, 1.0547, 0.9893,\n",
      "        0.9625, 0.9989, 1.0197, 1.0120, 1.0111, 0.9957, 0.9866, 1.0129, 1.0304,\n",
      "        0.9951, 1.0086, 0.9809, 1.0036, 0.9987, 0.9918, 0.9986, 1.0057, 1.0215,\n",
      "        1.0011, 1.0055, 1.0011, 1.0204, 1.0056, 0.9913, 0.9919, 0.9840, 0.9983,\n",
      "        1.0028, 1.0099, 1.0292, 1.0234, 0.9859, 0.9914, 0.9957, 0.9850, 1.0053,\n",
      "        0.9842, 0.9777, 0.9819, 1.0008, 1.0108, 0.9929, 0.9905, 1.0081, 0.9828,\n",
      "        0.9897, 1.0055, 0.9997, 1.0237, 1.0228, 1.0058, 0.9893, 0.9872, 1.0170,\n",
      "        0.9759, 1.0009, 0.9709, 1.0249, 0.9794, 1.0019, 1.0051, 1.0193, 1.0077,\n",
      "        0.9908, 1.0061, 1.0126, 1.0002, 1.0139, 1.0214, 1.0078, 0.9874, 0.9758,\n",
      "        1.0011, 1.0028, 0.9988, 0.9919, 0.9974, 1.0051, 1.0115, 1.0039, 0.9866,\n",
      "        0.9855, 1.0067, 0.9837, 0.9938, 0.9924, 1.0028, 0.9954, 1.0168, 1.0204,\n",
      "        1.0073, 0.9856, 0.9963, 0.9972, 0.9888, 0.9822, 0.9882, 0.9934, 0.9922,\n",
      "        0.9993, 1.0106, 1.0019, 0.9905, 1.0205, 1.0139, 0.9789, 0.9992, 1.0066,\n",
      "        0.9844, 0.9962, 0.9965, 1.0231, 0.9970, 1.0054, 1.0269, 0.9945, 0.9886,\n",
      "        1.0074, 0.9894, 0.9873, 0.9951, 1.0006, 1.0201, 0.9737, 1.0104, 0.9920,\n",
      "        1.0009, 0.9873, 1.0162, 1.0094, 0.9946, 0.9970, 1.0024, 0.9969, 0.9985,\n",
      "        1.0081, 1.0128, 1.0019, 0.9890, 1.0112, 0.9897, 1.0010, 0.9876, 0.9863,\n",
      "        1.0006, 0.9779, 1.0262, 1.0043, 1.0106, 0.9786, 0.9985, 1.0027, 0.9953,\n",
      "        0.9861, 1.0169, 1.0026, 1.0037, 0.9978, 1.0152, 1.0074, 1.0169, 1.0020,\n",
      "        1.0183, 0.9889, 1.0044, 0.9778, 0.9884, 1.0010, 0.9890, 1.0256, 0.9885,\n",
      "        0.9931, 0.9842, 1.0168, 1.0078, 0.9889, 1.0092, 0.9952, 1.0095, 0.9994,\n",
      "        1.0182, 0.9929, 1.0232, 0.9807, 0.9911, 0.9997, 0.9979, 0.9935, 1.0034,\n",
      "        1.0092, 0.9916, 0.9855, 0.9905, 1.0012, 0.9911, 1.0169, 1.0311, 1.0031,\n",
      "        0.9908, 0.9532, 1.0277, 1.0047, 0.9926, 1.0140, 0.9891, 0.9925, 0.9997,\n",
      "        0.9976, 0.9802, 0.9960, 0.9941, 1.0078, 0.9827, 0.9994, 1.0023, 1.0254,\n",
      "        1.0012, 0.9853, 0.9961, 1.0030, 0.9929, 0.9660, 1.0057, 0.9981, 0.9913,\n",
      "        1.0018, 0.9868, 0.9893, 0.9995, 0.9983, 0.9704, 1.0009, 1.0091, 1.0119,\n",
      "        0.9879, 1.0053, 0.9994, 1.0033, 1.0046, 1.0139, 0.9861, 0.9972, 1.0063,\n",
      "        0.9810, 0.9959, 1.0118, 1.0022, 0.9934, 1.0108, 1.0049, 0.9991, 0.9868,\n",
      "        0.9887, 0.9997, 1.0040, 0.9981, 1.0195, 1.0025, 1.0198, 1.0080, 1.0082,\n",
      "        0.9980, 0.9981, 1.0188, 1.0039, 0.9942, 0.9806, 0.9914, 0.9945, 0.9984,\n",
      "        0.9992, 1.0044, 0.9751, 1.0081, 1.0026, 1.0216, 1.0051, 0.9843, 1.0155,\n",
      "        1.0056, 1.0016, 1.0144, 1.0080, 1.0047, 1.0250, 0.9752, 1.0055, 0.9960,\n",
      "        0.9783, 0.9992, 0.9810, 1.0150, 1.0084, 1.0197, 0.9825, 1.0059, 0.9895,\n",
      "        1.0119, 1.0093, 0.9906, 0.9964, 1.0087, 1.0028, 1.0265, 1.0034, 0.9878,\n",
      "        1.0168, 0.9800, 1.0383, 1.0328, 1.0337, 1.0166, 0.9943, 1.0022])), ('layer2.7.bias', tensor([ 2.6575e-06, -2.6105e-06, -3.2662e-06,  2.5004e-07,  1.1926e-06,\n",
      "        -3.4143e-07, -7.4195e-07, -2.1850e-06,  4.1644e-06,  6.2476e-07,\n",
      "         3.2992e-07, -4.2590e-07, -5.6501e-07,  1.4345e-06, -1.9265e-06,\n",
      "         2.1159e-06,  6.9427e-07, -9.9699e-07, -5.7467e-07,  1.5484e-06,\n",
      "         1.1326e-07,  1.7427e-07,  1.3251e-06,  1.0744e-06, -4.1507e-07,\n",
      "        -1.2065e-06, -1.3770e-06, -1.3995e-07,  2.4805e-07,  6.1735e-07,\n",
      "        -6.0160e-07, -1.3997e-07,  4.1509e-07,  1.7351e-06, -3.0902e-07,\n",
      "        -1.9268e-06, -1.1124e-06, -1.9720e-06,  4.1174e-07, -1.7633e-06,\n",
      "         1.6837e-06, -5.2920e-07, -6.9510e-09,  5.5084e-07,  2.5140e-08,\n",
      "         2.1754e-06,  4.7180e-06, -1.8779e-06,  3.5755e-06, -3.2057e-07,\n",
      "         1.8174e-06,  2.1689e-06, -3.2001e-08,  1.2284e-06,  1.2595e-06,\n",
      "        -1.2780e-06, -3.0937e-06, -1.9560e-06, -1.7501e-06,  2.4842e-06,\n",
      "         2.0779e-06,  3.8190e-07, -7.2107e-07,  2.5248e-06,  9.7305e-07,\n",
      "         1.5158e-06,  7.8714e-07,  3.3691e-06, -3.1466e-06,  5.0886e-07,\n",
      "        -1.4683e-06, -2.3213e-06,  2.2489e-06,  1.1467e-08, -1.1752e-06,\n",
      "        -5.6526e-07, -1.0952e-06, -1.7462e-06, -1.6893e-06,  2.5929e-06,\n",
      "         3.2467e-07, -2.1807e-06,  4.3983e-07,  1.6969e-06,  1.2782e-07,\n",
      "         3.3269e-07,  1.7453e-06,  5.0623e-07,  1.4879e-06,  2.3277e-07,\n",
      "         1.5313e-06,  9.6846e-07,  3.7866e-08, -7.7749e-07, -4.5226e-07,\n",
      "        -2.4589e-06, -3.0735e-06, -2.2380e-06, -9.8666e-08, -2.2728e-06,\n",
      "        -1.7640e-07, -1.0828e-07,  1.8949e-06,  3.1135e-06, -3.9085e-07,\n",
      "        -9.4889e-08,  4.7776e-08, -3.8440e-06,  7.8460e-08,  5.5414e-07,\n",
      "        -2.3677e-06,  9.1721e-07,  5.8616e-07,  8.2261e-07, -1.4554e-07,\n",
      "         2.5653e-06,  6.9395e-07,  1.4614e-06,  2.3476e-06, -3.9607e-06,\n",
      "        -9.3261e-08,  1.5599e-06,  6.1595e-07,  4.3646e-06,  7.8585e-07,\n",
      "        -2.5332e-06,  1.3582e-06,  2.9020e-06, -1.3764e-06, -8.2179e-07,\n",
      "         1.0248e-06,  3.5116e-06,  2.5275e-06, -4.1325e-06, -2.1818e-06,\n",
      "        -2.1160e-06,  3.6935e-08,  3.1474e-06, -6.6498e-07,  1.1483e-06,\n",
      "        -3.4837e-06,  5.4545e-06, -1.4670e-06, -8.0337e-07, -2.1510e-06,\n",
      "         2.1577e-06,  4.3727e-07, -1.4287e-06,  1.1826e-06, -2.1188e-06,\n",
      "        -3.3544e-07,  1.8362e-06, -9.3058e-08,  1.0892e-06,  1.8454e-06,\n",
      "        -1.0780e-06, -7.0842e-07, -9.3745e-07,  6.6255e-07,  4.3085e-07,\n",
      "         1.6371e-06,  2.3355e-06,  1.7855e-06, -1.8910e-06,  2.7480e-06,\n",
      "         2.5146e-06,  2.5274e-06,  1.0039e-06,  9.0635e-08, -2.1157e-06,\n",
      "         1.3176e-06,  8.7725e-08,  7.7819e-07,  3.4542e-07, -9.9785e-07,\n",
      "         1.0557e-06, -2.2644e-06, -1.1253e-06,  8.2906e-07, -1.5282e-06,\n",
      "        -7.6601e-07, -4.9080e-06,  2.4010e-06,  2.9341e-06,  7.8060e-07,\n",
      "        -3.1927e-06, -1.4445e-06,  9.2809e-08,  1.4812e-07,  2.8781e-06,\n",
      "        -2.3408e-06,  3.7149e-06,  8.4850e-07, -1.6123e-06, -3.1077e-07,\n",
      "        -1.2374e-06,  2.1295e-06, -1.2642e-06, -2.1996e-06, -2.2431e-06,\n",
      "        -1.1182e-06, -1.0162e-06,  1.2346e-06,  2.5730e-06, -9.4663e-07,\n",
      "        -1.0953e-06, -7.6031e-07, -1.1409e-06, -1.4295e-06,  2.1025e-06,\n",
      "        -4.7773e-06, -2.0194e-06,  3.6813e-07, -5.5711e-07,  1.4511e-06,\n",
      "         3.7834e-06, -1.0140e-06,  3.8500e-07,  3.7231e-06,  9.2018e-07,\n",
      "         2.5603e-07, -1.0623e-07, -5.1991e-07,  4.2414e-07,  1.3366e-06,\n",
      "        -2.7779e-06,  1.2784e-06,  2.6877e-06, -5.1046e-07, -1.9838e-06,\n",
      "        -9.6049e-07, -2.3229e-06, -2.1258e-06, -2.6236e-07, -2.2535e-07,\n",
      "        -2.3578e-06, -5.3410e-07, -8.7266e-07, -1.3829e-06,  3.7699e-07,\n",
      "        -1.2886e-06,  3.9206e-07,  1.3074e-06,  1.1403e-06,  1.7374e-08,\n",
      "        -2.7335e-06, -6.2782e-08,  3.9674e-07,  3.1109e-06,  2.0213e-06,\n",
      "         4.9542e-07, -2.0525e-06, -1.7810e-06,  3.2377e-06,  9.0642e-07,\n",
      "        -1.2879e-06, -4.8496e-07,  2.0374e-07,  1.6565e-06, -1.4651e-06,\n",
      "         3.6166e-08,  1.5564e-06,  2.1211e-06,  6.4432e-07, -2.3744e-07,\n",
      "        -7.9577e-07, -3.5330e-06, -7.7897e-07,  3.4252e-06,  2.0421e-06,\n",
      "        -3.3600e-06,  2.5230e-06, -4.2481e-06,  4.0061e-07,  1.5703e-06,\n",
      "         7.1090e-09,  1.3390e-06, -8.3167e-08, -1.8032e-06,  4.0219e-07,\n",
      "         1.3329e-06, -1.3808e-07,  1.8365e-06, -8.2305e-07, -1.0689e-06,\n",
      "         1.5872e-06,  2.3306e-06,  2.2624e-06, -2.4609e-06, -6.6286e-07,\n",
      "         1.2614e-06,  3.8658e-06, -9.9177e-08, -1.1866e-06, -3.3067e-07,\n",
      "         2.2487e-06, -2.5046e-06,  1.9726e-06, -1.8479e-06, -1.1840e-07,\n",
      "         6.3923e-07, -1.5462e-06, -2.1113e-06, -5.7508e-07, -4.6151e-06,\n",
      "        -1.9132e-06,  1.4278e-07,  2.0492e-06,  9.0350e-07,  1.9984e-07,\n",
      "        -7.2597e-07, -3.5888e-06,  1.5088e-06, -9.2150e-07,  1.9068e-06,\n",
      "        -1.3785e-06,  3.2101e-06, -1.3265e-06, -2.7536e-07,  1.9582e-07,\n",
      "        -1.6487e-06,  1.7421e-07,  3.7199e-07, -8.5626e-07,  2.4808e-06,\n",
      "        -2.9012e-06,  7.9800e-07,  8.4748e-07,  1.9959e-06,  2.4537e-06,\n",
      "         5.8167e-07, -1.2430e-06,  2.6922e-06, -8.0140e-07, -3.7967e-08,\n",
      "        -2.4564e-07, -3.2236e-07, -4.1803e-06,  1.5950e-06, -1.3724e-06,\n",
      "         8.3778e-07, -1.8668e-06,  1.0974e-06,  1.2016e-07, -1.2041e-06,\n",
      "         1.6709e-06,  1.2513e-06, -3.8570e-07, -1.2864e-06, -6.9840e-07,\n",
      "         1.6555e-06, -2.3054e-08, -2.5222e-06,  2.2752e-06,  2.0050e-06,\n",
      "        -1.3818e-07,  2.1670e-06, -4.8295e-07,  1.1872e-06,  1.9224e-06,\n",
      "         8.6233e-07,  7.8595e-07,  1.5502e-07, -1.2688e-06,  1.9485e-06,\n",
      "        -2.0477e-06,  5.4883e-07, -3.5276e-07,  2.2726e-06,  1.4738e-06,\n",
      "        -9.4985e-07, -9.7019e-07, -1.1397e-06,  3.6368e-07, -9.0284e-07,\n",
      "         2.9087e-07, -3.4403e-07, -2.1252e-06, -2.6149e-06, -8.7115e-07,\n",
      "        -2.2108e-06,  1.2317e-06,  4.3150e-06,  1.4884e-06, -1.7209e-06,\n",
      "         1.7015e-06, -5.4631e-07, -4.9045e-07,  1.9008e-06, -5.6915e-07,\n",
      "         3.4626e-07,  2.8902e-06, -3.5212e-06, -1.9388e-06,  1.9291e-06,\n",
      "        -1.0070e-06,  1.7182e-06,  3.8878e-06,  1.4008e-06,  1.0325e-06,\n",
      "        -2.4756e-06, -1.4416e-06,  4.6871e-08, -3.4645e-06,  5.7593e-07,\n",
      "        -2.3453e-06, -3.4802e-07, -1.1134e-06, -9.2841e-07, -2.5862e-06,\n",
      "         6.7394e-07,  4.8424e-06, -9.2008e-07,  2.7995e-06, -1.1716e-06,\n",
      "         1.8237e-07, -1.8123e-06,  1.3599e-06,  1.9446e-06,  2.4015e-06,\n",
      "        -3.9751e-07,  3.8844e-06, -4.6986e-07,  2.0026e-06,  7.7870e-07,\n",
      "        -1.2947e-06, -2.8774e-06,  1.6894e-07, -2.1029e-06,  1.3011e-06,\n",
      "         2.4954e-06, -6.8682e-07, -1.6286e-06, -5.5776e-07,  2.9363e-07,\n",
      "         7.8014e-07,  1.2458e-07,  2.5964e-06, -2.4332e-06,  2.8064e-06,\n",
      "        -1.9973e-06, -7.3619e-07, -3.5761e-07,  2.0860e-06, -1.1144e-06,\n",
      "        -3.3779e-06,  5.5828e-07, -8.0564e-07,  5.7367e-07,  1.4634e-06,\n",
      "        -1.5186e-07,  1.2407e-06,  1.3697e-06, -5.4721e-07,  4.2731e-06,\n",
      "         2.4138e-06,  1.8745e-06, -1.8705e-07, -7.5025e-07,  3.1336e-06,\n",
      "        -5.5654e-06,  1.2486e-06,  2.2796e-06, -3.1475e-06, -3.7273e-06,\n",
      "        -1.7013e-06, -6.0481e-07,  4.2595e-07, -3.4916e-07, -1.3220e-06,\n",
      "         8.0304e-07,  2.5309e-07, -3.0170e-06,  2.1635e-06,  3.4663e-07,\n",
      "        -3.6203e-07,  4.4655e-07, -3.6202e-06,  2.8320e-08,  9.8480e-07,\n",
      "        -9.3847e-07, -3.0831e-06, -2.5517e-06,  2.9422e-07,  1.6517e-06,\n",
      "         1.2857e-06,  3.7303e-07,  3.9011e-06,  3.7169e-06, -1.6337e-06,\n",
      "        -3.2873e-06, -1.8943e-06,  1.8074e-06, -3.7210e-06,  2.8239e-06,\n",
      "        -1.8992e-06,  2.8858e-07,  1.2205e-06,  2.1088e-07,  2.7101e-06,\n",
      "        -1.7665e-06,  2.8784e-06, -4.5355e-07,  2.3387e-06, -1.4748e-06,\n",
      "        -7.3663e-07,  1.4450e-06,  1.0383e-06, -3.9954e-07, -2.5531e-06,\n",
      "         3.1947e-07,  1.3286e-06])), ('layer2.7.running_mean', tensor([ 2.0561e-02, -3.9812e-01, -5.6668e-01,  2.0151e-01,  3.5849e-01,\n",
      "         6.4142e-01, -6.1359e-01,  9.7347e-02, -2.4870e-01, -7.2698e-01,\n",
      "        -3.9135e-01, -4.3147e-02,  2.3604e-01, -9.5540e-03,  2.5987e-01,\n",
      "        -6.6835e-01, -3.5474e-01,  6.2070e-01,  7.7534e-01, -4.6275e-01,\n",
      "        -4.4271e-01,  1.0779e-02,  6.9068e-02, -1.7113e-02, -5.2173e-02,\n",
      "        -1.1669e-01,  1.5796e-03,  4.4763e-01,  7.8603e-02, -4.2333e-01,\n",
      "        -4.3830e-01,  7.2649e-01, -1.9892e-01, -1.2535e-01, -2.0835e-02,\n",
      "         5.2961e-01,  7.8718e-02, -2.7544e-01, -5.5774e-01,  5.8255e-01,\n",
      "         5.3997e-01, -4.8133e-01,  1.0542e-01,  9.6530e-01, -1.8559e-01,\n",
      "        -3.4111e-01, -6.7928e-01, -3.6885e-01,  1.2470e-01, -4.3906e-01,\n",
      "         7.2901e-01, -3.7759e-01, -1.7877e-01,  3.6836e-01,  4.1978e-01,\n",
      "         4.0067e-02,  7.0849e-01,  1.2771e-02,  2.9097e-01, -2.9096e-02,\n",
      "        -2.3129e-01,  2.4428e-01,  1.0561e-01,  3.9701e-01,  7.9801e-01,\n",
      "         8.4042e-02, -5.7515e-01, -1.0556e-01, -3.4503e-01,  1.1177e-01,\n",
      "         2.3699e-01, -5.5538e-01, -3.8165e-01,  7.3090e-02,  3.2771e-01,\n",
      "         5.8677e-01, -3.1864e-01, -2.8357e-01,  1.5159e-01,  1.0967e-01,\n",
      "         4.3185e-01, -8.7027e-01,  2.1783e-01, -3.8243e-03, -1.7278e-01,\n",
      "        -2.7165e-01,  7.6773e-01,  3.2468e-02, -2.9409e-01, -2.7112e-01,\n",
      "         6.0628e-01,  1.4727e-01, -4.4060e-01, -5.5349e-01,  4.5203e-01,\n",
      "        -3.9049e-01,  6.7253e-01,  1.8684e-01, -7.6727e-01, -6.9269e-01,\n",
      "         9.4555e-02, -1.5980e-01, -8.0548e-01,  4.7443e-01,  3.7556e-01,\n",
      "        -5.2514e-01,  1.9630e-01,  1.9827e-01, -4.2290e-01,  3.1400e-01,\n",
      "        -3.8969e-01,  7.4803e-02,  2.4556e-01, -2.9954e-01,  3.8654e-01,\n",
      "        -2.6927e-01,  8.0272e-02,  3.5457e-01,  2.1044e-01,  7.6723e-01,\n",
      "        -1.3994e-01,  1.1035e-01, -5.0117e-02, -5.1687e-01,  3.0118e-01,\n",
      "         8.9501e-01, -2.6484e-01,  1.2163e-01,  3.2525e-01, -3.7637e-01,\n",
      "         4.0732e-01, -2.1767e-01, -3.6287e-01,  2.9582e-01, -5.2840e-01,\n",
      "         3.1564e-01, -2.7584e-01, -4.1899e-01,  1.2483e-01,  2.8972e-03,\n",
      "         3.5571e-01,  7.7695e-02,  1.1611e-04,  4.0295e-01,  1.3652e-01,\n",
      "         5.0036e-01, -2.7427e-01, -5.9302e-01,  1.6635e-01, -5.0122e-01,\n",
      "         2.7983e-01,  5.0248e-01, -3.8664e-01, -6.7684e-01,  8.7108e-01,\n",
      "         4.3197e-01,  1.2047e-01, -4.5442e-01,  3.6255e-01,  1.8501e-01,\n",
      "         4.5743e-01, -3.0394e-01, -1.8597e-01,  6.3012e-01,  1.3327e-01,\n",
      "         2.6476e-01,  5.3833e-01, -7.6633e-01, -3.1597e-02,  2.4975e-01,\n",
      "         1.3489e-02,  4.1730e-01, -2.3312e-01,  4.4362e-01, -1.2870e-01,\n",
      "        -6.7023e-02, -3.9012e-01, -2.1042e-01, -2.3333e-01, -6.4018e-01,\n",
      "        -8.1699e-02, -5.0295e-01, -2.8909e-01, -1.1547e-01,  1.5830e-01,\n",
      "         9.3727e-02, -2.6396e-02,  1.0878e-01,  2.3415e-01, -2.9660e-01,\n",
      "         3.0267e-01,  3.8573e-01,  2.4977e-02,  6.7598e-01, -2.5171e-01,\n",
      "        -1.6267e-02, -4.7351e-01, -5.2907e-01, -3.1950e-01,  1.2430e-01,\n",
      "        -2.9762e-01,  2.1453e-01,  8.6246e-03,  3.6223e-02,  1.4687e-03,\n",
      "         2.6748e-01, -9.5236e-02, -3.2124e-01, -8.2026e-02,  5.0966e-01,\n",
      "        -7.3027e-01,  2.0551e-01,  2.0416e-01, -5.2364e-01,  5.7458e-02,\n",
      "        -2.0479e-01,  3.4642e-01,  1.4618e-01,  5.3878e-02,  6.5041e-01,\n",
      "        -2.4935e-01, -3.9125e-01,  3.9709e-02, -6.3788e-01, -5.3141e-01,\n",
      "         4.6995e-01,  4.3732e-01,  3.3759e-02, -3.7596e-01,  1.5982e-02,\n",
      "        -1.4340e-01,  5.6248e-01,  5.6339e-01,  1.4868e-01,  6.6587e-01,\n",
      "         1.3914e-01,  8.1393e-02,  5.8741e-01,  1.8276e-01, -4.6543e-01,\n",
      "        -4.7156e-01,  4.3345e-01, -6.2713e-01, -2.2549e-01, -1.3211e-01,\n",
      "         3.2067e-01, -5.6735e-01,  3.2059e-01, -9.3827e-02, -5.5018e-01,\n",
      "         1.8677e-01,  2.0093e-01, -1.9112e-01,  4.4527e-01, -6.8713e-01,\n",
      "        -2.4742e-01,  2.4378e-01, -6.4053e-01,  2.2807e-01, -3.6920e-01,\n",
      "         4.5672e-02,  5.9699e-01,  1.0379e-01, -2.0336e-03,  6.9373e-02,\n",
      "         8.0425e-01,  6.7945e-02,  5.5442e-01, -2.1876e-01, -5.4195e-01,\n",
      "        -1.2753e-01,  1.9349e-01, -6.9581e-04, -4.7966e-02,  2.4802e-01,\n",
      "         5.6845e-01, -4.3221e-01, -7.8548e-01,  4.2830e-01,  2.7022e-01,\n",
      "        -1.0103e+00, -2.6760e-01,  3.4138e-01, -9.0870e-02, -3.0567e-01,\n",
      "        -5.0221e-03, -9.1570e-01, -2.0950e-01,  5.6292e-01,  2.2495e-01,\n",
      "         1.4927e-01, -6.2809e-01, -3.0116e-01,  1.2138e-01,  5.3749e-01,\n",
      "        -3.7567e-01, -3.4492e-01,  1.9172e-01, -4.0440e-01, -2.3007e-03,\n",
      "        -2.3312e-02,  4.4186e-01, -4.8777e-02, -3.3702e-01, -1.1273e-01,\n",
      "        -1.5503e-01,  4.6396e-01, -2.1888e-01, -4.3138e-01,  2.2102e-01,\n",
      "         3.9275e-01,  9.0302e-02, -1.0177e-01, -2.1047e-01, -4.5571e-01,\n",
      "        -4.1242e-01,  1.3630e-01, -2.5912e-01,  3.9287e-01,  1.8205e-01,\n",
      "        -3.5826e-02,  2.0399e-01, -4.4033e-01,  1.5219e-01,  6.3932e-02,\n",
      "         3.2421e-01,  1.1999e-01, -2.7157e-01, -3.9963e-01, -6.3744e-01,\n",
      "        -3.9530e-01,  4.3877e-01, -7.5115e-01,  6.8810e-01, -4.7040e-01,\n",
      "         5.0477e-01,  4.2843e-01,  1.1417e+00, -1.4580e-01, -4.5432e-01,\n",
      "        -4.4614e-01, -2.7829e-01, -1.4770e-01,  2.0502e-01, -1.0325e-01,\n",
      "        -7.4358e-01,  2.2270e-01, -4.7038e-01,  1.0142e-01, -7.3011e-01,\n",
      "        -3.6486e-01, -7.3175e-01,  2.0115e-01, -3.0259e-01, -2.1691e-01,\n",
      "         3.7044e-01,  9.0289e-01, -1.9617e-01,  2.9266e-01, -8.0057e-02,\n",
      "        -7.2035e-01, -2.5448e-01,  2.7205e-01,  4.4777e-01,  8.3576e-02,\n",
      "         2.0735e-01,  5.9508e-01,  3.6500e-02,  5.6822e-01, -3.9118e-01,\n",
      "        -3.4110e-01,  6.7019e-02, -1.2968e-01,  6.5987e-01, -3.0301e-01,\n",
      "        -3.0021e-01,  2.9857e-01, -4.2334e-01,  6.4727e-01,  5.4234e-01,\n",
      "        -6.3102e-01,  5.3624e-01, -1.9583e-01,  6.2023e-02, -6.7667e-01,\n",
      "         2.4319e-01, -2.5515e-01,  6.0201e-01, -3.9935e-01, -4.2795e-01,\n",
      "        -1.9314e-01, -7.1009e-01,  4.6382e-03,  6.6017e-01, -5.1648e-01,\n",
      "         2.4265e-01,  7.9088e-02,  3.6126e-01,  3.6157e-01,  3.9408e-01,\n",
      "         4.4110e-01,  1.8925e-02, -9.6735e-01,  2.0716e-01,  1.7823e-01,\n",
      "        -1.7292e-01,  6.7378e-02, -3.5024e-01,  2.1258e-01, -2.0518e-01,\n",
      "         1.6670e-01, -4.1439e-01,  5.7902e-01, -9.3231e-01,  1.3658e-01,\n",
      "         2.2845e-01,  2.3994e-01,  5.7743e-01,  1.2414e-02,  2.3171e-01,\n",
      "        -6.8127e-01,  3.0890e-01, -1.9708e-01, -8.1716e-02,  7.1004e-01,\n",
      "         8.8629e-02,  4.7741e-01, -2.9178e-01, -3.9220e-01,  4.1080e-02,\n",
      "         1.2493e-01,  7.0599e-01, -7.8603e-01,  6.9128e-01, -3.0024e-01,\n",
      "        -5.9061e-01, -8.9399e-01,  2.3488e-01,  3.7041e-01, -7.4305e-02,\n",
      "         8.3628e-01,  1.5038e-01, -2.4161e-02,  6.7657e-01, -3.9945e-01,\n",
      "        -1.2422e-01,  2.6096e-01,  4.8961e-01,  5.7227e-01,  4.1828e-01,\n",
      "         4.4412e-02, -2.0821e-02, -5.6264e-01, -4.4415e-03, -5.8826e-01,\n",
      "        -4.8475e-01,  2.2859e-01, -1.4193e-01, -7.0400e-01,  3.5567e-01,\n",
      "        -2.2955e-01,  5.3215e-01, -8.4777e-01, -1.0492e-01,  1.9719e-01,\n",
      "        -2.5963e-01, -3.9037e-01,  2.0287e-01, -4.6128e-01, -4.3347e-01,\n",
      "        -1.9471e-01, -2.2920e-01,  1.0999e+00,  1.5777e-01, -3.1435e-01,\n",
      "        -7.3285e-02,  3.9101e-01,  1.5926e-01,  4.4140e-01, -1.7750e-01,\n",
      "        -4.4536e-01, -5.0514e-01, -5.4485e-01,  2.8891e-01,  5.9838e-01,\n",
      "         4.3435e-01, -1.8437e-01,  3.2577e-01,  3.3672e-01,  3.0466e-01,\n",
      "         6.0200e-01,  6.1761e-01, -3.4753e-01, -1.3121e-01, -7.5903e-02,\n",
      "        -2.5121e-01, -1.2126e-01, -2.6142e-01, -5.0734e-01, -2.0745e-01,\n",
      "         6.7797e-02,  6.3910e-01,  7.5510e-01,  2.3591e-02, -7.9037e-01,\n",
      "        -3.3183e-01,  5.2387e-01,  2.7451e-01, -6.3614e-01,  7.7103e-02,\n",
      "         3.7528e-01, -5.1928e-01])), ('layer2.7.running_var', tensor([0.5110, 0.7857, 0.3175, 0.6702, 0.1910, 0.7949, 0.5983, 0.4462, 0.6847,\n",
      "        0.6232, 0.7950, 0.4396, 0.7965, 0.4149, 0.8223, 0.2987, 0.3901, 0.2652,\n",
      "        0.3314, 0.4768, 0.2981, 0.5532, 0.5185, 0.1367, 0.4284, 0.3824, 0.7576,\n",
      "        0.5358, 0.4503, 0.3667, 0.3397, 0.5001, 0.3991, 0.4070, 0.6103, 0.3632,\n",
      "        0.3899, 0.5935, 0.2850, 0.7351, 0.6705, 0.2988, 0.5675, 0.5278, 0.3897,\n",
      "        0.4579, 0.4130, 0.4463, 0.4346, 0.5351, 0.5327, 0.4509, 0.4597, 0.6585,\n",
      "        0.4282, 0.1377, 0.4523, 0.5558, 0.2851, 0.3833, 0.2500, 0.6870, 0.5004,\n",
      "        0.2647, 0.6575, 0.2597, 0.2671, 0.6408, 0.7998, 0.7028, 0.6367, 0.6015,\n",
      "        0.6910, 0.6303, 0.5066, 0.5120, 0.1381, 0.3233, 0.3835, 0.6117, 0.8845,\n",
      "        0.8530, 0.6297, 0.2330, 0.3491, 0.2091, 0.8047, 0.3102, 0.5443, 0.4795,\n",
      "        0.4928, 0.3306, 0.3376, 0.5546, 0.5858, 0.5638, 1.0877, 0.2436, 0.4943,\n",
      "        0.2087, 0.3796, 0.4116, 0.6642, 0.6274, 0.6871, 0.5081, 0.6623, 0.4147,\n",
      "        0.4143, 0.2673, 0.7371, 0.1487, 0.3179, 0.4161, 0.2348, 0.4924, 0.4712,\n",
      "        0.4997, 0.4670, 0.5460, 0.7809, 0.5514, 0.2484, 0.4935, 0.2760, 0.7110,\n",
      "        0.4093, 0.4132, 0.7460, 0.4765, 0.6898, 0.7214, 0.3835, 0.2578, 0.3785,\n",
      "        0.7449, 0.4150, 0.6207, 0.5149, 0.7992, 0.3540, 0.4173, 0.6220, 0.8304,\n",
      "        0.5404, 0.3821, 0.3762, 0.6396, 0.5053, 0.3927, 0.6063, 0.5966, 0.5474,\n",
      "        0.4622, 0.3490, 0.6707, 0.2738, 0.6194, 0.4557, 0.4942, 0.4953, 0.4581,\n",
      "        0.4144, 0.3772, 0.1836, 0.6142, 0.5360, 1.0562, 0.6898, 0.7164, 0.7631,\n",
      "        0.3159, 0.2973, 0.4413, 0.5241, 0.5267, 0.7757, 0.3591, 0.4926, 0.3989,\n",
      "        0.9532, 0.7239, 0.6057, 0.5392, 0.7735, 0.6153, 0.8069, 0.7426, 0.4318,\n",
      "        0.6127, 0.4625, 0.9322, 0.3114, 0.5859, 0.7939, 0.6263, 0.8483, 0.4486,\n",
      "        0.3927, 0.2549, 0.4814, 0.3848, 0.1498, 0.4674, 0.4013, 0.6735, 0.6807,\n",
      "        0.7453, 0.4008, 0.3572, 0.5287, 0.5331, 0.6876, 0.3012, 0.3089, 0.5248,\n",
      "        0.5166, 0.6808, 0.4786, 0.4404, 0.7012, 0.3156, 0.3851, 1.0144, 0.5087,\n",
      "        0.7655, 0.5626, 0.5215, 0.9344, 0.3377, 0.1793, 0.5303, 1.0394, 0.5578,\n",
      "        0.5280, 0.2149, 0.5825, 0.5792, 0.6712, 0.5312, 0.5513, 0.4418, 0.1538,\n",
      "        0.4385, 0.5768, 0.2936, 1.0603, 0.8786, 0.3682, 0.8207, 0.6781, 0.4114,\n",
      "        0.2893, 0.2763, 0.4204, 0.4715, 0.6090, 0.3720, 0.6593, 0.3311, 0.5559,\n",
      "        0.4392, 0.5268, 0.5670, 0.4654, 0.7038, 0.7682, 0.5130, 0.4542, 0.7145,\n",
      "        0.5811, 0.2233, 0.5681, 0.1121, 0.6524, 0.3246, 0.4257, 0.4118, 1.1339,\n",
      "        0.2941, 0.5788, 0.7388, 0.5145, 0.4516, 0.5642, 0.4940, 0.4345, 0.6946,\n",
      "        0.5051, 0.4118, 0.3856, 0.7062, 0.4347, 0.1548, 0.2762, 0.3609, 0.5323,\n",
      "        0.5604, 0.7086, 0.6020, 0.4861, 0.8127, 1.0074, 0.4941, 0.6419, 0.4767,\n",
      "        0.3413, 0.4510, 0.2875, 0.7759, 0.6855, 0.6843, 0.4963, 0.4168, 0.5747,\n",
      "        0.9159, 0.4551, 0.3204, 0.6014, 0.5937, 0.3219, 0.3415, 0.7114, 0.3238,\n",
      "        0.4060, 0.2784, 0.4428, 0.3258, 0.1688, 0.4168, 0.1564, 0.3694, 0.5203,\n",
      "        0.3229, 0.3971, 0.4553, 0.2627, 0.5095, 0.7674, 0.3815, 0.4006, 0.2867,\n",
      "        0.8579, 0.5839, 0.9115, 0.7748, 0.3487, 0.4180, 0.5732, 0.5671, 0.6619,\n",
      "        0.5578, 0.8208, 0.4049, 0.3362, 0.5939, 0.8373, 0.3222, 1.1707, 0.9747,\n",
      "        0.8920, 0.3179, 0.4650, 0.5324, 0.4091, 0.4850, 0.3324, 0.4276, 0.3749,\n",
      "        0.6419, 0.5407, 0.5654, 0.4337, 0.4103, 0.5741, 0.5120, 0.4175, 0.5344,\n",
      "        0.8767, 0.5419, 0.7009, 0.4923, 0.5789, 0.8722, 0.8050, 0.3411, 0.5017,\n",
      "        0.5481, 0.3398, 0.3757, 0.4991, 0.6205, 0.6710, 0.6537, 0.8669, 0.4456,\n",
      "        0.9448, 0.4310, 1.1059, 0.4435, 0.3676, 1.1190, 0.5869, 0.3112, 0.6264,\n",
      "        0.5596, 0.3509, 0.4648, 0.2931, 0.5504, 0.4517, 0.5475, 0.2610, 0.5219,\n",
      "        0.6326, 0.2855, 0.2681, 0.3538, 0.4389, 0.3508, 0.5531, 0.1302, 0.5356,\n",
      "        0.6508, 0.3662, 0.5732, 0.4617, 0.4546, 0.5004, 0.3589, 0.9063, 0.6628,\n",
      "        0.3923, 0.5085, 0.3961, 0.2502, 0.1715, 1.1997, 0.4479, 0.4965, 0.3593,\n",
      "        0.3984, 0.5078, 0.5128, 0.4159, 0.4246, 0.5815, 0.5621, 0.4243, 0.4011,\n",
      "        0.6896, 0.4422, 0.5562, 0.3221, 0.5293, 0.4595, 0.6225, 0.7070, 0.8346,\n",
      "        0.4693, 0.1449, 0.2578, 0.3055, 0.4511, 0.2241, 0.2153, 0.3812, 0.5881,\n",
      "        0.4921, 0.9474, 0.4675, 0.4949, 0.3882, 0.7921, 0.2850, 0.5212, 0.4171,\n",
      "        0.7754, 0.3103, 0.3713, 0.4362, 0.3280, 0.3121, 0.4167, 0.8534, 0.2776,\n",
      "        0.4286, 0.7044, 0.2503, 0.5105, 0.2502, 0.6951, 0.2489, 0.3903, 0.6526,\n",
      "        0.3559, 0.5744, 0.3542, 0.4461, 0.6665, 0.6031, 0.3651, 0.7750, 0.2326,\n",
      "        0.6459, 0.5507, 1.0174, 0.6476, 0.2988, 0.6550, 0.5729, 0.2341])), ('layer2.7.num_batches_tracked', tensor(309)), ('layer3.0.weight', tensor([[[[ 0.0267]],\n",
      "\n",
      "         [[ 0.0229]],\n",
      "\n",
      "         [[-0.0318]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[-0.0340]],\n",
      "\n",
      "         [[ 0.0519]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0142]],\n",
      "\n",
      "         [[-0.0176]],\n",
      "\n",
      "         [[-0.0497]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0157]],\n",
      "\n",
      "         [[-0.0285]],\n",
      "\n",
      "         [[-0.0647]]],\n",
      "\n",
      "\n",
      "        [[[-0.0229]],\n",
      "\n",
      "         [[ 0.0085]],\n",
      "\n",
      "         [[-0.0331]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[-0.0423]],\n",
      "\n",
      "         [[ 0.0647]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0094]],\n",
      "\n",
      "         [[ 0.0361]],\n",
      "\n",
      "         [[ 0.0700]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0911]],\n",
      "\n",
      "         [[-0.0264]],\n",
      "\n",
      "         [[ 0.0405]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0143]],\n",
      "\n",
      "         [[ 0.0238]],\n",
      "\n",
      "         [[ 0.0010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0234]],\n",
      "\n",
      "         [[-0.0148]],\n",
      "\n",
      "         [[ 0.0203]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0955]],\n",
      "\n",
      "         [[-0.0320]],\n",
      "\n",
      "         [[-0.0200]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0519]],\n",
      "\n",
      "         [[-0.0089]],\n",
      "\n",
      "         [[-0.0130]]]])), ('layer3.1.weight', tensor([0.9983, 1.0556, 0.9982, 0.9528, 1.0221, 1.0866, 0.9698, 1.0030, 1.0155,\n",
      "        1.0062, 1.0055, 0.9929, 0.9821, 1.0434, 0.9928, 0.9226, 1.0248, 0.9496,\n",
      "        0.9778, 1.0205, 1.0496, 1.1121, 0.9592, 1.0088, 0.9201, 0.9992, 1.0163,\n",
      "        1.0057, 1.0555, 1.0020, 0.9846, 0.8819, 1.0263, 1.0061, 0.9900, 1.0798,\n",
      "        1.0220, 0.9876, 1.0593, 1.0013, 0.9451, 1.0269, 1.0105, 1.0283, 1.0203,\n",
      "        1.0032, 0.9709, 1.0130, 1.0551, 0.9641, 1.0082, 0.9822, 0.9666, 0.9441,\n",
      "        0.9884, 1.0105, 0.9548, 0.9116, 0.9414, 1.0020, 0.9548, 1.0253, 1.0205,\n",
      "        0.9632, 1.0128, 0.9732, 0.9980, 0.8911, 0.9668, 0.8952, 0.9773, 1.0241,\n",
      "        1.0390, 0.9801, 1.0015, 1.0004, 0.9072, 1.0241, 0.9920, 0.9682, 0.9988,\n",
      "        1.0104, 1.0146, 1.0377, 0.9910, 1.0058, 1.0038, 1.0171, 0.9985, 0.9684,\n",
      "        1.0551, 0.9555, 1.0055, 1.1152, 1.1069, 0.9997, 0.9792, 1.0500, 0.9054,\n",
      "        1.0291, 1.0462, 0.9056, 1.0836, 1.0031, 0.9740, 1.0226, 1.0037, 1.0359,\n",
      "        1.0137, 0.9627, 1.0280, 1.0282, 1.0016, 1.0021, 1.0134, 1.0761, 1.0491,\n",
      "        0.9449, 1.0032, 0.9084, 0.9762, 0.9357, 0.9946, 0.9355, 0.9858, 1.0032,\n",
      "        1.0480, 0.9969, 0.9801, 0.9295, 1.1751, 1.0174, 1.0328, 1.0634, 1.0063,\n",
      "        0.9866, 1.0037, 1.0224, 1.0317, 1.0012, 0.9646, 0.9366, 1.0754, 0.9456,\n",
      "        1.0275, 1.0011, 1.0315, 1.0077, 1.0780, 0.9328, 1.0383, 1.1330, 1.0173,\n",
      "        0.8729, 0.9966, 0.9751, 0.9924, 1.0241, 1.0425, 1.0805, 1.0019, 1.0099,\n",
      "        1.0063, 0.9311, 0.9921, 0.9484, 0.9743, 0.9992, 1.0177, 1.0393, 0.9496,\n",
      "        0.9918, 0.9878, 1.0153, 0.9637, 0.9686, 1.0009, 0.9884, 0.9746, 0.9652,\n",
      "        1.0532, 1.0008, 1.0377, 1.1210, 0.9963, 1.0343, 1.0354, 1.0111, 0.9437,\n",
      "        1.0298, 0.9808, 1.0116, 1.0203, 0.9187, 0.9750, 1.0058, 0.9708, 0.9202,\n",
      "        0.9689, 1.0083, 1.0277, 0.9619, 0.9647, 1.1241, 1.0251, 0.9888, 1.0152,\n",
      "        1.0232, 1.0175, 0.9829, 0.8961, 0.9825, 1.0164, 1.0447, 1.0112, 0.9861,\n",
      "        1.0123, 1.0142, 0.9240, 0.9849, 1.0318, 0.9244, 0.9914, 1.0264, 0.9426,\n",
      "        1.0216, 0.9165, 1.0154, 1.0148, 0.9890, 0.9992, 1.0280, 0.9859, 1.0089,\n",
      "        1.0010, 0.8988, 1.0041, 0.9533, 1.1198, 1.0034, 1.0279, 0.9978, 1.0231,\n",
      "        0.9892, 0.9929, 0.9973, 0.9489, 0.9869, 1.0291, 0.9909, 0.9950, 0.9878,\n",
      "        1.0326, 1.0164, 0.9885, 1.0995])), ('layer3.1.bias', tensor([ 0.0445,  0.0327,  0.0626, -0.0314, -0.0125, -0.0631,  0.0337, -0.0273,\n",
      "        -0.0368, -0.0036, -0.0078, -0.0305, -0.0305,  0.0165, -0.0823, -0.0380,\n",
      "         0.0196,  0.0326,  0.0080,  0.0523, -0.0671, -0.1238, -0.0258,  0.0205,\n",
      "         0.0245,  0.0580,  0.0190, -0.0004,  0.0087,  0.0242, -0.0324,  0.0147,\n",
      "         0.0390, -0.0595, -0.0807, -0.0538,  0.0394,  0.0036, -0.0267, -0.0247,\n",
      "        -0.0138, -0.0182,  0.0177,  0.0060,  0.0590, -0.0015, -0.0368, -0.0629,\n",
      "         0.0077, -0.0392,  0.0111,  0.0134, -0.0577,  0.0292,  0.0247,  0.0388,\n",
      "         0.0341, -0.1017, -0.0665,  0.0219, -0.0128,  0.0209,  0.0486,  0.0643,\n",
      "        -0.0124,  0.0232, -0.0348, -0.1248, -0.0182, -0.0039,  0.0060,  0.0444,\n",
      "        -0.0101,  0.0270, -0.0045,  0.0555, -0.0501,  0.0116, -0.0249, -0.0253,\n",
      "         0.0474, -0.0039, -0.0713, -0.0752, -0.0020, -0.0034, -0.0082, -0.0056,\n",
      "         0.0501,  0.0466,  0.0353, -0.0061,  0.0262, -0.0673, -0.0565, -0.0109,\n",
      "        -0.0015,  0.0531,  0.0175, -0.0108,  0.0565, -0.0110, -0.0722, -0.0030,\n",
      "        -0.0454,  0.0423,  0.0833, -0.0007, -0.0212,  0.0126,  0.0618,  0.0232,\n",
      "        -0.0198, -0.0359, -0.0293, -0.0337, -0.0418,  0.0173,  0.0114,  0.0065,\n",
      "        -0.0236,  0.0034, -0.0006, -0.0372, -0.0220,  0.0118, -0.0254,  0.0113,\n",
      "        -0.0197, -0.0304, -0.0200, -0.0495,  0.0411,  0.0355,  0.0045,  0.0240,\n",
      "        -0.0111, -0.0050, -0.0077, -0.0080, -0.0161,  0.0098,  0.0148, -0.0625,\n",
      "        -0.0492,  0.0044,  0.0080,  0.0377, -0.0720, -0.0729, -0.0017, -0.0650,\n",
      "         0.0139, -0.0880, -0.0023,  0.0318, -0.0145,  0.0229, -0.0391, -0.0553,\n",
      "         0.0327,  0.0339, -0.0208, -0.0261,  0.0279, -0.0184,  0.0129, -0.0058,\n",
      "        -0.0233,  0.0427, -0.0340, -0.0244,  0.0439,  0.0501,  0.0483,  0.0316,\n",
      "         0.0149,  0.0058, -0.0088, -0.0164,  0.0217, -0.0398,  0.0671,  0.0701,\n",
      "        -0.0530, -0.0120, -0.0092,  0.0190, -0.0420, -0.0197,  0.0075,  0.0003,\n",
      "         0.0278,  0.0284, -0.0416, -0.0381,  0.0423, -0.0183,  0.0200,  0.0316,\n",
      "         0.0173, -0.0721, -0.0505, -0.1034, -0.0056,  0.0431,  0.0122,  0.0178,\n",
      "        -0.0789, -0.0258,  0.0144, -0.0569,  0.0375,  0.0209, -0.0113,  0.0027,\n",
      "         0.0101,  0.0139, -0.1153, -0.0004, -0.0129, -0.0289,  0.0257,  0.0480,\n",
      "        -0.0642, -0.0149, -0.0058,  0.0510, -0.0168, -0.0425, -0.0257,  0.0187,\n",
      "        -0.0961,  0.0207, -0.0206,  0.0122, -0.0180,  0.0172, -0.0541, -0.0784,\n",
      "         0.0411, -0.0059, -0.0307, -0.0261, -0.0046,  0.0049,  0.0572,  0.0238,\n",
      "         0.0415, -0.0161, -0.0007, -0.0282,  0.0099,  0.0285,  0.0346, -0.0056])), ('layer3.1.running_mean', tensor([-1.2010e+00, -8.7470e-01, -5.9037e-01, -1.2776e+00,  6.6218e-01,\n",
      "         7.7736e-01, -6.7250e-01,  4.4424e-01,  3.2745e-01,  7.2502e-01,\n",
      "         6.8407e-01,  5.7921e-01, -3.3922e-01,  4.3823e-01,  2.7676e-01,\n",
      "         1.4223e-01, -9.4084e-01, -6.9926e-01,  5.8231e-01, -3.2006e-01,\n",
      "         5.0512e-01,  7.4678e-01,  9.4901e-01, -4.6585e-01, -5.1341e-01,\n",
      "        -1.5955e-01,  4.9120e-01,  1.0044e+00, -3.6275e-01, -7.6845e-01,\n",
      "        -4.1386e-01, -5.4063e-01,  2.5534e-01,  2.4341e-02, -4.1735e-01,\n",
      "         3.0742e-01,  3.1306e-01, -3.8027e-01,  7.1752e-02,  6.7901e-01,\n",
      "         6.0475e-01, -5.6680e-01,  6.0408e-01,  1.4656e-01, -8.0509e-02,\n",
      "         1.7582e-01,  4.4366e-01,  3.8140e-02,  3.7637e-01, -3.4494e-01,\n",
      "        -2.0701e-01, -7.7352e-01,  8.0039e-02, -5.3330e-02, -2.1011e-01,\n",
      "         2.8734e-01, -7.8393e-01, -6.4176e-01, -3.4543e-02,  2.8951e-01,\n",
      "        -2.2861e+00,  4.7197e-01, -3.9748e-01, -8.6064e-01,  1.0544e+00,\n",
      "        -3.1801e-01, -1.1620e-01, -1.2354e+00,  3.0109e-01, -1.5450e+00,\n",
      "         2.2430e-03,  5.7990e-01, -6.9137e-01, -3.3837e-01,  6.6468e-02,\n",
      "        -7.9593e-01, -8.9937e-01, -8.4967e-02, -8.6497e-01, -2.5497e-01,\n",
      "        -6.0045e-02,  1.5847e-02,  7.0104e-01,  7.9978e-01, -9.8210e-02,\n",
      "         5.5084e-01, -5.5180e-03, -8.4796e-01,  2.3391e-01, -5.4517e-01,\n",
      "        -1.3172e-01, -6.1769e-01,  4.8389e-01,  5.3489e-01,  4.7596e-02,\n",
      "         6.1012e-01, -1.9589e+00, -3.0346e-01, -4.7950e-01, -1.1948e+00,\n",
      "         1.8538e-01, -5.6723e-01, -7.3194e-02,  7.4977e-01,  1.6089e-02,\n",
      "        -2.4567e-01, -5.9785e-01,  2.8634e-01, -4.3428e-01,  4.5857e-02,\n",
      "         4.6159e-02, -7.9577e-01,  8.4072e-01, -4.4174e-01, -1.5841e-01,\n",
      "         2.4171e-02,  1.1629e-02, -1.1965e+00,  5.6697e-01, -8.4035e-01,\n",
      "         6.2251e-02, -5.1140e-01,  3.7301e-01, -5.4568e-01,  1.9671e-01,\n",
      "         3.0433e-01,  6.6124e-01,  2.9819e-01,  5.7097e-01, -1.1824e+00,\n",
      "         3.9381e-01,  5.4413e-01,  3.8953e-01, -3.6777e-01, -1.4263e-01,\n",
      "         1.9294e-01,  3.9431e-01,  1.6945e-01,  5.7654e-01,  7.1297e-01,\n",
      "        -7.3244e-01, -1.4631e+00, -1.4474e+00, -7.8699e-01,  1.5517e+00,\n",
      "         7.7350e-01,  4.9527e-01,  9.8366e-02,  1.1069e+00, -5.2818e-01,\n",
      "         1.1843e+00,  6.1589e-01,  5.8616e-01, -9.2409e-01,  8.6393e-01,\n",
      "        -1.0309e+00,  1.0542e-02,  1.4919e-01,  7.1552e-01,  8.7398e-01,\n",
      "        -4.5208e-01,  1.1608e+00,  8.0945e-01, -7.9132e-01, -6.9550e-01,\n",
      "         7.1833e-01,  4.8083e-01,  4.6128e-01, -1.0755e+00,  8.7651e-02,\n",
      "        -7.3801e-01,  1.3554e+00, -5.5118e-01, -5.5914e-02, -7.5489e-01,\n",
      "        -3.5092e-02,  2.7653e-01, -8.5152e-01, -5.8326e-01, -8.9001e-02,\n",
      "         2.0542e-01,  8.2022e-01, -1.5352e+00, -1.5219e+00,  5.4621e-01,\n",
      "        -8.6717e-01,  2.9945e-01, -2.5802e-01, -1.5041e+00, -2.7192e-01,\n",
      "         1.2622e+00, -7.8465e-01, -9.9203e-01, -8.4865e-01,  6.1419e-01,\n",
      "         7.8804e-02, -1.6622e+00, -3.9232e-01,  5.8737e-01, -4.7688e-01,\n",
      "        -2.6761e-01, -8.6750e-01, -7.6175e-01,  5.7739e-01, -2.8649e-01,\n",
      "        -5.6440e-01,  6.7406e-01, -1.2316e-01, -2.6294e-01, -5.1733e-01,\n",
      "        -7.9913e-01,  9.6187e-01, -1.4108e+00,  2.4498e-01,  2.9638e-01,\n",
      "        -4.9141e-01,  2.8181e-01, -1.7879e-01, -4.0796e-01,  2.1864e-01,\n",
      "         6.5830e-01, -9.8563e-02, -8.0185e-01, -3.3562e-01, -1.6472e-01,\n",
      "         2.9547e-01, -5.6096e-01, -4.9064e-01,  3.5079e-01,  8.9799e-01,\n",
      "         6.3994e-01,  2.0294e-02, -1.0580e-01,  1.6182e-01,  3.4997e-01,\n",
      "        -4.6742e-01, -1.6839e-01, -3.5786e-01, -1.3750e-01, -3.6481e-01,\n",
      "        -1.8371e-01,  8.3094e-01,  7.1952e-01, -1.3969e-01,  1.8107e-01,\n",
      "         2.5888e-01, -5.8296e-01,  8.5843e-02,  3.7527e-02,  8.3724e-01,\n",
      "         3.4967e-01, -3.0608e-01,  1.8194e-01, -1.6232e+00, -2.4062e-01,\n",
      "        -1.5736e+00])), ('layer3.1.running_var', tensor([300.2179,  35.6300,  23.8663,  33.2572,  48.2472,  54.8969,  25.3409,\n",
      "         40.8286,  30.2894,  10.2455,   4.3577,  47.9929,  25.1937,  16.8887,\n",
      "         62.3600,  38.9609,  20.5857, 122.7439,   9.9470,  10.7376,  41.1747,\n",
      "         51.1938,  46.9392,  34.4265,  73.5863,  21.2774,  21.1778,  11.1333,\n",
      "          7.7729,  37.7047,  26.0506,  28.3121,  25.8293,  52.0638, 198.7185,\n",
      "         51.9296,  11.1248,  16.4629,  97.6677,  10.3712,  26.1927,  54.7674,\n",
      "         17.2602,  17.1887,   6.6564,   8.8061,  39.8311,   8.9558,  25.6418,\n",
      "         38.8350,  42.7652,  26.6047,  64.9699,  32.3938,  19.9874,   7.8766,\n",
      "         22.0807,  57.3677,  39.7627,   8.8906, 112.0580,  25.2053,  17.4186,\n",
      "        124.9563,  14.3217,  17.0352,  73.6248,  69.1041,  21.8689,  76.4009,\n",
      "         27.3715,  17.5794,   4.6980,  22.5098,  30.5981,  11.6751,  38.2523,\n",
      "          7.8618,   3.3791,  62.3988,  24.4140,   6.3963,  52.0350,  58.5423,\n",
      "         25.5812,  37.8099,  15.7522,   4.2310,  13.1372,  11.6423,  17.3078,\n",
      "         23.4465,   5.2084,  64.4510,  43.9223,   4.4256,  39.3121,  19.0008,\n",
      "         28.0441,   8.9055,  24.8255,  26.4245,  43.9061,   8.7230,  84.1455,\n",
      "         11.2261,  29.2334,  14.6637,  36.4479,  24.6257,   9.8764,   6.6046,\n",
      "          7.3665,  29.8733,  24.5543,  27.8057,  12.2724, 114.1193,   9.9069,\n",
      "         38.7473,  25.0044,  38.7956,  13.7105,  19.3615,  57.2926,   9.0753,\n",
      "         35.4586,  10.9516,  27.3948,  21.3240, 183.2516,  46.9284,  30.5059,\n",
      "          8.4710,   9.9077,  14.1961,  24.7247,  27.6054,   8.9560, 102.6773,\n",
      "         13.0332,  53.2265,  11.7723,  49.5697,  49.3442,   6.0249,   6.1513,\n",
      "          7.9841,  27.8213,  46.9039,  20.6610,  40.3232,  12.9308,  34.9266,\n",
      "          9.8672, 145.8146,  25.3695,  13.2970,  31.8665,  33.0630,  22.6044,\n",
      "         10.9746,   7.4435,  40.2594,  26.1221,  50.7731,  12.5801,  10.9752,\n",
      "          4.4949,   7.0274,  32.7640,  85.0212,  13.7108,  16.0934, 127.3766,\n",
      "         26.3920,  12.2301, 192.6328,  25.0047,  70.7587,  12.5647,  18.0171,\n",
      "        182.1471, 416.1231,  62.3343,  21.3230,  29.2742,  25.8847,  37.0716,\n",
      "          6.2003,   7.9937,   4.3674,  17.6007,  85.6357,  27.9795,   9.4299,\n",
      "         27.9379,  29.4612,  37.1643,   6.1023,  18.1130,  39.4001, 125.9973,\n",
      "         54.6763,   9.6733,   9.2593,  15.4593,  11.6861, 157.5702,  27.7275,\n",
      "         35.5398,  15.3961, 134.4569,  26.0219,  21.0981,   9.1823,   5.8615,\n",
      "         40.4919,  70.7900,   8.4111,  42.7774,  30.1086, 234.0309,  11.8249,\n",
      "         34.8986,  28.0644,  15.3833,  18.2980,  41.6545,  10.9157,  29.7957,\n",
      "          5.7637,  75.7567,  75.8165,  34.2776,  25.5054,  81.3832,   5.9527,\n",
      "         54.2433,  78.2975,  20.4829,   6.4917,  10.0632,  69.7618,  17.2713,\n",
      "          8.5576,  30.8211,  34.4066,  12.7847,   8.4333,   8.3686,  25.0215,\n",
      "          9.7172, 110.0781,  21.8026,  10.4771])), ('layer3.1.num_batches_tracked', tensor(309)), ('layer3.3.weight', tensor([[[[-1.7440e-02,  1.0308e-02,  3.6708e-03],\n",
      "          [ 5.0209e-04, -9.5244e-03, -3.1567e-03],\n",
      "          [ 1.5646e-03,  2.7018e-02, -5.5187e-02]],\n",
      "\n",
      "         [[-2.4653e-02,  3.4428e-03,  1.3628e-02],\n",
      "          [ 6.1888e-03,  1.9932e-02,  1.2646e-02],\n",
      "          [-1.2497e-02,  1.3291e-02, -7.9161e-03]],\n",
      "\n",
      "         [[ 2.6894e-03, -2.5329e-02, -2.3873e-02],\n",
      "          [-5.9924e-03, -6.3501e-03,  1.7237e-02],\n",
      "          [-6.7244e-03, -2.5314e-02,  4.6041e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.4302e-03,  8.8978e-04,  4.5997e-03],\n",
      "          [-3.6165e-03, -1.1594e-02,  1.4265e-02],\n",
      "          [ 3.1185e-03, -1.3937e-02,  9.0721e-02]],\n",
      "\n",
      "         [[ 2.5637e-03, -9.5781e-04,  5.5382e-03],\n",
      "          [-2.1959e-02, -7.2529e-04,  2.3716e-03],\n",
      "          [ 2.0297e-02,  3.1210e-02,  2.3010e-02]],\n",
      "\n",
      "         [[ 3.1998e-03, -1.6934e-02, -2.1872e-02],\n",
      "          [-1.0045e-02, -9.6069e-03,  7.8222e-02],\n",
      "          [ 1.9181e-02, -6.4095e-03,  8.4071e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6195e-03,  4.4492e-03,  1.4727e-02],\n",
      "          [-1.1773e-02, -2.3676e-02, -2.5330e-02],\n",
      "          [ 9.9304e-03,  1.3661e-03, -2.9301e-02]],\n",
      "\n",
      "         [[-8.9214e-03,  1.9084e-03, -2.0380e-02],\n",
      "          [ 5.8881e-03, -2.5584e-02,  3.4824e-03],\n",
      "          [-2.0589e-04, -3.2801e-02,  2.2592e-02]],\n",
      "\n",
      "         [[ 9.9955e-03, -8.4601e-03, -3.4405e-03],\n",
      "          [ 1.0942e-02,  1.3133e-02,  1.7246e-03],\n",
      "          [ 1.8696e-02,  1.0877e-02,  1.8115e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1741e-03, -1.2002e-02, -1.2292e-02],\n",
      "          [ 1.5586e-02,  2.3083e-02,  5.0157e-03],\n",
      "          [ 6.2842e-03,  3.0174e-02,  3.6544e-03]],\n",
      "\n",
      "         [[-1.9518e-02,  3.0085e-03,  9.1937e-03],\n",
      "          [ 1.3623e-03, -9.9670e-03, -1.4622e-02],\n",
      "          [-1.4147e-02,  1.3946e-02,  2.2028e-02]],\n",
      "\n",
      "         [[ 5.5358e-03, -1.8377e-02,  5.5876e-03],\n",
      "          [-1.5187e-02, -1.2678e-02,  4.6874e-02],\n",
      "          [-1.3908e-02,  1.1588e-02,  3.2611e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7887e-04,  1.3472e-02,  6.9584e-03],\n",
      "          [-1.2464e-02, -5.8127e-02,  7.9519e-02],\n",
      "          [ 3.8890e-04,  5.3948e-03, -9.0440e-02]],\n",
      "\n",
      "         [[-1.4065e-02, -4.0429e-02,  4.4034e-02],\n",
      "          [-7.6605e-03,  6.5826e-03, -8.9938e-02],\n",
      "          [-1.4989e-02, -2.1772e-02,  2.7675e-02]],\n",
      "\n",
      "         [[-1.1880e-02, -9.1810e-03,  2.3594e-02],\n",
      "          [-9.5618e-03, -3.0486e-02,  6.2890e-02],\n",
      "          [-1.1746e-02,  3.5642e-02, -2.6521e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5770e-02,  8.5071e-03,  3.3101e-02],\n",
      "          [ 8.6341e-03,  2.5449e-03, -4.1482e-02],\n",
      "          [ 2.0286e-02, -2.4401e-02,  5.1009e-02]],\n",
      "\n",
      "         [[ 1.9804e-03, -1.0872e-02,  6.7378e-03],\n",
      "          [-1.5788e-02, -3.4871e-02,  3.2857e-02],\n",
      "          [-1.0374e-02, -1.2154e-02,  2.8335e-02]],\n",
      "\n",
      "         [[ 1.9357e-02, -1.7031e-02,  7.2768e-02],\n",
      "          [ 1.4485e-03,  8.9397e-03, -6.1673e-03],\n",
      "          [ 1.0809e-02, -1.0974e-02,  1.5758e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.1151e-03, -4.0567e-03,  1.6328e-02],\n",
      "          [ 9.4475e-03,  2.5821e-02,  1.1254e-02],\n",
      "          [ 1.4919e-02,  2.6251e-02,  3.1933e-03]],\n",
      "\n",
      "         [[ 2.1721e-02,  2.1342e-02,  1.1155e-02],\n",
      "          [ 2.5017e-02, -5.6952e-03, -2.0062e-02],\n",
      "          [-4.5305e-03, -1.9424e-03, -2.7938e-02]],\n",
      "\n",
      "         [[-3.7684e-03, -9.3162e-03,  2.9732e-03],\n",
      "          [-1.3913e-02, -7.7926e-03,  1.2422e-02],\n",
      "          [-1.3241e-02,  1.7970e-02, -6.9960e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0316e-02, -1.7584e-02, -2.9691e-03],\n",
      "          [ 1.3728e-02, -2.7414e-02, -3.2385e-02],\n",
      "          [-2.2604e-04, -2.2452e-02, -1.3130e-02]],\n",
      "\n",
      "         [[-1.8237e-02,  1.0175e-02, -2.6073e-03],\n",
      "          [ 1.9937e-02,  6.1640e-03, -6.9609e-03],\n",
      "          [ 1.1622e-03,  6.8266e-03, -3.1086e-02]],\n",
      "\n",
      "         [[ 1.0145e-02, -6.9135e-03,  1.4729e-02],\n",
      "          [ 3.4963e-03,  1.9804e-02, -3.3986e-02],\n",
      "          [ 2.4274e-02,  2.1010e-02, -1.2281e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6191e-02,  4.1823e-03,  1.2783e-03],\n",
      "          [ 9.4267e-03,  2.3134e-02, -8.0566e-03],\n",
      "          [-4.1620e-03, -1.3330e-02, -7.1037e-03]],\n",
      "\n",
      "         [[-3.4388e-03,  1.3856e-02,  4.8109e-03],\n",
      "          [ 1.6315e-02,  2.2042e-02, -1.8698e-02],\n",
      "          [ 5.1543e-04, -6.3506e-03, -5.7001e-03]],\n",
      "\n",
      "         [[ 1.6672e-02,  3.3018e-03,  8.4804e-03],\n",
      "          [ 1.8162e-02,  3.0732e-04, -2.2302e-02],\n",
      "          [-7.2881e-03,  1.9327e-02, -2.2529e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7413e-02, -1.1292e-02, -2.1714e-02],\n",
      "          [ 1.4859e-02, -1.0094e-02,  2.1578e-03],\n",
      "          [ 1.9285e-02, -1.3585e-02, -1.5108e-02]],\n",
      "\n",
      "         [[-6.3010e-03, -8.5056e-03,  9.0128e-03],\n",
      "          [-9.7222e-03, -8.9344e-05, -2.5873e-03],\n",
      "          [-1.0026e-02,  1.0644e-03,  1.3337e-02]],\n",
      "\n",
      "         [[ 2.3520e-03,  9.2295e-03,  1.2598e-02],\n",
      "          [ 1.1357e-02,  9.9411e-03,  1.1124e-02],\n",
      "          [ 2.0033e-02,  1.4190e-02, -1.1419e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0835e-02, -1.1770e-02,  7.6108e-03],\n",
      "          [ 8.9740e-04, -1.9016e-02,  4.3505e-02],\n",
      "          [-2.0689e-02, -1.7099e-02, -8.4293e-03]],\n",
      "\n",
      "         [[-1.0518e-02,  5.5758e-03,  2.0420e-02],\n",
      "          [-1.9271e-02,  2.7479e-02, -1.2934e-01],\n",
      "          [ 4.3364e-03, -1.8420e-02,  1.4783e-02]],\n",
      "\n",
      "         [[ 3.4225e-03, -3.4863e-03,  6.4291e-03],\n",
      "          [-6.8951e-03, -7.4941e-03,  4.3470e-02],\n",
      "          [-1.6610e-02, -3.3784e-02, -1.2476e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1894e-02, -2.3222e-02,  1.4334e-02],\n",
      "          [-1.9449e-02, -8.7512e-03, -2.6388e-02],\n",
      "          [ 1.6532e-02,  2.5725e-02,  4.0569e-02]],\n",
      "\n",
      "         [[-1.9249e-02, -7.1956e-03, -1.6456e-02],\n",
      "          [ 1.9326e-02, -9.6915e-03,  5.6794e-02],\n",
      "          [-1.5287e-02, -1.8297e-03,  6.3392e-02]],\n",
      "\n",
      "         [[-5.1496e-04, -1.7372e-02, -2.7920e-03],\n",
      "          [-2.4616e-03, -2.1808e-02, -6.8560e-02],\n",
      "          [ 8.3850e-03,  7.2353e-03, -2.1064e-03]]]])), ('layer3.4.weight', tensor([0.9348, 0.9860, 0.8916, 0.9920, 0.9920, 0.9966, 0.9915, 0.9994, 0.9948,\n",
      "        0.8956, 1.3453, 0.9971, 0.9929, 1.0057, 0.9903, 1.0010, 0.9550, 0.9712,\n",
      "        1.0258, 0.9629, 0.9924, 1.1796, 1.0222, 1.1485, 1.0010, 0.9001, 0.9230,\n",
      "        1.0165, 1.1643, 1.0690, 1.0164, 0.9995, 1.0349, 0.9878, 1.0008, 1.0049,\n",
      "        0.9909, 0.9888, 1.1120, 0.9895, 1.3109, 0.9885, 1.1797, 1.0078, 0.9807,\n",
      "        0.9850, 0.9872, 0.9808, 0.9683, 1.0150, 0.9306, 0.9839, 1.0080, 1.0864,\n",
      "        0.9711, 1.1189, 0.9884, 0.9347, 1.2535, 0.9211, 0.9872, 0.9728, 1.0184,\n",
      "        0.9972, 0.9933, 1.0050, 1.0094, 0.9898, 1.0009, 0.9978, 0.9980, 0.9914,\n",
      "        1.0027, 0.9451, 0.9991, 1.0409, 0.9491, 0.9849, 1.0106, 1.0007, 0.9989,\n",
      "        0.9961, 1.1599, 1.0075, 0.9839, 0.9940, 0.9793, 0.9401, 0.9953, 0.9869,\n",
      "        0.9915, 0.9557, 0.9649, 0.9774, 0.9941, 0.9932, 1.0578, 0.7477, 1.0170,\n",
      "        0.9703, 1.2147, 0.9878, 0.9701, 0.9898, 0.9910, 1.0055, 0.9660, 0.9871,\n",
      "        0.9971, 0.9477, 0.9889, 1.0013, 1.0193, 1.0486, 1.0127, 1.0125, 0.9402,\n",
      "        0.9266, 1.0158, 0.9613, 0.9636, 1.0057, 0.9521, 1.0411, 1.0142, 0.9790,\n",
      "        1.0320, 0.9660, 0.9228, 1.0412, 0.9854, 0.9838, 0.9611, 0.9605, 0.9830,\n",
      "        1.0012, 0.9823, 0.9968, 0.9496, 1.0020, 0.9967, 1.0640, 0.9641, 0.9917,\n",
      "        1.0307, 1.0272, 0.9502, 0.9736, 0.8883, 0.9838, 0.9954, 0.9500, 1.1229,\n",
      "        1.0020, 1.0259, 0.9993, 1.0022, 0.9691, 1.0816, 0.9950, 1.0388, 0.9957,\n",
      "        0.9660, 1.0083, 0.9897, 1.0215, 0.9407, 1.0058, 0.9565, 0.9564, 0.9849,\n",
      "        0.9742, 0.9997, 0.9823, 1.1014, 0.9905, 0.9867, 0.8842, 1.0085, 0.9853,\n",
      "        1.0021, 1.0187, 1.0160, 1.1131, 0.9661, 0.9825, 0.9646, 0.9848, 0.9933,\n",
      "        0.9819, 0.9909, 0.9656, 0.9808, 0.9508, 1.0089, 0.9602, 0.9658, 0.9906,\n",
      "        0.9876, 0.9501, 1.0008, 1.1831, 0.9956, 0.9850, 1.0574, 0.9576, 0.9553,\n",
      "        0.9897, 0.9926, 0.8199, 0.9951, 1.0493, 0.9774, 0.9973, 1.0464, 0.9991,\n",
      "        1.0058, 1.1596, 1.0236, 0.9858, 0.8525, 1.0683, 0.9937, 1.0926, 0.9862,\n",
      "        0.9738, 0.9948, 0.9919, 0.9953, 0.9880, 0.9963, 0.9776, 0.9958, 0.9959,\n",
      "        0.9937, 0.9573, 0.9835, 1.0894, 0.9379, 0.9992, 1.0039, 0.9954, 0.9819,\n",
      "        0.9906, 0.9957, 0.9563, 1.0145, 0.9784, 1.0083, 0.9977, 0.9460, 0.9878,\n",
      "        1.0785, 0.9843, 0.9874, 0.9798])), ('layer3.4.bias', tensor([ 5.6749e-03, -2.2655e-02, -1.6058e-01, -3.8207e-03, -1.5686e-02,\n",
      "        -8.7495e-03, -2.7887e-03, -1.7290e-02,  1.0820e-02,  1.3649e-02,\n",
      "        -1.2774e-01, -1.2945e-02,  3.2950e-02,  3.2641e-02, -1.7995e-02,\n",
      "        -2.4410e-03,  2.1989e-02, -6.1381e-03, -9.5532e-02, -2.3435e-05,\n",
      "        -2.9318e-02, -1.7722e-01, -1.1169e-01, -1.5123e-01, -1.7536e-02,\n",
      "         2.7750e-03, -3.9378e-02,  4.8923e-02, -9.7439e-02,  6.0011e-03,\n",
      "         4.6160e-03, -2.7071e-04, -1.1982e-02, -1.1203e-02, -1.5814e-02,\n",
      "         1.4245e-03, -1.4228e-02, -1.2698e-02, -7.6464e-02, -5.1227e-03,\n",
      "         6.6633e-02, -1.1005e-02, -1.1343e-01,  3.8063e-03, -1.3397e-02,\n",
      "        -2.2095e-02, -5.6629e-03, -1.1399e-02,  4.4318e-02, -5.7118e-02,\n",
      "        -8.9908e-02, -3.2714e-02,  1.9601e-03, -2.2871e-01, -7.3218e-03,\n",
      "         4.1528e-02, -5.7069e-02, -1.2917e-03,  9.9621e-02,  2.4057e-02,\n",
      "        -1.7602e-02, -3.0273e-02, -9.2611e-02,  2.2474e-04, -5.5564e-03,\n",
      "         9.4409e-03,  5.3879e-03, -2.2225e-03,  1.2260e-03, -1.1860e-02,\n",
      "        -4.4556e-03, -1.8430e-02, -1.2826e-01, -3.1358e-02, -2.8863e-03,\n",
      "        -9.9730e-02,  2.5078e-02, -2.2594e-02, -1.2698e-02,  3.1839e-02,\n",
      "         1.8163e-03, -6.9491e-03, -7.4279e-02, -5.6939e-02,  2.1399e-02,\n",
      "        -2.8241e-02,  2.0086e-02, -1.1032e-02, -4.9252e-03, -1.8903e-02,\n",
      "        -6.0505e-03, -9.0575e-03, -5.8940e-03, -1.8218e-02, -1.1590e-02,\n",
      "        -4.1283e-03, -5.9538e-02, -1.1574e-02,  1.1656e-02, -1.7504e-02,\n",
      "        -1.5822e-02, -3.1604e-02, -6.0502e-03, -1.3995e-02, -6.7738e-02,\n",
      "        -1.6386e-03, -2.5554e-02, -1.0739e-02, -3.7430e-03, -2.3645e-02,\n",
      "        -6.9692e-03, -4.1736e-03, -9.7841e-02,  2.0460e-02, -8.4301e-03,\n",
      "        -6.3671e-02, -1.6282e-02, -3.2751e-03,  4.3735e-02,  6.8385e-02,\n",
      "        -2.4482e-02, -3.4382e-02, -9.6672e-03,  2.5545e-02, -1.8474e-01,\n",
      "        -1.6365e-02, -6.4332e-02, -3.4696e-02, -1.0438e-02,  1.5560e-03,\n",
      "        -2.6453e-02, -1.6911e-02, -9.0658e-02,  1.2656e-02,  1.5962e-05,\n",
      "         1.0195e-02,  1.3109e-02, -9.1796e-03,  1.4634e-02, -1.8507e-02,\n",
      "        -1.3472e-02, -1.4950e-01, -4.4266e-02,  3.4678e-02, -1.2203e-01,\n",
      "        -6.8398e-02, -6.4027e-03,  1.5264e-02, -4.9909e-03, -8.1487e-02,\n",
      "        -6.8763e-03,  5.2187e-02,  6.2168e-02,  4.2813e-03, -7.3800e-03,\n",
      "        -1.4067e-02, -2.4190e-03, -2.6535e-02, -3.7405e-02, -2.3765e-02,\n",
      "        -1.5568e-01, -9.4229e-03, -2.1479e-03,  4.0134e-03, -7.9607e-03,\n",
      "        -3.8959e-02, -6.8205e-03,  5.6354e-02, -1.5140e-02, -3.0434e-02,\n",
      "        -9.0382e-05, -2.0860e-02, -4.3235e-03,  1.3646e-02, -5.1355e-02,\n",
      "        -9.8798e-03, -1.6148e-02, -1.4218e-01,  5.7440e-02,  8.2941e-02,\n",
      "        -2.0258e-03, -1.4998e-02, -8.8733e-02, -1.1445e-01,  6.5904e-03,\n",
      "        -1.1553e-02,  1.6064e-02,  3.8852e-02, -6.1081e-03, -1.4526e-02,\n",
      "        -6.5858e-03, -3.8315e-02,  1.2957e-02,  3.6341e-03,  4.6828e-04,\n",
      "         2.7142e-02,  6.1714e-03, -4.7856e-03, -2.0988e-02, -6.0615e-02,\n",
      "         6.9315e-03, -2.0026e-01, -6.0539e-03, -1.1695e-02, -1.6692e-01,\n",
      "        -6.0506e-02,  3.1024e-02, -5.1424e-03, -2.0145e-01,  2.8464e-02,\n",
      "        -2.8753e-02, -9.3743e-02,  9.5913e-03,  8.4528e-03, -1.3546e-02,\n",
      "        -5.3640e-02,  4.2911e-03, -2.2852e-01,  7.8788e-02, -3.1737e-03,\n",
      "        -8.3101e-02, -5.1310e-02, -1.1595e-02, -8.8993e-02, -5.9031e-03,\n",
      "        -7.6232e-02,  4.4351e-02, -6.1283e-03, -3.2166e-02, -1.3957e-02,\n",
      "         1.2968e-02, -3.1171e-02, -1.8879e-02,  7.7088e-03, -4.6918e-02,\n",
      "         2.5375e-02, -1.4678e-02, -1.4592e-01,  1.1823e-02, -9.4292e-03,\n",
      "         1.4324e-03, -6.6567e-03, -1.6996e-02, -1.7929e-02, -7.4217e-03,\n",
      "        -5.1919e-03, -5.2035e-02,  4.4920e-02,  1.3599e-03, -9.8497e-03,\n",
      "        -1.0912e-01, -1.3477e-02,  1.3634e-02, -1.8095e-02, -8.7226e-03,\n",
      "         1.4731e-02])), ('layer3.4.running_mean', tensor([-4.7285e-01, -5.8400e-01,  5.6520e-01,  3.0386e-01, -8.1036e-02,\n",
      "        -1.5263e-01,  3.6434e-01,  1.9390e-01, -1.3683e+00,  3.8141e-01,\n",
      "         2.4777e+00,  4.0474e-01,  2.7103e-01, -1.6168e+00,  4.5515e-01,\n",
      "         1.8499e-01, -9.4903e-01,  3.9317e-01,  1.8780e+00,  1.0950e+00,\n",
      "        -8.3520e-02,  4.6350e-01,  2.7175e-01,  2.0722e+00,  2.3612e-01,\n",
      "        -2.0561e-01, -8.1642e-01,  8.1093e-01,  7.3106e-01, -2.7950e-03,\n",
      "         2.1744e-01, -2.8767e-01,  6.1889e-01,  4.7844e-01,  2.0173e-01,\n",
      "        -6.7635e-01,  3.6467e-02, -2.3872e-01, -2.8883e-02,  9.7389e-01,\n",
      "        -4.0865e-01, -1.1356e-01,  3.5124e-01,  7.3469e-01,  6.9459e-02,\n",
      "         8.4228e-01, -1.3835e-01,  2.1217e-01, -5.2557e-01, -1.2541e+00,\n",
      "         1.4211e+00, -5.3769e-01, -1.1420e-01,  2.5130e+00,  4.2097e+00,\n",
      "        -5.5940e-01,  8.8713e-01, -4.3398e-01,  1.4625e+00,  7.0047e-01,\n",
      "         3.5990e-01,  3.4480e-01,  1.9408e+00, -3.4786e-01, -3.1919e-01,\n",
      "         1.8504e-04,  3.8090e-01, -1.9195e-01,  9.6877e-02,  6.2753e-01,\n",
      "         3.9588e-02,  5.4064e-01,  4.9298e-01,  7.5098e-01, -9.9854e-02,\n",
      "         1.5362e+00, -6.6718e-01,  1.2014e-01, -1.0686e-02,  2.1567e-01,\n",
      "         2.2886e-01,  1.7849e-01,  2.1683e+00, -2.5847e-01, -1.5214e+00,\n",
      "         7.4637e-01, -1.2891e+00,  6.0405e-01,  1.7984e-01,  7.3886e-02,\n",
      "        -2.1256e-01,  8.6721e-01,  1.4718e-01,  2.3634e-01,  2.6002e-01,\n",
      "         8.8417e-02,  1.7270e+00, -2.2415e+00,  2.4048e-01, -1.8873e-01,\n",
      "         1.4671e-01, -4.6665e-02,  3.9626e-01, -3.3058e-01, -4.1126e-01,\n",
      "         1.1299e-01, -1.2748e-02, -4.4321e-02, -3.6387e-01,  1.0965e+00,\n",
      "        -4.1224e-01,  9.9731e-02,  2.1892e-01, -2.3754e-01,  4.0717e-01,\n",
      "        -7.3088e-01, -5.7016e-01, -8.0123e-01, -9.7264e-01, -4.3451e-01,\n",
      "        -2.1165e-01, -1.4036e-01,  6.8133e-01, -2.7943e-01,  1.8052e+00,\n",
      "        -3.6814e-01, -2.4437e-01,  5.6758e-01, -7.4074e-02,  7.8457e-02,\n",
      "         9.2216e-02,  1.3551e-01,  4.6746e-01, -1.3248e+00, -4.9592e-01,\n",
      "        -1.9765e-01,  1.0859e-01,  1.2106e-01,  1.6923e+00, -2.3221e-01,\n",
      "        -3.5729e-02, -2.2834e-01,  2.9653e-01,  1.9386e-01,  1.6549e+00,\n",
      "         9.8349e-01,  1.0889e+00, -8.3533e-01, -1.0954e+00,  8.3468e-01,\n",
      "         2.0151e-01,  3.2507e-01, -2.0374e-01,  6.4167e-01,  7.2189e-01,\n",
      "        -8.7769e-01, -8.3729e-01,  4.9379e-01,  5.2193e-01,  3.8733e-01,\n",
      "         4.0863e-01,  2.4206e-01,  9.8902e-01, -6.9207e-01,  3.9634e-01,\n",
      "        -1.9879e-01,  4.4528e-01,  2.2345e-01,  2.0754e-02, -2.9519e-01,\n",
      "         1.0617e-01,  7.7118e-02, -6.2271e-01,  1.8503e-01,  1.1675e+00,\n",
      "         9.6443e-02, -2.1809e-01, -1.0126e+01,  6.8709e-02,  2.1363e+00,\n",
      "         5.4893e-01,  7.8230e-01,  2.7846e-01, -3.5411e-01, -9.7612e-01,\n",
      "        -1.0713e+00, -5.8282e-01, -3.0403e-01,  2.0718e-01,  4.3543e-01,\n",
      "         4.0320e-01, -3.8066e-01,  1.1178e-01,  1.1862e-01,  2.5882e-01,\n",
      "         1.3340e-01, -9.0381e-01, -9.4706e-01, -1.1175e+00,  8.4007e-01,\n",
      "         2.0883e-01,  2.7659e+00, -4.0615e-02, -1.0944e-01,  1.2364e-01,\n",
      "        -7.7104e-01, -6.8451e-01, -2.5423e-01, -9.0650e-02, -1.2134e+00,\n",
      "        -6.0713e-01, -8.7439e-02, -3.2665e-01, -6.2806e-01,  4.3017e-02,\n",
      "         4.7704e-01, -3.1446e-01, -1.8407e-01, -1.2650e+00,  2.5353e-01,\n",
      "        -8.4113e-01, -6.7018e-01,  2.8836e-01,  2.1651e-01,  1.0036e-01,\n",
      "         1.4948e-01,  1.4993e-01,  5.7952e-01,  9.1854e-01, -1.6789e-01,\n",
      "         8.1849e-02, -1.6515e-01,  2.6247e-02, -3.9572e-01,  2.5717e-01,\n",
      "        -7.4562e-01, -2.1607e-01,  2.2132e+00, -1.5416e+00,  3.0865e-01,\n",
      "         1.9216e-01,  1.9936e-01, -2.2207e-02,  6.1004e-01,  4.8978e-01,\n",
      "        -3.5196e-01,  2.5383e-01, -1.3243e+00,  1.1133e-01, -2.9950e-01,\n",
      "        -4.7496e-01, -5.2442e-02,  1.0154e+00,  2.0737e-01, -1.5618e-01,\n",
      "         7.9618e-01])), ('layer3.4.running_var', tensor([5.4414e+00, 3.2952e+00, 2.2759e+01, 9.3902e-01, 1.8727e+00, 1.1422e+00,\n",
      "        6.2698e-01, 2.1642e+00, 4.9135e+00, 1.6007e+01, 1.3948e+01, 2.2320e+00,\n",
      "        9.8392e+00, 3.4205e+00, 9.7754e-01, 2.2464e+00, 5.2609e+00, 5.9734e+00,\n",
      "        9.4720e+01, 7.9263e+00, 1.0630e+00, 1.0175e+01, 9.8538e+00, 7.1373e+00,\n",
      "        1.3548e+00, 9.5507e+00, 1.8169e+01, 2.8200e+01, 1.2639e+01, 2.8475e+00,\n",
      "        1.6383e+01, 9.9794e-01, 1.6146e+00, 1.3588e+00, 1.2597e+00, 2.3481e+00,\n",
      "        9.7423e-01, 1.1607e+00, 3.0562e+01, 1.8204e+01, 5.9152e+01, 2.8954e+00,\n",
      "        8.0905e+00, 1.3400e+00, 5.8752e-01, 1.2251e+00, 4.7385e-01, 5.0444e-01,\n",
      "        1.7344e+01, 2.2334e+01, 2.0911e+01, 4.0457e+00, 1.1068e+00, 1.6625e+01,\n",
      "        3.3409e+01, 6.5081e+01, 1.2670e+01, 4.7331e+00, 5.0149e+01, 8.5434e+00,\n",
      "        2.0360e+00, 6.4752e+00, 4.8865e+01, 1.5379e+00, 6.9729e-01, 2.0662e+00,\n",
      "        6.8570e-01, 1.7273e+00, 3.6335e-01, 1.9274e+00, 5.0332e-01, 1.4862e+00,\n",
      "        4.7217e+00, 3.7682e+00, 1.4515e+00, 3.3650e+01, 9.0937e+00, 1.1559e+00,\n",
      "        1.6605e+00, 8.4727e+00, 1.6223e+00, 8.9171e-01, 1.4666e+01, 1.9300e+01,\n",
      "        1.0529e+01, 1.7743e+00, 4.6883e+00, 1.0847e+01, 9.6437e-01, 7.1966e-01,\n",
      "        4.7557e-01, 5.4862e+00, 5.2443e+00, 2.9141e+00, 1.5396e+00, 7.5201e-01,\n",
      "        8.5739e+00, 1.0228e+02, 3.0520e-01, 9.6931e+00, 1.2935e+01, 3.8964e+00,\n",
      "        4.8750e+00, 8.0326e-01, 1.9771e+01, 5.2924e-01, 1.9974e+00, 9.1381e-01,\n",
      "        8.6419e-01, 3.2762e+00, 9.3958e-01, 6.0637e-01, 4.2755e+00, 5.3507e+00,\n",
      "        9.3459e-01, 1.5130e+01, 3.9071e+00, 4.5219e+00, 1.9747e+01, 7.3671e+00,\n",
      "        1.6224e+00, 4.3506e+00, 2.4235e+01, 3.7010e+01, 1.1210e+01, 1.6277e+00,\n",
      "        7.6917e+00, 2.2721e+00, 4.9035e+00, 6.5972e+00, 1.0155e+00, 6.0471e-01,\n",
      "        4.5048e+00, 2.5413e+01, 5.0582e+00, 2.4367e+00, 4.4920e+00, 8.8895e-01,\n",
      "        4.0556e+01, 7.2701e-01, 1.2301e+01, 3.8393e+01, 3.8804e+00, 9.5285e+00,\n",
      "        1.1043e+01, 1.5452e+01, 1.3449e+01, 5.2936e+00, 1.3176e+01, 5.1173e+00,\n",
      "        4.1606e-01, 7.6781e+00, 1.7610e+01, 1.4969e+00, 1.0132e+00, 6.5801e-01,\n",
      "        7.1055e+00, 2.8857e+00, 7.3964e+00, 4.3186e-01, 2.6144e+00, 5.4927e-01,\n",
      "        5.6520e+00, 6.6196e-01, 9.5636e-01, 7.6375e+00, 8.1230e+00, 9.5299e+00,\n",
      "        1.2798e+01, 7.4499e+00, 4.6086e+00, 1.2919e+00, 1.4461e+00, 5.7251e+00,\n",
      "        2.4294e+01, 4.1281e+00, 5.4070e+00, 6.8623e+02, 6.3880e+00, 3.0120e+01,\n",
      "        1.2479e+00, 6.2872e+00, 7.0226e+00, 5.2356e+01, 7.1962e+00, 6.9336e+00,\n",
      "        8.2269e+00, 9.3756e+00, 5.0362e-01, 4.3656e-01, 7.6000e-01, 5.5243e+00,\n",
      "        5.7100e+00, 6.0062e+00, 8.5531e-01, 1.0435e+01, 6.6503e+00, 1.8770e+00,\n",
      "        2.5023e+00, 3.6449e+00, 9.0512e-01, 2.4545e+01, 7.4833e-01, 1.1538e+00,\n",
      "        6.1490e+00, 4.2840e+00, 7.1679e+00, 6.9873e+00, 1.0800e+01, 6.4212e+01,\n",
      "        4.2365e+00, 1.2318e+01, 3.9899e+00, 2.3973e+00, 1.1183e+00, 1.1541e+01,\n",
      "        3.7260e-01, 3.9301e+01, 5.5501e+01, 1.1536e+00, 3.6552e+01, 4.2038e+00,\n",
      "        1.9343e+00, 1.1498e+01, 2.4249e+00, 4.4630e+01, 7.2800e+00, 1.2084e+00,\n",
      "        4.0793e+00, 5.7837e-01, 2.4740e+00, 3.9784e+00, 7.7258e-01, 2.8341e+00,\n",
      "        1.7002e+01, 5.1479e+00, 9.5038e-01, 1.2183e+01, 1.0472e+01, 8.5070e-01,\n",
      "        5.8261e-01, 7.8540e-01, 1.7600e+00, 4.9552e+00, 2.6859e-01, 6.9158e+00,\n",
      "        2.1785e+00, 6.3647e+00, 5.9336e-01, 2.3427e+00, 4.1704e+00, 4.3717e-01,\n",
      "        9.6245e+00, 3.0404e+00, 7.3220e-01, 8.5002e+00])), ('layer3.4.num_batches_tracked', tensor(309)), ('layer3.6.weight', tensor([[[[ 0.0446]],\n",
      "\n",
      "         [[ 0.0115]],\n",
      "\n",
      "         [[-0.0609]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0340]],\n",
      "\n",
      "         [[-0.0066]],\n",
      "\n",
      "         [[-0.0539]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0154]],\n",
      "\n",
      "         [[ 0.0033]],\n",
      "\n",
      "         [[-0.0197]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0463]],\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         [[-0.0485]]],\n",
      "\n",
      "\n",
      "        [[[-0.0548]],\n",
      "\n",
      "         [[-0.0174]],\n",
      "\n",
      "         [[ 0.0442]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0174]],\n",
      "\n",
      "         [[ 0.0444]],\n",
      "\n",
      "         [[-0.0016]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0263]],\n",
      "\n",
      "         [[-0.0295]],\n",
      "\n",
      "         [[ 0.0820]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0453]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[ 0.0039]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0164]],\n",
      "\n",
      "         [[ 0.0062]],\n",
      "\n",
      "         [[ 0.0334]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0543]],\n",
      "\n",
      "         [[-0.0029]],\n",
      "\n",
      "         [[ 0.0303]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0006]],\n",
      "\n",
      "         [[-0.0422]],\n",
      "\n",
      "         [[ 0.0422]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0522]],\n",
      "\n",
      "         [[ 0.0037]],\n",
      "\n",
      "         [[ 0.0683]]]])), ('layer3.7.weight', tensor([0.9920, 0.9954, 0.9981,  ..., 0.9945, 0.9970, 0.9967])), ('layer3.7.bias', tensor([ 5.3180e-08,  3.3072e-07,  8.3869e-07,  ..., -2.2514e-06,\n",
      "        -3.2109e-06, -6.2376e-07])), ('layer3.7.running_mean', tensor([-0.6685,  0.3533, -0.3196,  ...,  0.7278,  0.5217,  0.1200])), ('layer3.7.running_var', tensor([0.4845, 0.4782, 0.6332,  ..., 0.1824, 0.3613, 0.5052])), ('layer3.7.num_batches_tracked', tensor(309)), ('layer4.0.weight', tensor([[[[ 0.0041]],\n",
      "\n",
      "         [[-0.0165]],\n",
      "\n",
      "         [[ 0.0094]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0197]],\n",
      "\n",
      "         [[ 0.0336]],\n",
      "\n",
      "         [[-0.0139]]],\n",
      "\n",
      "\n",
      "        [[[-0.0260]],\n",
      "\n",
      "         [[-0.0323]],\n",
      "\n",
      "         [[ 0.0003]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0161]],\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         [[-0.0042]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0124]],\n",
      "\n",
      "         [[-0.0339]],\n",
      "\n",
      "         [[-0.0391]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0524]],\n",
      "\n",
      "         [[ 0.0102]],\n",
      "\n",
      "         [[-0.0313]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0194]],\n",
      "\n",
      "         [[-0.0028]],\n",
      "\n",
      "         [[ 0.0056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0414]],\n",
      "\n",
      "         [[-0.0289]],\n",
      "\n",
      "         [[-0.0009]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0037]],\n",
      "\n",
      "         [[-0.0039]],\n",
      "\n",
      "         [[-0.0037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0040]],\n",
      "\n",
      "         [[-0.0314]],\n",
      "\n",
      "         [[-0.0222]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0260]],\n",
      "\n",
      "         [[ 0.0057]],\n",
      "\n",
      "         [[ 0.0252]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0174]],\n",
      "\n",
      "         [[-0.0044]],\n",
      "\n",
      "         [[-0.0263]]]])), ('layer4.1.weight', tensor([1.0021, 1.0173, 1.0528, 0.9951, 0.9949, 0.9805, 0.9920, 1.0248, 0.9782,\n",
      "        0.9874, 0.9925, 1.0096, 1.0127, 0.9765, 0.9779, 0.9846, 0.9992, 0.9815,\n",
      "        0.9992, 1.0229, 0.9956, 1.0082, 0.9959, 0.9807, 0.9919, 1.0113, 0.9697,\n",
      "        0.9963, 0.9908, 0.9959, 0.9958, 1.0107, 0.9847, 1.0093, 1.0064, 0.9870,\n",
      "        1.0105, 1.0069, 0.9813, 0.9998, 1.0007, 0.9822, 1.0105, 0.9870, 1.0135,\n",
      "        1.0072, 0.9901, 1.0226, 1.0076, 0.9873, 1.0094, 1.0002, 0.9921, 1.0025,\n",
      "        0.9939, 0.9898, 0.9819, 1.0053, 0.9963, 1.0006, 0.9888, 0.9902, 1.0190,\n",
      "        0.9991, 1.0018, 0.9926, 0.9787, 1.0009, 0.9945, 0.9862, 0.9997, 1.0200,\n",
      "        1.0129, 0.9900, 1.0606, 1.0126, 1.0166, 0.9940, 1.0022, 0.9979, 1.0075,\n",
      "        0.9868, 0.9778, 0.9969, 1.0025, 0.9721, 0.9878, 1.0022, 0.9953, 1.0056,\n",
      "        0.9853, 0.9863, 1.0175, 1.0067, 1.0145, 1.0042, 1.0018, 1.0145, 0.9842,\n",
      "        1.0404, 1.0081, 0.9848, 0.9786, 1.0024, 0.9975, 1.0105, 0.9976, 1.0070,\n",
      "        0.9787, 1.0514, 0.9926, 1.0045, 0.9887, 0.9955, 1.0206, 0.9870, 0.9878,\n",
      "        1.0188, 1.0142, 0.9924, 1.0201, 1.0115, 0.9991, 1.0003, 1.0002, 0.9862,\n",
      "        0.9847, 1.0082, 1.0047, 0.9852, 0.9813, 1.0048, 0.9991, 0.9839, 1.0192,\n",
      "        0.9867, 0.9936, 1.0249, 0.9922, 1.0100, 1.0014, 0.9943, 0.9856, 1.0018,\n",
      "        0.9853, 0.9936, 1.0513, 0.9962, 0.9893, 1.0001, 0.9846, 0.9945, 0.9956,\n",
      "        0.9879, 1.0044, 0.9939, 1.0085, 0.9921, 0.9994, 1.0133, 0.9962, 0.9939,\n",
      "        0.9963, 0.9970, 1.0130, 0.9963, 0.9858, 0.9942, 0.9852, 1.0103, 0.9892,\n",
      "        0.9969, 1.0048, 0.9845, 0.9913, 1.0375, 0.9890, 1.0007, 1.0042, 0.9930,\n",
      "        1.0008, 0.9777, 0.9930, 1.0286, 1.0132, 0.9944, 0.9823, 1.0005, 0.9860,\n",
      "        0.9992, 1.0020, 0.9785, 0.9970, 0.9853, 1.0033, 0.9842, 0.9768, 0.9758,\n",
      "        1.0039, 0.9977, 0.9934, 0.9941, 1.0067, 0.9825, 0.9875, 0.9875, 0.9910,\n",
      "        0.9965, 1.0132, 1.0121, 0.9954, 0.9781, 1.0090, 0.9942, 0.9867, 0.9985,\n",
      "        0.9846, 1.0312, 0.9782, 1.0091, 0.9797, 0.9989, 0.9876, 0.9917, 1.0193,\n",
      "        0.9873, 0.9958, 1.0084, 0.9836, 0.9970, 1.0008, 0.9919, 0.9876, 1.0201,\n",
      "        0.9913, 0.9937, 0.9905, 0.9990, 1.0020, 1.0056, 1.0178, 0.9997, 0.9822,\n",
      "        0.9969, 1.0149, 1.0309, 0.9881, 1.0195, 1.0098, 1.0018, 0.9880, 1.0272,\n",
      "        0.9840, 1.0243, 1.0046, 0.9856, 0.9936, 0.9800, 0.9788, 0.9884, 0.9869,\n",
      "        1.0106, 0.9918, 0.9773, 1.0010, 1.0433, 0.9825, 1.0097, 0.9910, 0.9908,\n",
      "        0.9986, 0.9869, 1.0248, 1.0193, 1.0069, 1.0004, 0.9989, 1.0331, 0.9816,\n",
      "        0.9842, 0.9764, 1.0041, 0.9835, 1.0103, 0.9992, 0.9837, 1.0160, 0.9893,\n",
      "        0.9998, 0.9987, 0.9990, 1.0378, 0.9936, 0.9949, 1.0010, 0.9829, 0.9965,\n",
      "        1.0134, 1.0275, 0.9847, 0.9982, 0.9984, 0.9944, 0.9852, 0.9881, 1.0171,\n",
      "        1.0029, 0.9910, 0.9980, 0.9822, 0.9871, 1.0234, 1.0063, 1.0078, 1.0025,\n",
      "        0.9809, 1.0139, 1.0362, 0.9963, 0.9949, 1.0339, 1.0148, 0.9867, 1.0082,\n",
      "        1.0132, 0.9959, 1.0218, 1.0227, 1.0115, 1.0250, 0.9946, 0.9828, 0.9944,\n",
      "        0.9861, 1.0274, 1.0291, 1.0012, 1.0056, 0.9916, 0.9863, 0.9842, 0.9836,\n",
      "        0.9848, 0.9876, 0.9843, 0.9876, 1.0059, 0.9911, 0.9995, 1.0094, 1.0150,\n",
      "        1.0303, 1.0268, 1.0027, 1.0008, 0.9933, 1.0018, 0.9869, 0.9932, 1.0039,\n",
      "        0.9851, 0.9805, 0.9833, 0.9967, 1.0114, 1.0062, 0.9903, 1.0069, 0.9961,\n",
      "        1.0065, 1.0298, 1.0125, 0.9883, 1.0098, 0.9885, 0.9906, 0.9935, 0.9746,\n",
      "        0.9935, 0.9874, 0.9980, 1.0069, 0.9993, 1.0010, 0.9868, 1.0220, 0.9902,\n",
      "        0.9984, 1.0054, 1.0014, 0.9894, 0.9853, 1.0243, 0.9858, 1.0150, 1.0175,\n",
      "        0.9970, 0.9689, 0.9982, 0.9858, 1.0141, 0.9945, 1.0011, 0.9931, 0.9829,\n",
      "        0.9698, 1.0131, 1.0134, 0.9953, 0.9874, 0.9850, 0.9999, 1.0022, 0.9865,\n",
      "        0.9871, 0.9857, 1.0141, 1.0048, 0.9858, 0.9911, 1.0031, 0.9944, 0.9892,\n",
      "        1.0500, 0.9950, 0.9904, 0.9860, 0.9936, 1.0225, 0.9960, 1.0028, 1.0183,\n",
      "        0.9959, 0.9947, 0.9778, 0.9923, 1.0209, 0.9999, 1.0146, 0.9987, 1.0199,\n",
      "        1.0000, 0.9957, 0.9994, 1.0189, 0.9844, 0.9911, 0.9985, 1.0128, 0.9961,\n",
      "        0.9829, 1.0082, 1.0071, 1.0024, 1.0066, 1.0098, 1.0220, 0.9892, 1.0023,\n",
      "        1.0027, 0.9975, 0.9727, 0.9876, 0.9937, 0.9882, 0.9878, 0.9886, 0.9947,\n",
      "        1.0291, 0.9834, 1.0255, 0.9879, 1.0073, 0.9788, 0.9946, 0.9954, 0.9847,\n",
      "        0.9944, 0.9893, 0.9904, 1.0090, 0.9827, 0.9909, 1.0308, 1.0005, 0.9950,\n",
      "        1.0430, 1.0144, 0.9964, 0.9879, 0.9836, 0.9778, 1.0292, 1.0128, 1.0023,\n",
      "        0.9953, 1.0189, 0.9886, 1.0096, 1.0140, 0.9935, 1.0120, 1.0044, 1.0014,\n",
      "        0.9960, 0.9777, 1.0041, 0.9952, 0.9807, 0.9936, 1.0112, 0.9986])), ('layer4.1.bias', tensor([-0.0809,  0.0175,  0.0035, -0.0451, -0.0542, -0.0507, -0.0422,  0.0370,\n",
      "        -0.0210, -0.0500, -0.0598,  0.0112, -0.0233, -0.0647, -0.0799, -0.0604,\n",
      "        -0.0780, -0.0170, -0.0634, -0.0123, -0.0353,  0.0147, -0.0108, -0.0623,\n",
      "        -0.0158,  0.0240, -0.0551, -0.0016, -0.0146, -0.0347, -0.0280, -0.0178,\n",
      "        -0.0215,  0.0004, -0.0099, -0.0025,  0.0177, -0.0143, -0.0231, -0.0169,\n",
      "        -0.0107, -0.0796,  0.0101, -0.0868, -0.0250, -0.0427,  0.0002,  0.0188,\n",
      "         0.0037, -0.0730,  0.0066, -0.0377, -0.0102, -0.0145, -0.0703, -0.0892,\n",
      "        -0.0675,  0.0130, -0.0615, -0.0323, -0.0649, -0.0498, -0.0231, -0.0265,\n",
      "        -0.0125, -0.0020, -0.0231, -0.0418, -0.0375, -0.0271, -0.0169, -0.0024,\n",
      "         0.0468, -0.0867,  0.0342,  0.0088,  0.0204, -0.0495, -0.0307, -0.0417,\n",
      "        -0.0205, -0.0765, -0.0788, -0.0210, -0.0493, -0.0909, -0.0537, -0.0220,\n",
      "        -0.0161, -0.0395, -0.0552, -0.0128,  0.0088,  0.0085, -0.0303,  0.0077,\n",
      "         0.0282,  0.0334, -0.0520,  0.0284,  0.0117, -0.0953, -0.0765, -0.0349,\n",
      "        -0.0628, -0.0168, -0.0974, -0.0133, -0.0685,  0.0923, -0.0092, -0.0858,\n",
      "        -0.0177, -0.0070,  0.0170, -0.0208, -0.0305,  0.0272,  0.0461, -0.0409,\n",
      "         0.0359,  0.0361,  0.0189, -0.0548, -0.0719, -0.0538, -0.0395, -0.0317,\n",
      "        -0.0503, -0.0329, -0.0414,  0.0129,  0.0103, -0.0779,  0.0160, -0.0169,\n",
      "        -0.0650,  0.0156, -0.0455, -0.0257,  0.0199, -0.0239, -0.0194,  0.0191,\n",
      "        -0.0766, -0.0234,  0.0349,  0.0058, -0.0224,  0.0093, -0.0624, -0.0065,\n",
      "        -0.0227, -0.0608, -0.0702, -0.0616, -0.0308, -0.0192, -0.0690,  0.0061,\n",
      "        -0.0458, -0.0174, -0.0571,  0.0076,  0.0316, -0.0667, -0.0877, -0.0494,\n",
      "        -0.0464,  0.0126, -0.0957, -0.0176,  0.0194, -0.0578, -0.0076,  0.0676,\n",
      "        -0.0237, -0.0573, -0.0071, -0.0143,  0.0101, -0.0593, -0.0016, -0.0088,\n",
      "         0.0348, -0.0558, -0.0852, -0.0062, -0.0586, -0.0273, -0.0697, -0.0113,\n",
      "        -0.0467, -0.0487, -0.0269, -0.0563, -0.0554, -0.0618,  0.0204,  0.0136,\n",
      "        -0.0605, -0.0123, -0.0096, -0.0355, -0.0112, -0.0483, -0.0185, -0.0446,\n",
      "        -0.0009, -0.0068, -0.0268, -0.0256, -0.0859, -0.0239, -0.0531,  0.0095,\n",
      "        -0.0132,  0.0495, -0.0666, -0.0559, -0.0886, -0.0067, -0.0188, -0.0605,\n",
      "        -0.0315, -0.0115, -0.0559,  0.0078, -0.0698, -0.0105, -0.0065, -0.0332,\n",
      "        -0.0703,  0.0233, -0.0025, -0.0155, -0.0446, -0.0066, -0.0072,  0.0279,\n",
      "         0.0383, -0.0337, -0.0583, -0.0706,  0.0279, -0.0019, -0.0272,  0.0248,\n",
      "        -0.0175, -0.0288, -0.0100,  0.0344, -0.0400,  0.0256,  0.0165, -0.0711,\n",
      "        -0.0435, -0.0585, -0.0849, -0.0353, -0.0042,  0.0252, -0.0132, -0.0591,\n",
      "        -0.0070,  0.0154, -0.0613, -0.0087, -0.0117, -0.0125, -0.0066, -0.0118,\n",
      "         0.0116,  0.0254, -0.0398, -0.0199, -0.0739, -0.0057, -0.0760, -0.0178,\n",
      "        -0.0231, -0.0177, -0.0346,  0.0205, -0.0123, -0.0561,  0.0138, -0.0526,\n",
      "         0.0138, -0.0187, -0.0185,  0.0316,  0.0170, -0.0712, -0.0145, -0.0742,\n",
      "        -0.0149,  0.0313,  0.0370, -0.0210, -0.0124,  0.0181, -0.0287, -0.0561,\n",
      "        -0.0328,  0.0256, -0.0017, -0.0539, -0.0243, -0.0968, -0.0755,  0.0110,\n",
      "         0.0158, -0.0200, -0.0352, -0.0255, -0.0133,  0.0495, -0.0179,  0.0092,\n",
      "         0.0249,  0.0309, -0.0642, -0.0012, -0.0207, -0.0459,  0.0225,  0.0193,\n",
      "        -0.0047, -0.0102, -0.0054, -0.0840, -0.0454, -0.0060,  0.0162, -0.0545,\n",
      "         0.0108, -0.0074, -0.0678, -0.0561, -0.0660, -0.0752, -0.0423, -0.0567,\n",
      "        -0.0714, -0.0903,  0.0198, -0.0024,  0.0083, -0.0360,  0.0420,  0.0366,\n",
      "         0.0426,  0.0128,  0.0106, -0.0165, -0.0099, -0.0692, -0.0380, -0.0124,\n",
      "        -0.0641, -0.0300, -0.0627, -0.0087,  0.0174, -0.0471, -0.0366, -0.0025,\n",
      "        -0.0084, -0.0189,  0.0290,  0.0179, -0.0708,  0.0124, -0.0293,  0.0003,\n",
      "        -0.0795, -0.0608,  0.0177, -0.0752, -0.0170, -0.0694, -0.0887, -0.0183,\n",
      "        -0.0116, -0.0002, -0.0589, -0.0282, -0.0153, -0.0181, -0.0147, -0.0828,\n",
      "         0.0218, -0.0320,  0.0105, -0.0086, -0.0689, -0.0342, -0.0226, -0.0722,\n",
      "         0.0194, -0.0720, -0.0159, -0.0178, -0.0479, -0.0809,  0.0380,  0.0177,\n",
      "        -0.0278, -0.0219, -0.0580,  0.0103, -0.0051, -0.0495,  0.0003, -0.0229,\n",
      "        -0.0206, -0.0151, -0.0497, -0.0065, -0.0404, -0.0723, -0.0258,  0.0491,\n",
      "        -0.0896, -0.0102, -0.0809, -0.0076,  0.0050, -0.0588, -0.0037,  0.0196,\n",
      "         0.0089, -0.0021, -0.0483, -0.0035,  0.0290, -0.0085, -0.0225,  0.0033,\n",
      "         0.0390, -0.0486, -0.0601, -0.0847,  0.0362, -0.0636, -0.0515, -0.0591,\n",
      "         0.0288,  0.0003, -0.0720,  0.0302, -0.0469, -0.0234, -0.0102, -0.0065,\n",
      "         0.0222, -0.0518, -0.0528,  0.0252, -0.0066, -0.0888, -0.0523, -0.0200,\n",
      "        -0.0432,  0.0368, -0.0262,  0.0071,  0.0151, -0.0403,  0.0397, -0.0046,\n",
      "         0.0179, -0.0749, -0.0662, -0.0314, -0.0852, -0.0826, -0.0544, -0.0114,\n",
      "         0.0095, -0.0423, -0.0660, -0.0145,  0.0011, -0.0024,  0.0438,  0.0352,\n",
      "         0.0057, -0.0385, -0.0339, -0.0742,  0.0462, -0.0077, -0.0129, -0.0196,\n",
      "         0.0263, -0.0545,  0.0329,  0.0262,  0.0023,  0.0185,  0.0275,  0.0095,\n",
      "         0.0150, -0.0775, -0.0142, -0.0797, -0.0476,  0.0068, -0.0322, -0.0242])), ('layer4.1.running_mean', tensor([ 6.6418e-01, -2.8666e+00,  6.7254e+00,  2.1395e+00,  2.6462e+00,\n",
      "         5.8565e-01,  1.8957e+00, -3.0894e+00,  1.1728e+00, -1.8368e+00,\n",
      "        -4.0389e-01, -1.0494e+00, -2.3829e+00,  1.7109e-01,  6.0080e-01,\n",
      "        -1.3400e+00,  6.5920e+00, -4.0656e-01, -8.3392e-01,  4.8482e+00,\n",
      "         4.9137e+00, -3.2312e+00,  9.7118e-01,  1.0565e+00,  1.0560e-01,\n",
      "        -2.2220e+00,  5.2377e-01, -2.1513e+00,  2.9508e+00,  3.8921e+00,\n",
      "         4.5986e+00,  1.0417e+01, -5.0572e-01,  2.8725e-01, -2.2092e+00,\n",
      "        -8.3073e-01,  5.1409e-01, -2.9686e-01,  1.1743e+00, -1.2565e+00,\n",
      "        -2.0535e+00,  2.4699e+00, -2.0299e+00,  3.4866e+00,  1.0865e+01,\n",
      "         3.7159e+00, -1.6801e+00,  2.1579e+00, -3.3593e+00,  5.9104e-01,\n",
      "        -4.7680e+00,  8.3848e-01, -1.3796e-01, -9.0946e-01,  4.4896e+00,\n",
      "         2.4632e+00,  1.2930e+00, -5.2786e+00,  2.2429e+00,  4.7065e+00,\n",
      "         7.2920e-02,  1.0590e+00,  4.7727e+00,  4.6531e+00, -2.3922e+00,\n",
      "         1.2326e+00,  5.1786e-01,  3.6294e+00, -7.5086e-01,  1.6477e+00,\n",
      "        -1.8353e+00, -2.0764e+00, -4.9137e+00,  3.1873e+00,  4.5596e+00,\n",
      "         5.5037e+00, -1.1330e+00, -9.3726e-01,  2.1198e+00,  4.7110e+00,\n",
      "         4.5386e+00,  7.9465e-01,  3.3586e+00, -3.5979e-01,  3.0831e+00,\n",
      "         3.5863e+00,  4.1943e+00, -1.6611e+00,  1.0293e+00,  3.7297e+00,\n",
      "         1.9751e+00, -3.4854e-01, -1.5735e+00, -3.2253e+00,  2.5500e+00,\n",
      "        -2.6250e+00, -6.8389e-01, -4.5273e+00, -1.4051e-01, -2.3021e+00,\n",
      "         1.6838e+00,  6.0466e+00, -2.5111e-01, -9.2052e-01, -5.3456e-01,\n",
      "        -2.8337e+00,  4.6504e+00, -7.6404e-01,  1.8881e+00, -7.6387e+00,\n",
      "        -1.0117e+00,  2.9911e+00, -1.5343e+00, -2.5919e+00,  2.6213e+00,\n",
      "         2.6858e+00,  2.3190e+00,  8.3707e-01, -2.0824e-01,  1.8201e+00,\n",
      "        -1.1153e+00, -1.4532e+00, -4.6832e-01,  9.8125e-01,  2.9240e-01,\n",
      "         8.1713e-01,  2.9151e-01,  5.7806e+00,  1.5012e+00,  7.6089e-01,\n",
      "        -1.2446e+00, -3.6552e+00, -1.3187e+00, -1.2626e-01,  4.4992e-02,\n",
      "        -7.7245e-01,  1.8875e-01,  2.4246e+00, -2.4114e+00,  7.2995e+00,\n",
      "        -4.1743e+00,  6.6899e-01,  2.0147e+00, -4.3493e+00,  3.3601e+00,\n",
      "         2.3165e+00, -1.2021e+00, -1.0513e+00, -2.2915e+00, -1.7341e+00,\n",
      "         1.4522e+00, -5.1227e-01, -1.2987e+00,  1.6116e+00, -2.3617e-01,\n",
      "        -1.6335e-02,  5.7631e-02, -1.6396e+00, -5.0470e-02, -1.3174e+00,\n",
      "         1.6375e+00,  3.6278e+00,  2.0854e+00, -2.3950e+00, -4.1398e-01,\n",
      "         6.7173e-01,  5.1391e+00, -1.2062e+00,  2.1185e+00, -2.0949e+00,\n",
      "         2.8020e+00,  2.5594e+00, -3.1431e+00, -4.0030e-01, -1.4374e+00,\n",
      "        -3.8192e+00, -6.8620e-01,  1.6613e+00, -2.6313e+00, -1.7049e+00,\n",
      "        -2.1146e+00,  3.0331e+00,  8.8829e-02,  3.4688e+00, -1.5822e+00,\n",
      "         3.4914e+00,  3.4060e+00, -6.2061e-01,  1.0483e-01,  2.2867e-01,\n",
      "         3.2255e+00,  2.9513e+00,  2.1010e+00, -8.7709e-01,  3.2332e+00,\n",
      "        -3.8571e-01,  1.3552e-01,  2.8513e+00, -3.6904e-01, -1.0125e+00,\n",
      "         4.0808e+00, -1.7044e+00, -2.7092e+00, -1.3013e+00, -3.9518e-01,\n",
      "        -1.4544e+00,  3.2861e-01,  2.5497e+00,  3.1905e-01, -2.2456e+00,\n",
      "         2.8439e-01,  2.2154e+00,  2.8368e+00, -7.5351e-01, -1.7843e-01,\n",
      "        -2.3368e+00,  2.7323e-01, -1.4859e+00,  2.8576e+00,  2.8128e+00,\n",
      "         3.0477e+00, -1.7226e-01, -1.9769e+00,  2.5160e+00, -2.4748e-01,\n",
      "         2.3760e+00,  4.0292e+00, -1.0529e+00,  1.1568e+00, -8.6568e-01,\n",
      "         6.3921e-02, -5.1346e-01,  3.6856e+00, -2.0006e+00, -3.4851e+00,\n",
      "        -8.0756e-01, -9.9018e-01,  1.0870e+00, -8.5065e-02, -3.5492e+00,\n",
      "        -1.6545e+00,  3.8526e+00, -1.7957e+00,  2.9927e+00, -8.6174e-01,\n",
      "        -2.5909e+00,  1.5231e+00, -4.4927e+00, -7.9362e-02,  1.7451e+00,\n",
      "         1.9899e+00, -2.5561e+00, -9.9402e-01, -3.5058e+00, -3.6544e+00,\n",
      "         2.1063e+00,  1.3952e+00,  1.4655e+00,  3.2768e+00,  2.8871e+00,\n",
      "        -3.4479e+00,  1.9209e+00,  1.0570e+00,  3.3365e+00,  4.0414e-01,\n",
      "         6.6689e+00, -1.9873e+00,  1.0004e+00,  3.3715e+00, -3.4942e+00,\n",
      "        -1.8151e+00, -3.1094e-01, -5.3900e+00,  6.7577e-01, -2.0698e+00,\n",
      "        -1.8517e+00,  8.1793e-01, -5.9901e-01, -5.9932e-01,  2.3510e+00,\n",
      "         2.3050e+00, -1.6945e+00,  2.6100e+00, -3.4295e-02, -1.0695e+00,\n",
      "        -3.4091e-01, -1.9209e+00,  3.0338e+00, -4.0023e+00, -1.6752e+00,\n",
      "        -2.0133e+00,  3.3534e+00, -3.0405e-02,  3.8511e+00, -1.3716e+00,\n",
      "        -3.0524e+00, -1.5212e+00, -1.9351e+00, -4.0185e+00,  1.2911e-01,\n",
      "        -1.5452e+00, -1.3497e+00,  6.9692e-01,  4.2395e-01,  2.9230e+00,\n",
      "        -4.7907e+00,  1.6706e+00,  2.1089e+00, -2.5633e-01,  3.7677e+00,\n",
      "         2.9950e+00, -4.7747e+00, -1.0254e+01, -1.8052e+00,  3.4406e+00,\n",
      "        -2.5739e+00, -1.7671e+00,  2.0551e+00,  2.3749e+00, -1.8849e+00,\n",
      "        -2.1065e+00, -4.8851e+00, -5.2997e-01, -2.7359e+00, -1.8264e+00,\n",
      "         1.8923e+00,  1.6075e+00,  3.2948e+00, -4.5825e-01, -1.2514e+00,\n",
      "        -1.5690e+00,  2.9213e+00,  2.3279e+00, -2.5206e+00,  1.4661e+00,\n",
      "         7.0031e+00, -2.2482e+00,  2.0306e-01, -1.1403e+00,  7.4562e-01,\n",
      "         9.2518e-01,  5.7746e+00,  1.8919e+00,  7.9138e-01,  2.0996e+00,\n",
      "         2.0524e+00, -6.7568e-01, -7.4617e-01, -2.6752e+00,  5.7761e+00,\n",
      "        -2.0558e+00, -2.8260e+00, -2.1654e+00,  3.7097e-02, -2.4546e+00,\n",
      "        -3.3683e-01, -3.7368e-01, -1.0472e+00,  2.9528e+00,  1.2182e+00,\n",
      "         6.9954e-01, -2.4199e+00,  5.0829e-01,  2.4139e+00, -1.5614e+00,\n",
      "         3.4220e+00,  2.1874e+00, -1.4406e-01,  1.7944e-01,  2.3709e+00,\n",
      "        -6.9206e-01, -3.4131e-02,  4.2849e+00, -6.4046e-01, -3.1187e-01,\n",
      "        -1.2203e+00,  3.1812e+00,  4.7019e+00, -3.1335e+00,  3.4348e+00,\n",
      "        -1.4747e+00,  4.4125e+00,  2.3882e+00, -9.6533e-01, -3.5294e+00,\n",
      "         2.9581e+00,  2.7801e+00, -2.1407e+00, -3.3692e+00, -1.8794e+00,\n",
      "         2.6167e+00,  1.7320e+00,  2.3220e+00,  2.2354e+00,  1.0656e+00,\n",
      "         1.0677e+00,  4.2842e-01,  3.0891e+00,  8.4799e-01,  2.0868e+00,\n",
      "         6.1975e-01,  3.9496e+00, -1.4092e+00, -2.5511e+00,  1.0243e+00,\n",
      "         1.5123e+00, -1.6254e+00, -3.2601e+00,  2.5994e+00, -7.5615e-01,\n",
      "         2.2264e+00, -1.5887e+00,  9.3067e-01,  2.3362e+00,  5.9343e-01,\n",
      "        -8.4814e-02, -5.1676e-01,  3.2922e-01, -1.6217e-01,  1.6753e-01,\n",
      "         2.9029e+00, -1.2034e-01, -1.1822e+00,  3.3277e+00,  2.6568e+00,\n",
      "         3.1330e+00,  1.3051e+00, -1.5027e+00,  2.2814e+00,  1.8011e+00,\n",
      "        -5.6732e-01, -1.4104e-01, -4.5226e+00, -4.2965e+00,  2.4833e-01,\n",
      "        -4.1629e-01, -2.0171e+00, -2.2551e-01,  4.4217e+00, -7.4878e-01,\n",
      "        -3.9704e+00,  2.5530e+00,  5.1897e-01,  4.4059e+00, -1.0079e+00,\n",
      "        -1.3199e+00,  1.6089e+00, -4.4138e-01,  1.5117e+00, -1.5039e+00,\n",
      "         3.5191e+00, -1.5648e-01,  5.8273e+00, -1.3433e+00,  1.4293e+00,\n",
      "        -1.9540e+00, -6.1103e-01, -2.1634e-01, -5.9176e-01, -1.5670e+00,\n",
      "        -1.2272e+00,  2.9934e+00, -6.2840e-01, -9.1379e-01,  3.4394e+00,\n",
      "        -3.3339e+00,  2.5904e+00, -1.4488e+00, -3.5452e+00,  1.6330e+00,\n",
      "        -3.9304e+00, -5.5068e-01, -1.1251e+00, -7.8783e-03,  6.5171e-01,\n",
      "         3.4922e+00,  3.9151e+00,  1.3248e+00, -1.8590e+00,  1.3359e-01,\n",
      "        -2.0500e+00, -3.0116e-01,  2.4191e+00,  6.5881e+00,  1.4796e+00,\n",
      "        -5.6047e-01,  1.2851e+00, -1.4326e+00, -2.5229e-01,  2.9970e+00,\n",
      "         3.0098e+00,  2.7029e+00,  2.0671e+00,  5.2508e-01,  5.4358e+00,\n",
      "         1.1480e+00,  2.2964e+00,  6.9619e-01, -1.8314e+00, -1.6547e+00,\n",
      "        -2.7485e+00, -2.8643e+00, -2.4947e+00, -2.9645e+00,  1.0082e+00,\n",
      "        -5.2359e-01, -5.9974e-01, -2.9600e-02,  1.3861e+00, -2.5452e+00,\n",
      "         2.1195e-01,  2.3236e+00])), ('layer4.1.running_var', tensor([26.3122,  2.0940, 46.9496, 23.0341, 31.3110, 17.9919, 12.7658, 14.4811,\n",
      "        29.1266, 12.0580, 25.2984,  9.0642, 13.1866,  4.2786, 18.6143, 10.4120,\n",
      "        41.5748, 10.8053, 19.6849, 35.1855, 19.8300,  3.9856, 25.9819, 14.6750,\n",
      "        26.8907,  8.9000, 18.1475, 17.6307, 24.4054, 15.1009,  8.2079, 99.6110,\n",
      "        17.0694,  9.0894, 15.9087, 11.7470,  6.1773, 15.1811,  9.8936, 13.1931,\n",
      "        10.8780, 19.2054,  8.2732, 20.9451, 98.0977, 29.9821, 14.8737, 15.4596,\n",
      "        10.6014, 12.6690, 10.6613, 22.1732,  9.1869, 14.5542, 15.4868, 17.5051,\n",
      "        19.4655, 16.1651, 20.6247, 17.3060, 19.0864, 21.1374, 23.6470, 22.7550,\n",
      "         8.1377,  7.3735,  4.9544, 10.9010, 19.0188,  6.0093, 11.0730, 10.3321,\n",
      "        27.7742, 21.4992,  3.6367, 12.0120, 16.8527, 16.3182, 31.1047, 27.4204,\n",
      "        19.8090, 25.7194, 18.0848, 23.5849, 19.4840,  6.8608, 17.7483, 16.1626,\n",
      "        26.8963, 23.0417, 21.4439,  6.1726, 19.2748, 17.9895, 20.4122, 10.5121,\n",
      "         3.4355, 20.1245, 17.6703, 15.6479, 10.6077, 31.4781, 22.3959, 23.7797,\n",
      "        22.8582, 10.6680, 20.5515, 11.8819,  6.7085, 56.2837, 15.8463, 25.5908,\n",
      "        14.5083, 12.1021, 11.5539, 41.7017, 14.1957, 15.2107,  5.3279, 11.0517,\n",
      "        10.9292, 24.2068, 13.6179, 22.9132, 23.2542, 18.5782, 15.3386, 42.6199,\n",
      "        17.0083, 26.6625,  8.0473, 13.4299,  9.5019, 11.0047, 16.4527, 11.2252,\n",
      "        28.1044,  6.2928,  9.2603, 75.7951, 15.3167, 16.4416,  5.0055,  5.4108,\n",
      "        19.6389, 52.6796, 16.8433,  7.7056, 16.2338,  5.3152, 26.3654, 21.7337,\n",
      "        15.9636, 12.4332, 25.1006, 32.5609, 24.5890, 24.7341, 21.5240, 10.0195,\n",
      "        15.8236, 11.5637, 22.4738,  2.8088,  2.5697, 24.1047, 12.0325, 18.3318,\n",
      "        20.0089, 15.7350, 20.5366, 14.8343,  7.1754, 20.4505, 15.9897, 13.7576,\n",
      "        21.2703, 13.4576, 10.2346, 19.7013,  9.9109,  6.2010, 15.9391, 28.9940,\n",
      "        10.2878, 18.2282, 22.5535, 19.1673, 27.6325, 12.5047, 21.5542, 12.4301,\n",
      "         8.1531, 13.9047, 38.3384, 10.4036, 10.1273, 21.8749, 17.3927,  7.4636,\n",
      "        18.0639,  8.5438, 12.5262, 14.4574, 10.8846, 20.3845, 17.4060, 13.6745,\n",
      "        10.8385,  4.4944, 13.4544, 22.2267, 22.7528, 16.3794, 14.3051, 15.5998,\n",
      "        10.7260,  7.6284, 16.0806, 10.4761, 18.3248, 12.8881,  2.8288, 19.1747,\n",
      "        20.8758, 16.1530, 18.4918, 16.6823, 25.3130, 18.2896, 18.6288, 19.0127,\n",
      "        11.6134, 12.0807,  3.1850, 17.3599, 19.9541, 16.8763, 15.7567,  6.1602,\n",
      "        26.3449, 19.7073, 10.4800, 21.4767, 10.8891,  8.2317, 26.8950, 13.9159,\n",
      "        13.9665, 17.6476, 19.6395, 12.8808, 16.1758, 12.7206, 13.0791, 16.5128,\n",
      "        26.4391,  7.8763, 21.2624, 20.4939,  8.6220, 18.5151, 25.3320, 10.4526,\n",
      "        18.7780, 25.8588, 12.7013, 13.3559,  8.9710, 12.2785, 16.7667,  9.5555,\n",
      "         4.8239, 20.9658, 13.6590, 19.8971, 29.9949, 51.5129, 19.4459,  8.3946,\n",
      "        24.3993, 23.4747, 15.7375,  2.8852, 19.0170, 11.2138,  7.9211, 16.5407,\n",
      "        21.3613, 16.6293,  8.7088, 17.3530,  8.9425, 27.4329,  9.8839, 11.1814,\n",
      "        23.7970,  8.3490, 15.1386, 15.1727,  9.7682,  8.9112, 29.9447,  6.5114,\n",
      "        14.4747, 22.3528,  3.3374,  9.8954, 20.1660, 19.8860, 22.9301,  9.0843,\n",
      "        56.5957, 21.3324, 15.9422, 14.2046,  5.8910,  3.3944, 11.3747,  9.8419,\n",
      "        13.6895, 17.9684, 13.0787, 10.5197, 21.5511, 20.6186,  6.0028, 22.9059,\n",
      "        32.0255, 24.2877,  9.8821, 19.8086, 24.5569,  8.4188, 14.2685, 45.4336,\n",
      "        18.2045, 22.9292, 15.4768, 18.4366, 17.2114, 24.7470, 32.2343, 16.5706,\n",
      "        21.1835, 19.2909, 17.4545, 18.9166, 11.5759, 14.9124, 23.8714,  6.2372,\n",
      "        27.2504, 20.3451, 13.1120, 21.2833, 24.9663, 18.3937, 21.1898, 32.0760,\n",
      "        12.5305,  9.9850, 10.6802,  8.9385, 23.0105, 18.3320, 19.5744, 14.3437,\n",
      "        19.3685, 23.0539, 11.5219,  8.7167, 21.2349,  7.5717,  9.4733, 18.1848,\n",
      "        17.6287,  8.5232, 14.2738, 16.5454, 12.2992, 22.6647, 24.3624, 24.8893,\n",
      "        12.9125, 21.0097, 15.1009, 14.2307, 15.0117, 27.1055,  7.5715, 22.9960,\n",
      "        17.6689, 37.1385, 33.9512, 50.1337, 26.9509, 12.4468, 29.7731, 21.9607,\n",
      "         5.9362, 17.4097,  8.6110, 17.8753,  5.7983,  4.1574,  9.8709,  8.7850,\n",
      "        16.1324, 15.2468, 20.9320, 13.3364,  7.7528, 15.7650, 16.9057,  8.2251,\n",
      "        35.8392, 34.5625, 16.3755, 11.7662, 15.8139, 19.8953, 17.5590,  1.7333,\n",
      "        24.2441, 11.7122, 10.2459, 10.4543, 21.8676,  6.9871, 17.5068, 19.1899,\n",
      "        13.9330, 11.8671, 16.7053,  7.8468, 11.5575, 15.2920, 28.7721,  5.9957,\n",
      "        35.4336, 10.8789, 24.0589, 19.5030,  4.6826, 18.8308, 28.9727, 15.2518,\n",
      "         2.6003,  8.6070, 18.8890, 12.4441, 15.2867, 19.1584, 20.6618, 16.5801,\n",
      "        12.6387, 13.3847, 20.7052, 14.4927,  5.2121, 17.8641, 21.0102, 13.4769,\n",
      "         2.0465,  3.5428, 18.7483,  3.1091, 14.2408, 15.6598, 56.4085,  6.4793,\n",
      "        29.4032,  9.3927, 22.3580, 11.5703, 19.3785, 12.2508, 14.6409, 14.9497,\n",
      "        20.5749, 11.8129, 18.2707, 19.4164,  1.6442, 14.8636, 17.3603, 11.8325,\n",
      "        12.9020, 25.1322,  6.1456, 22.6578,  2.1803, 12.7686, 16.9341, 20.4725,\n",
      "         2.6711, 27.0951,  4.5227,  7.0566,  2.8163,  8.3544, 10.5898,  5.0996,\n",
      "         3.7315, 17.0314,  6.9835, 41.7290,  9.2975,  5.2171, 20.0402, 16.3074])), ('layer4.1.num_batches_tracked', tensor(309)), ('layer4.3.weight', tensor([[[[-0.0096, -0.0071,  0.0142],\n",
      "          [ 0.0117,  0.0258, -0.0020],\n",
      "          [ 0.0110,  0.0098, -0.0059]],\n",
      "\n",
      "         [[-0.0026, -0.0109, -0.0077],\n",
      "          [-0.0050, -0.0284, -0.0111],\n",
      "          [-0.0054,  0.0062,  0.0082]],\n",
      "\n",
      "         [[-0.0043,  0.0136,  0.0123],\n",
      "          [-0.0013,  0.0034,  0.0136],\n",
      "          [-0.0100, -0.0019,  0.0068]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0033, -0.0005,  0.0120],\n",
      "          [ 0.0041,  0.0194, -0.0090],\n",
      "          [ 0.0146,  0.0135, -0.0144]],\n",
      "\n",
      "         [[ 0.0123, -0.0032,  0.0126],\n",
      "          [ 0.0135,  0.0014,  0.0010],\n",
      "          [ 0.0096,  0.0012,  0.0109]],\n",
      "\n",
      "         [[ 0.0090, -0.0037, -0.0145],\n",
      "          [ 0.0015, -0.0166, -0.0044],\n",
      "          [-0.0107, -0.0010,  0.0049]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0064,  0.0089,  0.0019],\n",
      "          [-0.0032,  0.0221, -0.0138],\n",
      "          [ 0.0014,  0.0077,  0.0011]],\n",
      "\n",
      "         [[ 0.0025,  0.0112,  0.0033],\n",
      "          [ 0.0055, -0.0184, -0.0105],\n",
      "          [-0.0005,  0.0099, -0.0036]],\n",
      "\n",
      "         [[ 0.0113, -0.0023,  0.0025],\n",
      "          [-0.0068, -0.0047,  0.0051],\n",
      "          [-0.0075, -0.0057,  0.0038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0042, -0.0007, -0.0014],\n",
      "          [-0.0019,  0.0073,  0.0097],\n",
      "          [ 0.0120, -0.0076,  0.0080]],\n",
      "\n",
      "         [[-0.0043, -0.0042, -0.0059],\n",
      "          [ 0.0018,  0.0162,  0.0089],\n",
      "          [-0.0128,  0.0101, -0.0028]],\n",
      "\n",
      "         [[ 0.0008,  0.0021, -0.0034],\n",
      "          [-0.0001, -0.0006, -0.0072],\n",
      "          [-0.0072,  0.0082,  0.0076]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0070, -0.0101, -0.0125],\n",
      "          [-0.0050, -0.0107,  0.0009],\n",
      "          [-0.0035,  0.0075, -0.0099]],\n",
      "\n",
      "         [[ 0.0062,  0.0017,  0.0048],\n",
      "          [ 0.0103,  0.0114,  0.0078],\n",
      "          [-0.0115,  0.0100, -0.0110]],\n",
      "\n",
      "         [[ 0.0013,  0.0118,  0.0141],\n",
      "          [ 0.0120,  0.0341, -0.0025],\n",
      "          [ 0.0016,  0.0033, -0.0074]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0130, -0.0019,  0.0060],\n",
      "          [ 0.0133, -0.0040, -0.0069],\n",
      "          [-0.0077,  0.0049, -0.0012]],\n",
      "\n",
      "         [[-0.0070, -0.0145,  0.0135],\n",
      "          [-0.0132, -0.0062,  0.0127],\n",
      "          [-0.0026,  0.0020,  0.0077]],\n",
      "\n",
      "         [[ 0.0067,  0.0061,  0.0105],\n",
      "          [ 0.0131,  0.0080,  0.0117],\n",
      "          [ 0.0104, -0.0146,  0.0142]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0012,  0.0026, -0.0103],\n",
      "          [ 0.0134,  0.0140,  0.0098],\n",
      "          [-0.0060, -0.0023, -0.0092]],\n",
      "\n",
      "         [[ 0.0100, -0.0014, -0.0100],\n",
      "          [ 0.0031, -0.0090, -0.0105],\n",
      "          [-0.0005, -0.0122, -0.0143]],\n",
      "\n",
      "         [[-0.0018, -0.0054,  0.0087],\n",
      "          [ 0.0055,  0.0007,  0.0135],\n",
      "          [ 0.0130,  0.0077,  0.0009]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0089,  0.0102,  0.0098],\n",
      "          [-0.0083,  0.0265, -0.0053],\n",
      "          [-0.0016, -0.0026,  0.0081]],\n",
      "\n",
      "         [[-0.0142, -0.0071,  0.0044],\n",
      "          [ 0.0111,  0.0047, -0.0052],\n",
      "          [-0.0104,  0.0104, -0.0054]],\n",
      "\n",
      "         [[ 0.0047,  0.0028,  0.0109],\n",
      "          [ 0.0015, -0.0224, -0.0058],\n",
      "          [ 0.0134, -0.0024,  0.0131]]],\n",
      "\n",
      "\n",
      "        [[[-0.0035,  0.0090,  0.0069],\n",
      "          [-0.0070,  0.0077,  0.0124],\n",
      "          [-0.0049, -0.0134, -0.0049]],\n",
      "\n",
      "         [[-0.0027, -0.0125, -0.0016],\n",
      "          [ 0.0079,  0.0002,  0.0069],\n",
      "          [ 0.0065, -0.0135,  0.0065]],\n",
      "\n",
      "         [[-0.0117,  0.0055,  0.0078],\n",
      "          [ 0.0004,  0.0149, -0.0007],\n",
      "          [-0.0059,  0.0050,  0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0039, -0.0054,  0.0003],\n",
      "          [ 0.0136, -0.0018,  0.0057],\n",
      "          [-0.0109, -0.0002,  0.0017]],\n",
      "\n",
      "         [[-0.0061, -0.0090,  0.0137],\n",
      "          [-0.0071,  0.0186,  0.0086],\n",
      "          [-0.0080,  0.0022,  0.0001]],\n",
      "\n",
      "         [[ 0.0094,  0.0025,  0.0020],\n",
      "          [ 0.0092,  0.0191, -0.0011],\n",
      "          [-0.0072,  0.0018,  0.0108]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0081,  0.0059,  0.0092],\n",
      "          [ 0.0046,  0.0214, -0.0037],\n",
      "          [ 0.0141,  0.0098, -0.0074]],\n",
      "\n",
      "         [[-0.0118,  0.0053,  0.0032],\n",
      "          [ 0.0057, -0.0003, -0.0087],\n",
      "          [-0.0065,  0.0101,  0.0022]],\n",
      "\n",
      "         [[-0.0094,  0.0091,  0.0060],\n",
      "          [ 0.0128, -0.0004, -0.0107],\n",
      "          [-0.0107, -0.0080,  0.0072]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0080, -0.0001,  0.0101],\n",
      "          [-0.0001,  0.0046, -0.0103],\n",
      "          [-0.0002, -0.0083,  0.0074]],\n",
      "\n",
      "         [[ 0.0077,  0.0075,  0.0019],\n",
      "          [-0.0016,  0.0103, -0.0112],\n",
      "          [-0.0055,  0.0025,  0.0096]],\n",
      "\n",
      "         [[ 0.0015,  0.0116,  0.0082],\n",
      "          [ 0.0066, -0.0103,  0.0064],\n",
      "          [-0.0068, -0.0070,  0.0125]]]])), ('layer4.4.weight', tensor([1.0112, 0.9792, 0.9989, 0.9861, 0.9969, 1.0395, 1.0156, 1.0163, 0.9877,\n",
      "        0.9964, 1.0353, 1.0041, 1.0204, 1.0057, 0.9882, 0.9718, 0.9749, 1.0116,\n",
      "        0.9810, 0.9922, 0.9874, 0.9908, 0.9910, 0.9780, 0.9888, 0.9772, 0.9539,\n",
      "        1.0047, 0.9908, 1.0177, 0.9868, 0.9941, 1.0142, 0.9697, 0.9892, 0.9761,\n",
      "        0.9753, 0.9964, 0.9771, 0.9780, 1.0046, 1.0042, 0.9818, 0.9829, 0.9990,\n",
      "        0.9827, 0.9867, 0.9850, 0.9916, 1.0491, 0.9934, 0.9861, 0.9915, 0.9835,\n",
      "        1.0032, 1.0062, 1.0026, 1.0039, 1.0060, 0.9812, 0.9947, 1.0140, 1.0474,\n",
      "        1.0094, 0.9842, 0.9772, 1.0307, 0.9925, 0.9861, 1.0242, 1.0172, 1.0275,\n",
      "        1.0074, 0.9968, 1.0002, 0.9896, 0.9895, 1.0205, 0.9964, 0.9766, 0.9921,\n",
      "        0.9742, 1.0390, 1.0054, 0.9983, 1.0148, 1.0104, 1.0049, 0.9799, 0.9970,\n",
      "        0.9843, 0.9849, 0.9913, 0.9719, 1.0033, 0.9882, 0.9936, 0.9976, 0.9952,\n",
      "        0.9850, 1.0410, 0.9883, 1.0496, 0.9784, 0.9953, 1.0307, 1.0028, 0.9942,\n",
      "        0.9807, 1.0385, 1.0129, 1.0132, 1.0484, 1.0452, 1.0237, 1.0008, 0.9719,\n",
      "        1.0030, 0.9885, 0.9813, 0.9979, 1.0208, 0.9860, 0.9925, 0.9978, 0.9770,\n",
      "        1.0086, 0.9869, 0.9843, 0.9831, 1.0191, 0.9666, 0.9993, 0.9977, 1.0445,\n",
      "        0.9945, 0.9919, 0.9969, 0.9900, 0.9902, 0.9942, 1.0109, 0.9998, 0.9899,\n",
      "        0.9820, 0.9783, 1.0072, 1.0322, 0.9942, 0.9909, 1.0032, 0.9888, 0.9964,\n",
      "        0.9946, 0.9707, 1.0010, 0.9804, 0.9895, 0.9890, 0.9955, 0.9942, 0.9727,\n",
      "        0.9726, 1.0286, 1.0138, 0.9908, 1.0200, 0.9734, 0.9782, 1.0298, 1.0282,\n",
      "        0.9929, 0.9995, 0.9763, 1.0128, 0.9964, 0.9751, 0.9889, 0.9711, 0.9871,\n",
      "        0.9977, 0.9905, 0.9912, 1.0252, 1.0487, 1.0111, 0.9994, 1.0042, 0.9850,\n",
      "        0.9827, 0.9690, 0.9942, 0.9748, 1.0200, 1.0000, 1.0143, 1.0323, 0.9989,\n",
      "        0.9953, 1.0159, 0.9887, 0.9716, 0.9958, 0.9933, 1.0114, 0.9958, 0.9885,\n",
      "        1.0134, 0.9810, 0.9797, 1.0222, 0.9932, 0.9892, 1.0390, 1.0036, 0.9827,\n",
      "        0.9834, 0.9751, 0.9888, 1.0130, 1.0111, 0.9904, 0.9999, 1.0198, 0.9843,\n",
      "        1.0047, 0.9813, 0.9778, 1.0158, 1.0016, 1.0031, 0.9865, 0.9908, 0.9795,\n",
      "        0.9915, 0.9851, 0.9956, 0.9912, 0.9947, 1.0516, 0.9879, 0.9981, 0.9766,\n",
      "        0.9823, 0.9702, 1.0063, 0.9840, 1.0586, 0.9649, 1.0177, 0.9741, 1.0331,\n",
      "        0.9847, 0.9914, 0.9894, 0.9854, 1.0108, 1.0178, 0.9908, 1.0112, 0.9761,\n",
      "        0.9960, 1.0047, 0.9822, 1.0029, 1.0014, 0.9722, 0.9909, 1.0568, 1.0445,\n",
      "        0.9855, 0.9980, 1.0311, 0.9790, 0.9854, 1.0214, 1.0020, 1.0001, 0.9786,\n",
      "        0.9956, 0.9577, 0.9751, 1.0001, 0.9976, 0.9788, 0.9737, 1.0024, 0.9838,\n",
      "        0.9855, 1.0249, 0.9994, 1.0160, 0.9815, 1.0212, 1.0044, 0.9937, 0.9988,\n",
      "        0.9880, 0.9956, 0.9911, 0.9843, 0.9838, 1.0048, 0.9821, 1.0095, 0.9999,\n",
      "        1.0339, 0.9953, 0.9980, 1.0092, 0.9798, 1.0025, 1.0348, 0.9841, 0.9987,\n",
      "        0.9964, 0.9856, 0.9852, 1.0457, 1.0284, 1.0129, 0.9857, 1.0336, 0.9866,\n",
      "        0.9943, 0.9861, 1.0008, 0.9906, 1.0084, 0.9897, 1.0047, 1.0146, 1.0005,\n",
      "        0.9889, 1.0033, 0.9854, 1.0015, 1.0139, 0.9912, 1.0052, 1.0357, 0.9914,\n",
      "        1.0106, 1.0430, 0.9789, 0.9892, 0.9866, 0.9984, 0.9938, 1.0041, 0.9937,\n",
      "        1.0290, 1.0323, 0.9927, 1.0118, 1.0054, 0.9949, 0.9947, 0.9980, 0.9865,\n",
      "        0.9797, 0.9764, 1.0129, 1.0033, 1.0622, 1.0002, 0.9956, 0.9918, 0.9694,\n",
      "        0.9897, 0.9965, 0.9674, 0.9960, 0.9964, 0.9828, 1.0012, 0.9596, 0.9855,\n",
      "        0.9836, 1.0120, 0.9720, 1.0214, 1.0200, 0.9929, 1.0036, 0.9809, 1.0411,\n",
      "        0.9901, 0.9749, 0.9874, 1.0233, 0.9839, 1.0018, 0.9934, 0.9891, 1.0000,\n",
      "        1.0064, 0.9645, 0.9829, 0.9790, 0.9902, 1.0202, 1.0055, 0.9897, 0.9680,\n",
      "        1.0078, 0.9964, 0.9960, 0.9808, 0.9920, 0.9706, 0.9911, 1.0082, 0.9994,\n",
      "        0.9988, 0.9773, 1.0257, 1.0118, 1.0081, 0.9733, 0.9914, 1.0017, 0.9976,\n",
      "        0.9786, 1.0058, 0.9570, 0.9667, 0.9692, 0.9998, 1.0043, 1.0119, 1.0076,\n",
      "        0.9790, 0.9933, 0.9975, 0.9858, 0.9912, 0.9984, 1.0007, 1.0288, 1.0141,\n",
      "        0.9833, 1.0121, 0.9940, 1.0006, 0.9760, 0.9960, 1.0115, 0.9890, 0.9860,\n",
      "        0.9919, 1.0195, 0.9792, 1.0224, 0.9929, 1.0456, 1.0065, 1.0075, 1.0878,\n",
      "        0.9623, 0.9931, 1.0068, 0.9831, 1.0180, 0.9753, 1.0191, 0.9844, 0.9812,\n",
      "        0.9887, 1.0063, 0.9993, 1.0271, 0.9899, 0.9758, 0.9922, 0.9922, 0.9874,\n",
      "        0.9931, 0.9877, 1.0299, 1.0131, 1.0118, 1.0138, 1.0027, 1.0158, 1.0053,\n",
      "        0.9752, 0.9640, 0.9892, 1.0125, 0.9903, 0.9898, 0.9751, 0.9950, 0.9982,\n",
      "        0.9891, 1.0004, 1.0046, 0.9910, 1.0059, 1.0314, 0.9939, 0.9625, 0.9963,\n",
      "        0.9869, 1.0239, 1.0029, 0.9849, 1.0150, 0.9711, 0.9880, 0.9776])), ('layer4.4.bias', tensor([ 1.1887e-02, -1.0299e-01, -4.1887e-03, -9.6232e-03, -9.2010e-02,\n",
      "         8.9554e-03, -5.6833e-02,  2.8423e-02, -1.3021e-01, -1.4553e-02,\n",
      "         4.1178e-02, -9.4641e-02, -4.7716e-03,  2.5175e-02, -1.0747e-01,\n",
      "        -8.5938e-02, -7.6211e-02,  2.1645e-02, -1.3766e-01, -2.8384e-02,\n",
      "        -6.3856e-02, -1.2021e-01, -9.6866e-03, -2.9411e-02, -9.7388e-02,\n",
      "        -6.9653e-02, -1.2700e-01, -6.6385e-02,  1.4619e-03, -2.5868e-02,\n",
      "        -1.4734e-01, -1.7293e-02, -1.7707e-02, -8.9122e-02, -1.6972e-02,\n",
      "        -8.7261e-02, -9.9008e-02, -9.3633e-02, -3.7879e-02, -3.4895e-02,\n",
      "        -1.1016e-02,  2.2957e-03, -8.3694e-02, -1.2487e-01, -9.0404e-02,\n",
      "        -5.5684e-02, -1.0778e-01, -1.1468e-01, -1.0358e-01,  4.5862e-02,\n",
      "        -1.1762e-01, -3.0925e-02, -1.0183e-01, -4.5700e-02, -2.4495e-02,\n",
      "        -2.1126e-02,  1.8027e-02, -3.2568e-03, -4.9863e-02, -6.4061e-02,\n",
      "        -5.3412e-02,  3.2009e-02, -1.6849e-02, -1.5749e-02, -8.1593e-02,\n",
      "        -9.2955e-02,  1.7892e-03, -1.0424e-01, -5.9623e-02,  1.0808e-02,\n",
      "        -6.9924e-03,  2.9442e-02, -6.0883e-03, -2.4088e-03, -1.7467e-02,\n",
      "        -6.2133e-02, -1.0401e-01,  5.8128e-03, -2.8527e-02, -1.3295e-01,\n",
      "        -1.4938e-02, -7.2425e-02, -2.0370e-02, -5.5128e-02, -1.0157e-01,\n",
      "        -4.1583e-02,  2.4475e-02, -1.1654e-02, -2.7667e-02, -5.4113e-02,\n",
      "        -1.0401e-01, -9.8136e-02, -6.4305e-02, -5.3359e-02,  1.0557e-02,\n",
      "        -3.8671e-02, -7.4593e-03, -9.8874e-02, -1.9343e-02, -9.4407e-02,\n",
      "         4.4230e-04, -6.7160e-02,  4.4715e-03, -9.2255e-02, -2.2419e-02,\n",
      "         3.2613e-02, -7.4201e-02, -1.1235e-01, -1.2767e-01,  1.7736e-03,\n",
      "         4.1271e-02, -8.4750e-02,  3.6895e-02,  2.5334e-02, -4.2003e-03,\n",
      "        -3.2384e-02, -6.5392e-02,  4.0549e-03, -8.3046e-02, -1.1820e-01,\n",
      "        -6.0954e-03,  1.9723e-02, -3.0350e-02, -5.1982e-03, -7.0023e-02,\n",
      "        -1.0389e-01, -2.0718e-02, -1.3728e-01, -9.0462e-02, -1.1327e-01,\n",
      "         2.8593e-02, -8.8734e-02, -5.0311e-02, -9.6828e-02,  1.2100e-02,\n",
      "        -3.5163e-03, -1.1683e-01, -2.2438e-02, -1.0200e-01, -4.2267e-02,\n",
      "        -2.0808e-02, -3.5753e-02, -1.0105e-01, -1.0823e-01, -1.1868e-01,\n",
      "        -1.1118e-02,  2.2020e-03,  2.2528e-02, -2.6133e-02, -7.7510e-02,\n",
      "         1.2253e-02, -1.0511e-01,  2.2819e-03, -4.8635e-03, -1.2722e-01,\n",
      "        -5.3663e-02, -6.4045e-02, -1.2298e-01, -6.6540e-04, -8.9621e-03,\n",
      "        -3.0054e-02, -8.9007e-02, -1.1372e-01, -1.4813e-02,  1.2320e-02,\n",
      "        -8.4585e-02,  1.3288e-03, -6.0716e-02, -9.2050e-02,  3.1426e-02,\n",
      "        -2.8078e-02, -6.2459e-03, -4.4369e-02, -7.5488e-02, -1.9085e-02,\n",
      "        -2.7255e-02, -5.3620e-02, -7.4975e-02, -6.6712e-02, -1.6379e-03,\n",
      "        -9.2477e-02, -6.4362e-02, -1.1948e-01, -3.4739e-02, -1.2284e-02,\n",
      "         2.8514e-02, -2.5287e-02, -2.6807e-03, -1.2154e-01, -1.1494e-01,\n",
      "        -1.2099e-01, -7.5901e-02, -8.0341e-02, -3.5008e-02,  6.4113e-03,\n",
      "        -4.9498e-03,  4.5807e-02, -9.0799e-02, -4.4326e-02, -7.9824e-02,\n",
      "        -1.1757e-02, -8.8253e-02,  3.1512e-03, -1.3567e-02, -2.7267e-02,\n",
      "         3.4837e-04, -3.4287e-02,  3.1940e-02, -8.7994e-02, -4.4715e-02,\n",
      "         2.1942e-02, -1.2132e-02, -1.2818e-01,  2.4047e-02, -4.2099e-03,\n",
      "        -8.9786e-02, -1.1411e-01, -1.1980e-01, -6.9943e-02, -2.8782e-02,\n",
      "        -2.0088e-03, -1.4871e-02, -2.2866e-02,  3.0331e-02, -7.6570e-02,\n",
      "        -1.5508e-02, -1.4683e-01, -1.1500e-01,  4.5753e-03, -2.0105e-02,\n",
      "        -2.0487e-02, -6.4947e-02, -1.0225e-01, -2.3455e-02, -6.3026e-02,\n",
      "        -1.3599e-02, -2.8439e-02, -6.2175e-02, -7.0784e-02, -1.2614e-02,\n",
      "        -3.0673e-02, -1.6679e-02, -1.1400e-01, -1.4139e-01, -9.6826e-02,\n",
      "        -8.4321e-03, -6.6492e-02,  1.6752e-03, -9.2744e-02,  2.2341e-03,\n",
      "        -1.1107e-01, -3.7702e-02, -5.1318e-02, -1.0788e-01, -1.4713e-01,\n",
      "        -1.2229e-01,  1.1243e-02, -8.6307e-03, -8.7252e-02, -3.2555e-02,\n",
      "        -1.1099e-01, -5.1818e-02,  1.8238e-03, -8.2657e-02, -5.8758e-02,\n",
      "        -9.2104e-02, -8.9288e-02, -2.5631e-02, -4.7098e-02, -1.2594e-02,\n",
      "        -6.5423e-03,  9.1313e-04,  6.2450e-02, -1.0817e-01, -1.0851e-01,\n",
      "         1.3606e-02, -7.8910e-02, -1.8549e-02, -1.0271e-01, -1.0784e-01,\n",
      "        -1.0876e-01, -6.4828e-02,  1.0382e-02, -7.2181e-02, -9.6176e-02,\n",
      "        -7.8420e-02, -3.5569e-02, -1.0105e-01, -1.5060e-01,  7.9319e-03,\n",
      "         1.0604e-02,  1.8113e-02, -1.6163e-02,  2.5132e-02, -7.9486e-02,\n",
      "        -1.2822e-01, -1.0630e-01, -1.0392e-01, -1.6703e-02, -1.4028e-03,\n",
      "        -1.2900e-01, -1.2176e-01, -1.1083e-02, -1.1019e-01, -1.5932e-02,\n",
      "        -3.5662e-02, -1.6304e-02,  8.6715e-03, -1.8298e-02, -8.4300e-02,\n",
      "        -5.9835e-02, -4.1511e-04, -3.1602e-03, -7.8078e-02,  1.4643e-05,\n",
      "        -9.2649e-02, -1.3277e-01, -1.1082e-01,  3.0052e-02,  1.7547e-02,\n",
      "        -9.3181e-02, -1.1796e-01, -2.7406e-02, -1.2405e-01, -6.3422e-02,\n",
      "        -4.9615e-02,  3.4088e-03, -6.0767e-02,  2.0740e-03, -9.7129e-02,\n",
      "        -7.8785e-02, -5.3117e-02, -6.7122e-02, -2.8035e-02,  6.9878e-03,\n",
      "        -3.3583e-03,  1.4599e-02, -1.1123e-02, -6.4594e-02, -2.6198e-02,\n",
      "        -1.3047e-02, -1.7549e-03, -2.9329e-03,  4.3815e-02, -1.4323e-01,\n",
      "        -7.3275e-02, -7.2568e-02, -1.3796e-02, -9.3138e-03, -7.5150e-03,\n",
      "        -8.9200e-02, -1.5227e-02,  1.5369e-02, -1.0212e-02, -1.1647e-02,\n",
      "        -5.4567e-02, -3.8437e-02, -1.4667e-02, -9.1681e-02, -6.1306e-02,\n",
      "        -1.2441e-01, -8.5617e-02,  3.8451e-03,  9.8322e-04,  3.3421e-02,\n",
      "        -1.6518e-02, -9.0208e-02, -1.0272e-01, -8.2609e-02, -9.7663e-02,\n",
      "        -3.2021e-03, -8.6266e-02, -1.1285e-01,  1.7943e-03, -9.6663e-02,\n",
      "        -3.1608e-02, -8.3603e-02, -1.7739e-02, -4.4270e-02,  2.4269e-02,\n",
      "        -1.1468e-01,  4.5702e-02,  2.5351e-02, -1.9007e-02, -1.5954e-02,\n",
      "        -8.8560e-02, -5.8986e-03, -2.7583e-02, -1.1755e-01, -1.1425e-02,\n",
      "         3.4392e-02, -1.0323e-01, -7.8150e-02, -5.6230e-02, -5.9982e-02,\n",
      "        -5.2125e-02, -3.0338e-02, -1.1391e-01, -1.4777e-01, -5.6789e-02,\n",
      "        -8.3903e-02, -3.3320e-02, -1.1143e-01, -3.1621e-02, -8.0879e-02,\n",
      "        -5.8440e-02, -9.9694e-02, -6.4258e-02, -9.4829e-02, -9.7623e-02,\n",
      "        -1.4045e-01, -1.2236e-01, -6.5095e-03, -4.6062e-02,  1.8418e-03,\n",
      "        -3.4060e-02, -3.1949e-02,  1.4728e-02, -1.4681e-03, -5.5604e-02,\n",
      "        -3.0097e-02, -1.0082e-01, -3.2045e-02, -8.4699e-02, -8.1472e-02,\n",
      "        -1.0161e-01, -1.2245e-01, -4.0798e-02,  9.3214e-03,  4.8680e-03,\n",
      "        -5.6267e-03, -1.8958e-02, -9.7000e-02, -1.0203e-01,  4.2228e-03,\n",
      "        -5.2853e-02, -8.7688e-02, -1.0042e-01, -2.3562e-02, -3.3453e-03,\n",
      "        -2.3728e-02, -9.7796e-02, -1.0603e-02, -7.6350e-02, -1.5953e-02,\n",
      "        -7.7759e-02,  1.1288e-02, -4.4269e-02, -1.0479e-01, -9.4141e-02,\n",
      "        -6.5985e-02,  7.6851e-03, -3.7706e-02,  3.1141e-02, -3.0266e-02,\n",
      "        -2.8434e-02, -1.7158e-02, -1.3981e-01,  4.1808e-02, -9.7718e-02,\n",
      "        -1.0595e-01,  8.2871e-03, -8.7698e-02, -6.3645e-02, -7.2552e-02,\n",
      "        -1.1253e-02, -5.1170e-02, -9.3911e-02, -9.9854e-02, -1.5512e-02,\n",
      "        -6.1241e-02,  1.4131e-02, -1.2037e-01, -8.9830e-02, -9.3493e-02,\n",
      "        -1.1262e-01, -1.2105e-02, -7.2212e-02, -1.2159e-01,  2.1308e-02,\n",
      "         1.8483e-03, -1.5693e-02,  7.5706e-03,  2.0958e-03,  1.8819e-02,\n",
      "        -7.5975e-03, -1.5722e-01, -4.4936e-02, -1.6845e-02, -3.0308e-02,\n",
      "        -1.3779e-02, -5.1406e-02, -9.7662e-02, -1.0437e-01, -1.0820e-04,\n",
      "        -1.2326e-01, -2.1697e-02, -4.3732e-02, -8.7253e-03, -2.0728e-03,\n",
      "         5.1111e-02, -4.4699e-02, -1.1473e-01, -8.1855e-02, -1.0164e-01,\n",
      "         2.2803e-02, -3.7898e-02, -1.0789e-01, -2.7720e-02, -9.6958e-02,\n",
      "        -8.4139e-02, -9.8016e-02])), ('layer4.4.running_mean', tensor([ 9.1205e-01,  1.2984e+00, -4.4314e-01,  4.1276e-03,  1.0788e+00,\n",
      "        -6.6770e-01,  7.0502e-01,  5.9513e-01,  1.5852e+00, -1.2876e-01,\n",
      "        -1.2174e+00,  1.2946e+00,  1.2888e+00, -3.8044e-01,  1.6249e+00,\n",
      "         1.0793e+00,  1.4363e+00,  3.2795e-01,  1.6207e+00, -1.3301e-02,\n",
      "         5.8280e-01,  1.3070e+00,  5.4551e-01, -3.5611e-01,  1.6521e+00,\n",
      "         7.2670e-01,  1.6476e+00,  1.2801e+00, -1.3767e-01,  1.6011e+00,\n",
      "         1.5154e+00,  6.6297e-01,  1.0571e-01,  1.1706e+00,  2.7094e-01,\n",
      "         1.1393e+00,  1.2663e+00,  1.5960e+00,  9.4045e-02,  2.9240e-01,\n",
      "         7.0014e-01, -1.3528e-01,  8.3173e-01,  1.4944e+00,  1.1792e+00,\n",
      "         9.8557e-01,  1.3836e+00,  1.8225e+00,  1.1289e+00, -1.0986e+00,\n",
      "         1.4783e+00, -3.3670e-01,  1.4433e+00, -1.0566e-01,  1.2428e-01,\n",
      "         8.4789e-02, -1.1581e+00, -3.9292e-01,  1.1593e+00,  5.5235e-01,\n",
      "         8.6198e-01, -1.1024e+00, -3.4880e-01,  5.8637e-01,  1.2523e+00,\n",
      "         7.9300e-01,  1.6047e-01,  1.1272e+00,  4.3574e-01,  2.6337e-01,\n",
      "         2.7431e-01, -1.3296e+00,  6.0796e-01, -6.8673e-01,  1.2767e+00,\n",
      "         9.9944e-01,  1.3628e+00,  3.8200e-01,  6.9886e-01,  1.5563e+00,\n",
      "         4.2420e-01,  1.2639e+00,  6.4829e-01,  1.4231e+00,  1.3207e+00,\n",
      "         1.3722e+00,  1.5253e-01,  5.7973e-02,  7.8164e-01,  1.3880e+00,\n",
      "         1.4718e+00,  1.2495e+00,  9.0972e-01,  1.2178e+00, -5.5903e-01,\n",
      "         9.2823e-01, -2.1698e-01,  1.1477e+00,  7.1046e-01,  1.3390e+00,\n",
      "         8.4016e-01,  3.3886e+00,  1.4488e+00,  1.2098e+00, -5.4952e-01,\n",
      "        -7.9093e-01,  1.2733e+00,  1.4348e+00,  1.4728e+00, -1.0994e-01,\n",
      "        -1.1365e+00,  1.8478e+00,  5.0597e-01, -1.0310e+00,  1.5570e-01,\n",
      "         4.2300e-01,  9.8398e-01, -9.1012e-01,  1.2805e+00,  1.5174e+00,\n",
      "         1.9298e-01,  7.8581e-03,  7.2790e-01, -2.4198e-01,  9.4945e-01,\n",
      "         1.3564e+00,  9.7720e-01,  1.7391e+00,  1.5070e+00,  1.4968e+00,\n",
      "        -1.8536e+00,  1.0695e+00,  1.1645e+00,  1.1716e+00, -8.1981e-02,\n",
      "         3.4089e-01,  1.5907e+00,  4.1698e-01,  1.7303e+00,  8.8152e-01,\n",
      "         7.6508e-01,  1.3523e+00,  1.3968e+00,  1.5183e+00,  1.3018e+00,\n",
      "         5.8964e-01, -1.5178e+00, -6.7457e-01,  5.6662e-02,  8.1022e-01,\n",
      "        -8.4362e-01,  1.3096e+00, -1.5324e+00, -8.2248e-01,  1.5365e+00,\n",
      "         1.0993e+00, -2.0988e-02,  1.4088e+00, -9.3818e-03,  1.3120e+00,\n",
      "        -2.4163e-01,  1.0423e+00,  1.3677e+00,  1.1218e+00,  1.2367e+00,\n",
      "         1.2289e+00,  4.7203e-01,  7.0989e-01,  1.2262e+00, -9.2575e-01,\n",
      "        -3.9061e-01, -5.0000e-01,  4.5048e-01,  8.8991e-01,  2.8826e-01,\n",
      "        -7.6959e-01,  3.0289e-01,  1.2425e+00,  1.0282e+00,  1.8158e-01,\n",
      "         1.3277e+00,  9.0142e-01,  1.4218e+00,  7.5402e-01,  1.2745e+00,\n",
      "        -3.3280e+00,  2.2670e-01, -1.2370e-01,  1.4490e+00,  1.3768e+00,\n",
      "         1.6656e+00,  1.4809e+00,  9.6948e-01,  6.1634e-01, -2.6531e-01,\n",
      "        -1.5852e-01, -1.0530e+00,  1.8368e+00,  9.1587e-01,  1.4194e+00,\n",
      "        -2.3772e-01,  1.0351e+00, -9.6039e-02,  1.6128e-01,  1.5909e+00,\n",
      "         3.2675e-01,  1.0387e+00, -7.8229e-01,  2.0525e+00, -2.7650e-01,\n",
      "        -6.1236e-01,  5.2210e-01,  1.4674e+00,  6.2131e-01, -3.8231e-01,\n",
      "         1.4537e+00,  1.0128e+00,  1.5168e+00,  1.1429e+00,  4.8482e-01,\n",
      "         1.3882e-01,  3.3824e-01,  2.9462e-01,  7.0649e-01,  1.1721e+00,\n",
      "         9.6525e-01,  1.6286e+00,  1.4856e+00,  7.2610e-01, -3.3202e-01,\n",
      "         5.5547e-02,  1.0627e+00,  2.8292e+00, -5.2257e-01,  1.1624e+00,\n",
      "         7.1290e-01,  9.1780e-01,  7.3961e-01,  1.0773e+00,  3.4352e-01,\n",
      "         3.5357e-01, -1.3803e-01,  1.4594e+00,  1.5273e+00,  1.3349e+00,\n",
      "        -3.8716e-02,  1.5201e+00,  4.6966e-01,  1.1171e+00, -4.0358e-01,\n",
      "         1.3301e+00,  1.0589e+00,  8.7379e-01,  1.4720e+00,  1.7371e+00,\n",
      "         1.9200e+00, -5.2075e-01, -3.4609e-01,  1.0630e+00,  9.2710e-01,\n",
      "         1.6878e+00,  9.3145e-01, -4.6639e-01,  1.4652e+00,  1.0923e+00,\n",
      "         1.2010e+00,  1.2787e+00,  1.0494e+00,  9.7929e-01,  3.9745e-02,\n",
      "         2.2844e-01, -2.3265e+00, -1.7312e+00,  1.6002e+00,  1.2872e+00,\n",
      "        -6.7618e-01,  1.2895e+00,  1.2107e+00,  1.5731e+00,  1.4431e+00,\n",
      "         1.2809e+00,  5.5677e-01,  4.9467e-01,  8.4323e-01,  1.2610e+00,\n",
      "         8.8439e-01, -2.0831e-01,  1.4186e+00,  2.1909e+00, -2.2065e-01,\n",
      "         3.0375e-02, -6.9410e-01, -2.6315e-01, -5.0828e-01,  1.8019e+00,\n",
      "         1.3171e+00,  1.4988e+00,  1.3103e+00,  4.9818e-01,  1.0174e-01,\n",
      "         1.7260e+00,  1.8375e+00,  5.5050e-01,  1.3055e+00,  7.5445e-01,\n",
      "         1.2394e+00,  8.5265e-01, -1.1528e-01, -7.5431e-02,  1.5443e+00,\n",
      "         8.4641e-01, -5.5257e-01,  1.5129e-01,  1.2550e+00, -1.5565e+00,\n",
      "         1.3310e+00,  1.4429e+00,  1.4627e+00, -1.4304e+00,  4.0617e-01,\n",
      "         2.1364e+00,  1.5521e+00,  3.1181e-01,  1.3687e+00,  7.5122e-01,\n",
      "         1.7527e-01, -6.0947e-02,  1.0137e+00,  2.5645e-01,  1.9630e+00,\n",
      "         9.1427e-01,  1.5332e+00,  8.0420e-01,  6.2205e-01, -7.9945e-01,\n",
      "         9.3015e-02, -8.7614e-01,  1.5306e+00,  1.1021e+00,  9.2498e-01,\n",
      "         6.6574e-01,  7.4196e-01, -6.5433e-01, -4.2070e-01,  1.6672e+00,\n",
      "         1.1452e+00,  1.6065e+00,  7.5994e-01, -1.9550e-01,  3.4496e-01,\n",
      "         1.5320e+00,  5.7057e-01,  3.9224e-01,  1.2909e+00,  5.6215e-01,\n",
      "         1.0297e+00,  1.1432e+00, -3.9898e-01,  1.4515e+00,  1.7105e+00,\n",
      "         1.6178e+00,  1.1632e+00,  1.5292e+00, -6.4745e-01,  1.2761e+00,\n",
      "         1.1224e+00,  1.9168e+00,  1.2598e+00,  2.3453e-01,  1.3336e+00,\n",
      "        -3.8008e-02,  1.2883e+00,  1.6208e+00, -6.9176e-01,  1.1198e+00,\n",
      "         4.2417e-01,  1.0115e+00,  1.0765e+00,  5.1993e-01, -1.0925e+00,\n",
      "         1.5381e+00, -9.5253e-01, -1.1812e+00,  4.2508e-01,  2.4074e-01,\n",
      "         1.3763e+00, -7.1446e-02,  6.2953e-01,  1.3066e+00,  3.2829e-01,\n",
      "        -2.8956e-01,  1.2636e+00,  1.6519e+00,  1.7803e+00,  1.2366e+00,\n",
      "         1.1122e+00,  7.3948e-01,  1.7218e+00,  1.6518e+00,  9.7918e-01,\n",
      "         1.1774e+00,  4.0120e-01,  1.3493e+00, -6.9810e-01,  9.1170e-01,\n",
      "         1.5742e+00,  1.3222e+00,  9.4499e-01,  1.7293e+00,  1.3632e+00,\n",
      "         1.6032e+00,  1.6224e+00,  6.2127e-01,  9.1942e-01, -1.0463e+00,\n",
      "        -2.6831e-01,  6.7509e-01,  8.1343e-01, -3.2257e-01, -9.2769e-02,\n",
      "         1.3910e-01,  1.4366e+00,  1.1836e+00,  1.2520e+00,  1.3148e+00,\n",
      "         1.3038e+00,  1.5025e+00,  1.1881e-01, -6.9311e-01, -1.1605e+00,\n",
      "         1.4973e-01, -2.5049e-01,  1.4034e+00,  1.4660e+00,  1.1474e-01,\n",
      "         1.9992e+00,  7.4720e-01,  1.2666e+00,  1.1571e+00, -5.3570e-02,\n",
      "         1.0250e+00,  1.9650e+00,  1.5108e+00,  1.4619e+00,  1.0723e+00,\n",
      "         8.8888e-01,  6.3707e-01,  1.4674e+00,  1.2832e+00,  1.6954e+00,\n",
      "         1.4110e+00,  9.0699e-01,  8.6294e-01,  1.2705e-02,  9.7596e-01,\n",
      "         8.2225e-01,  4.0959e-01,  2.6198e+00,  4.9154e-02,  1.3653e+00,\n",
      "         1.1843e+00, -1.4021e+00,  1.0338e+00,  8.0852e-01,  1.6538e+00,\n",
      "         9.6834e-01,  1.6172e+00,  1.3881e+00,  1.3744e+00,  6.6101e-01,\n",
      "         1.1916e+00,  5.5251e-01,  1.7096e+00,  1.0602e+00,  1.1737e+00,\n",
      "         1.2916e+00,  3.3519e-01,  9.1642e-01,  1.3694e+00, -5.2491e-01,\n",
      "         1.0851e-03,  4.9778e-01, -7.1650e-01,  7.2814e-01,  2.5069e-01,\n",
      "         3.7511e-01,  1.8445e+00,  1.1008e-01, -4.2481e-01,  2.1865e-01,\n",
      "        -5.5059e-02,  1.2168e-02,  1.1481e+00,  1.2509e+00,  1.5483e+00,\n",
      "         1.8106e+00,  6.2357e-02,  9.5348e-01, -4.2468e-01,  3.7489e-02,\n",
      "        -1.4407e+00,  4.8528e-01,  1.5520e+00,  1.0294e+00,  1.4112e+00,\n",
      "         2.3917e-02, -3.4373e-01,  1.3899e+00,  2.3632e-01,  1.1895e+00,\n",
      "         1.4033e+00,  1.3106e+00])), ('layer4.4.running_var', tensor([ 2.2736,  5.4866,  3.5240,  2.0221,  5.2372,  6.1574,  3.6583,  1.8361,\n",
      "         9.5427,  1.3421,  3.8470,  5.4201,  4.0047,  1.9106,  5.5751,  3.2038,\n",
      "         3.7751,  3.3213,  5.2680,  3.0094,  2.2403,  5.6479,  2.4056,  2.4366,\n",
      "         6.1932,  5.0747,  7.6875,  4.3948,  1.6861,  5.6006,  6.2346,  1.4467,\n",
      "         1.4461,  2.7867,  1.7099,  1.8201,  5.7518,  5.4123,  3.0414,  0.9167,\n",
      "         2.1709,  2.1664,  4.1863,  6.3953,  5.6397,  2.9860,  6.3747,  5.9977,\n",
      "         5.3903,  1.9560,  3.9058,  2.8180,  7.3321,  2.0355,  3.4829,  2.2093,\n",
      "         0.9937,  1.6218,  8.0259,  2.0481,  4.6585,  1.5929,  2.6678,  3.2991,\n",
      "         5.4116,  3.5017,  1.7591,  5.6366,  0.7447,  3.0220,  2.0873,  4.7962,\n",
      "         2.7092,  1.1661,  2.4146,  5.6055,  8.0661,  1.3769,  4.1685,  8.1490,\n",
      "         1.2667,  4.2265,  4.9858,  5.5901,  5.6039,  9.0499,  1.9971,  1.1015,\n",
      "         2.1788,  5.0503,  7.6994,  6.4722,  2.4678,  5.7407,  2.5047,  4.7118,\n",
      "         1.2895,  5.8624,  0.9323,  6.0914,  1.9707, 12.2429,  3.8946,  4.1039,\n",
      "         1.6458,  8.2945,  4.2826,  8.9700,  5.1047,  2.4973,  5.9428,  4.8337,\n",
      "         1.5392,  3.0518,  1.8317,  1.9750,  3.6970,  3.0823,  5.9685,  4.6547,\n",
      "         0.3834,  5.6756,  2.6221,  2.8541,  5.6783,  7.2474,  2.2960,  5.6847,\n",
      "        11.0942,  4.8321, 15.5788,  2.8558,  5.9028,  4.8514,  1.0088,  0.8530,\n",
      "         8.3192,  1.8960,  5.7319,  0.8581,  1.9478,  2.5585,  5.8491,  7.0793,\n",
      "         4.9818,  1.5882,  3.2168,  4.1651,  0.6060,  5.7595,  2.9855,  5.7461,\n",
      "         1.8342,  2.2671,  6.7566,  3.0085,  3.7012,  6.0646,  0.6131,  2.8511,\n",
      "         1.9645,  4.9488,  6.0290,  2.8544,  1.9952,  6.5370,  1.2379,  2.8259,\n",
      "         5.9929,  5.5566,  2.8523,  1.6355,  3.7476,  2.4741,  1.4560,  2.6360,\n",
      "         1.2951,  2.9513,  3.8601,  1.1728,  3.9348,  4.5206,  6.8098,  2.7140,\n",
      "         4.9984, 15.3794,  1.4190,  3.0087,  7.0426,  6.5471,  6.5428,  3.5777,\n",
      "         2.0011,  1.5408,  2.0465,  3.7268,  3.7712,  6.3681,  1.7294,  5.2693,\n",
      "         1.8058,  2.9670,  0.6777,  1.5123,  2.2496,  0.4492,  4.6217,  2.4027,\n",
      "         4.5059,  2.3107,  4.4951,  1.1336,  5.7246,  1.0894,  0.7098,  3.6770,\n",
      "         7.7537,  5.2706,  6.2713,  2.2719,  1.5877,  1.3761,  1.6861,  1.0670,\n",
      "         5.6988,  2.0512,  8.6599,  5.3373,  2.0845,  1.8268,  1.2929,  5.9660,\n",
      "        10.3977,  2.9489,  1.2101,  1.7179,  3.5908,  6.7920,  2.5533,  2.7261,\n",
      "         1.4563,  1.7451,  5.4280,  5.6990, 10.0293,  1.1047,  4.7013,  1.7265,\n",
      "         5.2523,  0.6648,  3.5881,  4.9565,  1.5514,  6.7351,  7.4755,  7.0682,\n",
      "         3.5307,  1.9726,  2.3151,  2.5051,  6.8369,  3.6544,  2.5883,  5.3790,\n",
      "         2.8773,  6.4440,  5.8183,  2.2054,  5.3927,  3.6551,  1.6207,  5.1939,\n",
      "        10.5987,  3.2403,  4.9649,  7.7766,  7.6560,  3.7014, 13.0290,  3.7304,\n",
      "         5.3794,  2.3333,  1.1014,  3.4005,  4.3504,  4.4049,  1.8567,  7.2417,\n",
      "         9.9269,  1.1420,  0.3940,  3.4009,  3.2800,  4.0656, 10.3554,  7.2037,\n",
      "         7.9283,  7.3496,  1.7111,  1.4607, 10.6223,  3.9311,  1.2018,  6.2405,\n",
      "         2.1381,  3.1453,  3.6074,  1.6248,  0.8910,  4.0344,  2.4685,  1.4575,\n",
      "         2.3831,  3.4882,  7.5757,  6.8928,  4.6369,  6.1014,  1.3442,  1.0158,\n",
      "         6.0508,  8.4054,  4.1258,  4.5570,  3.8662,  2.2934,  2.6894,  6.3048,\n",
      "         1.0745,  4.3026,  4.7425,  4.6660,  5.2520,  4.6914,  4.6660,  2.2855,\n",
      "         1.2010,  3.0548,  6.3509,  7.8186,  1.2276,  2.3197,  1.5603,  1.5664,\n",
      "         6.7475,  7.2054,  4.6561,  2.1858,  0.5691,  0.7383,  3.7855,  3.0933,\n",
      "         1.4157,  2.7541,  4.4414,  6.0967,  2.4708,  1.4187,  7.6930,  3.9580,\n",
      "         5.6489,  5.6563,  0.8997,  3.4577,  5.9008,  1.4276, 12.2619,  5.2656,\n",
      "         1.0834,  4.8247,  2.2844,  5.3296,  9.7078,  1.3742,  5.3810,  1.3985,\n",
      "         2.8759,  2.0158,  1.4950,  6.7016,  9.1985,  2.5288,  6.3830,  1.7808,\n",
      "         1.0263,  7.1525,  1.6043,  4.8344,  6.0334,  0.6702,  4.1095,  6.6993,\n",
      "         7.2089,  9.7240,  5.6223,  4.6583,  4.5168,  3.7392,  5.9470,  5.2158,\n",
      "         8.5984,  1.6191,  6.2379,  1.8681,  2.9411,  6.1503,  5.2071,  1.4392,\n",
      "         4.7979,  3.5691,  4.6426,  7.4196,  1.4859,  1.9467,  6.0711,  3.5617,\n",
      "         3.9606,  1.5177,  6.5798,  0.3979,  1.3155,  6.8973,  0.7670,  5.3806,\n",
      "         3.7726,  1.9747,  9.6371,  0.9977,  3.6267,  2.8792,  2.0375,  1.0427,\n",
      "         3.7223,  8.3302,  0.5913, 16.2606,  4.2429,  7.5770,  2.9227,  2.2133,\n",
      "         2.4260, 10.6165,  2.8542,  1.9733,  0.9905,  5.6782,  0.8504,  5.0029,\n",
      "         5.0581,  9.3364, 10.2632,  1.9442,  1.6130,  1.8727,  3.4438,  3.2459,\n",
      "         0.8052,  7.1920,  6.9898,  5.7866,  4.5844,  6.8689,  4.6526,  1.2949,\n",
      "         6.4859,  2.7030,  1.1796,  7.8396,  3.4387,  1.7283,  2.0240,  4.4427,\n",
      "         7.8670,  4.2961,  3.5783,  6.5164,  2.0584,  3.6745,  5.4024,  0.9769,\n",
      "         2.7678,  2.8340,  5.3518,  2.8549,  0.7823,  2.3580,  9.7754,  1.7258,\n",
      "         0.5186,  1.8942,  0.8605,  0.3633,  6.0220,  5.1613,  1.7702,  4.9074,\n",
      "         0.4910,  5.5048,  1.2657,  2.4624,  3.2781,  1.1629,  6.7587,  4.5401,\n",
      "         6.9714,  3.1254,  0.6883,  9.0649,  2.5766,  5.5851,  7.7764,  3.6899])), ('layer4.4.num_batches_tracked', tensor(309)), ('layer4.6.weight', tensor([[[[ 0.0238]],\n",
      "\n",
      "         [[ 0.0200]],\n",
      "\n",
      "         [[-0.0036]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0257]],\n",
      "\n",
      "         [[ 0.0415]],\n",
      "\n",
      "         [[ 0.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0227]],\n",
      "\n",
      "         [[ 0.0195]],\n",
      "\n",
      "         [[-0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0069]],\n",
      "\n",
      "         [[ 0.0414]],\n",
      "\n",
      "         [[-0.0097]]],\n",
      "\n",
      "\n",
      "        [[[-0.0090]],\n",
      "\n",
      "         [[-0.0151]],\n",
      "\n",
      "         [[-0.0499]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         [[-0.0417]],\n",
      "\n",
      "         [[-0.0356]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0065]],\n",
      "\n",
      "         [[-0.0113]],\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0352]],\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         [[-0.0005]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0183]],\n",
      "\n",
      "         [[ 0.0154]],\n",
      "\n",
      "         [[-0.0060]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0175]],\n",
      "\n",
      "         [[ 0.0312]],\n",
      "\n",
      "         [[ 0.0438]]],\n",
      "\n",
      "\n",
      "        [[[-0.0284]],\n",
      "\n",
      "         [[-0.0063]],\n",
      "\n",
      "         [[-0.0069]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0200]],\n",
      "\n",
      "         [[ 0.0220]],\n",
      "\n",
      "         [[ 0.0227]]]])), ('layer4.7.weight', tensor([0.9170, 0.9156, 0.9119,  ..., 0.9158, 0.9203, 0.9149])), ('layer4.7.bias', tensor([ 0.0484,  0.0225, -0.0466,  ..., -0.0314,  0.0585,  0.0304])), ('layer4.7.running_mean', tensor([ 0.1614,  0.0802, -0.7098,  ..., -0.6569,  0.6944,  0.1732])), ('layer4.7.running_var', tensor([0.9914, 0.3723, 1.1145,  ..., 0.8561, 0.8686, 0.4605])), ('layer4.7.num_batches_tracked', tensor(309)), ('fc.alpha', tensor([[ 0.2032, -0.1659, -0.2677,  0.0793,  0.3469, -0.3455, -0.0596,  0.1050],\n",
      "        [-0.2328,  0.2052,  0.1655, -0.1608, -0.0161,  0.1581,  0.3254, -0.1919],\n",
      "        [-0.3464, -0.2883, -0.1177, -0.2302,  0.0124, -0.0620,  0.3194,  0.2062],\n",
      "        [-0.0595,  0.1027,  0.1294,  0.1705, -0.0480,  0.2805,  0.1372, -0.0967],\n",
      "        [-0.3256, -0.2715,  0.1398,  0.0864, -0.2004, -0.2281, -0.3479,  0.2365],\n",
      "        [-0.1489,  0.2332, -0.2240, -0.2572, -0.1111,  0.0688,  0.1443, -0.1676],\n",
      "        [ 0.3049, -0.3455, -0.2360, -0.1851,  0.1738, -0.2953,  0.1586,  0.0969],\n",
      "        [-0.2785, -0.3289, -0.0660,  0.2656,  0.2031,  0.2589, -0.2250,  0.0833],\n",
      "        [ 0.2174, -0.1123,  0.2330,  0.2535,  0.1639, -0.3442, -0.0375,  0.2703],\n",
      "        [-0.2247,  0.1471,  0.2697, -0.2125,  0.1665, -0.0155, -0.2666, -0.2751]])), ('fc.beta', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])), ('fc.bias', tensor([-0.2680, -0.0206,  0.1038,  0.1529,  0.2208, -0.0921, -0.2793,  0.0204,\n",
      "         0.1853,  0.0026]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sd = model.state_dict()\n",
    "for k, v in torch.load(BRANCH_LOC).items():\n",
    "\n",
    "    # print(k)\n",
    "    if k not in DECOMPOSED_LAYERS:\n",
    "        new_sd[k] = v\n",
    "\n",
    "print(new_sd)\n",
    "\n",
    "model.load_state_dict(new_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading checkpoint, optimizer setup, and layer filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_sd_decomp(torch.load(BRANCH_LOC), model, DECOMPOSED_LAYERS)\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "optimizer_full = torch.optim.SGD(model_original.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using checkpoint, creation of model with only LC-checkpoint and another with LC-checkpoint + LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.75\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.75\n",
      "model accuracy: 0.803\n",
      "model accuracy: 0.815\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.803, LC accuracy: 0.096, Decomposed-Full accuracy: 0.815, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_0\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.125, Full : 0.96875\n",
      "model accuracy: 0.786\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.786, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Epoch: 0, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Epoch: 0, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Epoch: 0, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Epoch: 0, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 0.90625\n",
      "model accuracy: 0.778\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.778, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 0, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Epoch: 0, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Epoch: 0, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Epoch: 0, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_1\n",
      "Epoch: 0, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 0.75\n",
      "model accuracy: 0.765\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.765, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 0, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Epoch: 0, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Epoch: 0, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Epoch: 0, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Epoch: 0, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Training Accuracy | Decomposed: 0.25, Full : 0.90625\n",
      "model accuracy: 0.828\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.828, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 0, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Epoch: 0, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Epoch: 0, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Epoch: 0, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_2\n",
      "Epoch: 0, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_3\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_3/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.03125, Full : 0.875\n",
      "model accuracy: 0.858\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.858, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 0, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_3\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.125, Full : 0.4375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 0.65625\n",
      "model accuracy: 0.815\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.815, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_4\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 0.84375\n",
      "model accuracy: 0.79\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.79, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Epoch: 1, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Epoch: 1, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Epoch: 1, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Epoch: 1, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Training Accuracy | Decomposed: 0.28125, Full : 0.875\n",
      "model accuracy: 0.837\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.837, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 1, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Epoch: 1, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Epoch: 1, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Epoch: 1, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_5\n",
      "Epoch: 1, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.0625, Full : 0.78125\n",
      "model accuracy: 0.738\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.738, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 1, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Epoch: 1, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Epoch: 1, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Epoch: 1, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Epoch: 1, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 0.84375\n",
      "model accuracy: 0.872\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.872, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 1, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Epoch: 1, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Epoch: 1, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Epoch: 1, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_6\n",
      "Epoch: 1, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_7\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_7/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.0625, Full : 0.9375\n",
      "model accuracy: 0.872\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.872, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 1, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_7\n",
      "Epoch: 2, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 0.6875\n",
      "Epoch: 2, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Epoch: 2, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Epoch: 2, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Epoch: 2, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Epoch: 2, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 0.90625\n",
      "model accuracy: 0.88\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.88, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 2, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Epoch: 2, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Epoch: 2, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Epoch: 2, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_8\n",
      "Epoch: 2, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 0.90625\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.893, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 2, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Epoch: 2, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Epoch: 2, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Epoch: 2, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Epoch: 2, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Training Accuracy | Decomposed: 0.375, Full : 1.0\n",
      "model accuracy: 0.879\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.879, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 2, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Epoch: 2, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Epoch: 2, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Epoch: 2, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_9\n",
      "Epoch: 2, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.0625, Full : 0.8125\n",
      "model accuracy: 0.855\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.855, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 2, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Epoch: 2, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Epoch: 2, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Epoch: 2, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Epoch: 2, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 0.90625\n",
      "model accuracy: 0.873\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.873, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 2, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Epoch: 2, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Epoch: 2, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Epoch: 2, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_10\n",
      "Epoch: 2, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_11\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_11/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 1.0\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.909, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 2, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_11\n",
      "Epoch: 3, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 0.71875\n",
      "Epoch: 3, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Epoch: 3, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Epoch: 3, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Epoch: 3, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Epoch: 3, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Training Accuracy | Decomposed: 0.21875, Full : 0.90625\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.894, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 3, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Epoch: 3, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Epoch: 3, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Epoch: 3, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_12\n",
      "Epoch: 3, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 0.9375\n",
      "model accuracy: 0.907\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.907, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 3, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Epoch: 3, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Epoch: 3, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Epoch: 3, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Epoch: 3, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Training Accuracy | Decomposed: 0.34375, Full : 1.0\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.908, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 3, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Epoch: 3, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Epoch: 3, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Epoch: 3, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_13\n",
      "Epoch: 3, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.125, Full : 0.84375\n",
      "model accuracy: 0.849\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.849, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 3, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Epoch: 3, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Epoch: 3, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Epoch: 3, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Epoch: 3, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Training Accuracy | Decomposed: 0.375, Full : 0.96875\n",
      "model accuracy: 0.888\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.888, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 3, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Epoch: 3, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Epoch: 3, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Epoch: 3, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_14\n",
      "Epoch: 3, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_15\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_15/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.0625, Full : 1.0\n",
      "model accuracy: 0.921\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.921, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 3, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_15\n",
      "Epoch: 4, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.0625, Full : 0.8125\n",
      "Epoch: 4, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Epoch: 4, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Epoch: 4, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Epoch: 4, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Epoch: 4, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Training Accuracy | Decomposed: 0.25, Full : 0.9375\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.909, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 4, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Epoch: 4, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Epoch: 4, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Epoch: 4, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_16\n",
      "Epoch: 4, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.03125, Full : 0.9375\n",
      "model accuracy: 0.925\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.925, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 4, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Epoch: 4, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Epoch: 4, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Epoch: 4, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Epoch: 4, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Training Accuracy | Decomposed: 0.3125, Full : 1.0\n",
      "model accuracy: 0.914\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.914, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 4, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Epoch: 4, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Epoch: 4, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Epoch: 4, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_17\n",
      "Epoch: 4, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.28125, Full : 0.84375\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.887, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 4, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Epoch: 4, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Epoch: 4, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Epoch: 4, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Epoch: 4, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Training Accuracy | Decomposed: 0.28125, Full : 1.0\n",
      "model accuracy: 0.92\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.92, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 4, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Epoch: 4, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Epoch: 4, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Epoch: 4, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_18\n",
      "Epoch: 4, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_19\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_19/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 0.96875\n",
      "model accuracy: 0.923\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.923, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 4, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_19\n",
      "Epoch: 5, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 0.78125\n",
      "Epoch: 5, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Epoch: 5, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Epoch: 5, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Epoch: 5, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Epoch: 5, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Training Accuracy | Decomposed: 0.3125, Full : 0.84375\n",
      "model accuracy: 0.93\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.93, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 5, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Epoch: 5, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Epoch: 5, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Epoch: 5, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_20\n",
      "Epoch: 5, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 0.9375\n",
      "model accuracy: 0.929\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.929, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 5, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Epoch: 5, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Epoch: 5, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Epoch: 5, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Epoch: 5, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Training Accuracy | Decomposed: 0.375, Full : 1.0\n",
      "model accuracy: 0.924\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.924, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 5, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Epoch: 5, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Epoch: 5, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Epoch: 5, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_21\n",
      "Epoch: 5, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 0.875\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.894, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 5, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Epoch: 5, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Epoch: 5, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Epoch: 5, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Epoch: 5, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Training Accuracy | Decomposed: 0.3125, Full : 1.0\n",
      "model accuracy: 0.934\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.934, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 5, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Epoch: 5, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Epoch: 5, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Epoch: 5, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_22\n",
      "Epoch: 5, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_23\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_23/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 1.0\n",
      "model accuracy: 0.941\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.941, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 5, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_23\n",
      "Epoch: 6, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 0.8125\n",
      "Epoch: 6, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Epoch: 6, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Epoch: 6, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Epoch: 6, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Epoch: 6, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Training Accuracy | Decomposed: 0.21875, Full : 1.0\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.893, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 6, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Epoch: 6, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Epoch: 6, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Epoch: 6, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_24\n",
      "Epoch: 6, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.03125, Full : 0.9375\n",
      "model accuracy: 0.925\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.925, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 6, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Epoch: 6, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Epoch: 6, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Epoch: 6, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Epoch: 6, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 1.0\n",
      "model accuracy: 0.92\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.92, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 6, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Epoch: 6, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Epoch: 6, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Epoch: 6, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_25\n",
      "Epoch: 6, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 0.875\n",
      "model accuracy: 0.9\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.9, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 6, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Epoch: 6, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Epoch: 6, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Epoch: 6, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Epoch: 6, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 1.0\n",
      "model accuracy: 0.944\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.944, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 6, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Epoch: 6, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Epoch: 6, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Epoch: 6, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_26\n",
      "Epoch: 6, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_27\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_27/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.3125, Full : 0.96875\n",
      "model accuracy: 0.943\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.943, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 6, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_27\n",
      "Epoch: 7, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.03125, Full : 0.8125\n",
      "Epoch: 7, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Epoch: 7, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Epoch: 7, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Epoch: 7, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Epoch: 7, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Training Accuracy | Decomposed: 0.125, Full : 1.0\n",
      "model accuracy: 0.928\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.928, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 7, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Epoch: 7, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Epoch: 7, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Epoch: 7, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_28\n",
      "Epoch: 7, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 0.9375\n",
      "model accuracy: 0.934\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.934, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 7, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Epoch: 7, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Epoch: 7, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Epoch: 7, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Epoch: 7, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Training Accuracy | Decomposed: 0.15625, Full : 1.0\n",
      "model accuracy: 0.915\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.915, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 7, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Epoch: 7, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Epoch: 7, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Epoch: 7, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_29\n",
      "Epoch: 7, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.0, Full : 0.90625\n",
      "model accuracy: 0.935\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.935, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 7, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Epoch: 7, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Epoch: 7, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Epoch: 7, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Epoch: 7, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Training Accuracy | Decomposed: 0.3125, Full : 1.0\n",
      "model accuracy: 0.953\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.953, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 7, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Epoch: 7, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Epoch: 7, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Epoch: 7, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_30\n",
      "Epoch: 7, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_31\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_31/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 1.0\n",
      "model accuracy: 0.955\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.955, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 7, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_31\n",
      "Epoch: 8, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.125, Full : 0.75\n",
      "Epoch: 8, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Epoch: 8, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Epoch: 8, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Epoch: 8, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Epoch: 8, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Training Accuracy | Decomposed: 0.25, Full : 0.71875\n",
      "model accuracy: 0.641\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.641, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 8, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Epoch: 8, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Epoch: 8, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Epoch: 8, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_32\n",
      "Epoch: 8, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.03125, Full : 0.875\n",
      "model accuracy: 0.533\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.533, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 8, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Epoch: 8, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Epoch: 8, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Epoch: 8, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Epoch: 8, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Training Accuracy | Decomposed: 0.1875, Full : 0.96875\n",
      "model accuracy: 0.76\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.76, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 8, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Epoch: 8, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Epoch: 8, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Epoch: 8, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_33\n",
      "Epoch: 8, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.21875, Full : 0.84375\n",
      "model accuracy: 0.885\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.885, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 8, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Epoch: 8, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Epoch: 8, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Epoch: 8, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Epoch: 8, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 0.84375\n",
      "model accuracy: 0.92\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.92, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 8, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Epoch: 8, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Epoch: 8, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Epoch: 8, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_34\n",
      "Epoch: 8, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_35\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_35/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 0.9375\n",
      "model accuracy: 0.915\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.915, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 8, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_35\n",
      "Epoch: 9, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.03125, Full : 0.75\n",
      "Epoch: 9, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Epoch: 9, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Epoch: 9, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Epoch: 9, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Epoch: 9, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Training Accuracy | Decomposed: 0.25, Full : 0.90625\n",
      "model accuracy: 0.861\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.861, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 9, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Epoch: 9, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Epoch: 9, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Epoch: 9, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_36\n",
      "Epoch: 9, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37/initial_model.pt\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 1.0\n",
      "model accuracy: 0.92\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.92, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 9, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37\n",
      "Epoch: 9, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37\n",
      "Epoch: 9, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37\n",
      "Epoch: 9, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37\n",
      "Epoch: 9, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37\n",
      "Training Accuracy | Decomposed: 0.09375, Full : 1.0\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "model accuracy: 0.096\n",
      "Full accuracy: 0.909, LC accuracy: 0.096, Decomposed-Full accuracy: 0.096, Decomposed-Restored accuracy: 0.096\n",
      "Epoch: 9, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37\n",
      "Epoch: 9, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37\n",
      "Epoch: 9, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/old-lc/set_37\n",
      "Epoch: 9, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/lobranch/set_37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m cstate \u001b[38;5;241m=\u001b[39m model_original\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[0;32m     91\u001b[0m old_lc_delta, old_lc_bias \u001b[38;5;241m=\u001b[39m olc\u001b[38;5;241m.\u001b[39mgenerate_delta(prev_state, cstate, DECOMPOSED_LAYERS)\n\u001b[1;32m---> 92\u001b[0m olc_compressed_delta, update_prev \u001b[38;5;241m=\u001b[39m \u001b[43molc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_lc_delta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m olc\u001b[38;5;241m.\u001b[39msave_checkpoint(SAVE_LOC_OLC \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/set_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(current_set_old_lc), olc_compressed_delta, \n\u001b[0;32m     94\u001b[0m                     old_lc_bias, current_iter_old_lc)\n\u001b[0;32m     95\u001b[0m prev_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(prev_state, update_prev)\n",
      "File \u001b[1;32mc:\\Personal\\Singapour\\PFE\\code_of_shu-heng_with_models\\pfe_lc_lora\\old_lc\\main.py:741\u001b[0m, in \u001b[0;36mcompress_data\u001b[1;34m(δt, num_bits, threshhold)\u001b[0m\n\u001b[0;32m    739\u001b[0m mp \u001b[38;5;241m=\u001b[39m  defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(δt)):\n\u001b[1;32m--> 741\u001b[0m     mp[(δt_exp[i], δt_sign[i])]\u001b[38;5;241m.\u001b[39mappend((i, δt[i]))\n\u001b[0;32m    742\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mp:\n\u001b[0;32m    743\u001b[0m     mp[k] \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39marray([x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mp[k]])), \n\u001b[0;32m    744\u001b[0m              [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mp[k]])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# delta_normal_max = []\n",
    "# delta_normal_min = []\n",
    "# delta_decomposed_max = []\n",
    "# delta_decomposed_min = []\n",
    "\n",
    "full_accuracy = []\n",
    "decomposed_full_accuracy = []\n",
    "restored_accuracy = []\n",
    "lc_accuracy = []\n",
    "\n",
    "current_iter = 0\n",
    "current_set = 0\n",
    "\n",
    "current_iter_old_lc = 0\n",
    "current_set_old_lc = 0\n",
    "\n",
    "acc = lambda x, y : (torch.max(x, 1)[1] == y).sum().item() / y.size(0)\n",
    "\n",
    "for epch in range(20):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        print(\"Epoch: {}, Iteration: {}\".format(epch, i))\n",
    "        \n",
    "        set_path = \"/set_{}\".format(current_set)\n",
    "        if not os.path.exists(SAVE_LOC + set_path):\n",
    "            os.makedirs(SAVE_LOC + set_path)\n",
    "\n",
    "        if i == 0 and epch == 0: # first iteration, create baseline model\n",
    "            base, base_decomp = lc.extract_weights(model, SAVE_LOC + \n",
    "                                                       \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "        else:\n",
    "            if i % 10 == 0: \n",
    "                # full snapshot!\n",
    "                new_model = lazy_restore(base, base_decomp, bias, ResNet50(), \n",
    "                                          original.state_dict(), DECOMPOSED_LAYERS, rank = RANK, scaling = SCALING)\n",
    "                original = new_model # Changing previous \"original model\" used to restore the loRA model.\n",
    "                \n",
    "                current_set += 1\n",
    "                current_iter = 0\n",
    "\n",
    "                set_path = \"/set_{}\".format(current_set)\n",
    "                if not os.path.exists(SAVE_LOC + set_path):\n",
    "                    os.makedirs(SAVE_LOC + set_path)\n",
    "                \n",
    "                # Rebuilding LoRA layers => reset model!\n",
    "                w, b = getBase(original)\n",
    "                model = ResNet50_LowRank(w, b, rank = RANK)\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "                load_sd_decomp(original.state_dict(), model, DECOMPOSED_LAYERS)\n",
    "                base, base_decomp = lc.extract_weights(model, SAVE_LOC + \n",
    "                                                       \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "\n",
    "            else:\n",
    "                # Delta-compression\n",
    "                delta, decomp_delta, bias = lc.generate_delta(base, \n",
    "                                                                base_decomp, model.state_dict(), DECOMPOSED_LAYERS)\n",
    "                compressed_delta, full_delta, compressed_dcomp_delta, full_dcomp_delta  = lc.compress_delta(delta, \n",
    "                                                                                                            decomp_delta)\n",
    "                \n",
    "                # Saving checkpoint\n",
    "                lc.save_checkpoint(compressed_delta, compressed_dcomp_delta, bias, current_iter, SAVE_LOC + \n",
    "                                \"/set_{}\".format(current_set))\n",
    "    \n",
    "                base = np.add(base, full_delta) # Replace base with latest for delta to accumulate.\n",
    "                base_decomp = np.add(full_dcomp_delta, base_decomp)\n",
    "\n",
    "                current_iter += 1\n",
    "            \n",
    "        # # ==========================\n",
    "        # # Saving using LC-Checkpoint\n",
    "        # # ==========================\n",
    "                \n",
    "        if i == 0 and epch == 0:\n",
    "            cstate = model_original.state_dict()\n",
    "            set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "            if not os.path.exists(SAVE_LOC_OLC + set_path):\n",
    "                os.makedirs(SAVE_LOC_OLC + set_path)\n",
    "            # torch.save(cstate, SAVE_LOC_OLC + set_path + \"/initial_model.pt\")\n",
    "            prev_state = olc.extract_weights(cstate, SAVE_LOC_OLC + set_path, DECOMPOSED_LAYERS)\n",
    "        else:\n",
    "            if i % 10 == 0:\n",
    "                cstate = model_original.state_dict()\n",
    "                current_set_old_lc += 1\n",
    "                current_iter_old_lc = 0\n",
    "                set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                if not os.path.exists(SAVE_LOC_OLC + set_path):\n",
    "                    os.makedirs(SAVE_LOC_OLC + set_path)\n",
    "                # torch.save(cstate, SAVE_LOC_OLC + set_path + \"/initial_model.pt\")\n",
    "                prev_state = olc.extract_weights(cstate, SAVE_LOC_OLC + set_path, DECOMPOSED_LAYERS)\n",
    "            else:\n",
    "                cstate = model_original.state_dict()\n",
    "                old_lc_delta, old_lc_bias = olc.generate_delta(prev_state, cstate, DECOMPOSED_LAYERS)\n",
    "                olc_compressed_delta, update_prev = olc.compress_data(old_lc_delta, num_bits = 3)\n",
    "                olc.save_checkpoint(SAVE_LOC_OLC + \"/set_{}\".format(current_set_old_lc), olc_compressed_delta, \n",
    "                                    old_lc_bias, current_iter_old_lc)\n",
    "                prev_state = np.add(prev_state, update_prev)\n",
    "                current_iter_old_lc += 1\n",
    "        \n",
    "        # ==========================\n",
    "        # Training on Low-Rank Model\n",
    "        # ==========================\n",
    "\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # ======================\n",
    "        # Training on Full Model\n",
    "        # ======================\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer_full.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs_full = model_original(inputs)\n",
    "        loss_full = torch.nn.functional.cross_entropy(outputs_full,labels)\n",
    "        loss_full.backward()\n",
    "        optimizer_full.step()\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            print(\"Training Accuracy | Decomposed: {}, Full : {}\".format(acc(outputs, labels), \n",
    "                                                                         acc(outputs_full, labels)))\n",
    "\n",
    "        if i != 0  and i % 5 == 0: # Evaluation on testing set\n",
    "            full_accuracy.append(evaluate_accuracy(model_original, test_loader))\n",
    "            decomposed_full_accuracy.append(evaluate_accuracy(model, test_loader))\n",
    "            restored_model = lazy_restore(base, base_decomp, bias, ResNet50(), \n",
    "                                          original.state_dict(), DECOMPOSED_LAYERS, \n",
    "                                          rank = RANK, scaling = SCALING)\n",
    "            restored_accuracy.append(evaluate_accuracy(restored_model, test_loader))\n",
    "            restored_lc_model = ResNet50()\n",
    "            restored_lc_model.load_state_dict(olc.restore_state_dict(prev_state, old_lc_bias, \n",
    "                                                                  restored_model.state_dict(), DECOMPOSED_LAYERS))\n",
    "            lc_accuracy.append(evaluate_accuracy(restored_lc_model, test_loader))\n",
    "            print(\"Full accuracy: {}, LC accuracy: {}, Decomposed-Full accuracy: {}, Decomposed-Restored accuracy: {}\".format(\n",
    "                full_accuracy[-1], lc_accuracy[-1], decomposed_full_accuracy[-1], restored_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For recovery and not restart from scratch : having the plots and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/data.json\") as f:\n",
    "    data = json.load(f)\n",
    "full_accuracy = data['full_acc']\n",
    "lc_accuracy = data[\"lc_restored_accuracy\"]\n",
    "restored_accuracy = data[\"decomposed_restored_accuracy\"]\n",
    "decomposed_full_accuracy = data[\"decomposed_full_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30, 5))\n",
    "plt.title(\"ResNet50, Accuracy, Branched @ {} Accuracy\".format(BRANCH_ACC))\n",
    "plt.plot(full_accuracy, label = \"Default ResNet50\")\n",
    "plt.plot(lc_accuracy, label = \"LC ResNet50\")\n",
    "plt.plot(decomposed_full_accuracy, label = \"dLoRA ResNet50\")\n",
    "plt.plot(restored_accuracy, label = \"dLoRA + LC ResNet50\")\n",
    "plt.xticks([x for x in range(0, 120) if x % 6 == 0], [x for x in range(0, 20)])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the absolute accuracy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangex = [x for x in range(0, 120) if x % 6 == 0]\n",
    "rangey = [x for x in range(0, 20)]\n",
    "plt.figure(figsize = (40, 10))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title(\"ResNet50 Absolute Accuracy Loss (Default ResNet50 vs LC + dLoRA ResNet50)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(restored_accuracy))), label = \"LC + dLoRA ResNet50\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC ResNet50\")\n",
    "plt.legend()\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.ylim(0, 0.5)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.set_title(\"ResNet50 Absolute Restoration Accuracy Loss (LC + dLoRA ResNet50 & LC ResNet50)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(restored_accuracy), \n",
    "                     np.array(decomposed_full_accuracy))), label = \"LC + dLoRA ResNet50\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC ResNet50\")\n",
    "plt.legend()\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function which compute the size of compressed and uncompressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def getsize(sl):\n",
    "    dir = [x for x in os.listdir(sl)]\n",
    "    csize, usize = 0, 0\n",
    "    for set in dir:\n",
    "        for f in os.listdir(sl + \"/\" + set):\n",
    "            fp = sl + \"/{}/{}\".format(set, f)\n",
    "            csize += os.path.getsize(fp)\n",
    "            usize += 119.6 * math.pow(2, 20) # torch checkpoint same size\n",
    "    return csize, usize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_size, uncompressed_size = getsize(SAVE_LOC)\n",
    "a, b = evaluate_compression(uncompressed_size, compressed_size)\n",
    "compressed_size, uncompressed_size = getsize(SAVE_LOC_OLC)\n",
    "a1, b1 = evaluate_compression(uncompressed_size, compressed_size)\n",
    "\n",
    "print(\"LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a1, b1))\n",
    "print(\"LoRA + LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data in a dictionary and save it in a file data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"full_acc\" : full_accuracy,\n",
    "    \"decomposed_restored_accuracy\" : restored_accuracy,\n",
    "    \"decomposed_full_accuracy\" : decomposed_full_accuracy,\n",
    "    \"lc_restored_accuracy\" : lc_accuracy\n",
    "}\n",
    "with open(HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/resnet50/data.json\", 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
