{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Implementation with Old LC on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bradf\\anaconda3\\envs\\py310\\lib\\site-packages\\transformers\\utils\\generic.py:485: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy as spy\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import ssl\n",
    "import pickle, json\n",
    "import src.main as lc\n",
    "import old_lc.main as olc\n",
    "from src.models.LeNet import LeNet\n",
    "import src.compression.deltaCompress as lc_compress\n",
    "from src.models.LeNet_LowRank import getBase, LeNet_LowRank, load_sd_decomp\n",
    "from src.utils.utils import evaluate_accuracy, lazy_restore, evaluate_compression\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 61706\n",
      "Linear parameters (excluding the last nn.Linear): 59134\n"
     ]
    }
   ],
   "source": [
    "# Function to count the number of parameters\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    # Exclude the last nn.Linear layer\n",
    "    linear_params = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear) and name != 'classifier.6':\n",
    "            linear_params += sum(p.numel() for p in module.parameters())\n",
    "\n",
    "    return total_params, linear_params\n",
    "\n",
    "model = LeNet()\n",
    "# Get the total and linear parameters\n",
    "total_params, linear_params = count_parameters(model)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Linear parameters (excluding the last nn.Linear): {linear_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Data Loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDFP = \"./volumes/Ultra Touch\" # Load HHD\n",
    "\n",
    "def data_loader():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.1307, 0.3081)])\n",
    "\n",
    "    trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                          download=True, transform=transform)\n",
    "    # Reintroduce the 2000 datapoints model has not seen before.\n",
    "    trainset.data = trainset.data.clone()[-2000:-1000]\n",
    "    trainset.targets = trainset.targets.clone()[-2000:-1000]\n",
    "    # trainset.data = trainset.data.clone()[-7000:]\n",
    "    # trainset.targets = trainset.targets.clone()[-7000:]\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size = 32,\n",
    "                                              shuffle=False, num_workers=2)\n",
    "\n",
    "    testset = datasets.MNIST(root='./data', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "\n",
    "    testset.data = trainset.data[-1000:]\n",
    "    testset.targets = trainset.targets[-1000:]\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# HDFP = \"./volumes/Ultra Touch\" # Load HHD\n",
    "\n",
    "# def data_loader():\n",
    "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.1307, 0.3081)])\n",
    "\n",
    "#     trainset = datasets.MNIST(root='./data', train=True,\n",
    "#                                           download=True, transform=transform)\n",
    "#     # Reintroduce the 7000 datapoints model has not seen before.\n",
    "#     trainset.data = trainset.data.clone()[-7000:]\n",
    "#     trainset.targets = trainset.targets.clone()[:-7000:]\n",
    "#     train_loader = torch.utils.data.DataLoader(trainset, batch_size = 32,\n",
    "#                                               shuffle=False, num_workers=2)\n",
    "\n",
    "#     testset = datasets.MNIST(root='./data', train=False,\n",
    "#                                          download=True, transform=transform)\n",
    "\n",
    "#     testset.data = trainset.data[-2000:]\n",
    "#     testset.targets = trainset.targets[-2000:]\n",
    "#     test_loader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "#                                              shuffle=False, num_workers=2)\n",
    "    \n",
    "#     return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bypass using SSL unverified\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# MNIST dataset \n",
    "train_loader, test_loader = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bypass the matplotlib error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing some images of the dataset we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) tensor(3) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# Adjust these values to match the normalization values used during the loading of your dataset\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    # Adjusting unnormalization for potentially 3-channel images\n",
    "    img = img * std + mean  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Assuming train_loader is defined and loaded as before\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images[:3]))\n",
    "# Print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of folder to save the results (for plots and compression rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch\"\n",
    "if not os.path.exists(SAVE_LOC):\n",
    "    os.makedirs(SAVE_LOC)\n",
    "\n",
    "SAVE_LOC_OLC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc\"\n",
    "if not os.path.exists(SAVE_LOC_OLC):\n",
    "    os.makedirs(SAVE_LOC_OLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binary(model, evaluation_set):\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for input, label in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            output = torch.sigmoid(model(input))  # Apply sigmoid to model output to get probabilities.\n",
    "            output = torch.where(output > 0.5, 1, 0)  # Threshold probabilities at 0.5 to decide between classes 0 and 1.\n",
    "            no_seen += label.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += (output == label).sum().item()  # Increment correct predictions by the number of matches in the batch.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n",
    "\n",
    "def accuracy_multiclass(model, evaluation_set):\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for input, label in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            output = model(input)  # Get the raw logits from the model.\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit which represents the predicted class.\n",
    "            no_seen += label.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += pred.eq(label.view_as(pred)).sum().item()  # Compare predictions with true labels and sum up correct predictions.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special function for the accuracy of the model on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multiclass_gpu(model, evaluation_set):\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for inputs, labels in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device of the model\n",
    "            output = model(inputs)  # Get the raw logits from the model.\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit which represents the predicted class.\n",
    "            no_seen += labels.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += pred.eq(labels.view_as(pred)).sum().item()  # Compare predictions with true labels and sum up correct predictions.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual training on GPU (Creating branchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Running validation for 0 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.011\n",
      "Running validation for 0 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.133\n",
      "Length of train_loader is:  32\n",
      "Running validation for 1 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.229\n",
      "Running validation for 1 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.322\n",
      "Length of train_loader is:  32\n",
      "Running validation for 2 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.402\n",
      "Running validation for 2 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.57\n",
      "Length of train_loader is:  32\n",
      "Running validation for 3 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.592\n",
      "Running validation for 3 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.636\n",
      "Length of train_loader is:  32\n",
      "Running validation for 4 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.615\n",
      "Running validation for 4 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.649\n",
      "Length of train_loader is:  32\n",
      "Running validation for 5 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.638\n",
      "Running validation for 5 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.674\n",
      "Length of train_loader is:  32\n",
      "Running validation for 6 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.692\n",
      "Running validation for 6 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.729\n",
      "Length of train_loader is:  32\n",
      "Running validation for 7 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.748\n",
      "Running validation for 7 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.785\n",
      "Length of train_loader is:  32\n",
      "Running validation for 8 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.8\n",
      "Running validation for 8 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.836\n",
      "Length of train_loader is:  32\n",
      "Running validation for 9 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.853\n",
      "Running validation for 9 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.875\n",
      "Length of train_loader is:  32\n",
      "Running validation for 10 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.878\n",
      "Running validation for 10 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.899\n",
      "Length of train_loader is:  32\n",
      "Running validation for 11 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.901\n",
      "Running validation for 11 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.913\n",
      "Length of train_loader is:  32\n",
      "Running validation for 12 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.914\n",
      "Running validation for 12 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.927\n",
      "Length of train_loader is:  32\n",
      "Running validation for 13 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.92\n",
      "Running validation for 13 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.939\n",
      "Length of train_loader is:  32\n",
      "Running validation for 14 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.93\n",
      "Running validation for 14 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.944\n",
      "Length of train_loader is:  32\n",
      "Running validation for 15 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.936\n",
      "Running validation for 15 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.948\n",
      "Length of train_loader is:  32\n",
      "Running validation for 16 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.945\n",
      "Running validation for 16 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.951\n",
      "Length of train_loader is:  32\n",
      "Running validation for 17 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.95\n",
      "Running validation for 17 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.955\n",
      "Length of train_loader is:  32\n",
      "Running validation for 18 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.953\n",
      "Running validation for 18 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.958\n",
      "Length of train_loader is:  32\n",
      "Running validation for 19 Epoch, 0 Iteration...\n",
      "ACCURACY: 0.955\n",
      "Running validation for 19 Epoch, 20 Iteration...\n",
      "ACCURACY: 0.959\n",
      "Length of train_loader is:  32\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# get the base model (LeNet) and move it to the chosen device\n",
    "model_for_checkpoint = LeNet().to(device)\n",
    "\n",
    "# creating branchpoints\n",
    "epochs = 20\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.02)  # momentum=0.9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_for_checkpoint(inputs)\n",
    "\n",
    "        # Here assuming your loss function and any other operation are compatible with CUDA tensors\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % 20 == 0:\n",
    "            print(\"Running validation for {} Epoch, {} Iteration...\".format(epoch, iter))\n",
    "            res = accuracy_multiclass_gpu(model_for_checkpoint, test_loader)  # Ensure this function also handles data on GPU\n",
    "\n",
    "            print(\"ACCURACY: {}\".format(res))\n",
    "            if res > 0.7:\n",
    "                # Move model to CPU before saving\n",
    "                model_for_checkpoint.to('cpu')\n",
    "                # torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch_{}.pt\".format(res))\n",
    "                # Optionally, move model back to the original device (GPU) if further computation is needed\n",
    "                model_for_checkpoint.to(device)\n",
    "            if res > 0.98:\n",
    "                isLoop = False\n",
    "                break\n",
    "    if not isLoop:\n",
    "        break\n",
    "    print(\"Length of train_loader is: \", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual training on CPU (Creating branchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the base model (LeNet)\n",
    "\n",
    "model_for_checkpoint = LeNet()\n",
    "\n",
    "# creating branchpoints : \n",
    "\n",
    "epochs = 10\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.01, momentum=0.9) # momentum=0.9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_for_checkpoint(inputs)\n",
    "\n",
    "        # if self.config.loss_function == \"binary_cross_entropy\":\n",
    "        #     outputs = torch.sigmoid(outputs)\n",
    "        \n",
    "        # loss = loss_function(outputs, labels)\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(\"Epoch {} | Iteration {} : Loss {}\".format(epoch, iter, loss.item()))\n",
    "        if iter % 20 == 0:\n",
    "            print(\"Running validation for {} Epoch, {} Iteration...\".format(epoch, iter))\n",
    "            # Previously: res = accuracy_binary(model_for_checkpoint, test_loader)\n",
    "            res = accuracy_multiclass(model_for_checkpoint, test_loader)\n",
    "\n",
    "            # res = accuracy_binary(model_for_checkpoint, test_loader)\n",
    "            \n",
    "            print(\"ACCURACY: {}\".format(res))\n",
    "            if res > 0.7:\n",
    "                torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch_{}.pt\".format(res))\n",
    "            if res > 0.9:\n",
    "                isLoop = False\n",
    "                break\n",
    "    if not isLoop:\n",
    "        break\n",
    "    print(\"Length of train_loader is: \", len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploiting branchpoints of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call of the different models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['feature.0.weight', 'feature.0.bias', 'feature.3.weight', 'feature.3.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.3.weight', 'classifier.3.bias', 'classifier.5.weight', 'classifier.5.bias'])\n"
     ]
    }
   ],
   "source": [
    "DECOMPOSED_LAYERS = ['classifier.1.weight', 'classifier.3.weight']\n",
    "RANK = -1\n",
    "SCALING = -1\n",
    "# BRANCH_ACC = \"0.721\"\n",
    "BRANCH_ACC = \"0.768\"\n",
    "\n",
    "original = LeNet()\n",
    "model_original = LeNet()\n",
    "\n",
    "# Load from \"branch point\"\n",
    "BRANCH_LOC = HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch_{}.pt\".format(BRANCH_ACC)\n",
    "original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "model_original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "print(model_original.state_dict().keys())\n",
    "\n",
    "\n",
    "w, b = getBase(model_original)\n",
    "model = LeNet_LowRank(w, b, rank = RANK)\n",
    "load_sd_decomp(torch.load(BRANCH_LOC), model, DECOMPOSED_LAYERS)\n",
    "learning_rate = 0.01\n",
    "# momentum = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "optimizer_full = torch.optim.SGD(model_original.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using checkpoint, creation of model with only LC-checkpoint and another with LC-checkpoint + LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7626869678497314\n",
      "LC Training Loss (Full): 0.7626869678497314\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.75\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6298003792762756\n",
      "LC Training Loss (Full): 0.6258125901222229\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9276137351989746\n",
      "LC Training Loss (Full): 0.9295843839645386\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.763249397277832\n",
      "LC Training Loss (Full): 0.7572423815727234\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9235199689865112\n",
      "LC Training Loss (Full): 0.917472243309021\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6184536814689636\n",
      "LC Training Loss (Full): 0.6161471009254456\n",
      "model accuracy: 0.841\n",
      "model accuracy: 0.828\n",
      "model accuracy: 0.829\n",
      "model accuracy: 0.832\n",
      "Full accuracy: 0.841, LC accuracy: 0.832, Decomposed-Full accuracy: 0.828, Decomposed-Restored accuracy: 0.829\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5761883854866028\n",
      "LC Training Loss (Full): 0.5725480318069458\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7134878635406494\n",
      "LC Training Loss (Full): 0.7073811292648315\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7739165425300598\n",
      "LC Training Loss (Full): 0.7653117775917053\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_0\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7540963292121887\n",
      "LC Training Loss (Full): 0.7476621270179749\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8019412755966187\n",
      "LC Training Loss (Full): 0.7925922870635986\n",
      "model accuracy: 0.843\n",
      "model accuracy: 0.835\n",
      "model accuracy: 0.832\n",
      "model accuracy: 0.84\n",
      "Full accuracy: 0.843, LC accuracy: 0.84, Decomposed-Full accuracy: 0.835, Decomposed-Restored accuracy: 0.832\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7398446798324585\n",
      "LC Training Loss (Full): 0.7252185940742493\n",
      "Epoch: 0, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.940829873085022\n",
      "LC Training Loss (Full): 0.9309353828430176\n",
      "Epoch: 0, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.839718759059906\n",
      "LC Training Loss (Full): 0.8220059871673584\n",
      "Epoch: 0, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7817955613136292\n",
      "LC Training Loss (Full): 0.7719190120697021\n",
      "Epoch: 0, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5812649726867676\n",
      "LC Training Loss (Full): 0.5758011341094971\n",
      "model accuracy: 0.842\n",
      "model accuracy: 0.84\n",
      "model accuracy: 0.84\n",
      "model accuracy: 0.842\n",
      "Full accuracy: 0.842, LC accuracy: 0.842, Decomposed-Full accuracy: 0.84, Decomposed-Restored accuracy: 0.84\n",
      "Epoch: 0, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.8012281060218811\n",
      "LC Training Loss (Full): 0.7995725870132446\n",
      "Epoch: 0, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7824204564094543\n",
      "LC Training Loss (Full): 0.7738078832626343\n",
      "Epoch: 0, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.8839449882507324\n",
      "LC Training Loss (Full): 0.8726987838745117\n",
      "Epoch: 0, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_1\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7807349562644958\n",
      "LC Training Loss (Full): 0.7543001770973206\n",
      "Epoch: 0, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.013931155204773\n",
      "LC Training Loss (Full): 0.964902400970459\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.78125\n",
      "model accuracy: 0.848\n",
      "model accuracy: 0.844\n",
      "model accuracy: 0.844\n",
      "model accuracy: 0.85\n",
      "Full accuracy: 0.848, LC accuracy: 0.85, Decomposed-Full accuracy: 0.844, Decomposed-Restored accuracy: 0.844\n",
      "Epoch: 0, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6071370244026184\n",
      "LC Training Loss (Full): 0.5854220986366272\n",
      "Epoch: 0, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6526151299476624\n",
      "LC Training Loss (Full): 0.620607316493988\n",
      "Epoch: 0, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6349361538887024\n",
      "LC Training Loss (Full): 0.6125180721282959\n",
      "Epoch: 0, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8148437738418579\n",
      "LC Training Loss (Full): 0.7840854525566101\n",
      "Epoch: 0, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7083094716072083\n",
      "LC Training Loss (Full): 0.703595757484436\n",
      "model accuracy: 0.853\n",
      "model accuracy: 0.848\n",
      "model accuracy: 0.847\n",
      "model accuracy: 0.851\n",
      "Full accuracy: 0.853, LC accuracy: 0.851, Decomposed-Full accuracy: 0.848, Decomposed-Restored accuracy: 0.847\n",
      "Epoch: 0, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.791094958782196\n",
      "LC Training Loss (Full): 0.7787405848503113\n",
      "Epoch: 0, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6686305403709412\n",
      "LC Training Loss (Full): 0.6597158908843994\n",
      "Epoch: 0, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5340365171432495\n",
      "LC Training Loss (Full): 0.5196247696876526\n",
      "Epoch: 0, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_2\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5127500295639038\n",
      "LC Training Loss (Full): 0.4950854778289795\n",
      "Epoch: 0, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_3\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_3/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7577775120735168\n",
      "LC Training Loss (Full): 0.7440599203109741\n",
      "model accuracy: 0.858\n",
      "model accuracy: 0.851\n",
      "model accuracy: 0.852\n",
      "model accuracy: 0.86\n",
      "Full accuracy: 0.858, LC accuracy: 0.86, Decomposed-Full accuracy: 0.851, Decomposed-Restored accuracy: 0.852\n",
      "Epoch: 0, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_3\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5756415128707886\n",
      "LC Training Loss (Full): 0.5730423331260681\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.726560652256012\n",
      "LC Training Loss (Full): 0.6863532066345215\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.78125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.6006348729133606\n",
      "LC Training Loss (Full): 0.5701008439064026\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.9016501307487488\n",
      "LC Training Loss (Full): 0.8926314115524292\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7350539565086365\n",
      "LC Training Loss (Full): 0.701468288898468\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.8869243860244751\n",
      "LC Training Loss (Full): 0.8593838214874268\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.5831405520439148\n",
      "LC Training Loss (Full): 0.5521377921104431\n",
      "model accuracy: 0.862\n",
      "model accuracy: 0.857\n",
      "model accuracy: 0.857\n",
      "model accuracy: 0.861\n",
      "Full accuracy: 0.862, LC accuracy: 0.861, Decomposed-Full accuracy: 0.857, Decomposed-Restored accuracy: 0.857\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.5485164523124695\n",
      "LC Training Loss (Full): 0.5132145881652832\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.676676869392395\n",
      "LC Training Loss (Full): 0.6435256600379944\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7358605861663818\n",
      "LC Training Loss (Full): 0.7049000859260559\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_4\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.722986102104187\n",
      "LC Training Loss (Full): 0.6915864944458008\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.764735221862793\n",
      "LC Training Loss (Full): 0.7406278848648071\n",
      "model accuracy: 0.857\n",
      "model accuracy: 0.857\n",
      "model accuracy: 0.855\n",
      "model accuracy: 0.86\n",
      "Full accuracy: 0.857, LC accuracy: 0.86, Decomposed-Full accuracy: 0.857, Decomposed-Restored accuracy: 0.855\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7029146552085876\n",
      "LC Training Loss (Full): 0.6669760346412659\n",
      "Epoch: 1, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.9032871127128601\n",
      "LC Training Loss (Full): 0.8745533227920532\n",
      "Epoch: 1, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.8103237152099609\n",
      "LC Training Loss (Full): 0.7675462365150452\n",
      "Epoch: 1, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7555482387542725\n",
      "LC Training Loss (Full): 0.7313281893730164\n",
      "Epoch: 1, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.5619906187057495\n",
      "LC Training Loss (Full): 0.5406847596168518\n",
      "model accuracy: 0.865\n",
      "model accuracy: 0.857\n",
      "model accuracy: 0.857\n",
      "model accuracy: 0.863\n",
      "Full accuracy: 0.865, LC accuracy: 0.863, Decomposed-Full accuracy: 0.857, Decomposed-Restored accuracy: 0.857\n",
      "Epoch: 1, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7870942950248718\n",
      "LC Training Loss (Full): 0.7721080780029297\n",
      "Epoch: 1, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7588669657707214\n",
      "LC Training Loss (Full): 0.7286219596862793\n",
      "Epoch: 1, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.8669657707214355\n",
      "LC Training Loss (Full): 0.8362149596214294\n",
      "Epoch: 1, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_5\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7400110960006714\n",
      "LC Training Loss (Full): 0.6814776062965393\n",
      "Epoch: 1, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9752737879753113\n",
      "LC Training Loss (Full): 0.893505334854126\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.8125\n",
      "model accuracy: 0.863\n",
      "model accuracy: 0.859\n",
      "model accuracy: 0.857\n",
      "model accuracy: 0.862\n",
      "Full accuracy: 0.863, LC accuracy: 0.862, Decomposed-Full accuracy: 0.859, Decomposed-Restored accuracy: 0.857\n",
      "Epoch: 1, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.5798039436340332\n",
      "LC Training Loss (Full): 0.5396851897239685\n",
      "Epoch: 1, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6148010492324829\n",
      "LC Training Loss (Full): 0.5601745247840881\n",
      "Epoch: 1, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.600558876991272\n",
      "LC Training Loss (Full): 0.5580037236213684\n",
      "Epoch: 1, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.7832282185554504\n",
      "LC Training Loss (Full): 0.7374680042266846\n",
      "Epoch: 1, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6751635074615479\n",
      "LC Training Loss (Full): 0.6500571966171265\n",
      "model accuracy: 0.869\n",
      "model accuracy: 0.862\n",
      "model accuracy: 0.862\n",
      "model accuracy: 0.865\n",
      "Full accuracy: 0.869, LC accuracy: 0.865, Decomposed-Full accuracy: 0.862, Decomposed-Restored accuracy: 0.862\n",
      "Epoch: 1, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.7595787644386292\n",
      "LC Training Loss (Full): 0.7246221303939819\n",
      "Epoch: 1, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6456961631774902\n",
      "LC Training Loss (Full): 0.6182917356491089\n",
      "Epoch: 1, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.50799161195755\n",
      "LC Training Loss (Full): 0.4749385118484497\n",
      "Epoch: 1, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_6\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.4880079925060272\n",
      "LC Training Loss (Full): 0.4512265920639038\n",
      "Epoch: 1, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_7\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_7/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7336063981056213\n",
      "LC Training Loss (Full): 0.6982318162918091\n",
      "model accuracy: 0.869\n",
      "model accuracy: 0.863\n",
      "model accuracy: 0.86\n",
      "model accuracy: 0.868\n",
      "Full accuracy: 0.869, LC accuracy: 0.868, Decomposed-Full accuracy: 0.863, Decomposed-Restored accuracy: 0.86\n",
      "Epoch: 1, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_7\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.5686621069908142\n",
      "LC Training Loss (Full): 0.5463171005249023\n",
      "Epoch: 2, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6981093287467957\n",
      "LC Training Loss (Full): 0.6370283365249634\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.78125\n",
      "Epoch: 2, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5767499208450317\n",
      "LC Training Loss (Full): 0.5315403938293457\n",
      "Epoch: 2, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.8817660212516785\n",
      "LC Training Loss (Full): 0.8560377359390259\n",
      "Epoch: 2, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7108290195465088\n",
      "LC Training Loss (Full): 0.6567252278327942\n",
      "Epoch: 2, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.8548285961151123\n",
      "LC Training Loss (Full): 0.8040745854377747\n",
      "Epoch: 2, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5542938709259033\n",
      "LC Training Loss (Full): 0.5040117502212524\n",
      "model accuracy: 0.869\n",
      "model accuracy: 0.864\n",
      "model accuracy: 0.864\n",
      "model accuracy: 0.869\n",
      "Full accuracy: 0.869, LC accuracy: 0.869, Decomposed-Full accuracy: 0.864, Decomposed-Restored accuracy: 0.864\n",
      "Epoch: 2, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5240969657897949\n",
      "LC Training Loss (Full): 0.4674919545650482\n",
      "Epoch: 2, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.646418035030365\n",
      "LC Training Loss (Full): 0.5922848582267761\n",
      "Epoch: 2, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7042251825332642\n",
      "LC Training Loss (Full): 0.6572020053863525\n",
      "Epoch: 2, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_8\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.6957709789276123\n",
      "LC Training Loss (Full): 0.6452208757400513\n",
      "Epoch: 2, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7326602339744568\n",
      "LC Training Loss (Full): 0.6904237866401672\n",
      "model accuracy: 0.87\n",
      "model accuracy: 0.862\n",
      "model accuracy: 0.863\n",
      "model accuracy: 0.87\n",
      "Full accuracy: 0.87, LC accuracy: 0.87, Decomposed-Full accuracy: 0.862, Decomposed-Restored accuracy: 0.863\n",
      "Epoch: 2, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.671840488910675\n",
      "LC Training Loss (Full): 0.6190698146820068\n",
      "Epoch: 2, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.8727771639823914\n",
      "LC Training Loss (Full): 0.8267917633056641\n",
      "Epoch: 2, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7836875915527344\n",
      "LC Training Loss (Full): 0.7239999175071716\n",
      "Epoch: 2, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7329789996147156\n",
      "LC Training Loss (Full): 0.6925863027572632\n",
      "Epoch: 2, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.5441493988037109\n",
      "LC Training Loss (Full): 0.5060150027275085\n",
      "model accuracy: 0.878\n",
      "model accuracy: 0.862\n",
      "model accuracy: 0.862\n",
      "model accuracy: 0.876\n",
      "Full accuracy: 0.878, LC accuracy: 0.876, Decomposed-Full accuracy: 0.862, Decomposed-Restored accuracy: 0.862\n",
      "Epoch: 2, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7747236490249634\n",
      "LC Training Loss (Full): 0.7390610575675964\n",
      "Epoch: 2, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7383217811584473\n",
      "LC Training Loss (Full): 0.6871947646141052\n",
      "Epoch: 2, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.853330671787262\n",
      "LC Training Loss (Full): 0.8056517839431763\n",
      "Epoch: 2, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_9\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7059276103973389\n",
      "LC Training Loss (Full): 0.6271538138389587\n",
      "Epoch: 2, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9447341561317444\n",
      "LC Training Loss (Full): 0.8413309454917908\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.8125\n",
      "model accuracy: 0.875\n",
      "model accuracy: 0.867\n",
      "model accuracy: 0.866\n",
      "model accuracy: 0.878\n",
      "Full accuracy: 0.875, LC accuracy: 0.878, Decomposed-Full accuracy: 0.867, Decomposed-Restored accuracy: 0.866\n",
      "Epoch: 2, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.5567829608917236\n",
      "LC Training Loss (Full): 0.5001673698425293\n",
      "Epoch: 2, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.5825204849243164\n",
      "LC Training Loss (Full): 0.5121230483055115\n",
      "Epoch: 2, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.5709035992622375\n",
      "LC Training Loss (Full): 0.5121864080429077\n",
      "Epoch: 2, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.7567896246910095\n",
      "LC Training Loss (Full): 0.6985353827476501\n",
      "Epoch: 2, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6463075876235962\n",
      "LC Training Loss (Full): 0.6016644239425659\n",
      "model accuracy: 0.879\n",
      "model accuracy: 0.871\n",
      "model accuracy: 0.871\n",
      "model accuracy: 0.878\n",
      "Full accuracy: 0.879, LC accuracy: 0.878, Decomposed-Full accuracy: 0.871, Decomposed-Restored accuracy: 0.871\n",
      "Epoch: 2, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.7318457365036011\n",
      "LC Training Loss (Full): 0.6770291328430176\n",
      "Epoch: 2, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6243755221366882\n",
      "LC Training Loss (Full): 0.5802193880081177\n",
      "Epoch: 2, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.48489075899124146\n",
      "LC Training Loss (Full): 0.43659859895706177\n",
      "Epoch: 2, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_10\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.4651636481285095\n",
      "LC Training Loss (Full): 0.4117712080478668\n",
      "Epoch: 2, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_11\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_11/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7115542888641357\n",
      "LC Training Loss (Full): 0.6552153825759888\n",
      "model accuracy: 0.886\n",
      "model accuracy: 0.871\n",
      "model accuracy: 0.871\n",
      "model accuracy: 0.885\n",
      "Full accuracy: 0.886, LC accuracy: 0.885, Decomposed-Full accuracy: 0.871, Decomposed-Restored accuracy: 0.871\n",
      "Epoch: 2, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_11\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.5561969876289368\n",
      "LC Training Loss (Full): 0.5219641923904419\n",
      "Epoch: 3, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6718944311141968\n",
      "LC Training Loss (Full): 0.5969950556755066\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.8125\n",
      "Epoch: 3, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.5560378432273865\n",
      "LC Training Loss (Full): 0.4994315803050995\n",
      "Epoch: 3, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.865969717502594\n",
      "LC Training Loss (Full): 0.8233162760734558\n",
      "Epoch: 3, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.6876612305641174\n",
      "LC Training Loss (Full): 0.6169108748435974\n",
      "Epoch: 3, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.8252453804016113\n",
      "LC Training Loss (Full): 0.7524722218513489\n",
      "Epoch: 3, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.5283408164978027\n",
      "LC Training Loss (Full): 0.4629822075366974\n",
      "model accuracy: 0.883\n",
      "model accuracy: 0.871\n",
      "model accuracy: 0.871\n",
      "model accuracy: 0.883\n",
      "Full accuracy: 0.883, LC accuracy: 0.883, Decomposed-Full accuracy: 0.871, Decomposed-Restored accuracy: 0.871\n",
      "Epoch: 3, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.5006725788116455\n",
      "LC Training Loss (Full): 0.4274124503135681\n",
      "Epoch: 3, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.6206853985786438\n",
      "LC Training Loss (Full): 0.5477822422981262\n",
      "Epoch: 3, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.6769583225250244\n",
      "LC Training Loss (Full): 0.6154972314834595\n",
      "Epoch: 3, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_12\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.670972466468811\n",
      "LC Training Loss (Full): 0.6036022305488586\n",
      "Epoch: 3, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.705049991607666\n",
      "LC Training Loss (Full): 0.6444945335388184\n",
      "model accuracy: 0.885\n",
      "model accuracy: 0.87\n",
      "model accuracy: 0.869\n",
      "model accuracy: 0.885\n",
      "Full accuracy: 0.885, LC accuracy: 0.885, Decomposed-Full accuracy: 0.87, Decomposed-Restored accuracy: 0.869\n",
      "Epoch: 3, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6443020701408386\n",
      "LC Training Loss (Full): 0.5766637921333313\n",
      "Epoch: 3, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8472546339035034\n",
      "LC Training Loss (Full): 0.78407222032547\n",
      "Epoch: 3, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7613545060157776\n",
      "LC Training Loss (Full): 0.6845180988311768\n",
      "Epoch: 3, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7121718525886536\n",
      "LC Training Loss (Full): 0.6563181281089783\n",
      "Epoch: 3, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.5274596810340881\n",
      "LC Training Loss (Full): 0.4734722673892975\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.875\n",
      "model accuracy: 0.875\n",
      "model accuracy: 0.891\n",
      "Full accuracy: 0.893, LC accuracy: 0.891, Decomposed-Full accuracy: 0.875, Decomposed-Restored accuracy: 0.875\n",
      "Epoch: 3, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7616956830024719\n",
      "LC Training Loss (Full): 0.7056840658187866\n",
      "Epoch: 3, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7184259295463562\n",
      "LC Training Loss (Full): 0.6482136249542236\n",
      "Epoch: 3, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8399922847747803\n",
      "LC Training Loss (Full): 0.7777058482170105\n",
      "Epoch: 3, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_13\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6752432584762573\n",
      "LC Training Loss (Full): 0.5811178684234619\n",
      "Epoch: 3, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9155158400535583\n",
      "LC Training Loss (Full): 0.7977273464202881\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.84375\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.875\n",
      "model accuracy: 0.874\n",
      "model accuracy: 0.892\n",
      "Full accuracy: 0.891, LC accuracy: 0.892, Decomposed-Full accuracy: 0.875, Decomposed-Restored accuracy: 0.874\n",
      "Epoch: 3, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5358716249465942\n",
      "LC Training Loss (Full): 0.4658784568309784\n",
      "Epoch: 3, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5542771220207214\n",
      "LC Training Loss (Full): 0.4708084464073181\n",
      "Epoch: 3, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5452566742897034\n",
      "LC Training Loss (Full): 0.4719374477863312\n",
      "Epoch: 3, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.7344056367874146\n",
      "LC Training Loss (Full): 0.6636967658996582\n",
      "Epoch: 3, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6196964383125305\n",
      "LC Training Loss (Full): 0.5581825971603394\n",
      "model accuracy: 0.895\n",
      "model accuracy: 0.875\n",
      "model accuracy: 0.875\n",
      "model accuracy: 0.892\n",
      "Full accuracy: 0.895, LC accuracy: 0.892, Decomposed-Full accuracy: 0.875, Decomposed-Restored accuracy: 0.875\n",
      "Epoch: 3, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.707629919052124\n",
      "LC Training Loss (Full): 0.6343977451324463\n",
      "Epoch: 3, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6052060723304749\n",
      "LC Training Loss (Full): 0.5456389784812927\n",
      "Epoch: 3, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.46424612402915955\n",
      "LC Training Loss (Full): 0.4028363823890686\n",
      "Epoch: 3, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_14\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.44429466128349304\n",
      "LC Training Loss (Full): 0.37641820311546326\n",
      "Epoch: 3, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_15\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_15/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6900671720504761\n",
      "LC Training Loss (Full): 0.6159929633140564\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.877\n",
      "model accuracy: 0.877\n",
      "model accuracy: 0.897\n",
      "Full accuracy: 0.898, LC accuracy: 0.897, Decomposed-Full accuracy: 0.877, Decomposed-Restored accuracy: 0.877\n",
      "Epoch: 3, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_15\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.5471197366714478\n",
      "LC Training Loss (Full): 0.49982041120529175\n",
      "Epoch: 4, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6496665477752686\n",
      "LC Training Loss (Full): 0.5624733567237854\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.8125\n",
      "Epoch: 4, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.538027286529541\n",
      "LC Training Loss (Full): 0.47141847014427185\n",
      "Epoch: 4, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.8505264520645142\n",
      "LC Training Loss (Full): 0.7943682074546814\n",
      "Epoch: 4, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6670113205909729\n",
      "LC Training Loss (Full): 0.580743134021759\n",
      "Epoch: 4, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.7961689829826355\n",
      "LC Training Loss (Full): 0.7050374150276184\n",
      "Epoch: 4, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5063744783401489\n",
      "LC Training Loss (Full): 0.42709267139434814\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.881\n",
      "model accuracy: 0.881\n",
      "model accuracy: 0.893\n",
      "Full accuracy: 0.893, LC accuracy: 0.893, Decomposed-Full accuracy: 0.881, Decomposed-Restored accuracy: 0.881\n",
      "Epoch: 4, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.4804532527923584\n",
      "LC Training Loss (Full): 0.39176860451698303\n",
      "Epoch: 4, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5970856547355652\n",
      "LC Training Loss (Full): 0.5084158778190613\n",
      "Epoch: 4, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6527705192565918\n",
      "LC Training Loss (Full): 0.5781891942024231\n",
      "Epoch: 4, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_16\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6492170095443726\n",
      "LC Training Loss (Full): 0.5659019351005554\n",
      "Epoch: 4, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.677344799041748\n",
      "LC Training Loss (Full): 0.6027291417121887\n",
      "model accuracy: 0.899\n",
      "model accuracy: 0.879\n",
      "model accuracy: 0.879\n",
      "model accuracy: 0.894\n",
      "Full accuracy: 0.899, LC accuracy: 0.894, Decomposed-Full accuracy: 0.879, Decomposed-Restored accuracy: 0.879\n",
      "Epoch: 4, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.6190958023071289\n",
      "LC Training Loss (Full): 0.5385353565216064\n",
      "Epoch: 4, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8242194652557373\n",
      "LC Training Loss (Full): 0.7450235486030579\n",
      "Epoch: 4, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.741355836391449\n",
      "LC Training Loss (Full): 0.6478663086891174\n",
      "Epoch: 4, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.6929429173469543\n",
      "LC Training Loss (Full): 0.6223669648170471\n",
      "Epoch: 4, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.5114971995353699\n",
      "LC Training Loss (Full): 0.44319215416908264\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.88\n",
      "model accuracy: 0.88\n",
      "model accuracy: 0.899\n",
      "Full accuracy: 0.904, LC accuracy: 0.899, Decomposed-Full accuracy: 0.88, Decomposed-Restored accuracy: 0.88\n",
      "Epoch: 4, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.7482959032058716\n",
      "LC Training Loss (Full): 0.6733855605125427\n",
      "Epoch: 4, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.6998198628425598\n",
      "LC Training Loss (Full): 0.6114102602005005\n",
      "Epoch: 4, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8285011649131775\n",
      "LC Training Loss (Full): 0.7514877319335938\n",
      "Epoch: 4, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_17\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.6507092118263245\n",
      "LC Training Loss (Full): 0.5402724742889404\n",
      "Epoch: 4, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8946285247802734\n",
      "LC Training Loss (Full): 0.7595680952072144\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.879\n",
      "model accuracy: 0.879\n",
      "model accuracy: 0.904\n",
      "Full accuracy: 0.902, LC accuracy: 0.904, Decomposed-Full accuracy: 0.879, Decomposed-Restored accuracy: 0.879\n",
      "Epoch: 4, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.5168121457099915\n",
      "LC Training Loss (Full): 0.4356415569782257\n",
      "Epoch: 4, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.5303810238838196\n",
      "LC Training Loss (Full): 0.4346374273300171\n",
      "Epoch: 4, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.5229888558387756\n",
      "LC Training Loss (Full): 0.43614301085472107\n",
      "Epoch: 4, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.7150765061378479\n",
      "LC Training Loss (Full): 0.6321120858192444\n",
      "Epoch: 4, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.5960001349449158\n",
      "LC Training Loss (Full): 0.5189734697341919\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.881\n",
      "model accuracy: 0.881\n",
      "model accuracy: 0.903\n",
      "Full accuracy: 0.904, LC accuracy: 0.903, Decomposed-Full accuracy: 0.881, Decomposed-Restored accuracy: 0.881\n",
      "Epoch: 4, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6860756278038025\n",
      "LC Training Loss (Full): 0.5959084033966064\n",
      "Epoch: 4, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.587325394153595\n",
      "LC Training Loss (Full): 0.5143453478813171\n",
      "Epoch: 4, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.4457884728908539\n",
      "LC Training Loss (Full): 0.3727785348892212\n",
      "Epoch: 4, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_18\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.4247860610485077\n",
      "LC Training Loss (Full): 0.3448416590690613\n",
      "Epoch: 4, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_19\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_19/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6703200936317444\n",
      "LC Training Loss (Full): 0.5802358388900757\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.882\n",
      "model accuracy: 0.882\n",
      "model accuracy: 0.906\n",
      "Full accuracy: 0.906, LC accuracy: 0.906, Decomposed-Full accuracy: 0.882, Decomposed-Restored accuracy: 0.882\n",
      "Epoch: 4, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_19\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.5364776253700256\n",
      "LC Training Loss (Full): 0.47995489835739136\n",
      "Epoch: 5, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6295804381370544\n",
      "LC Training Loss (Full): 0.5318945646286011\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.8125\n",
      "Epoch: 5, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.5216572880744934\n",
      "LC Training Loss (Full): 0.4464264214038849\n",
      "Epoch: 5, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.8377010822296143\n",
      "LC Training Loss (Full): 0.7684909701347351\n",
      "Epoch: 5, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6478781700134277\n",
      "LC Training Loss (Full): 0.5476021766662598\n",
      "Epoch: 5, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7714262008666992\n",
      "LC Training Loss (Full): 0.6615805625915527\n",
      "Epoch: 5, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.4863610863685608\n",
      "LC Training Loss (Full): 0.3954704999923706\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.882\n",
      "model accuracy: 0.882\n",
      "model accuracy: 0.902\n",
      "Full accuracy: 0.902, LC accuracy: 0.902, Decomposed-Full accuracy: 0.882, Decomposed-Restored accuracy: 0.882\n",
      "Epoch: 5, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.4610500633716583\n",
      "LC Training Loss (Full): 0.3600655794143677\n",
      "Epoch: 5, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.5764515995979309\n",
      "LC Training Loss (Full): 0.4733237624168396\n",
      "Epoch: 5, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6305294632911682\n",
      "LC Training Loss (Full): 0.5445134043693542\n",
      "Epoch: 5, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_20\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6286005973815918\n",
      "LC Training Loss (Full): 0.5316725969314575\n",
      "Epoch: 5, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6525733470916748\n",
      "LC Training Loss (Full): 0.564603328704834\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.906\n",
      "Full accuracy: 0.911, LC accuracy: 0.906, Decomposed-Full accuracy: 0.884, Decomposed-Restored accuracy: 0.884\n",
      "Epoch: 5, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.5966329574584961\n",
      "LC Training Loss (Full): 0.5040119290351868\n",
      "Epoch: 5, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.8021668195724487\n",
      "LC Training Loss (Full): 0.7089381814002991\n",
      "Epoch: 5, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.720910370349884\n",
      "LC Training Loss (Full): 0.6136022210121155\n",
      "Epoch: 5, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6746248006820679\n",
      "LC Training Loss (Full): 0.5904898047447205\n",
      "Epoch: 5, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.49664849042892456\n",
      "LC Training Loss (Full): 0.4149755835533142\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.886\n",
      "model accuracy: 0.909\n",
      "Full accuracy: 0.908, LC accuracy: 0.909, Decomposed-Full accuracy: 0.884, Decomposed-Restored accuracy: 0.886\n",
      "Epoch: 5, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.7373251914978027\n",
      "LC Training Loss (Full): 0.6425849199295044\n",
      "Epoch: 5, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6839970946311951\n",
      "LC Training Loss (Full): 0.5766622424125671\n",
      "Epoch: 5, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.8182560801506042\n",
      "LC Training Loss (Full): 0.7266051769256592\n",
      "Epoch: 5, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_21\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.62577223777771\n",
      "LC Training Loss (Full): 0.5032511353492737\n",
      "Epoch: 5, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.872718870639801\n",
      "LC Training Loss (Full): 0.7254160046577454\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.882\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.913\n",
      "Full accuracy: 0.913, LC accuracy: 0.913, Decomposed-Full accuracy: 0.882, Decomposed-Restored accuracy: 0.884\n",
      "Epoch: 5, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.49964216351509094\n",
      "LC Training Loss (Full): 0.4086473882198334\n",
      "Epoch: 5, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.5075966715812683\n",
      "LC Training Loss (Full): 0.40276914834976196\n",
      "Epoch: 5, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.5016926527023315\n",
      "LC Training Loss (Full): 0.40414515137672424\n",
      "Epoch: 5, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6962742805480957\n",
      "LC Training Loss (Full): 0.6034570336341858\n",
      "Epoch: 5, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.5742616653442383\n",
      "LC Training Loss (Full): 0.48354238271713257\n",
      "model accuracy: 0.914\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.912\n",
      "Full accuracy: 0.914, LC accuracy: 0.912, Decomposed-Full accuracy: 0.884, Decomposed-Restored accuracy: 0.884\n",
      "Epoch: 5, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6665076017379761\n",
      "LC Training Loss (Full): 0.561068058013916\n",
      "Epoch: 5, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.5705238580703735\n",
      "LC Training Loss (Full): 0.4860897958278656\n",
      "Epoch: 5, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.42912739515304565\n",
      "LC Training Loss (Full): 0.3458670973777771\n",
      "Epoch: 5, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_22\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.4070305824279785\n",
      "LC Training Loss (Full): 0.31664443016052246\n",
      "Epoch: 5, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_23\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_23/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6518772840499878\n",
      "LC Training Loss (Full): 0.5474803447723389\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.888\n",
      "model accuracy: 0.888\n",
      "model accuracy: 0.911\n",
      "Full accuracy: 0.912, LC accuracy: 0.911, Decomposed-Full accuracy: 0.888, Decomposed-Restored accuracy: 0.888\n",
      "Epoch: 5, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_23\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.5281012058258057\n",
      "LC Training Loss (Full): 0.46222159266471863\n",
      "Epoch: 6, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6120303869247437\n",
      "LC Training Loss (Full): 0.5043993592262268\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "Epoch: 6, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.5072879195213318\n",
      "LC Training Loss (Full): 0.4238405227661133\n",
      "Epoch: 6, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.8262202143669128\n",
      "LC Training Loss (Full): 0.7451260685920715\n",
      "Epoch: 6, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6300832033157349\n",
      "LC Training Loss (Full): 0.5171024799346924\n",
      "Epoch: 6, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7473573684692383\n",
      "LC Training Loss (Full): 0.621808648109436\n",
      "Epoch: 6, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.46844539046287537\n",
      "LC Training Loss (Full): 0.3675180673599243\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.886\n",
      "model accuracy: 0.911\n",
      "Full accuracy: 0.912, LC accuracy: 0.911, Decomposed-Full accuracy: 0.887, Decomposed-Restored accuracy: 0.886\n",
      "Epoch: 6, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.44285354018211365\n",
      "LC Training Loss (Full): 0.3318771421909332\n",
      "Epoch: 6, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.5572990775108337\n",
      "LC Training Loss (Full): 0.4418885111808777\n",
      "Epoch: 6, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6103634238243103\n",
      "LC Training Loss (Full): 0.5139699578285217\n",
      "Epoch: 6, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_24\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6090494394302368\n",
      "LC Training Loss (Full): 0.5005552768707275\n",
      "Epoch: 6, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6294140815734863\n",
      "LC Training Loss (Full): 0.5297063589096069\n",
      "model accuracy: 0.915\n",
      "model accuracy: 0.888\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.914\n",
      "Full accuracy: 0.915, LC accuracy: 0.914, Decomposed-Full accuracy: 0.888, Decomposed-Restored accuracy: 0.887\n",
      "Epoch: 6, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.5756264328956604\n",
      "LC Training Loss (Full): 0.47261643409729004\n",
      "Epoch: 6, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7836191058158875\n",
      "LC Training Loss (Full): 0.6754308938980103\n",
      "Epoch: 6, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7034926414489746\n",
      "LC Training Loss (Full): 0.5814540386199951\n",
      "Epoch: 6, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.6584245562553406\n",
      "LC Training Loss (Full): 0.5605099201202393\n",
      "Epoch: 6, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.4821864068508148\n",
      "LC Training Loss (Full): 0.3886069655418396\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.886\n",
      "model accuracy: 0.886\n",
      "model accuracy: 0.914\n",
      "Full accuracy: 0.913, LC accuracy: 0.914, Decomposed-Full accuracy: 0.886, Decomposed-Restored accuracy: 0.886\n",
      "Epoch: 6, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7242181897163391\n",
      "LC Training Loss (Full): 0.613403856754303\n",
      "Epoch: 6, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.6673447489738464\n",
      "LC Training Loss (Full): 0.5438928008079529\n",
      "Epoch: 6, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.8070071339607239\n",
      "LC Training Loss (Full): 0.702825665473938\n",
      "Epoch: 6, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_25\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.6034058332443237\n",
      "LC Training Loss (Full): 0.4693155586719513\n",
      "Epoch: 6, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8512510061264038\n",
      "LC Training Loss (Full): 0.6944360733032227\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "model accuracy: 0.92\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.888\n",
      "model accuracy: 0.919\n",
      "Full accuracy: 0.92, LC accuracy: 0.919, Decomposed-Full accuracy: 0.887, Decomposed-Restored accuracy: 0.888\n",
      "Epoch: 6, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.4832240343093872\n",
      "LC Training Loss (Full): 0.3843527138233185\n",
      "Epoch: 6, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.48663344979286194\n",
      "LC Training Loss (Full): 0.374576598405838\n",
      "Epoch: 6, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.482244610786438\n",
      "LC Training Loss (Full): 0.37545937299728394\n",
      "Epoch: 6, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6789155006408691\n",
      "LC Training Loss (Full): 0.5774955749511719\n",
      "Epoch: 6, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.5540742874145508\n",
      "LC Training Loss (Full): 0.45152273774147034\n",
      "model accuracy: 0.92\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.92\n",
      "Full accuracy: 0.92, LC accuracy: 0.92, Decomposed-Full accuracy: 0.89, Decomposed-Restored accuracy: 0.89\n",
      "Epoch: 6, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6480690240859985\n",
      "LC Training Loss (Full): 0.5295374393463135\n",
      "Epoch: 6, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.5553051233291626\n",
      "LC Training Loss (Full): 0.460637629032135\n",
      "Epoch: 6, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.4141731262207031\n",
      "LC Training Loss (Full): 0.32169222831726074\n",
      "Epoch: 6, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_26\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.39091378450393677\n",
      "LC Training Loss (Full): 0.2914313077926636\n",
      "Epoch: 6, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_27\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_27/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6342929601669312\n",
      "LC Training Loss (Full): 0.5173259377479553\n",
      "model accuracy: 0.918\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.918\n",
      "Full accuracy: 0.918, LC accuracy: 0.918, Decomposed-Full accuracy: 0.89, Decomposed-Restored accuracy: 0.89\n",
      "Epoch: 6, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_27\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.5191704034805298\n",
      "LC Training Loss (Full): 0.44637373089790344\n",
      "Epoch: 7, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5948845148086548\n",
      "LC Training Loss (Full): 0.47944164276123047\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "Epoch: 7, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.49405601620674133\n",
      "LC Training Loss (Full): 0.40326201915740967\n",
      "Epoch: 7, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.8149135708808899\n",
      "LC Training Loss (Full): 0.7238725423812866\n",
      "Epoch: 7, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6135246157646179\n",
      "LC Training Loss (Full): 0.4889666736125946\n",
      "Epoch: 7, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.7238613963127136\n",
      "LC Training Loss (Full): 0.5854313969612122\n",
      "Epoch: 7, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.45070892572402954\n",
      "LC Training Loss (Full): 0.342745304107666\n",
      "model accuracy: 0.917\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.917\n",
      "Full accuracy: 0.917, LC accuracy: 0.917, Decomposed-Full accuracy: 0.891, Decomposed-Restored accuracy: 0.891\n",
      "Epoch: 7, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.4256766140460968\n",
      "LC Training Loss (Full): 0.3067936897277832\n",
      "Epoch: 7, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5397805571556091\n",
      "LC Training Loss (Full): 0.41361457109451294\n",
      "Epoch: 7, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5922968983650208\n",
      "LC Training Loss (Full): 0.4861772656440735\n",
      "Epoch: 7, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_28\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.59075528383255\n",
      "LC Training Loss (Full): 0.4722385108470917\n",
      "Epoch: 7, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6100764274597168\n",
      "LC Training Loss (Full): 0.49774253368377686\n",
      "model accuracy: 0.919\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.919\n",
      "Full accuracy: 0.919, LC accuracy: 0.919, Decomposed-Full accuracy: 0.891, Decomposed-Restored accuracy: 0.89\n",
      "Epoch: 7, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.556357204914093\n",
      "LC Training Loss (Full): 0.44396936893463135\n",
      "Epoch: 7, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.766068696975708\n",
      "LC Training Loss (Full): 0.6442578434944153\n",
      "Epoch: 7, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6881493330001831\n",
      "LC Training Loss (Full): 0.5512200593948364\n",
      "Epoch: 7, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6415460705757141\n",
      "LC Training Loss (Full): 0.5323020219802856\n",
      "Epoch: 7, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.4689067304134369\n",
      "LC Training Loss (Full): 0.36391618847846985\n",
      "model accuracy: 0.917\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.919\n",
      "Full accuracy: 0.917, LC accuracy: 0.919, Decomposed-Full accuracy: 0.891, Decomposed-Restored accuracy: 0.891\n",
      "Epoch: 7, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7110059261322021\n",
      "LC Training Loss (Full): 0.5858543515205383\n",
      "Epoch: 7, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6497923135757446\n",
      "LC Training Loss (Full): 0.5130497217178345\n",
      "Epoch: 7, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7960999608039856\n",
      "LC Training Loss (Full): 0.679993748664856\n",
      "Epoch: 7, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_29\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.5846891403198242\n",
      "LC Training Loss (Full): 0.43801674246788025\n",
      "Epoch: 7, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8341658711433411\n",
      "LC Training Loss (Full): 0.6660844087600708\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "model accuracy: 0.921\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.892\n",
      "model accuracy: 0.922\n",
      "Full accuracy: 0.921, LC accuracy: 0.922, Decomposed-Full accuracy: 0.891, Decomposed-Restored accuracy: 0.892\n",
      "Epoch: 7, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.46941250562667847\n",
      "LC Training Loss (Full): 0.3623636066913605\n",
      "Epoch: 7, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.46823227405548096\n",
      "LC Training Loss (Full): 0.34953755140304565\n",
      "Epoch: 7, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.4646298289299011\n",
      "LC Training Loss (Full): 0.3496909737586975\n",
      "Epoch: 7, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.6643571853637695\n",
      "LC Training Loss (Full): 0.5539971590042114\n",
      "Epoch: 7, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5346102714538574\n",
      "LC Training Loss (Full): 0.42261120676994324\n",
      "model accuracy: 0.923\n",
      "model accuracy: 0.892\n",
      "model accuracy: 0.892\n",
      "model accuracy: 0.922\n",
      "Full accuracy: 0.923, LC accuracy: 0.922, Decomposed-Full accuracy: 0.892, Decomposed-Restored accuracy: 0.892\n",
      "Epoch: 7, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.6300840973854065\n",
      "LC Training Loss (Full): 0.5010412931442261\n",
      "Epoch: 7, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5398014783859253\n",
      "LC Training Loss (Full): 0.43776917457580566\n",
      "Epoch: 7, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.4004440903663635\n",
      "LC Training Loss (Full): 0.299923837184906\n",
      "Epoch: 7, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_30\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.3755963444709778\n",
      "LC Training Loss (Full): 0.2688409686088562\n",
      "Epoch: 7, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_31\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_31/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6170564293861389\n",
      "LC Training Loss (Full): 0.48945188522338867\n",
      "model accuracy: 0.924\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.923\n",
      "Full accuracy: 0.924, LC accuracy: 0.923, Decomposed-Full accuracy: 0.894, Decomposed-Restored accuracy: 0.894\n",
      "Epoch: 7, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_31\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.5110122561454773\n",
      "LC Training Loss (Full): 0.43214622139930725\n",
      "Epoch: 8, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5805980563163757\n",
      "LC Training Loss (Full): 0.4566364884376526\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "Epoch: 8, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.48250633478164673\n",
      "LC Training Loss (Full): 0.38440653681755066\n",
      "Epoch: 8, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.8027990460395813\n",
      "LC Training Loss (Full): 0.704429030418396\n",
      "Epoch: 8, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5985234379768372\n",
      "LC Training Loss (Full): 0.4629723131656647\n",
      "Epoch: 8, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.7021127939224243\n",
      "LC Training Loss (Full): 0.5521708726882935\n",
      "Epoch: 8, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.436197966337204\n",
      "LC Training Loss (Full): 0.3207261860370636\n",
      "model accuracy: 0.924\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.926\n",
      "Full accuracy: 0.924, LC accuracy: 0.926, Decomposed-Full accuracy: 0.894, Decomposed-Restored accuracy: 0.893\n",
      "Epoch: 8, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.41146916151046753\n",
      "LC Training Loss (Full): 0.28443124890327454\n",
      "Epoch: 8, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5237655639648438\n",
      "LC Training Loss (Full): 0.38808682560920715\n",
      "Epoch: 8, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5754261016845703\n",
      "LC Training Loss (Full): 0.460822194814682\n",
      "Epoch: 8, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_32\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5742725133895874\n",
      "LC Training Loss (Full): 0.44644737243652344\n",
      "Epoch: 8, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5891873240470886\n",
      "LC Training Loss (Full): 0.46847888827323914\n",
      "model accuracy: 0.925\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.924\n",
      "Full accuracy: 0.925, LC accuracy: 0.924, Decomposed-Full accuracy: 0.894, Decomposed-Restored accuracy: 0.894\n",
      "Epoch: 8, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.5383756160736084\n",
      "LC Training Loss (Full): 0.4177531599998474\n",
      "Epoch: 8, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.7486010789871216\n",
      "LC Training Loss (Full): 0.615230917930603\n",
      "Epoch: 8, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6735849380493164\n",
      "LC Training Loss (Full): 0.5227406024932861\n",
      "Epoch: 8, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6255131959915161\n",
      "LC Training Loss (Full): 0.5057687759399414\n",
      "Epoch: 8, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.4558153450489044\n",
      "LC Training Loss (Full): 0.3407820165157318\n",
      "model accuracy: 0.923\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.924\n",
      "Full accuracy: 0.923, LC accuracy: 0.924, Decomposed-Full accuracy: 0.894, Decomposed-Restored accuracy: 0.894\n",
      "Epoch: 8, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6982730031013489\n",
      "LC Training Loss (Full): 0.55990070104599\n",
      "Epoch: 8, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6348799467086792\n",
      "LC Training Loss (Full): 0.48409008979797363\n",
      "Epoch: 8, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.787475049495697\n",
      "LC Training Loss (Full): 0.6580005884170532\n",
      "Epoch: 8, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_33\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.5682405829429626\n",
      "LC Training Loss (Full): 0.40905776619911194\n",
      "Epoch: 8, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8197975158691406\n",
      "LC Training Loss (Full): 0.6399824619293213\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "model accuracy: 0.926\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.927\n",
      "Full accuracy: 0.926, LC accuracy: 0.927, Decomposed-Full accuracy: 0.894, Decomposed-Restored accuracy: 0.896\n",
      "Epoch: 8, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.4558447301387787\n",
      "LC Training Loss (Full): 0.3423716127872467\n",
      "Epoch: 8, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.45199981331825256\n",
      "LC Training Loss (Full): 0.32720765471458435\n",
      "Epoch: 8, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.4487910568714142\n",
      "LC Training Loss (Full): 0.3264995515346527\n",
      "Epoch: 8, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.6502150893211365\n",
      "LC Training Loss (Full): 0.5327264666557312\n",
      "Epoch: 8, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.5172567963600159\n",
      "LC Training Loss (Full): 0.39653071761131287\n",
      "model accuracy: 0.925\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.924\n",
      "Full accuracy: 0.925, LC accuracy: 0.924, Decomposed-Full accuracy: 0.894, Decomposed-Restored accuracy: 0.894\n",
      "Epoch: 8, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.6144590973854065\n",
      "LC Training Loss (Full): 0.47532403469085693\n",
      "Epoch: 8, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.5263446569442749\n",
      "LC Training Loss (Full): 0.41727256774902344\n",
      "Epoch: 8, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.3874591290950775\n",
      "LC Training Loss (Full): 0.280282199382782\n",
      "Epoch: 8, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_34\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.361544668674469\n",
      "LC Training Loss (Full): 0.24855314195156097\n",
      "Epoch: 8, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_35\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_35/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6012808680534363\n",
      "LC Training Loss (Full): 0.4636029601097107\n",
      "model accuracy: 0.928\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.929\n",
      "Full accuracy: 0.928, LC accuracy: 0.929, Decomposed-Full accuracy: 0.896, Decomposed-Restored accuracy: 0.896\n",
      "Epoch: 8, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_35\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.5034092664718628\n",
      "LC Training Loss (Full): 0.419292688369751\n",
      "Epoch: 9, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5673912167549133\n",
      "LC Training Loss (Full): 0.43569105863571167\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "Epoch: 9, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.4714977741241455\n",
      "LC Training Loss (Full): 0.3670565187931061\n",
      "Epoch: 9, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7926371693611145\n",
      "LC Training Loss (Full): 0.6865565776824951\n",
      "Epoch: 9, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5847314596176147\n",
      "LC Training Loss (Full): 0.43892815709114075\n",
      "Epoch: 9, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.6826383471488953\n",
      "LC Training Loss (Full): 0.5217599868774414\n",
      "Epoch: 9, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.4219799339771271\n",
      "LC Training Loss (Full): 0.3010846972465515\n",
      "model accuracy: 0.93\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.93\n",
      "Full accuracy: 0.93, LC accuracy: 0.93, Decomposed-Full accuracy: 0.897, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 9, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.3965849280357361\n",
      "LC Training Loss (Full): 0.26443979144096375\n",
      "Epoch: 9, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.508806049823761\n",
      "LC Training Loss (Full): 0.3649524748325348\n",
      "Epoch: 9, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5598143935203552\n",
      "LC Training Loss (Full): 0.43763962388038635\n",
      "Epoch: 9, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_36\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5583792924880981\n",
      "LC Training Loss (Full): 0.42293599247932434\n",
      "Epoch: 9, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5711185932159424\n",
      "LC Training Loss (Full): 0.44171035289764404\n",
      "model accuracy: 0.929\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.929\n",
      "Full accuracy: 0.929, LC accuracy: 0.929, Decomposed-Full accuracy: 0.896, Decomposed-Restored accuracy: 0.896\n",
      "Epoch: 9, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.5214259028434753\n",
      "LC Training Loss (Full): 0.393696129322052\n",
      "Epoch: 9, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7322817444801331\n",
      "LC Training Loss (Full): 0.5881839394569397\n",
      "Epoch: 9, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6592726707458496\n",
      "LC Training Loss (Full): 0.4958864450454712\n",
      "Epoch: 9, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6105196475982666\n",
      "LC Training Loss (Full): 0.4808255434036255\n",
      "Epoch: 9, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.44321581721305847\n",
      "LC Training Loss (Full): 0.3191199004650116\n",
      "model accuracy: 0.927\n",
      "model accuracy: 0.895\n",
      "model accuracy: 0.895\n",
      "model accuracy: 0.927\n",
      "Full accuracy: 0.927, LC accuracy: 0.927, Decomposed-Full accuracy: 0.895, Decomposed-Restored accuracy: 0.895\n",
      "Epoch: 9, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6860674023628235\n",
      "LC Training Loss (Full): 0.535484254360199\n",
      "Epoch: 9, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6193526983261108\n",
      "LC Training Loss (Full): 0.4569705128669739\n",
      "Epoch: 9, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7770724296569824\n",
      "LC Training Loss (Full): 0.6367695927619934\n",
      "Epoch: 9, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_37\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.5519751310348511\n",
      "LC Training Loss (Full): 0.3822263479232788\n",
      "Epoch: 9, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8041583299636841\n",
      "LC Training Loss (Full): 0.6158521175384521\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "model accuracy: 0.931\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.93\n",
      "Full accuracy: 0.931, LC accuracy: 0.93, Decomposed-Full accuracy: 0.898, Decomposed-Restored accuracy: 0.898\n",
      "Epoch: 9, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.4425102472305298\n",
      "LC Training Loss (Full): 0.32412222027778625\n",
      "Epoch: 9, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.43699556589126587\n",
      "LC Training Loss (Full): 0.30720630288124084\n",
      "Epoch: 9, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.4344412386417389\n",
      "LC Training Loss (Full): 0.30558550357818604\n",
      "Epoch: 9, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.6372696161270142\n",
      "LC Training Loss (Full): 0.5134493112564087\n",
      "Epoch: 9, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5012795329093933\n",
      "LC Training Loss (Full): 0.37301498651504517\n",
      "model accuracy: 0.928\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.929\n",
      "Full accuracy: 0.928, LC accuracy: 0.929, Decomposed-Full accuracy: 0.896, Decomposed-Restored accuracy: 0.898\n",
      "Epoch: 9, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.6000230312347412\n",
      "LC Training Loss (Full): 0.45213326811790466\n",
      "Epoch: 9, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5136274695396423\n",
      "LC Training Loss (Full): 0.3989388048648834\n",
      "Epoch: 9, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.37542104721069336\n",
      "LC Training Loss (Full): 0.26252281665802\n",
      "Epoch: 9, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_38\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.3482506573200226\n",
      "LC Training Loss (Full): 0.23028817772865295\n",
      "Epoch: 9, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_39\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_39/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5858944654464722\n",
      "LC Training Loss (Full): 0.43957406282424927\n",
      "model accuracy: 0.93\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.9\n",
      "model accuracy: 0.932\n",
      "Full accuracy: 0.93, LC accuracy: 0.932, Decomposed-Full accuracy: 0.898, Decomposed-Restored accuracy: 0.9\n",
      "Epoch: 9, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_39\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.49612951278686523\n",
      "LC Training Loss (Full): 0.40759697556495667\n",
      "Epoch: 10, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5549342036247253\n",
      "LC Training Loss (Full): 0.41637057065963745\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "Epoch: 10, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.46117642521858215\n",
      "LC Training Loss (Full): 0.3510369658470154\n",
      "Epoch: 10, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.7827958464622498\n",
      "LC Training Loss (Full): 0.6700566411018372\n",
      "Epoch: 10, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5714949369430542\n",
      "LC Training Loss (Full): 0.41666528582572937\n",
      "Epoch: 10, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6639872789382935\n",
      "LC Training Loss (Full): 0.49394136667251587\n",
      "Epoch: 10, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.4088651239871979\n",
      "LC Training Loss (Full): 0.28349027037620544\n",
      "model accuracy: 0.933\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.932\n",
      "Full accuracy: 0.933, LC accuracy: 0.932, Decomposed-Full accuracy: 0.898, Decomposed-Restored accuracy: 0.898\n",
      "Epoch: 10, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.3830467462539673\n",
      "LC Training Loss (Full): 0.24650642275810242\n",
      "Epoch: 10, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.49403485655784607\n",
      "LC Training Loss (Full): 0.3439100682735443\n",
      "Epoch: 10, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5444477796554565\n",
      "LC Training Loss (Full): 0.41640007495880127\n",
      "Epoch: 10, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_40\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5427860617637634\n",
      "LC Training Loss (Full): 0.4014817774295807\n",
      "Epoch: 10, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5519552230834961\n",
      "LC Training Loss (Full): 0.41724324226379395\n",
      "model accuracy: 0.932\n",
      "model accuracy: 0.899\n",
      "model accuracy: 0.9\n",
      "model accuracy: 0.931\n",
      "Full accuracy: 0.932, LC accuracy: 0.931, Decomposed-Full accuracy: 0.899, Decomposed-Restored accuracy: 0.9\n",
      "Epoch: 10, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5057743787765503\n",
      "LC Training Loss (Full): 0.3715642988681793\n",
      "Epoch: 10, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7169687151908875\n",
      "LC Training Loss (Full): 0.5629606246948242\n",
      "Epoch: 10, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.6446470618247986\n",
      "LC Training Loss (Full): 0.47054943442344666\n",
      "Epoch: 10, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5966793298721313\n",
      "LC Training Loss (Full): 0.45739272236824036\n",
      "Epoch: 10, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.43047794699668884\n",
      "LC Training Loss (Full): 0.2988675534725189\n",
      "model accuracy: 0.932\n",
      "model accuracy: 0.899\n",
      "model accuracy: 0.899\n",
      "model accuracy: 0.932\n",
      "Full accuracy: 0.932, LC accuracy: 0.932, Decomposed-Full accuracy: 0.899, Decomposed-Restored accuracy: 0.899\n",
      "Epoch: 10, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.6738778352737427\n",
      "LC Training Loss (Full): 0.5125300884246826\n",
      "Epoch: 10, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.605192244052887\n",
      "LC Training Loss (Full): 0.4316401779651642\n",
      "Epoch: 10, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7692012786865234\n",
      "LC Training Loss (Full): 0.6162464618682861\n",
      "Epoch: 10, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_41\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5369804501533508\n",
      "LC Training Loss (Full): 0.35735946893692017\n",
      "Epoch: 10, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.791638970375061\n",
      "LC Training Loss (Full): 0.5934799313545227\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.84375\n",
      "model accuracy: 0.934\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.935\n",
      "Full accuracy: 0.934, LC accuracy: 0.935, Decomposed-Full accuracy: 0.902, Decomposed-Restored accuracy: 0.902\n",
      "Epoch: 10, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.4310993254184723\n",
      "LC Training Loss (Full): 0.3073996901512146\n",
      "Epoch: 10, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.4220399558544159\n",
      "LC Training Loss (Full): 0.2892090380191803\n",
      "Epoch: 10, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.4207952618598938\n",
      "LC Training Loss (Full): 0.286682665348053\n",
      "Epoch: 10, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6239420175552368\n",
      "LC Training Loss (Full): 0.49594053626060486\n",
      "Epoch: 10, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.48617371916770935\n",
      "LC Training Loss (Full): 0.3518071174621582\n",
      "model accuracy: 0.935\n",
      "model accuracy: 0.899\n",
      "model accuracy: 0.899\n",
      "model accuracy: 0.934\n",
      "Full accuracy: 0.935, LC accuracy: 0.934, Decomposed-Full accuracy: 0.899, Decomposed-Restored accuracy: 0.899\n",
      "Epoch: 10, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5866810083389282\n",
      "LC Training Loss (Full): 0.431218683719635\n",
      "Epoch: 10, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5013948082923889\n",
      "LC Training Loss (Full): 0.3825613856315613\n",
      "Epoch: 10, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.36401084065437317\n",
      "LC Training Loss (Full): 0.24643002450466156\n",
      "Epoch: 10, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_42\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.3357541561126709\n",
      "LC Training Loss (Full): 0.21380263566970825\n",
      "Epoch: 10, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_43\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_43/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5717505812644958\n",
      "LC Training Loss (Full): 0.4171956777572632\n",
      "model accuracy: 0.932\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.901\n",
      "model accuracy: 0.932\n",
      "Full accuracy: 0.932, LC accuracy: 0.932, Decomposed-Full accuracy: 0.902, Decomposed-Restored accuracy: 0.901\n",
      "Epoch: 10, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_43\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.48835429549217224\n",
      "LC Training Loss (Full): 0.39687612652778625\n",
      "Epoch: 11, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5437757968902588\n",
      "LC Training Loss (Full): 0.39848145842552185\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.90625\n",
      "Epoch: 11, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.4518708288669586\n",
      "LC Training Loss (Full): 0.33620285987854004\n",
      "Epoch: 11, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7750800251960754\n",
      "LC Training Loss (Full): 0.6547605991363525\n",
      "Epoch: 11, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5586001873016357\n",
      "LC Training Loss (Full): 0.39603152871131897\n",
      "Epoch: 11, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.6459818482398987\n",
      "LC Training Loss (Full): 0.4684690237045288\n",
      "Epoch: 11, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.3962886929512024\n",
      "LC Training Loss (Full): 0.26765573024749756\n",
      "model accuracy: 0.933\n",
      "model accuracy: 0.9\n",
      "model accuracy: 0.9\n",
      "model accuracy: 0.934\n",
      "Full accuracy: 0.933, LC accuracy: 0.934, Decomposed-Full accuracy: 0.9, Decomposed-Restored accuracy: 0.9\n",
      "Epoch: 11, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.3699660003185272\n",
      "LC Training Loss (Full): 0.23035643994808197\n",
      "Epoch: 11, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.4803447425365448\n",
      "LC Training Loss (Full): 0.32470250129699707\n",
      "Epoch: 11, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5306065082550049\n",
      "LC Training Loss (Full): 0.39690274000167847\n",
      "Epoch: 11, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_44\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5300888419151306\n",
      "LC Training Loss (Full): 0.38188081979751587\n",
      "Epoch: 11, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5365949869155884\n",
      "LC Training Loss (Full): 0.3948880732059479\n",
      "model accuracy: 0.936\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.901\n",
      "model accuracy: 0.933\n",
      "Full accuracy: 0.936, LC accuracy: 0.933, Decomposed-Full accuracy: 0.903, Decomposed-Restored accuracy: 0.901\n",
      "Epoch: 11, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.49135881662368774\n",
      "LC Training Loss (Full): 0.35115519165992737\n",
      "Epoch: 11, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7027701139450073\n",
      "LC Training Loss (Full): 0.5394139289855957\n",
      "Epoch: 11, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6315521597862244\n",
      "LC Training Loss (Full): 0.44663771986961365\n",
      "Epoch: 11, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5830673575401306\n",
      "LC Training Loss (Full): 0.4353923499584198\n",
      "Epoch: 11, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.4189862310886383\n",
      "LC Training Loss (Full): 0.27997279167175293\n",
      "model accuracy: 0.934\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.936\n",
      "Full accuracy: 0.934, LC accuracy: 0.936, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.903\n",
      "Epoch: 11, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6626520752906799\n",
      "LC Training Loss (Full): 0.4909537732601166\n",
      "Epoch: 11, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5922297239303589\n",
      "LC Training Loss (Full): 0.4080374836921692\n",
      "Epoch: 11, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7624302506446838\n",
      "LC Training Loss (Full): 0.5963929891586304\n",
      "Epoch: 11, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_45\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5232645273208618\n",
      "LC Training Loss (Full): 0.3343224823474884\n",
      "Epoch: 11, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7805290222167969\n",
      "LC Training Loss (Full): 0.5726958513259888\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.935\n",
      "model accuracy: 0.905\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.937\n",
      "Full accuracy: 0.935, LC accuracy: 0.937, Decomposed-Full accuracy: 0.905, Decomposed-Restored accuracy: 0.906\n",
      "Epoch: 11, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.42009541392326355\n",
      "LC Training Loss (Full): 0.29201921820640564\n",
      "Epoch: 11, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.4084901809692383\n",
      "LC Training Loss (Full): 0.27294015884399414\n",
      "Epoch: 11, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.4076027572154999\n",
      "LC Training Loss (Full): 0.26955467462539673\n",
      "Epoch: 11, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6119790077209473\n",
      "LC Training Loss (Full): 0.47998958826065063\n",
      "Epoch: 11, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.47225600481033325\n",
      "LC Training Loss (Full): 0.33266139030456543\n",
      "model accuracy: 0.937\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.936\n",
      "Full accuracy: 0.937, LC accuracy: 0.936, Decomposed-Full accuracy: 0.903, Decomposed-Restored accuracy: 0.903\n",
      "Epoch: 11, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5736105442047119\n",
      "LC Training Loss (Full): 0.41233646869659424\n",
      "Epoch: 11, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.49032846093177795\n",
      "LC Training Loss (Full): 0.367937833070755\n",
      "Epoch: 11, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.35339465737342834\n",
      "LC Training Loss (Full): 0.23181341588497162\n",
      "Epoch: 11, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_46\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.3245846629142761\n",
      "LC Training Loss (Full): 0.19888544082641602\n",
      "Epoch: 11, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_47\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_47/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5587294101715088\n",
      "LC Training Loss (Full): 0.3963247835636139\n",
      "model accuracy: 0.935\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.936\n",
      "Full accuracy: 0.935, LC accuracy: 0.936, Decomposed-Full accuracy: 0.903, Decomposed-Restored accuracy: 0.902\n",
      "Epoch: 11, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_47\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.4829620122909546\n",
      "LC Training Loss (Full): 0.3869772255420685\n",
      "Epoch: 12, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5324903726577759\n",
      "LC Training Loss (Full): 0.38186100125312805\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.9375\n",
      "Epoch: 12, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.4430547058582306\n",
      "LC Training Loss (Full): 0.3224317133426666\n",
      "Epoch: 12, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.7658575773239136\n",
      "LC Training Loss (Full): 0.6405236124992371\n",
      "Epoch: 12, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.5465222597122192\n",
      "LC Training Loss (Full): 0.3768892288208008\n",
      "Epoch: 12, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.6282843351364136\n",
      "LC Training Loss (Full): 0.4451117217540741\n",
      "Epoch: 12, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.3848518431186676\n",
      "LC Training Loss (Full): 0.2533347010612488\n",
      "model accuracy: 0.936\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.937\n",
      "Full accuracy: 0.936, LC accuracy: 0.937, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 12, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.3585074841976166\n",
      "LC Training Loss (Full): 0.21575169265270233\n",
      "Epoch: 12, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.46679240465164185\n",
      "LC Training Loss (Full): 0.30711039900779724\n",
      "Epoch: 12, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.5175657868385315\n",
      "LC Training Loss (Full): 0.3789708912372589\n",
      "Epoch: 12, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_48\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_48\n",
      "LoRA+LC Training Loss (Decomposed): 0.5175582766532898\n",
      "LC Training Loss (Full): 0.3639466464519501\n",
      "Epoch: 12, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5201391577720642\n",
      "LC Training Loss (Full): 0.37446001172065735\n",
      "model accuracy: 0.939\n",
      "model accuracy: 0.905\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.936\n",
      "Full accuracy: 0.939, LC accuracy: 0.936, Decomposed-Full accuracy: 0.905, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 12, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.47770753502845764\n",
      "LC Training Loss (Full): 0.3322943150997162\n",
      "Epoch: 12, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.6896055936813354\n",
      "LC Training Loss (Full): 0.5174061059951782\n",
      "Epoch: 12, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.6189242005348206\n",
      "LC Training Loss (Full): 0.42407163977622986\n",
      "Epoch: 12, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.5701814889907837\n",
      "LC Training Loss (Full): 0.4147471785545349\n",
      "Epoch: 12, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.4082798361778259\n",
      "LC Training Loss (Full): 0.26238545775413513\n",
      "model accuracy: 0.939\n",
      "model accuracy: 0.907\n",
      "model accuracy: 0.907\n",
      "model accuracy: 0.939\n",
      "Full accuracy: 0.939, LC accuracy: 0.939, Decomposed-Full accuracy: 0.907, Decomposed-Restored accuracy: 0.907\n",
      "Epoch: 12, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.6518038511276245\n",
      "LC Training Loss (Full): 0.47066500782966614\n",
      "Epoch: 12, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.5788670778274536\n",
      "LC Training Loss (Full): 0.38608917593955994\n",
      "Epoch: 12, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.7540242671966553\n",
      "LC Training Loss (Full): 0.5771826505661011\n",
      "Epoch: 12, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_49\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_49\n",
      "LoRA+LC Training Loss (Decomposed): 0.5094765424728394\n",
      "LC Training Loss (Full): 0.31299638748168945\n",
      "Epoch: 12, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7680723071098328\n",
      "LC Training Loss (Full): 0.5533580183982849\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.938\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.94\n",
      "Full accuracy: 0.938, LC accuracy: 0.94, Decomposed-Full accuracy: 0.908, Decomposed-Restored accuracy: 0.908\n",
      "Epoch: 12, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.40940913558006287\n",
      "LC Training Loss (Full): 0.2778223156929016\n",
      "Epoch: 12, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.3955380320549011\n",
      "LC Training Loss (Full): 0.25816550850868225\n",
      "Epoch: 12, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.3948044180870056\n",
      "LC Training Loss (Full): 0.2539937198162079\n",
      "Epoch: 12, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.5996946096420288\n",
      "LC Training Loss (Full): 0.4654046297073364\n",
      "Epoch: 12, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.459500789642334\n",
      "LC Training Loss (Full): 0.31534773111343384\n",
      "model accuracy: 0.94\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.937\n",
      "Full accuracy: 0.94, LC accuracy: 0.937, Decomposed-Full accuracy: 0.906, Decomposed-Restored accuracy: 0.906\n",
      "Epoch: 12, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.5614949464797974\n",
      "LC Training Loss (Full): 0.3952561914920807\n",
      "Epoch: 12, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.47944512963294983\n",
      "LC Training Loss (Full): 0.3548738360404968\n",
      "Epoch: 12, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.34340986609458923\n",
      "LC Training Loss (Full): 0.2185056060552597\n",
      "Epoch: 12, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_50\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_50\n",
      "LoRA+LC Training Loss (Decomposed): 0.31342607736587524\n",
      "LC Training Loss (Full): 0.18535347282886505\n",
      "Epoch: 12, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_51\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_51/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5462608933448792\n",
      "LC Training Loss (Full): 0.376836895942688\n",
      "model accuracy: 0.938\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.905\n",
      "model accuracy: 0.938\n",
      "Full accuracy: 0.938, LC accuracy: 0.938, Decomposed-Full accuracy: 0.908, Decomposed-Restored accuracy: 0.905\n",
      "Epoch: 12, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_51\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_51\n",
      "LoRA+LC Training Loss (Decomposed): 0.47450393438339233\n",
      "LC Training Loss (Full): 0.3777732253074646\n",
      "Epoch: 13, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5209870934486389\n",
      "LC Training Loss (Full): 0.36637115478515625\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.9375\n",
      "Epoch: 13, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.4339151680469513\n",
      "LC Training Loss (Full): 0.3096187114715576\n",
      "Epoch: 13, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.7592692971229553\n",
      "LC Training Loss (Full): 0.6272210478782654\n",
      "Epoch: 13, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.533200740814209\n",
      "LC Training Loss (Full): 0.3591139018535614\n",
      "Epoch: 13, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.6129356622695923\n",
      "LC Training Loss (Full): 0.4236552119255066\n",
      "Epoch: 13, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.37384599447250366\n",
      "LC Training Loss (Full): 0.24031893908977509\n",
      "model accuracy: 0.94\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.94\n",
      "Full accuracy: 0.94, LC accuracy: 0.94, Decomposed-Full accuracy: 0.906, Decomposed-Restored accuracy: 0.906\n",
      "Epoch: 13, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.3463132083415985\n",
      "LC Training Loss (Full): 0.20248819887638092\n",
      "Epoch: 13, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.45553216338157654\n",
      "LC Training Loss (Full): 0.29094749689102173\n",
      "Epoch: 13, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.5049157738685608\n",
      "LC Training Loss (Full): 0.36244791746139526\n",
      "Epoch: 13, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_52\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_52\n",
      "LoRA+LC Training Loss (Decomposed): 0.5047948956489563\n",
      "LC Training Loss (Full): 0.34750813245773315\n",
      "Epoch: 13, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5068849325180054\n",
      "LC Training Loss (Full): 0.3557807505130768\n",
      "model accuracy: 0.943\n",
      "model accuracy: 0.907\n",
      "model accuracy: 0.905\n",
      "model accuracy: 0.94\n",
      "Full accuracy: 0.943, LC accuracy: 0.94, Decomposed-Full accuracy: 0.907, Decomposed-Restored accuracy: 0.905\n",
      "Epoch: 13, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.46541622281074524\n",
      "LC Training Loss (Full): 0.31483012437820435\n",
      "Epoch: 13, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.6766131520271301\n",
      "LC Training Loss (Full): 0.49681007862091064\n",
      "Epoch: 13, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.6071230173110962\n",
      "LC Training Loss (Full): 0.4027816951274872\n",
      "Epoch: 13, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.5575286746025085\n",
      "LC Training Loss (Full): 0.3953816294670105\n",
      "Epoch: 13, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.3982903063297272\n",
      "LC Training Loss (Full): 0.24605178833007812\n",
      "model accuracy: 0.943\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.942\n",
      "Full accuracy: 0.943, LC accuracy: 0.942, Decomposed-Full accuracy: 0.908, Decomposed-Restored accuracy: 0.908\n",
      "Epoch: 13, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.6428578495979309\n",
      "LC Training Loss (Full): 0.4515712559223175\n",
      "Epoch: 13, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.5648849010467529\n",
      "LC Training Loss (Full): 0.3657126724720001\n",
      "Epoch: 13, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.744480311870575\n",
      "LC Training Loss (Full): 0.5585965514183044\n",
      "Epoch: 13, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_53\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_53\n",
      "LoRA+LC Training Loss (Decomposed): 0.49500831961631775\n",
      "LC Training Loss (Full): 0.2932716906070709\n",
      "Epoch: 13, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7539002895355225\n",
      "LC Training Loss (Full): 0.5353450179100037\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.942\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.942\n",
      "Full accuracy: 0.942, LC accuracy: 0.942, Decomposed-Full accuracy: 0.908, Decomposed-Restored accuracy: 0.908\n",
      "Epoch: 13, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.39998558163642883\n",
      "LC Training Loss (Full): 0.26467353105545044\n",
      "Epoch: 13, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.38240036368370056\n",
      "LC Training Loss (Full): 0.24468697607517242\n",
      "Epoch: 13, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.3823746144771576\n",
      "LC Training Loss (Full): 0.23981726169586182\n",
      "Epoch: 13, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.5892473459243774\n",
      "LC Training Loss (Full): 0.45201411843299866\n",
      "Epoch: 13, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.4455798268318176\n",
      "LC Training Loss (Full): 0.29965469241142273\n",
      "model accuracy: 0.943\n",
      "model accuracy: 0.907\n",
      "model accuracy: 0.907\n",
      "model accuracy: 0.943\n",
      "Full accuracy: 0.943, LC accuracy: 0.943, Decomposed-Full accuracy: 0.907, Decomposed-Restored accuracy: 0.907\n",
      "Epoch: 13, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.5485478639602661\n",
      "LC Training Loss (Full): 0.3797655701637268\n",
      "Epoch: 13, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.4685472548007965\n",
      "LC Training Loss (Full): 0.34318628907203674\n",
      "Epoch: 13, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.3346409499645233\n",
      "LC Training Loss (Full): 0.2063603699207306\n",
      "Epoch: 13, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_54\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_54\n",
      "LoRA+LC Training Loss (Decomposed): 0.3029470145702362\n",
      "LC Training Loss (Full): 0.1730484962463379\n",
      "Epoch: 13, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_55\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_55/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.533980667591095\n",
      "LC Training Loss (Full): 0.3586224913597107\n",
      "model accuracy: 0.945\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.944\n",
      "Full accuracy: 0.945, LC accuracy: 0.944, Decomposed-Full accuracy: 0.909, Decomposed-Restored accuracy: 0.909\n",
      "Epoch: 13, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_55\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_55\n",
      "LoRA+LC Training Loss (Decomposed): 0.46885836124420166\n",
      "LC Training Loss (Full): 0.36915916204452515\n",
      "Epoch: 14, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5094274282455444\n",
      "LC Training Loss (Full): 0.3518945872783661\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Epoch: 14, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.4247906804084778\n",
      "LC Training Loss (Full): 0.29767322540283203\n",
      "Epoch: 14, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.7514264583587646\n",
      "LC Training Loss (Full): 0.6147444248199463\n",
      "Epoch: 14, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.5213505029678345\n",
      "LC Training Loss (Full): 0.3425925672054291\n",
      "Epoch: 14, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.5975574851036072\n",
      "LC Training Loss (Full): 0.40390411019325256\n",
      "Epoch: 14, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.36404749751091003\n",
      "LC Training Loss (Full): 0.22843365371227264\n",
      "model accuracy: 0.944\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.945\n",
      "Full accuracy: 0.944, LC accuracy: 0.945, Decomposed-Full accuracy: 0.908, Decomposed-Restored accuracy: 0.908\n",
      "Epoch: 14, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.33634573221206665\n",
      "LC Training Loss (Full): 0.19039279222488403\n",
      "Epoch: 14, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.44561275839805603\n",
      "LC Training Loss (Full): 0.2760551869869232\n",
      "Epoch: 14, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.49333032965660095\n",
      "LC Training Loss (Full): 0.3471948802471161\n",
      "Epoch: 14, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_56\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_56\n",
      "LoRA+LC Training Loss (Decomposed): 0.4921574294567108\n",
      "LC Training Loss (Full): 0.3324097990989685\n",
      "Epoch: 14, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4932541251182556\n",
      "LC Training Loss (Full): 0.33868151903152466\n",
      "model accuracy: 0.944\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.944\n",
      "Full accuracy: 0.944, LC accuracy: 0.944, Decomposed-Full accuracy: 0.909, Decomposed-Restored accuracy: 0.909\n",
      "Epoch: 14, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.45237600803375244\n",
      "LC Training Loss (Full): 0.29863178730010986\n",
      "Epoch: 14, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.664345383644104\n",
      "LC Training Loss (Full): 0.4775106906890869\n",
      "Epoch: 14, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.5960830450057983\n",
      "LC Training Loss (Full): 0.38270601630210876\n",
      "Epoch: 14, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.5460391044616699\n",
      "LC Training Loss (Full): 0.3772219121456146\n",
      "Epoch: 14, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.38843217492103577\n",
      "LC Training Loss (Full): 0.2309129238128662\n",
      "model accuracy: 0.943\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.944\n",
      "Full accuracy: 0.943, LC accuracy: 0.944, Decomposed-Full accuracy: 0.909, Decomposed-Restored accuracy: 0.909\n",
      "Epoch: 14, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.6317890286445618\n",
      "LC Training Loss (Full): 0.4335813522338867\n",
      "Epoch: 14, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.5527886748313904\n",
      "LC Training Loss (Full): 0.3468187153339386\n",
      "Epoch: 14, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.7365322709083557\n",
      "LC Training Loss (Full): 0.5406222343444824\n",
      "Epoch: 14, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_57\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_57\n",
      "LoRA+LC Training Loss (Decomposed): 0.48134177923202515\n",
      "LC Training Loss (Full): 0.2750437259674072\n",
      "Epoch: 14, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7406101226806641\n",
      "LC Training Loss (Full): 0.518550455570221\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.946\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.944\n",
      "Full accuracy: 0.946, LC accuracy: 0.944, Decomposed-Full accuracy: 0.909, Decomposed-Restored accuracy: 0.909\n",
      "Epoch: 14, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.39071276783943176\n",
      "LC Training Loss (Full): 0.25245746970176697\n",
      "Epoch: 14, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.3716851770877838\n",
      "LC Training Loss (Full): 0.23233692348003387\n",
      "Epoch: 14, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.37217292189598083\n",
      "LC Training Loss (Full): 0.2268667072057724\n",
      "Epoch: 14, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.580237090587616\n",
      "LC Training Loss (Full): 0.4396669864654541\n",
      "Epoch: 14, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.43349283933639526\n",
      "LC Training Loss (Full): 0.2853914201259613\n",
      "model accuracy: 0.947\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.946\n",
      "Full accuracy: 0.947, LC accuracy: 0.946, Decomposed-Full accuracy: 0.908, Decomposed-Restored accuracy: 0.908\n",
      "Epoch: 14, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.5377331972122192\n",
      "LC Training Loss (Full): 0.36567407846450806\n",
      "Epoch: 14, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.45947104692459106\n",
      "LC Training Loss (Full): 0.3327059745788574\n",
      "Epoch: 14, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.32463133335113525\n",
      "LC Training Loss (Full): 0.19525016844272614\n",
      "Epoch: 14, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_58\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_58\n",
      "LoRA+LC Training Loss (Decomposed): 0.2932285964488983\n",
      "LC Training Loss (Full): 0.16183356940746307\n",
      "Epoch: 14, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_59\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_59/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5224425792694092\n",
      "LC Training Loss (Full): 0.3415833115577698\n",
      "model accuracy: 0.947\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.946\n",
      "Full accuracy: 0.947, LC accuracy: 0.946, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 14, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_59\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_59\n",
      "LoRA+LC Training Loss (Decomposed): 0.4625910222530365\n",
      "LC Training Loss (Full): 0.3610480725765228\n",
      "Epoch: 15, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.49884265661239624\n",
      "LC Training Loss (Full): 0.3383307158946991\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Epoch: 15, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.4162510931491852\n",
      "LC Training Loss (Full): 0.2865162193775177\n",
      "Epoch: 15, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.7447985410690308\n",
      "LC Training Loss (Full): 0.6030005812644958\n",
      "Epoch: 15, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.5103306770324707\n",
      "LC Training Loss (Full): 0.3272227644920349\n",
      "Epoch: 15, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.583547055721283\n",
      "LC Training Loss (Full): 0.3856826424598694\n",
      "Epoch: 15, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.3544839322566986\n",
      "LC Training Loss (Full): 0.21753373742103577\n",
      "model accuracy: 0.947\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.947\n",
      "Full accuracy: 0.947, LC accuracy: 0.947, Decomposed-Full accuracy: 0.909, Decomposed-Restored accuracy: 0.909\n",
      "Epoch: 15, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.3260286748409271\n",
      "LC Training Loss (Full): 0.17931967973709106\n",
      "Epoch: 15, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.43536582589149475\n",
      "LC Training Loss (Full): 0.262298583984375\n",
      "Epoch: 15, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.4824923574924469\n",
      "LC Training Loss (Full): 0.33308833837509155\n",
      "Epoch: 15, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_60\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_60\n",
      "LoRA+LC Training Loss (Decomposed): 0.4809110760688782\n",
      "LC Training Loss (Full): 0.31851089000701904\n",
      "Epoch: 15, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48127853870391846\n",
      "LC Training Loss (Full): 0.32300516963005066\n",
      "model accuracy: 0.946\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.947\n",
      "Full accuracy: 0.946, LC accuracy: 0.947, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 15, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.4407418370246887\n",
      "LC Training Loss (Full): 0.2835850715637207\n",
      "Epoch: 15, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.6524438261985779\n",
      "LC Training Loss (Full): 0.4594041407108307\n",
      "Epoch: 15, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.5854482054710388\n",
      "LC Training Loss (Full): 0.36378881335258484\n",
      "Epoch: 15, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.534566342830658\n",
      "LC Training Loss (Full): 0.3601972758769989\n",
      "Epoch: 15, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.37973344326019287\n",
      "LC Training Loss (Full): 0.21690472960472107\n",
      "model accuracy: 0.943\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.945\n",
      "Full accuracy: 0.943, LC accuracy: 0.945, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 15, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.6231349110603333\n",
      "LC Training Loss (Full): 0.4166078269481659\n",
      "Epoch: 15, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.5410634875297546\n",
      "LC Training Loss (Full): 0.3293142318725586\n",
      "Epoch: 15, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.7279264330863953\n",
      "LC Training Loss (Full): 0.5232502818107605\n",
      "Epoch: 15, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_61\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_61\n",
      "LoRA+LC Training Loss (Decomposed): 0.46905598044395447\n",
      "LC Training Loss (Full): 0.25821125507354736\n",
      "Epoch: 15, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.728117048740387\n",
      "LC Training Loss (Full): 0.5028777718544006\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.95\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.909\n",
      "model accuracy: 0.948\n",
      "Full accuracy: 0.95, LC accuracy: 0.948, Decomposed-Full accuracy: 0.909, Decomposed-Restored accuracy: 0.909\n",
      "Epoch: 15, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.38185063004493713\n",
      "LC Training Loss (Full): 0.24107614159584045\n",
      "Epoch: 15, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.3613724708557129\n",
      "LC Training Loss (Full): 0.22097353637218475\n",
      "Epoch: 15, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.3613487780094147\n",
      "LC Training Loss (Full): 0.2150043100118637\n",
      "Epoch: 15, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.5722538828849792\n",
      "LC Training Loss (Full): 0.4282318949699402\n",
      "Epoch: 15, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.42165130376815796\n",
      "LC Training Loss (Full): 0.2723875939846039\n",
      "model accuracy: 0.949\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.949\n",
      "Full accuracy: 0.949, LC accuracy: 0.949, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.911\n",
      "Epoch: 15, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.5265616178512573\n",
      "LC Training Loss (Full): 0.352813184261322\n",
      "Epoch: 15, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.449747234582901\n",
      "LC Training Loss (Full): 0.32327917218208313\n",
      "Epoch: 15, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.3169395327568054\n",
      "LC Training Loss (Full): 0.18506412208080292\n",
      "Epoch: 15, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_62\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_62\n",
      "LoRA+LC Training Loss (Decomposed): 0.2838749885559082\n",
      "LC Training Loss (Full): 0.15158993005752563\n",
      "Epoch: 15, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_63\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_63/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5107269287109375\n",
      "LC Training Loss (Full): 0.32563039660453796\n",
      "model accuracy: 0.951\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.949\n",
      "Full accuracy: 0.951, LC accuracy: 0.949, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 15, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_63\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_63\n",
      "LoRA+LC Training Loss (Decomposed): 0.4561186730861664\n",
      "LC Training Loss (Full): 0.3533676564693451\n",
      "Epoch: 16, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48899784684181213\n",
      "LC Training Loss (Full): 0.3255932629108429\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Epoch: 16, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.4085877537727356\n",
      "LC Training Loss (Full): 0.2760785222053528\n",
      "Epoch: 16, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.737586259841919\n",
      "LC Training Loss (Full): 0.5919079184532166\n",
      "Epoch: 16, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.5000902414321899\n",
      "LC Training Loss (Full): 0.3129109740257263\n",
      "Epoch: 16, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.5700059533119202\n",
      "LC Training Loss (Full): 0.3688340187072754\n",
      "Epoch: 16, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.3461744785308838\n",
      "LC Training Loss (Full): 0.20749889314174652\n",
      "model accuracy: 0.949\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.949\n",
      "Full accuracy: 0.949, LC accuracy: 0.949, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 16, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.317335307598114\n",
      "LC Training Loss (Full): 0.1691458821296692\n",
      "Epoch: 16, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.42662420868873596\n",
      "LC Training Loss (Full): 0.24956229329109192\n",
      "Epoch: 16, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.47241517901420593\n",
      "LC Training Loss (Full): 0.32001787424087524\n",
      "Epoch: 16, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_64\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_64\n",
      "LoRA+LC Training Loss (Decomposed): 0.46887630224227905\n",
      "LC Training Loss (Full): 0.3056848347187042\n",
      "Epoch: 16, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.46923795342445374\n",
      "LC Training Loss (Full): 0.3086078464984894\n",
      "model accuracy: 0.948\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.949\n",
      "Full accuracy: 0.948, LC accuracy: 0.949, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 16, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.42954158782958984\n",
      "LC Training Loss (Full): 0.2695900797843933\n",
      "Epoch: 16, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.641465961933136\n",
      "LC Training Loss (Full): 0.44239747524261475\n",
      "Epoch: 16, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.5753430128097534\n",
      "LC Training Loss (Full): 0.3459787368774414\n",
      "Epoch: 16, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.5236002206802368\n",
      "LC Training Loss (Full): 0.3442401587963104\n",
      "Epoch: 16, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.3704479932785034\n",
      "LC Training Loss (Full): 0.20395927131175995\n",
      "model accuracy: 0.949\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.949\n",
      "Full accuracy: 0.949, LC accuracy: 0.949, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 16, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.613196611404419\n",
      "LC Training Loss (Full): 0.4005689322948456\n",
      "Epoch: 16, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.529021680355072\n",
      "LC Training Loss (Full): 0.31310445070266724\n",
      "Epoch: 16, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.7194024920463562\n",
      "LC Training Loss (Full): 0.5064737796783447\n",
      "Epoch: 16, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_65\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_65\n",
      "LoRA+LC Training Loss (Decomposed): 0.4587666690349579\n",
      "LC Training Loss (Full): 0.2426762580871582\n",
      "Epoch: 16, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7171059250831604\n",
      "LC Training Loss (Full): 0.4882391095161438\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.95\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.951\n",
      "Full accuracy: 0.95, LC accuracy: 0.951, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 16, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.3734467625617981\n",
      "LC Training Loss (Full): 0.23044626414775848\n",
      "Epoch: 16, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.3516328036785126\n",
      "LC Training Loss (Full): 0.21047675609588623\n",
      "Epoch: 16, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.35138097405433655\n",
      "LC Training Loss (Full): 0.20411060750484467\n",
      "Epoch: 16, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.5620562434196472\n",
      "LC Training Loss (Full): 0.4175950884819031\n",
      "Epoch: 16, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.4111376404762268\n",
      "LC Training Loss (Full): 0.2604934871196747\n",
      "model accuracy: 0.954\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.952\n",
      "Full accuracy: 0.954, LC accuracy: 0.952, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.91\n",
      "Epoch: 16, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.516786515712738\n",
      "LC Training Loss (Full): 0.34103628993034363\n",
      "Epoch: 16, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.4411082863807678\n",
      "LC Training Loss (Full): 0.31476813554763794\n",
      "Epoch: 16, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.3085956573486328\n",
      "LC Training Loss (Full): 0.17570576071739197\n",
      "Epoch: 16, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_66\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_66\n",
      "LoRA+LC Training Loss (Decomposed): 0.2753251791000366\n",
      "LC Training Loss (Full): 0.1422148495912552\n",
      "Epoch: 16, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_67\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_67/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4996621608734131\n",
      "LC Training Loss (Full): 0.31068286299705505\n",
      "model accuracy: 0.952\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.952\n",
      "Full accuracy: 0.952, LC accuracy: 0.952, Decomposed-Full accuracy: 0.91, Decomposed-Restored accuracy: 0.911\n",
      "Epoch: 16, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_67\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_67\n",
      "LoRA+LC Training Loss (Decomposed): 0.45221251249313354\n",
      "LC Training Loss (Full): 0.34605690836906433\n",
      "Epoch: 17, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48029929399490356\n",
      "LC Training Loss (Full): 0.3136073350906372\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Epoch: 17, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.4011482000350952\n",
      "LC Training Loss (Full): 0.2662990987300873\n",
      "Epoch: 17, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.7320690155029297\n",
      "LC Training Loss (Full): 0.5813959240913391\n",
      "Epoch: 17, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.4899483025074005\n",
      "LC Training Loss (Full): 0.299572229385376\n",
      "Epoch: 17, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.5567862391471863\n",
      "LC Training Loss (Full): 0.35321950912475586\n",
      "Epoch: 17, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.33676743507385254\n",
      "LC Training Loss (Full): 0.19822944700717926\n",
      "model accuracy: 0.95\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.95\n",
      "Full accuracy: 0.95, LC accuracy: 0.95, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.911\n",
      "Epoch: 17, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.3079136312007904\n",
      "LC Training Loss (Full): 0.15976859629154205\n",
      "Epoch: 17, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.41745901107788086\n",
      "LC Training Loss (Full): 0.23774699866771698\n",
      "Epoch: 17, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.46278050541877747\n",
      "LC Training Loss (Full): 0.30788499116897583\n",
      "Epoch: 17, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_68\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_68\n",
      "LoRA+LC Training Loss (Decomposed): 0.4591820538043976\n",
      "LC Training Loss (Full): 0.2938186526298523\n",
      "Epoch: 17, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4586658775806427\n",
      "LC Training Loss (Full): 0.29535916447639465\n",
      "model accuracy: 0.951\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.951\n",
      "Full accuracy: 0.951, LC accuracy: 0.951, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.911\n",
      "Epoch: 17, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.41837766766548157\n",
      "LC Training Loss (Full): 0.2565590441226959\n",
      "Epoch: 17, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.6301360726356506\n",
      "LC Training Loss (Full): 0.42640751600265503\n",
      "Epoch: 17, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.5654012560844421\n",
      "LC Training Loss (Full): 0.3292272984981537\n",
      "Epoch: 17, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.5126954913139343\n",
      "LC Training Loss (Full): 0.3292866051197052\n",
      "Epoch: 17, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.36182406544685364\n",
      "LC Training Loss (Full): 0.19200600683689117\n",
      "model accuracy: 0.952\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.951\n",
      "Full accuracy: 0.952, LC accuracy: 0.951, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.911\n",
      "Epoch: 17, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.6030541062355042\n",
      "LC Training Loss (Full): 0.3853897154331207\n",
      "Epoch: 17, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.518334686756134\n",
      "LC Training Loss (Full): 0.29809626936912537\n",
      "Epoch: 17, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.711936891078949\n",
      "LC Training Loss (Full): 0.49028661847114563\n",
      "Epoch: 17, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_69\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_69\n",
      "LoRA+LC Training Loss (Decomposed): 0.4473695755004883\n",
      "LC Training Loss (Full): 0.22834384441375732\n",
      "Epoch: 17, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7074150443077087\n",
      "LC Training Loss (Full): 0.4745537340641022\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.956\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.955\n",
      "Full accuracy: 0.956, LC accuracy: 0.955, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.911\n",
      "Epoch: 17, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.36492928862571716\n",
      "LC Training Loss (Full): 0.22049684822559357\n",
      "Epoch: 17, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.3418771028518677\n",
      "LC Training Loss (Full): 0.20074492692947388\n",
      "Epoch: 17, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.34166833758354187\n",
      "LC Training Loss (Full): 0.194082573056221\n",
      "Epoch: 17, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.5534400939941406\n",
      "LC Training Loss (Full): 0.4076592028141022\n",
      "Epoch: 17, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.4013570249080658\n",
      "LC Training Loss (Full): 0.24957776069641113\n",
      "model accuracy: 0.957\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.957\n",
      "Full accuracy: 0.957, LC accuracy: 0.957, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.911\n",
      "Epoch: 17, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.5075694918632507\n",
      "LC Training Loss (Full): 0.3302164077758789\n",
      "Epoch: 17, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.43296000361442566\n",
      "LC Training Loss (Full): 0.30705100297927856\n",
      "Epoch: 17, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.3014662563800812\n",
      "LC Training Loss (Full): 0.1670910269021988\n",
      "Epoch: 17, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_70\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_70\n",
      "LoRA+LC Training Loss (Decomposed): 0.2675318717956543\n",
      "LC Training Loss (Full): 0.13361890614032745\n",
      "Epoch: 17, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_71\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_71/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4897565245628357\n",
      "LC Training Loss (Full): 0.29666668176651\n",
      "model accuracy: 0.956\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.956\n",
      "Full accuracy: 0.956, LC accuracy: 0.956, Decomposed-Full accuracy: 0.912, Decomposed-Restored accuracy: 0.912\n",
      "Epoch: 17, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_71\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_71\n",
      "LoRA+LC Training Loss (Decomposed): 0.44757938385009766\n",
      "LC Training Loss (Full): 0.33906447887420654\n",
      "Epoch: 18, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4709721803665161\n",
      "LC Training Loss (Full): 0.30230793356895447\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Epoch: 18, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.39406779408454895\n",
      "LC Training Loss (Full): 0.25712355971336365\n",
      "Epoch: 18, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.7266325950622559\n",
      "LC Training Loss (Full): 0.5714019536972046\n",
      "Epoch: 18, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.479285329580307\n",
      "LC Training Loss (Full): 0.2871287763118744\n",
      "Epoch: 18, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.5446719527244568\n",
      "LC Training Loss (Full): 0.338716596364975\n",
      "Epoch: 18, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.32900673151016235\n",
      "LC Training Loss (Full): 0.189642533659935\n",
      "model accuracy: 0.954\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.953\n",
      "Full accuracy: 0.954, LC accuracy: 0.953, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.912\n",
      "Epoch: 18, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.2999271750450134\n",
      "LC Training Loss (Full): 0.15110118687152863\n",
      "Epoch: 18, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.4080182909965515\n",
      "LC Training Loss (Full): 0.22676673531532288\n",
      "Epoch: 18, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.45293697714805603\n",
      "LC Training Loss (Full): 0.29660162329673767\n",
      "Epoch: 18, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_72\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_72\n",
      "LoRA+LC Training Loss (Decomposed): 0.44901010394096375\n",
      "LC Training Loss (Full): 0.2828116714954376\n",
      "Epoch: 18, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.44763267040252686\n",
      "LC Training Loss (Full): 0.2831423282623291\n",
      "model accuracy: 0.952\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.953\n",
      "Full accuracy: 0.952, LC accuracy: 0.953, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.912\n",
      "Epoch: 18, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.40813684463500977\n",
      "LC Training Loss (Full): 0.24441388249397278\n",
      "Epoch: 18, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.6191969513893127\n",
      "LC Training Loss (Full): 0.4113599956035614\n",
      "Epoch: 18, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.5554834604263306\n",
      "LC Training Loss (Full): 0.3134876489639282\n",
      "Epoch: 18, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.5025221109390259\n",
      "LC Training Loss (Full): 0.3152758777141571\n",
      "Epoch: 18, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.3526911437511444\n",
      "LC Training Loss (Full): 0.18097379803657532\n",
      "model accuracy: 0.957\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.954\n",
      "Full accuracy: 0.957, LC accuracy: 0.954, Decomposed-Full accuracy: 0.912, Decomposed-Restored accuracy: 0.912\n",
      "Epoch: 18, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.5933569073677063\n",
      "LC Training Loss (Full): 0.3710016906261444\n",
      "Epoch: 18, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.5076085925102234\n",
      "LC Training Loss (Full): 0.28419870138168335\n",
      "Epoch: 18, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.7051464319229126\n",
      "LC Training Loss (Full): 0.4746823310852051\n",
      "Epoch: 18, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_73\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_73\n",
      "LoRA+LC Training Loss (Decomposed): 0.4370712339878082\n",
      "LC Training Loss (Full): 0.2151227742433548\n",
      "Epoch: 18, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6978939175605774\n",
      "LC Training Loss (Full): 0.46174612641334534\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.957\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.958\n",
      "Full accuracy: 0.957, LC accuracy: 0.958, Decomposed-Full accuracy: 0.912, Decomposed-Restored accuracy: 0.913\n",
      "Epoch: 18, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.35667684674263\n",
      "LC Training Loss (Full): 0.21116702258586884\n",
      "Epoch: 18, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.33341532945632935\n",
      "LC Training Loss (Full): 0.19169186055660248\n",
      "Epoch: 18, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.3325708508491516\n",
      "LC Training Loss (Full): 0.18483039736747742\n",
      "Epoch: 18, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.5456818342208862\n",
      "LC Training Loss (Full): 0.3983404338359833\n",
      "Epoch: 18, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.39127910137176514\n",
      "LC Training Loss (Full): 0.2395264208316803\n",
      "model accuracy: 0.959\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.911\n",
      "model accuracy: 0.96\n",
      "Full accuracy: 0.959, LC accuracy: 0.96, Decomposed-Full accuracy: 0.911, Decomposed-Restored accuracy: 0.911\n",
      "Epoch: 18, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.4987017810344696\n",
      "LC Training Loss (Full): 0.32024404406547546\n",
      "Epoch: 18, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.42474767565727234\n",
      "LC Training Loss (Full): 0.30002060532569885\n",
      "Epoch: 18, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.29441407322883606\n",
      "LC Training Loss (Full): 0.15914636850357056\n",
      "Epoch: 18, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_74\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_74\n",
      "LoRA+LC Training Loss (Decomposed): 0.2597772181034088\n",
      "LC Training Loss (Full): 0.12572383880615234\n",
      "Epoch: 18, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_75\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_75/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48004838824272156\n",
      "LC Training Loss (Full): 0.283513605594635\n",
      "model accuracy: 0.958\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.959\n",
      "Full accuracy: 0.958, LC accuracy: 0.959, Decomposed-Full accuracy: 0.913, Decomposed-Restored accuracy: 0.913\n",
      "Epoch: 18, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_75\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_75\n",
      "LoRA+LC Training Loss (Decomposed): 0.44347718358039856\n",
      "LC Training Loss (Full): 0.3323459327220917\n",
      "Epoch: 19, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4631461203098297\n",
      "LC Training Loss (Full): 0.29163801670074463\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Epoch: 19, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.3881821632385254\n",
      "LC Training Loss (Full): 0.24850323796272278\n",
      "Epoch: 19, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.7194759845733643\n",
      "LC Training Loss (Full): 0.5618712306022644\n",
      "Epoch: 19, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.4705776274204254\n",
      "LC Training Loss (Full): 0.27550941705703735\n",
      "Epoch: 19, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.5330244302749634\n",
      "LC Training Loss (Full): 0.32521766424179077\n",
      "Epoch: 19, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.3217145502567291\n",
      "LC Training Loss (Full): 0.18166883289813995\n",
      "model accuracy: 0.956\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.957\n",
      "Full accuracy: 0.956, LC accuracy: 0.957, Decomposed-Full accuracy: 0.913, Decomposed-Restored accuracy: 0.913\n",
      "Epoch: 19, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.2923690974712372\n",
      "LC Training Loss (Full): 0.1430700272321701\n",
      "Epoch: 19, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.39847028255462646\n",
      "LC Training Loss (Full): 0.21654659509658813\n",
      "Epoch: 19, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.4436085820198059\n",
      "LC Training Loss (Full): 0.2860882580280304\n",
      "Epoch: 19, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_76\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_76\n",
      "LoRA+LC Training Loss (Decomposed): 0.43923014402389526\n",
      "LC Training Loss (Full): 0.2725749611854553\n",
      "Epoch: 19, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.43664881587028503\n",
      "LC Training Loss (Full): 0.27185341715812683\n",
      "model accuracy: 0.956\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.955\n",
      "Full accuracy: 0.956, LC accuracy: 0.955, Decomposed-Full accuracy: 0.913, Decomposed-Restored accuracy: 0.912\n",
      "Epoch: 19, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.3979856073856354\n",
      "LC Training Loss (Full): 0.23308491706848145\n",
      "Epoch: 19, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.6094039082527161\n",
      "LC Training Loss (Full): 0.3971880376338959\n",
      "Epoch: 19, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.5454148054122925\n",
      "LC Training Loss (Full): 0.29871413111686707\n",
      "Epoch: 19, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.4930172562599182\n",
      "LC Training Loss (Full): 0.3021506071090698\n",
      "Epoch: 19, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.3443763256072998\n",
      "LC Training Loss (Full): 0.1707925647497177\n",
      "model accuracy: 0.959\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.958\n",
      "Full accuracy: 0.959, LC accuracy: 0.958, Decomposed-Full accuracy: 0.912, Decomposed-Restored accuracy: 0.912\n",
      "Epoch: 19, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.5838374495506287\n",
      "LC Training Loss (Full): 0.3573436141014099\n",
      "Epoch: 19, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.4976117014884949\n",
      "LC Training Loss (Full): 0.27132493257522583\n",
      "Epoch: 19, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.698314905166626\n",
      "LC Training Loss (Full): 0.4596532881259918\n",
      "Epoch: 19, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_77\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_77\n",
      "LoRA+LC Training Loss (Decomposed): 0.4284631311893463\n",
      "LC Training Loss (Full): 0.20292621850967407\n",
      "Epoch: 19, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6895691752433777\n",
      "LC Training Loss (Full): 0.4497465193271637\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "model accuracy: 0.96\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.913\n",
      "model accuracy: 0.959\n",
      "Full accuracy: 0.96, LC accuracy: 0.959, Decomposed-Full accuracy: 0.913, Decomposed-Restored accuracy: 0.913\n",
      "Epoch: 19, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.3497251272201538\n",
      "LC Training Loss (Full): 0.2024044394493103\n",
      "Epoch: 19, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.3252335786819458\n",
      "LC Training Loss (Full): 0.18324436247348785\n",
      "Epoch: 19, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.32430341839790344\n",
      "LC Training Loss (Full): 0.17627617716789246\n",
      "Epoch: 19, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.5379476547241211\n",
      "LC Training Loss (Full): 0.38956719636917114\n",
      "Epoch: 19, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.3817369043827057\n",
      "LC Training Loss (Full): 0.23024071753025055\n",
      "model accuracy: 0.961\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.961\n",
      "Full accuracy: 0.961, LC accuracy: 0.961, Decomposed-Full accuracy: 0.912, Decomposed-Restored accuracy: 0.912\n",
      "Epoch: 19, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.48979395627975464\n",
      "LC Training Loss (Full): 0.3110252618789673\n",
      "Epoch: 19, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.4170229732990265\n",
      "LC Training Loss (Full): 0.2935837507247925\n",
      "Epoch: 19, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.28721919655799866\n",
      "LC Training Loss (Full): 0.15180689096450806\n",
      "Epoch: 19, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_78\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_78\n",
      "LoRA+LC Training Loss (Decomposed): 0.2522558867931366\n",
      "LC Training Loss (Full): 0.11846134811639786\n",
      "Epoch: 19, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_79\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_79/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4700830280780792\n",
      "LC Training Loss (Full): 0.2711607813835144\n",
      "model accuracy: 0.961\n",
      "model accuracy: 0.915\n",
      "model accuracy: 0.914\n",
      "model accuracy: 0.962\n",
      "Full accuracy: 0.961, LC accuracy: 0.962, Decomposed-Full accuracy: 0.915, Decomposed-Restored accuracy: 0.914\n",
      "Epoch: 19, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/set_79\n",
      "Compressing delta for old_lc\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/set_79\n",
      "LoRA+LC Training Loss (Decomposed): 0.43911507725715637\n",
      "LC Training Loss (Full): 0.325863778591156\n"
     ]
    }
   ],
   "source": [
    "delta_normal_max = []\n",
    "delta_normal_min = []\n",
    "delta_decomposed_max = []\n",
    "delta_decomposed_min = []\n",
    "full_accuracy = []\n",
    "decomposed_full_accuracy = []\n",
    "restored_accuracy = []\n",
    "lc_accuracy = []\n",
    "current_iter = 0\n",
    "current_set = 0\n",
    "\n",
    "current_iter_old_lc = 0\n",
    "current_set_old_lc = 0\n",
    "\n",
    "acc = lambda x, y : (torch.max(x, 1)[1] == y).sum().item() / y.size(0)\n",
    "\n",
    "for epch in range(20):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        print(\"Epoch: {}, Iteration: {}\".format(epch, i))\n",
    "        \n",
    "        set_path = \"/set_{}\".format(current_set)\n",
    "        if not os.path.exists(SAVE_LOC + set_path):\n",
    "            os.makedirs(SAVE_LOC + set_path)\n",
    "\n",
    "        if i == 0 and epch == 0: # first iteration, create baseline model\n",
    "            base, base_decomp = lc.extract_weights(model, SAVE_LOC + \n",
    "                                                       \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "        else:\n",
    "            if i % 10 == 0: \n",
    "                # full snapshot!\n",
    "                new_model = lazy_restore(base, base_decomp, bias, LeNet(), \n",
    "                                          original.state_dict(), DECOMPOSED_LAYERS, rank = RANK, scaling = SCALING)\n",
    "                original = new_model # Changing previous \"original model\" used to restore the loRA model.\n",
    "                \n",
    "                current_set += 1\n",
    "                current_iter = 0\n",
    "\n",
    "                set_path = \"/set_{}\".format(current_set)\n",
    "                if not os.path.exists(SAVE_LOC + set_path):\n",
    "                    os.makedirs(SAVE_LOC + set_path)\n",
    "                \n",
    "                # Rebuilding LoRA layers => reset model!\n",
    "                w, b = getBase(original)\n",
    "                model = LeNet_LowRank(w, b, rank = RANK)\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "                load_sd_decomp(original.state_dict(), model, DECOMPOSED_LAYERS)\n",
    "                base, base_decomp = lc.extract_weights(model, SAVE_LOC + \n",
    "                                                       \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "\n",
    "            else:\n",
    "                # Delta-compression\n",
    "                delta, decomp_delta, bias = lc.generate_delta(base, \n",
    "                                                                base_decomp, model.state_dict(), DECOMPOSED_LAYERS)\n",
    "                compressed_delta, full_delta, compressed_dcomp_delta, full_dcomp_delta  = lc.compress_delta(delta, \n",
    "                                                                                                            decomp_delta)\n",
    "                \n",
    "                # Saving checkpoint\n",
    "                lc.save_checkpoint(compressed_delta, compressed_dcomp_delta, bias, current_iter, SAVE_LOC + \n",
    "                                \"/set_{}\".format(current_set))\n",
    "    \n",
    "                base = np.add(base, full_delta) # Replace base with latest for delta to accumulate.\n",
    "                base_decomp = np.add(full_dcomp_delta, base_decomp)\n",
    "\n",
    "                current_iter += 1\n",
    "            \n",
    "        # ==========================\n",
    "        # Saving using LC-Checkpoint\n",
    "        # ==========================\n",
    "                \n",
    "        if i == 0 and epch == 0:\n",
    "            cstate = model_original.state_dict()\n",
    "            set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "            if not os.path.exists(SAVE_LOC_OLC + set_path):\n",
    "                os.makedirs(SAVE_LOC_OLC + set_path)\n",
    "            # torch.save(cstate, SAVE_LOC_OLC + set_path + \"/initial_model.pt\")\n",
    "            prev_state = olc.extract_weights(cstate, SAVE_LOC_OLC + set_path, DECOMPOSED_LAYERS)\n",
    "        else:\n",
    "            if i % 10 == 0:\n",
    "                cstate = model_original.state_dict()\n",
    "                current_set_old_lc += 1\n",
    "                current_iter_old_lc = 0\n",
    "                set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                if not os.path.exists(SAVE_LOC_OLC + set_path):\n",
    "                    os.makedirs(SAVE_LOC_OLC + set_path)\n",
    "                # torch.save(cstate, SAVE_LOC_OLC + set_path + \"/initial_model.pt\")\n",
    "                prev_state = olc.extract_weights(cstate, SAVE_LOC_OLC + set_path, DECOMPOSED_LAYERS)\n",
    "            else:\n",
    "                cstate = model_original.state_dict()\n",
    "                old_lc_delta, old_lc_bias = olc.generate_delta(prev_state, cstate, DECOMPOSED_LAYERS)\n",
    "                print(\"Compressing delta for old_lc\")\n",
    "                # compressed_delta = olc.compress_delta(old_lc_delta, num_bits = 3)\n",
    "                olc_compressed_delta, update_prev = olc.compress_data(old_lc_delta, num_bits = 3)\n",
    "                olc.save_checkpoint(SAVE_LOC_OLC + \"/set_{}\".format(current_set_old_lc), olc_compressed_delta, \n",
    "                                    old_lc_bias, current_iter_old_lc)\n",
    "                prev_state = np.add(prev_state, update_prev)\n",
    "                current_iter_old_lc += 1\n",
    "        \n",
    "        # ==========================\n",
    "        # Training on Low-Rank Model\n",
    "        # ==========================\n",
    "\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs,labels)\n",
    "        loss.backward()\n",
    "        print(\"LoRA+LC Training Loss (Decomposed): {}\".format(loss.item()))\n",
    "        optimizer.step()\n",
    "            \n",
    "        # ======================\n",
    "        # Training on Full Model\n",
    "        # ======================\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer_full.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs_full = model_original(inputs)\n",
    "        loss_full = torch.nn.functional.cross_entropy(outputs_full,labels)\n",
    "        loss_full.backward()\n",
    "        print(\"LC Training Loss (Full): {}\".format(loss_full.item()))\n",
    "        optimizer_full.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print(\"Training Accuracy | Decomposed: {}, Full : {}\".format(acc(outputs, labels), \n",
    "                                                                         acc(outputs_full, labels)))\n",
    "\n",
    "        if i != 0  and i % 5 == 0: # Evaluation on testing set\n",
    "            full_accuracy.append(evaluate_accuracy(model_original, test_loader))\n",
    "            decomposed_full_accuracy.append(evaluate_accuracy(model, test_loader))\n",
    "            restored_model = lazy_restore(base, base_decomp, bias, LeNet(), \n",
    "                                          original.state_dict(), DECOMPOSED_LAYERS, \n",
    "                                          rank = RANK, scaling = SCALING)\n",
    "            restored_accuracy.append(evaluate_accuracy(restored_model, test_loader))\n",
    "            restored_lc_model = LeNet()\n",
    "            restored_lc_model.load_state_dict(olc.restore_state_dict(prev_state, old_lc_bias, \n",
    "                                                                  restored_model.state_dict(), DECOMPOSED_LAYERS))\n",
    "            lc_accuracy.append(evaluate_accuracy(restored_lc_model, test_loader))\n",
    "            print(\"Full accuracy: {}, LC accuracy: {}, Decomposed-Full accuracy: {}, Decomposed-Restored accuracy: {}\".format(\n",
    "                full_accuracy[-1], lc_accuracy[-1], decomposed_full_accuracy[-1], restored_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For recovery and not restart from scratch : having the plots and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/data.json\") as f:\n",
    "    data = json.load(f)\n",
    "full_accuracy = data['full_acc']\n",
    "lc_accuracy = data[\"lc_restored_accuracy\"]\n",
    "restored_accuracy = data[\"decomposed_restored_accuracy\"]\n",
    "decomposed_full_accuracy = data[\"decomposed_full_accuracy\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (30, 5))\n",
    "plt.title(\"LeNet, Accuracy, Branched @ {} Accuracy\".format(BRANCH_ACC))\n",
    "plt.plot(full_accuracy, label = \"Default LeNet\")\n",
    "plt.plot(lc_accuracy, label = \"LC LeNet\")\n",
    "plt.plot(decomposed_full_accuracy, label = \"dLoRA LeNet\")\n",
    "plt.plot(restored_accuracy, label = \"dLoRA + LC LeNet\")\n",
    "plt.xticks([x for x in range(0, 120) if x % 6 == 0], [x for x in range(0, 20)])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['feature.0.weight', 'feature.0.bias', 'feature.3.weight', 'feature.3.bias', 'classifier.1.alpha', 'classifier.1.beta', 'classifier.1.bias', 'classifier.3.alpha', 'classifier.3.beta', 'classifier.3.bias', 'classifier.5.weight', 'classifier.5.bias'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 5, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['feature.3.weight'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the absolute accuracy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rangex = [x for x in range(0, 120) if x % 6 == 0]\n",
    "rangey = [x for x in range(0, 20)]\n",
    "plt.figure(figsize = (40, 10))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title(\"LeNet Absolute Accuracy Loss (Default LeNet vs LC + dLoRA LeNet / LC LeNet)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(restored_accuracy))), label = \"LC + dLoRA LeNet\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC LeNet\")\n",
    "plt.legend()\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.ylim(0, 0.5)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.set_title(\"LeNet Absolute Restoration Accuracy Loss (LC + dLoRA LeNet & LC LeNet)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(restored_accuracy), \n",
    "                     np.array(decomposed_full_accuracy))), label = \"LC + dLoRA LeNet\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC LeNet\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 0.5)\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function which compute the size of compressed and uncompressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def getsize(sl):\n",
    "    dir = [x for x in os.listdir(sl)]\n",
    "    csize, usize = 0, 0\n",
    "    for set in dir:\n",
    "        for f in os.listdir(sl + \"/\" + set):\n",
    "            fp = sl + \"/{}/{}\".format(set, f)\n",
    "            csize += os.path.getsize(fp)\n",
    "            usize += 250 * math.pow(2, 10) # torch checkpoint same size\n",
    "    return csize, usize,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC-Checkpoint + GZIP\n",
      "Compression Ratio: 562.256%, Space Savings: 82.215%\n",
      "LoRA + LC-Checkpoint + GZIP\n",
      "Compression Ratio: 1885.7610000000002%, Space Savings: 94.697%\n"
     ]
    }
   ],
   "source": [
    "compressed_size, uncompressed_size = getsize(SAVE_LOC)\n",
    "a, b = evaluate_compression(uncompressed_size, compressed_size)\n",
    "compressed_size, uncompressed_size = getsize(SAVE_LOC_OLC)\n",
    "a1, b1 = evaluate_compression(uncompressed_size, compressed_size)\n",
    "\n",
    "print(\"LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a1, b1))\n",
    "print(\"LoRA + LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data in a dictionary and save it in a file data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"full_acc\" : full_accuracy,\n",
    "    \"decomposed_restored_accuracy\" : restored_accuracy,\n",
    "    \"decomposed_full_accuracy\" : decomposed_full_accuracy,\n",
    "    \"lc_restored_accuracy\" : lc_accuracy\n",
    "}\n",
    "with open(HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/data.json\", 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
