{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Implementation without Old LC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bradf\\anaconda3\\envs\\py310\\lib\\site-packages\\transformers\\utils\\generic.py:485: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy as spy\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import ssl\n",
    "import pickle, json\n",
    "import src.main as lc\n",
    "# import old_lc.main as olc\n",
    "from src.models.VGG16NoLite import VGG16NoLite\n",
    "import src.compression.deltaCompress as lc_compress\n",
    "from src.models.VGG16NoLite_LowRank import getBase, VGG16NoLite_LowRank, load_sd_decomp\n",
    "from src.utils.utils import evaluate_accuracy, lazy_restore, evaluate_compression\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Data Loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDFP = \"./volumes/Ultra Touch\" # Load HHD\n",
    "\n",
    "# def data_loader():\n",
    "#     transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(32, antialias=True)])\n",
    "\n",
    "#     trainset = datasets.MNIST(root='./data', train=True,\n",
    "#                                           download=True, transform=transform)\n",
    "#     # Reintroduce the 2000 datapoints model has not seen before.\n",
    "#     trainset.data = trainset.data.clone()[-2000:-1000]\n",
    "#     trainset.targets = trainset.targets.clone()[-2000:-1000]\n",
    "#     trainloader = torch.utils.data.DataLoader(trainset, batch_size = 32,\n",
    "#                                               shuffle=False, num_workers=2)\n",
    "\n",
    "#     testset = datasets.MNIST(root='./data', train=False,\n",
    "#                                          download=True, transform=transform)\n",
    "\n",
    "#     testset.data = trainset.data[-1000:]\n",
    "#     testset.targets = trainset.targets[-1000:]\n",
    "#     testloader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "#                                              shuffle=False, num_workers=2)\n",
    "    \n",
    "#     testloader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "#                                              shuffle=False, num_workers=2)\n",
    "    \n",
    "#     return trainloader, testloader\n",
    "\n",
    "HDFP = \"./volumes/Ultra Touch\"  # Placeholder for HDD path\n",
    "\n",
    "def data_loader():\n",
    "    # Définir les transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Redimensionner l'image à 224x224\n",
    "        transforms.Grayscale(num_output_channels=3),  # Convertir l'image en niveaux de gris à une image à 3 canaux\n",
    "        transforms.ToTensor(),  # Convertir en tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normaliser avec les moyennes et écarts-types du pré-entraînement de VGG\n",
    "    ])\n",
    "\n",
    "    # Charger le dataset d'entraînement MNIST\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    # Utiliser les dernières 1000 images pour l'entraînement\n",
    "    trainset.data = trainset.data.clone()[-7000:]\n",
    "    trainset.targets = trainset.targets.clone()[-7000:]\n",
    "    # trainset.data = trainset.data.clone()[-1000:]\n",
    "    # trainset.targets = trainset.targets.clone()[-1000:]\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Charger le dataset de test MNIST\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    # Utiliser les premières 300 images du dataset de test\n",
    "    testset.data = testset.data.clone()[:300]\n",
    "    testset.targets = testset.targets.clone()[:300]\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# def data_loader():\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ])\n",
    "\n",
    "#     # Load the MNIST training dataset\n",
    "#     trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "#     # Use the last 10,000 images for training\n",
    "#     trainset.data = trainset.data.clone()[-1000:]\n",
    "#     trainset.targets = trainset.targets.clone()[-1000:]\n",
    "#     # trainset.data = trainset.data.clone()[-58000:]\n",
    "#     # trainset.targets = trainset.targets.clone()[-58000:]\n",
    "#     train_loader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "#     # Load the MNIST test dataset\n",
    "#     testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "#     # Use the first 1,000 images from the test dataset\n",
    "#     testset.data = testset.data.clone()[:300]\n",
    "#     testset.targets = testset.targets.clone()[:300]\n",
    "#     test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "    \n",
    "#     return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bypass using SSL unverified\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# MNIST dataset \n",
    "train_loader, test_loader = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bypass the matplotlib error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing some images of the dataset we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) tensor(4) tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# Adjust these values to match the normalization values used during the loading of your dataset\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    # Adjusting unnormalization for potentially 3-channel images\n",
    "    img = img * std + mean  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Assuming train_loader is defined and loaded as before\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images[:3]))\n",
    "# Print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of folder to save the results (for plots and compression rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vgg16nolite/lobranch\"\n",
    "if not os.path.exists(SAVE_LOC):\n",
    "    os.makedirs(SAVE_LOC)\n",
    "\n",
    "# SAVE_LOC_OLC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vgg16nolite/old-lc\"\n",
    "# if not os.path.exists(SAVE_LOC_OLC):\n",
    "#     os.makedirs(SAVE_LOC_OLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binary(model, evaluation_set):\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for input, label in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            output = torch.sigmoid(model(input))  # Apply sigmoid to model output to get probabilities.\n",
    "            output = torch.where(output > 0.5, 1, 0)  # Threshold probabilities at 0.5 to decide between classes 0 and 1.\n",
    "            no_seen += label.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += (output == label).sum().item()  # Increment correct predictions by the number of matches in the batch.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n",
    "\n",
    "def accuracy_multiclass(model, evaluation_set):\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for input, label in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            output = model(input)  # Get the raw logits from the model.\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit which represents the predicted class.\n",
    "            no_seen += label.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += pred.eq(label.view_as(pred)).sum().item()  # Compare predictions with true labels and sum up correct predictions.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special function for the accuracy of the model on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multiclass_gpu(model, evaluation_set):\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for inputs, labels in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device of the model\n",
    "            output = model(inputs)  # Get the raw logits from the model.\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit which represents the predicted class.\n",
    "            no_seen += labels.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += pred.eq(labels.view_as(pred)).sum().item()  # Compare predictions with true labels and sum up correct predictions.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On GPU (Testing if it works with loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n",
      "Epoch: 1 \tTraining Loss: 0.330346 \tValidation Loss: 0.082776\n",
      "Validation loss decreased (inf --> 0.082776). Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.074766 \tValidation Loss: 0.067042\n",
      "Validation loss decreased (0.082776 --> 0.067042). Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.054759 \tValidation Loss: 0.020681\n",
      "Validation loss decreased (0.067042 --> 0.020681). Saving model ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 62\u001b[0m\n\u001b[0;32m     58\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     60\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 62\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mdata\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     64\u001b[0m model_for_checkpoint\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the base model (VGG16NoLite)\n",
    "\n",
    "model_for_checkpoint = VGG16NoLite()\n",
    "\n",
    "\n",
    "# train model_for_checkpoint such that we compute the loss for the validation dataset and the training dataset (just for the sake of it), et take the checkpoint at the minimum validation loss\n",
    "\n",
    "# define the loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the optimizer\n",
    "\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# define the number of epochs\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "# define the validation loss\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# GPU check with print\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU available\")\n",
    "\n",
    "else:\n",
    "    print(\"GPU not available\")\n",
    "\n",
    "    \n",
    "# move the model to the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# move the model to the GPU\n",
    "\n",
    "model_for_checkpoint.to(device)\n",
    "\n",
    "# train the model\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    model_for_checkpoint.train()\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model_for_checkpoint(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    model_for_checkpoint.eval()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model_for_checkpoint(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(test_loader.sampler)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "        # torch.save(model_for_checkpoint.state_dict(), 'model_for_checkpoint.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On CPU (Testing if it works with loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the base model (VGG16NoLite)\n",
    "\n",
    "# model_for_checkpoint = VGG16NoLite()\n",
    "\n",
    "\n",
    "# # train model_for_checkpoint such that we compute the loss for the validation dataset and the training dataset (just for the sake of it), et take the checkpoint at the minimum validation loss\n",
    "\n",
    "# # define the loss function\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # define the optimizer\n",
    "\n",
    "# optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # define the number of epochs\n",
    "\n",
    "# n_epochs = 10\n",
    "\n",
    "# # define the validation loss\n",
    "\n",
    "# valid_loss_min = np.Inf\n",
    "\n",
    "# # train the model\n",
    "\n",
    "# for epoch in range(1, n_epochs+1):\n",
    "#     train_loss = 0.0\n",
    "#     valid_loss = 0.0\n",
    "\n",
    "#     model_for_checkpoint.train()\n",
    "#     for data, target in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model_for_checkpoint(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         train_loss += loss.item()*data.size(0)\n",
    "\n",
    "#     model_for_checkpoint.eval()\n",
    "#     for data, target in test_loader:\n",
    "#         output = model_for_checkpoint(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "#     train_loss = train_loss/len(train_loader.sampler)\n",
    "#     valid_loss = valid_loss/len(test_loader.sampler)\n",
    "\n",
    "#     print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "\n",
    "#     if valid_loss <= valid_loss_min:\n",
    "#         print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "#         # torch.save(model_for_checkpoint.state_dict(), SAVE_LOC + '/model.pt')\n",
    "#         valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual training on GPU (Creating branchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# get the base model (VGG16NoLite) and move it to the chosen device\n",
    "model_for_checkpoint = VGG16NoLite().to(device)\n",
    "\n",
    "# creating branchpoints\n",
    "epochs = 10\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.001, momentum=0.9)  # momentum=0.9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_for_checkpoint(inputs)\n",
    "\n",
    "        # Here assuming your loss function and any other operation are compatible with CUDA tensors\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % 20 == 0:\n",
    "            print(\"Running validation for {} Epoch, {} Iteration...\".format(epoch, iter))\n",
    "            res = accuracy_multiclass_gpu(model_for_checkpoint, test_loader)  # Ensure this function also handles data on GPU\n",
    "\n",
    "            print(\"ACCURACY: {}\".format(res))\n",
    "            if res > 0.7:\n",
    "                # Move model to CPU before saving\n",
    "                model_for_checkpoint.to('cpu')\n",
    "                torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/vgg16nolite/branch_{}.pt\".format(res))\n",
    "                # Optionally, move model back to the original device (GPU) if further computation is needed\n",
    "                model_for_checkpoint.to(device)\n",
    "            if res > 0.9:\n",
    "                isLoop = False\n",
    "                break\n",
    "    if not isLoop:\n",
    "        break\n",
    "    print(\"Length of train_loader is: \", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual training on CPU (Creating branchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the base model (VGG16NoLite)\n",
    "\n",
    "model_for_checkpoint = VGG16NoLite()\n",
    "\n",
    "# creating branchpoints : \n",
    "\n",
    "epochs = 10\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.001, momentum=0.9) # momentum=0.9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        # print(inputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_for_checkpoint(inputs)\n",
    "\n",
    "        # if self.config.loss_function == \"binary_cross_entropy\":\n",
    "        #     outputs = torch.sigmoid(outputs)\n",
    "        \n",
    "        # loss = loss_function(outputs, labels)\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(\"Epoch {} | Iteration {} : Loss {}\".format(epoch, iter, loss.item()))\n",
    "        if iter % 20 == 0:\n",
    "            print(\"Running validation for {} Epoch, {} Iteration...\".format(epoch, iter))\n",
    "            # Previously: res = accuracy_binary(model_for_checkpoint, test_loader)\n",
    "            res = accuracy_multiclass(model_for_checkpoint, test_loader)\n",
    "\n",
    "            # res = accuracy_binary(model_for_checkpoint, test_loader)\n",
    "            \n",
    "            print(\"ACCURACY: {}\".format(res))\n",
    "            if res > 0.7:\n",
    "                torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/vgg16nolite/branch_{}.pt\".format(res))\n",
    "            if res > 0.9:\n",
    "                isLoop = False\n",
    "                break\n",
    "    if not isLoop:\n",
    "        break\n",
    "    print(\"Length of train_loader is: \", len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploiting branchpoints of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call of the different models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECOMPOSED_LAYERS = ['classifier.0.weight', 'classifier.4.weight', 'classifier.8.weight']\n",
    "RANK = -1\n",
    "SCALING = -1\n",
    "BRANCH_ACC = \"0.831\"\n",
    "\n",
    "# Set up weights for original VGG16 model\n",
    "original = VGG16NoLite()\n",
    "model_original = VGG16NoLite()\n",
    "\n",
    "# Load from \"branch point\"\n",
    "BRANCH_LOC = HDFP + \"/lobranch-snapshot/branchpoints/vgg16nolite/branch_{}.pt\".format(BRANCH_ACC)\n",
    "original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "model_original.load_state_dict(torch.load(BRANCH_LOC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole state of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the weights and bias as the base for the LoRA version of custom linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = getBase(model_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paying attention to the bias shape if it is a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bias in b:\n",
    "    print(bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having a LoRA version of the model with the weight and bias of the custom linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16NoLite_LowRank(w, b, rank = RANK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and updating model state dictionary from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# load_sd_decomp(org_sd, model, decomposed_layers):                     #\n",
    "#     \"\"\"                                                               #                          \n",
    "#     @param org_sd : The state_dict when the model is ongoing.         #\n",
    "#     @param model : The decomp model with decomposed layers.           #\n",
    "#     @param decomposed_layers : The decomposed layers in decomp model. #\n",
    "#                                                                       #\n",
    "#     @return The new model with the old state dictionary loaded in.    #\n",
    "#     \"\"\"                                                               #\n",
    "#     new_sd = model.state_dict()                                       #\n",
    "#     for k, v in org_sd.items():                                       #\n",
    "#         if k not in decomposed_layers:                                #\n",
    "#             new_sd[k] = v                                             #\n",
    "#     model.load_state_dict(new_sd)                                     #\n",
    "#########################################################################\n",
    "\n",
    "# Create a new state dictionary for the model\n",
    "new_sd = model.state_dict()\n",
    "\n",
    "# Load the state dictionary from the checkpoint file located at BRANCH_LOC\n",
    "for k, v in torch.load(BRANCH_LOC).items():\n",
    "\n",
    "    # Uncomment to print the keys from the loaded state dictionary\n",
    "    # print(k)\n",
    "\n",
    "    # Check if the key is not in DECOMPOSED_LAYERS\n",
    "    if k not in DECOMPOSED_LAYERS:\n",
    "        # If the key is not in DECOMPOSED_LAYERS, assign the value v to the corresponding key k in the new state dictionary\n",
    "        new_sd[k] = v\n",
    "\n",
    "# Print the updated state dictionary\n",
    "print(new_sd)\n",
    "\n",
    "# Load the updated state dictionary into the model\n",
    "model.load_state_dict(new_sd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading checkpoint, optimizer setup, and layer filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load state dictionary from checkpoint, excluding specified decomposed layers, and load it into the model\n",
    "load_sd_decomp(torch.load(BRANCH_LOC), model, DECOMPOSED_LAYERS)\n",
    "\n",
    "# Set the learning rate for the optimizer\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define an optimizer for the model's parameters with Stochastic Gradient Descent (SGD) and specified learning rate and momentum\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# Define an optimizer for the original model's parameters with Stochastic Gradient Descent (SGD) and specified learning rate and momentum\n",
    "optimizer_full = torch.optim.SGD(model_original.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the maximum and minimum values of the delta and decomposed delta\n",
    "delta_normal_max = []\n",
    "delta_normal_min = []\n",
    "delta_decomposed_max = []\n",
    "delta_decomposed_min = []\n",
    "\n",
    "# Initialize lists to store the maximum and minimum values of the compressed delta and decomposed delta\n",
    "full_accuracy = []\n",
    "decomposed_full_accuracy = []\n",
    "restored_accuracy = []\n",
    "lc_accuracy = []\n",
    "\n",
    "# Initialize the current iteration and set to 0\n",
    "current_iter = 0\n",
    "current_set = 0\n",
    "\n",
    "# Initialize the current iteration and set to 0 for the old LC method\n",
    "current_iter_old_lc = 0\n",
    "current_set_old_lc = 0\n",
    "\n",
    "# Define a function to evaluate the accuracy of the model on the test set\n",
    "acc = lambda x, y : (torch.max(x, 1)[1] == y).sum().item() / y.size(0)\n",
    "\n",
    "# Train the model for 20 epochs\n",
    "for epch in range(20):\n",
    "    # Iterate over the training data\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        print(\"Epoch: {}, Iteration: {}\".format(epch, i))\n",
    "        \n",
    "        # Create a new set directory if it does not exist\n",
    "        set_path = \"/set_{}\".format(current_set)\n",
    "        if not os.path.exists(SAVE_LOC + set_path):\n",
    "            os.makedirs(SAVE_LOC + set_path)\n",
    "\n",
    "        # Check if it is the first iteration of the first epoch\n",
    "        if i == 0 and epch == 0: # first iteration, create baseline model\n",
    "            base, base_decomp = lc.extract_weights(model, SAVE_LOC + \n",
    "                                                       \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "        # Check if it is a full snapshot\n",
    "        else:\n",
    "            # Check if the iteration is a multiple of 10\n",
    "            if i % 10 == 0: \n",
    "                # full snapshot!\n",
    "\n",
    "                new_model = lazy_restore(base, base_decomp, bias, VGG16NoLite(), \n",
    "                                          original.state_dict(), DECOMPOSED_LAYERS, rank = RANK, scaling = SCALING)\n",
    "                # Changing previous \"original model\" used to restore the loRA model.\n",
    "                original = new_model \n",
    "                \n",
    "                current_set += 1\n",
    "                current_iter = 0\n",
    "\n",
    "                # Create a new set directory if it does not exist\n",
    "                set_path = \"/set_{}\".format(current_set)\n",
    "                if not os.path.exists(SAVE_LOC + set_path):\n",
    "                    os.makedirs(SAVE_LOC + set_path)\n",
    "                \n",
    "                # Rebuilding LoRA layers => reset model!\n",
    "\n",
    "                # Get the base model weights and biases\n",
    "                w, b = getBase(original)\n",
    "                # Create a new model with the base weights and specified rank\n",
    "                model = VGG16NoLite_LowRank(w, b, rank = RANK)\n",
    "                # Optimizer for the model's parameters with Stochastic Gradient Descent (SGD) and specified learning rate\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "                # Load state dictionary from full snapshot, including specified decomposed layers, and load it into the model\n",
    "                load_sd_decomp(original.state_dict(), model, DECOMPOSED_LAYERS)\n",
    "                # The base for all delta calculations\n",
    "                base, base_decomp = lc.extract_weights(model, SAVE_LOC + \n",
    "                                                       \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "\n",
    "            # If it is not a full snapshot, perform delta compression\n",
    "            else:\n",
    "                # Delta-compression : The delta for the weights of the normal and decomposed layers.\n",
    "                # Also returns the full dictionary, which holds the bias.\n",
    "                delta, decomp_delta, bias = lc.generate_delta(base, \n",
    "                                                                base_decomp, model.state_dict(), DECOMPOSED_LAYERS)\n",
    "                \n",
    "                # Compressing the delta and decomposed delta\n",
    "                compressed_delta, full_delta, compressed_dcomp_delta, full_dcomp_delta  = lc.compress_delta(delta, \n",
    "                                                                                                            decomp_delta)\n",
    "                \n",
    "                # Saving checkpoint\n",
    "                lc.save_checkpoint(compressed_delta, compressed_dcomp_delta, bias, current_iter, SAVE_LOC + \n",
    "                                \"/set_{}\".format(current_set))\n",
    "    \n",
    "                # Update base and base_decomp\n",
    "                base = np.add(base, full_delta) # Replace base with latest for delta to accumulate.\n",
    "                base_decomp = np.add(full_dcomp_delta, base_decomp)\n",
    "\n",
    "                # Update current iteration\n",
    "                current_iter += 1\n",
    "            \n",
    "        # # ==========================\n",
    "        # # Saving using LC-Checkpoint\n",
    "        # # ==========================\n",
    "                \n",
    "        # if i == 0 and epch == 0:\n",
    "        #     cstate = model_original.state_dict()\n",
    "        #     set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "        #     if not os.path.exists(SAVE_LOC_OLC + set_path):\n",
    "        #         os.makedirs(SAVE_LOC_OLC + set_path)\n",
    "        #     torch.save(cstate, SAVE_LOC_OLC + set_path + \"/initial_model.pt\")\n",
    "        #     prev_state = olc.extract_weights(model_original)\n",
    "        # else:\n",
    "        #     if i % 10 == 0:\n",
    "        #         cstate = model_original.state_dict()\n",
    "        #         current_set_old_lc += 1\n",
    "        #         current_iter_old_lc = 0\n",
    "        #         set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "        #         if not os.path.exists(SAVE_LOC_OLC + set_path):\n",
    "        #             os.makedirs(SAVE_LOC_OLC + set_path)\n",
    "        #         torch.save(cstate, SAVE_LOC_OLC + set_path + \"/initial_model.pt\")\n",
    "        #         prev_state = olc.extract_weights(model_original)\n",
    "        #     else:\n",
    "        #         cstate = model_original.state_dict()\n",
    "        #         old_lc_delta, old_lc_bias, _ = olc.generate_delta(prev_state, cstate)\n",
    "        #         olc_compressed_delta, update_prev = olc.compress_data(old_lc_delta, num_bits = 3)\n",
    "        #         olc.save_checkpoint(SAVE_LOC_OLC + \"/set_{}\".format(current_set_old_lc), olc_compressed_delta, \n",
    "        #                             old_lc_bias, epch, current_iter_old_lc)\n",
    "        #         prev_state = np.add(prev_state, update_prev)\n",
    "        #         current_iter_old_lc += 1\n",
    "        \n",
    "        # ==========================\n",
    "        # Training on Low-Rank Model\n",
    "        # ==========================\n",
    "\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # ======================\n",
    "        # Training on Full Model\n",
    "        # ======================\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer_full.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs_full = model_original(inputs)\n",
    "        loss_full = torch.nn.functional.cross_entropy(outputs_full,labels)\n",
    "        loss_full.backward()\n",
    "        optimizer_full.step()\n",
    "\n",
    "        # Print training accuracy every 20 iterations\n",
    "        if i % 20 == 0:\n",
    "            print(\"Training Accuracy | Decomposed: {}, Full : {}\".format(acc(outputs, labels), \n",
    "                                                                         acc(outputs_full, labels)))\n",
    "\n",
    "        # Evaluation every 5 iterations\n",
    "        if i != 0  and i % 5 == 0: # Evaluation on testing set\n",
    "\n",
    "            # Evaluate the accuracy of the model on the test set\n",
    "            full_accuracy.append(evaluate_accuracy(model_original, test_loader))\n",
    "\n",
    "            # Evaluate the accuracy of the model on the test set for decomposed model\n",
    "            decomposed_full_accuracy.append(evaluate_accuracy(model, test_loader))\n",
    "\n",
    "            # Restore the model from the full snapshot\n",
    "            restored_model = lazy_restore(base, base_decomp, bias, VGG16NoLite(), \n",
    "                                          original.state_dict(), DECOMPOSED_LAYERS, \n",
    "                                          rank = RANK, scaling = SCALING)\n",
    "\n",
    "            # Evaluate the accuracy of the restored model on the test set\n",
    "            restored_accuracy.append(evaluate_accuracy(restored_model, test_loader))\n",
    "\n",
    "            # Restore VGG16NoLite model from the old LC method\n",
    "            restored_lc_model = VGG16NoLite()\n",
    "            # restored_lc_model.load_state_dict(olc.restore_state_dict(prev_state, old_lc_bias, \n",
    "            #                                                       restored_model.state_dict()))\n",
    "            lc_accuracy.append(evaluate_accuracy(restored_lc_model, test_loader))\n",
    "            print(\"Full accuracy: {}, LC accuracy: {}, Decomposed-Full accuracy: {}, Decomposed-Restored accuracy: {}\".format(\n",
    "                full_accuracy[-1], lc_accuracy[-1], decomposed_full_accuracy[-1], restored_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For recovery and not restart from scratch : having the plots and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open a file to save the data (if it exists, otherwise ignore this cell)\n",
    "with open(HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vgg16nolite/data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Update the data with the new values\n",
    "full_accuracy = data['full_acc']\n",
    "lc_accuracy = data[\"lc_restored_accuracy\"]\n",
    "restored_accuracy = data[\"decomposed_restored_accuracy\"]\n",
    "decomposed_full_accuracy = data[\"decomposed_full_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30, 5))\n",
    "plt.title(\"VGG-16 No Lite, Accuracy, Branched @ {} Accuracy\".format(BRANCH_ACC))\n",
    "plt.plot(full_accuracy, label = \"Default VGG-16 No Lite\")\n",
    "# plt.plot(lc_accuracy, label = \"LC VGG-16\")\n",
    "plt.plot(decomposed_full_accuracy, label = \"dLoRA VGG-16 No Lite\")\n",
    "plt.plot(restored_accuracy, label = \"dLoRA + LC VGG-16 No Lite\")\n",
    "plt.xticks([x for x in range(0, 120) if x % 6 == 0], [x for x in range(0, 20)])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30, 5))\n",
    "plt.title(\"VGG-16 No Lite, Accuracy, Branched @ {} Accuracy\".format(BRANCH_ACC))\n",
    "plt.plot(lc_accuracy, label = \"LC VGG-16 No Lite\")\n",
    "plt.xticks([x for x in range(0, 120) if x % 6 == 0], [x for x in range(0, 20)])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the absolute accuracy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangex = [x for x in range(0, 120) if x % 6 == 0]\n",
    "rangey = [x for x in range(0, 20)]\n",
    "plt.figure(figsize = (40, 10))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title(\"VGG-16 No Lite Absolute Accuracy Loss (Default VGG-16 vs LC + dLoRA VGG-16)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(restored_accuracy))), label = \"LC + dLoRA VGG-16 No Lite\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC VGG-16 No Lite\")\n",
    "plt.legend()\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.ylim(0, 0.5)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.set_title(\"VGG-16 No Lite Absolute Restoration Accuracy Loss (LC + dLoRA VGG-16 No Lite & LC VGG-16 No Lite)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(restored_accuracy), \n",
    "                     np.array(decomposed_full_accuracy))), label = \"LC + dLoRA VGG-16 No Lite\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC VGG-16 No Lite\")\n",
    "plt.legend()\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function which compute the size of compressed and uncompressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def getsize(sl):\n",
    "    dir = [x for x in os.listdir(sl)]\n",
    "    csize, usize = 0, 0\n",
    "    for set in dir:\n",
    "        for f in os.listdir(sl + \"/\" + set):\n",
    "            fp = sl + \"/{}/{}\".format(set, f)\n",
    "            csize += os.path.getsize(fp)\n",
    "            usize += 119.6 * math.pow(2, 20) # torch checkpoint same size\n",
    "    return csize, usize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_size, uncompressed_size = getsize(SAVE_LOC)\n",
    "a, b = evaluate_compression(uncompressed_size, compressed_size)\n",
    "# compressed_size, uncompressed_size = getsize(SAVE_LOC_OLC)\n",
    "# a1, b1 = evaluate_compression(uncompressed_size, compressed_size)\n",
    "\n",
    "# print(\"LC-Checkpoint + GZIP\")\n",
    "# print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a1, b1))\n",
    "print(\"LoRA + LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data in a dictionary and save it in a file data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"full_acc\" : full_accuracy,\n",
    "    \"decomposed_restored_accuracy\" : restored_accuracy,\n",
    "    \"decomposed_full_accuracy\" : decomposed_full_accuracy,\n",
    "    \"lc_restored_accuracy\" : lc_accuracy\n",
    "}\n",
    "with open(HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vgg16nolite/data.json\", 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
