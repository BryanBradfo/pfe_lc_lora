{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT Implementation with Old LC on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bradf\\anaconda3\\envs\\py310\\lib\\site-packages\\transformers\\utils\\generic.py:485: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy as spy\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import ssl\n",
    "import pickle, json\n",
    "import src.main as lc\n",
    "import old_lc.main as olc\n",
    "import src.compression.deltaCompress as lc_compress\n",
    "from src.models.ViT import ViT\n",
    "from src.models.ViTS_LowRank import getBase, ViTS_LowRank, load_sd_decomp\n",
    "from src.utils.utils import evaluate_accuracy, evaluate_accuracy_gpu, lazy_restore,lazy_restore_gpu, evaluate_compression\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LR=0.0002\n",
    "NUM_EPOCHES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Data Loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDFP = \"./volumes/Ultra Touch\"  # Placeholder for HDD path\n",
    "\n",
    "def data_loader():\n",
    "    # Définir les transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # Charger le dataset d'entraînement MNIST\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    # Utiliser les dernières 1000 images pour l'entraînement\n",
    "    # trainset.data = trainset.data.clone()[-40000:]\n",
    "    # trainset.targets = trainset.targets.clone()[-40000:]\n",
    "    trainset.data = trainset.data.clone()[-2000:-1000]\n",
    "    trainset.targets = trainset.targets.clone()[-2000:-1000]\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Charger le dataset de test MNIST\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    # Utiliser les premières 300 images du dataset de test\n",
    "    testset.data = trainset.data.clone()[-1000:]\n",
    "    testset.targets = trainset.targets.clone()[-1000:]\n",
    "    # testset.data = trainset.data.clone()[:3000]\n",
    "    # testset.targets = trainset.targets.clone()[:3000]\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bypass using SSL unverified\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# MNIST dataset \n",
    "train_loader, test_loader = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bypass the matplotlib error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing some images of the dataset we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6) tensor(9) tensor(4)\n"
     ]
    }
   ],
   "source": [
    "# Adjust these values to match the normalization values used during the loading of your dataset\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    # Adjusting unnormalization for potentially 3-channel images\n",
    "    img = img * std + mean  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Assuming train_loader is defined and loaded as before\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images[:3]))\n",
    "# Print labels\n",
    "print(' '.join('%5s' % labels[j] for j in range(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of folder to save the results (for plots and compression rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch\"\n",
    "if not os.path.exists(SAVE_LOC):\n",
    "    os.makedirs(SAVE_LOC)\n",
    "\n",
    "SAVE_LOC_OLC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc\"\n",
    "if not os.path.exists(SAVE_LOC_OLC):\n",
    "    os.makedirs(SAVE_LOC_OLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_binary(model, evaluation_set):\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for input, label in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            output = torch.sigmoid(model(input))  # Apply sigmoid to model output to get probabilities.\n",
    "            output = torch.where(output > 0.5, 1, 0)  # Threshold probabilities at 0.5 to decide between classes 0 and 1.\n",
    "            no_seen += label.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += (output == label).sum().item()  # Increment correct predictions by the number of matches in the batch.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n",
    "\n",
    "def accuracy_multiclass(model, evaluation_set):\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for input, label in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            output = model(input)  # Get the raw logits from the model.\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit which represents the predicted class.\n",
    "            no_seen += label.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += pred.eq(label.view_as(pred)).sum().item()  # Compare predictions with true labels and sum up correct predictions.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special function for the accuracy of the model on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_multiclass_gpu(model, evaluation_set):\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    model.eval()  # Switches the model to evaluation mode.\n",
    "\n",
    "    no_correct, no_seen = 0, 0  # Initialize counters for correct predictions and total samples seen.\n",
    "\n",
    "    with torch.no_grad():  # Disables gradient calculation.\n",
    "        for inputs, labels in evaluation_set:  # Iterate over the evaluation dataset.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device of the model\n",
    "            output = model(inputs)  # Get the raw logits from the model.\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max logit which represents the predicted class.\n",
    "            no_seen += labels.size(0)  # Count the number of samples seen (batch size).\n",
    "            no_correct += pred.eq(labels.view_as(pred)).sum().item()  # Compare predictions with true labels and sum up correct predictions.\n",
    "    \n",
    "    acc = no_correct / no_seen  # Calculate accuracy as the ratio of correct predictions to total samples.\n",
    "    model.train()  # Switch the model back to training mode.\n",
    "    return acc  # Return the computed accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual training on GPU (Creating branchpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda:0 (NVIDIA GeForce RTX 4060 Laptop GPU)\n",
      "Epoch : [0/999], Training Loss: 2.308612, Validation Loss: 2.300126\n",
      "Epoch : [1/999], Training Loss: 2.308866, Validation Loss: 2.302166\n",
      "Epoch : [2/999], Training Loss: 2.301739, Validation Loss: 2.290457\n",
      "Epoch : [3/999], Training Loss: 2.289952, Validation Loss: 2.273528\n",
      "Epoch : [4/999], Training Loss: 2.265100, Validation Loss: 2.256996\n",
      "Epoch : [5/999], Training Loss: 2.256778, Validation Loss: 2.250339\n",
      "Epoch : [6/999], Training Loss: 2.247834, Validation Loss: 2.241429\n",
      "Epoch : [7/999], Training Loss: 2.232489, Validation Loss: 2.219324\n",
      "Epoch : [8/999], Training Loss: 2.220486, Validation Loss: 2.207971\n",
      "Epoch : [9/999], Training Loss: 2.211632, Validation Loss: 2.202067\n",
      "Epoch : [10/999], Training Loss: 2.205711, Validation Loss: 2.200200\n",
      "Epoch : [11/999], Training Loss: 2.207266, Validation Loss: 2.192911\n",
      "Epoch : [12/999], Training Loss: 2.198009, Validation Loss: 2.200446\n",
      "Epoch : [13/999], Training Loss: 2.200977, Validation Loss: 2.202545\n",
      "Epoch : [14/999], Training Loss: 2.199870, Validation Loss: 2.179066\n",
      "Epoch : [15/999], Training Loss: 2.194867, Validation Loss: 2.184417\n",
      "Epoch : [16/999], Training Loss: 2.193690, Validation Loss: 2.191587\n",
      "Epoch : [17/999], Training Loss: 2.188061, Validation Loss: 2.185338\n",
      "Epoch : [18/999], Training Loss: 2.191464, Validation Loss: 2.181479\n",
      "Epoch : [19/999], Training Loss: 2.192379, Validation Loss: 2.167984\n",
      "Epoch : [20/999], Training Loss: 2.186193, Validation Loss: 2.186162\n",
      "Epoch : [21/999], Training Loss: 2.173993, Validation Loss: 2.162313\n",
      "Epoch : [22/999], Training Loss: 2.180760, Validation Loss: 2.166842\n",
      "Epoch : [23/999], Training Loss: 2.172059, Validation Loss: 2.164964\n",
      "Epoch : [24/999], Training Loss: 2.165833, Validation Loss: 2.141549\n",
      "Epoch : [25/999], Training Loss: 2.159021, Validation Loss: 2.140445\n",
      "Epoch : [26/999], Training Loss: 2.134819, Validation Loss: 2.100536\n",
      "Epoch : [27/999], Training Loss: 2.131887, Validation Loss: 2.112011\n",
      "Epoch : [28/999], Training Loss: 2.099610, Validation Loss: 2.059365\n",
      "Epoch : [29/999], Training Loss: 2.097827, Validation Loss: 2.034521\n",
      "Epoch : [30/999], Training Loss: 2.022844, Validation Loss: 2.024700\n",
      "Epoch : [31/999], Training Loss: 2.004816, Validation Loss: 1.946340\n",
      "Epoch : [32/999], Training Loss: 1.995288, Validation Loss: 2.001419\n",
      "Epoch : [33/999], Training Loss: 1.927958, Validation Loss: 1.890679\n",
      "Epoch : [34/999], Training Loss: 1.894199, Validation Loss: 1.834077\n",
      "Epoch : [35/999], Training Loss: 1.841255, Validation Loss: 1.813717\n",
      "Epoch : [36/999], Training Loss: 1.827161, Validation Loss: 1.775342\n",
      "model saved at accuracy:  0.701\n",
      "model saved at accuracy:  0.714\n",
      "Epoch : [37/999], Training Loss: 1.799077, Validation Loss: 1.766309\n",
      "model saved at accuracy:  0.714\n",
      "model saved at accuracy:  0.714\n",
      "Epoch : [38/999], Training Loss: 1.755780, Validation Loss: 1.719567\n",
      "model saved at accuracy:  0.76\n",
      "Epoch : [39/999], Training Loss: 1.745597, Validation Loss: 1.713078\n",
      "model saved at accuracy:  0.746\n",
      "model saved at accuracy:  0.766\n",
      "Epoch : [40/999], Training Loss: 1.732214, Validation Loss: 1.724033\n",
      "model saved at accuracy:  0.741\n",
      "model saved at accuracy:  0.779\n",
      "Epoch : [41/999], Training Loss: 1.722763, Validation Loss: 1.691999\n",
      "model saved at accuracy:  0.778\n",
      "model saved at accuracy:  0.797\n",
      "Epoch : [42/999], Training Loss: 1.686996, Validation Loss: 1.699475\n",
      "model saved at accuracy:  0.779\n",
      "model saved at accuracy:  0.818\n",
      "Epoch : [43/999], Training Loss: 1.673957, Validation Loss: 1.663618\n",
      "model saved at accuracy:  0.818\n",
      "model saved at accuracy:  0.806\n",
      "Epoch : [44/999], Training Loss: 1.649871, Validation Loss: 1.635110\n",
      "model saved at accuracy:  0.822\n",
      "model saved at accuracy:  0.855\n",
      "Epoch : [45/999], Training Loss: 1.634492, Validation Loss: 1.618859\n",
      "model saved at accuracy:  0.857\n",
      "model saved at accuracy:  0.855\n",
      "Epoch : [46/999], Training Loss: 1.622230, Validation Loss: 1.628698\n",
      "model saved at accuracy:  0.829\n",
      "model saved at accuracy:  0.865\n",
      "Epoch : [47/999], Training Loss: 1.624804, Validation Loss: 1.616916\n",
      "model saved at accuracy:  0.856\n",
      "model saved at accuracy:  0.856\n",
      "Epoch : [48/999], Training Loss: 1.617016, Validation Loss: 1.609083\n",
      "model saved at accuracy:  0.86\n",
      "model saved at accuracy:  0.855\n",
      "Epoch : [49/999], Training Loss: 1.613524, Validation Loss: 1.601146\n",
      "model saved at accuracy:  0.863\n",
      "model saved at accuracy:  0.851\n",
      "Epoch : [50/999], Training Loss: 1.616000, Validation Loss: 1.607699\n",
      "model saved at accuracy:  0.857\n",
      "model saved at accuracy:  0.857\n",
      "Epoch : [51/999], Training Loss: 1.632828, Validation Loss: 1.601490\n",
      "model saved at accuracy:  0.854\n",
      "model saved at accuracy:  0.854\n",
      "Epoch : [52/999], Training Loss: 1.646034, Validation Loss: 1.635124\n",
      "model saved at accuracy:  0.809\n",
      "model saved at accuracy:  0.873\n",
      "Epoch : [53/999], Training Loss: 1.613860, Validation Loss: 1.601772\n",
      "model saved at accuracy:  0.867\n",
      "model saved at accuracy:  0.873\n",
      "Epoch : [54/999], Training Loss: 1.599968, Validation Loss: 1.598273\n",
      "model saved at accuracy:  0.867\n",
      "model saved at accuracy:  0.859\n",
      "Epoch : [55/999], Training Loss: 1.600119, Validation Loss: 1.585288\n",
      "model saved at accuracy:  0.879\n",
      "model saved at accuracy:  0.881\n",
      "Epoch : [56/999], Training Loss: 1.586967, Validation Loss: 1.586634\n",
      "model saved at accuracy:  0.882\n",
      "model saved at accuracy:  0.876\n",
      "Epoch : [57/999], Training Loss: 1.590137, Validation Loss: 1.590590\n",
      "model saved at accuracy:  0.877\n",
      "model saved at accuracy:  0.869\n",
      "Epoch : [58/999], Training Loss: 1.595513, Validation Loss: 1.584626\n",
      "model saved at accuracy:  0.881\n",
      "model saved at accuracy:  0.872\n",
      "Epoch : [59/999], Training Loss: 1.592021, Validation Loss: 1.583654\n",
      "model saved at accuracy:  0.881\n",
      "model saved at accuracy:  0.88\n",
      "Epoch : [60/999], Training Loss: 1.584046, Validation Loss: 1.583458\n",
      "model saved at accuracy:  0.879\n",
      "model saved at accuracy:  0.894\n",
      "Epoch : [61/999], Training Loss: 1.579520, Validation Loss: 1.584402\n",
      "model saved at accuracy:  0.879\n",
      "model saved at accuracy:  0.913\n",
      "Epoch : [62/999], Training Loss: 1.057046, Validation Loss: 1.575197\n",
      "Max epoch reached\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "# get the base model (VGG16NoLite) and move it to the chosen device\n",
    "# model_for_checkpoint = ViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)\n",
    "model_for_checkpoint = ViT((1, 28, 28), n_patches=14, n_blocks=7, hidden_d=512, n_heads=8, out_d=10).to(device)\n",
    "\n",
    "# creating branchpoints\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=0.0004, momentum=0.9)  # momentum=0.9\n",
    "\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    model_for_checkpoint.train()\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to the device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_for_checkpoint(inputs)\n",
    "\n",
    "        # Here assuming your loss function and any other operation are compatible with CUDA tensors\n",
    "        loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        if iter % 20 == 0:\n",
    "            # print(\"Running validation for {} Epoch, {} Iteration...\".format(epoch, iter))\n",
    "            res = accuracy_multiclass_gpu(model_for_checkpoint, test_loader)  # Ensure this function also handles data on GPU\n",
    "\n",
    "            # print(\"ACCURACY: {}\".format(res))\n",
    "            if res > 0.7:\n",
    "                # Move model to CPU before saving\n",
    "                model_for_checkpoint.to('cpu')\n",
    "                torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/vitS/branch_{}.pt\".format(res))\n",
    "                # Optionally, move model back to the original device (GPU) if further computation is needed\n",
    "                print(\"model saved at accuracy: \", res)\n",
    "                model_for_checkpoint.to(device)\n",
    "            if res > 0.9:\n",
    "                isLoop = False\n",
    "                break\n",
    "\n",
    "    # Validation phase\n",
    "    model_for_checkpoint.eval()\n",
    "    with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "        for data, target in test_loader:\n",
    "            # Move data and target to the correct device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model_for_checkpoint(data)\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "            valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    valid_loss = valid_loss / len(test_loader.dataset)\n",
    "\n",
    "    print(\"Epoch : [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss))\n",
    "    if not isLoop:\n",
    "        break\n",
    "print(\"Max epoch reached\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploiting branchpoints of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DECOMPOSED_LAYERS = ['classifier.0.weight', 'classifier.4.weight', 'classifier.8.weight'\n",
    "DECOMPOSED_LAYERS = [\n",
    "        'blocks.0.mhsa.q_mappings.0.weight',  'blocks.0.mhsa.q_mappings.1.weight',\n",
    "         'blocks.0.mhsa.q_mappings.2.weight',  'blocks.0.mhsa.q_mappings.3.weight',\n",
    "         'blocks.0.mhsa.q_mappings.4.weight',  'blocks.0.mhsa.q_mappings.5.weight',\n",
    "         'blocks.0.mhsa.q_mappings.6.weight',  'blocks.0.mhsa.q_mappings.7.weight',\n",
    "\n",
    "         'blocks.0.mhsa.k_mappings.0.weight',  'blocks.0.mhsa.k_mappings.1.weight',\n",
    "         'blocks.0.mhsa.k_mappings.2.weight',  'blocks.0.mhsa.k_mappings.3.weight',\n",
    "         'blocks.0.mhsa.k_mappings.4.weight',  'blocks.0.mhsa.k_mappings.5.weight',\n",
    "         'blocks.0.mhsa.k_mappings.6.weight',  'blocks.0.mhsa.k_mappings.7.weight',\n",
    "\n",
    "         'blocks.0.mhsa.v_mappings.0.weight',  'blocks.0.mhsa.v_mappings.1.weight',\n",
    "         'blocks.0.mhsa.v_mappings.2.weight',  'blocks.0.mhsa.v_mappings.3.weight',\n",
    "         'blocks.0.mhsa.v_mappings.4.weight',  'blocks.0.mhsa.v_mappings.5.weight',\n",
    "         'blocks.0.mhsa.v_mappings.6.weight',  'blocks.0.mhsa.v_mappings.7.weight',\n",
    "\n",
    "         'blocks.0.mlp.0.weight', 'blocks.0.mlp.2.weight',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         'blocks.1.mhsa.q_mappings.0.weight',  'blocks.1.mhsa.q_mappings.1.weight',\n",
    "         'blocks.1.mhsa.q_mappings.2.weight',  'blocks.1.mhsa.q_mappings.3.weight',\n",
    "         'blocks.1.mhsa.q_mappings.4.weight',  'blocks.1.mhsa.q_mappings.5.weight',\n",
    "         'blocks.1.mhsa.q_mappings.6.weight',  'blocks.1.mhsa.q_mappings.7.weight',\n",
    "\n",
    "         'blocks.1.mhsa.k_mappings.0.weight',  'blocks.1.mhsa.k_mappings.1.weight',\n",
    "         'blocks.1.mhsa.k_mappings.2.weight',  'blocks.1.mhsa.k_mappings.3.weight',\n",
    "         'blocks.1.mhsa.k_mappings.4.weight',  'blocks.1.mhsa.k_mappings.5.weight',\n",
    "         'blocks.1.mhsa.k_mappings.6.weight',  'blocks.1.mhsa.k_mappings.7.weight',\n",
    "\n",
    "         'blocks.1.mhsa.v_mappings.0.weight',  'blocks.1.mhsa.v_mappings.1.weight',\n",
    "         'blocks.1.mhsa.v_mappings.2.weight',  'blocks.1.mhsa.v_mappings.3.weight',\n",
    "         'blocks.1.mhsa.v_mappings.4.weight',  'blocks.1.mhsa.v_mappings.5.weight',\n",
    "         'blocks.1.mhsa.v_mappings.6.weight',  'blocks.1.mhsa.v_mappings.7.weight',\n",
    "\n",
    "         'blocks.1.mlp.0.weight', 'blocks.1.mlp.2.weight',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         'blocks.2.mhsa.q_mappings.0.weight',  'blocks.2.mhsa.q_mappings.1.weight',\n",
    "         'blocks.2.mhsa.q_mappings.2.weight',  'blocks.2.mhsa.q_mappings.3.weight',\n",
    "         'blocks.2.mhsa.q_mappings.4.weight',  'blocks.2.mhsa.q_mappings.5.weight',\n",
    "         'blocks.2.mhsa.q_mappings.6.weight',  'blocks.2.mhsa.q_mappings.7.weight',\n",
    "\n",
    "         'blocks.2.mhsa.k_mappings.0.weight',  'blocks.2.mhsa.k_mappings.1.weight',\n",
    "         'blocks.2.mhsa.k_mappings.2.weight',  'blocks.2.mhsa.k_mappings.3.weight',\n",
    "         'blocks.2.mhsa.k_mappings.4.weight',  'blocks.2.mhsa.k_mappings.5.weight',\n",
    "         'blocks.2.mhsa.k_mappings.6.weight',  'blocks.2.mhsa.k_mappings.7.weight',\n",
    "\n",
    "         'blocks.2.mhsa.v_mappings.0.weight',  'blocks.2.mhsa.v_mappings.1.weight',\n",
    "         'blocks.2.mhsa.v_mappings.2.weight',  'blocks.2.mhsa.v_mappings.3.weight',\n",
    "         'blocks.2.mhsa.v_mappings.4.weight',  'blocks.2.mhsa.v_mappings.5.weight',\n",
    "         'blocks.2.mhsa.v_mappings.6.weight',  'blocks.2.mhsa.v_mappings.7.weight',\n",
    "\n",
    "         'blocks.2.mlp.0.weight', 'blocks.2.mlp.2.weight',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         'blocks.3.mhsa.q_mappings.0.weight',  'blocks.3.mhsa.q_mappings.1.weight',\n",
    "         'blocks.3.mhsa.q_mappings.2.weight',  'blocks.3.mhsa.q_mappings.3.weight',\n",
    "         'blocks.3.mhsa.q_mappings.4.weight',  'blocks.3.mhsa.q_mappings.5.weight',\n",
    "         'blocks.3.mhsa.q_mappings.6.weight',  'blocks.3.mhsa.q_mappings.7.weight',\n",
    "\n",
    "         'blocks.3.mhsa.k_mappings.0.weight',  'blocks.3.mhsa.k_mappings.1.weight',\n",
    "         'blocks.3.mhsa.k_mappings.2.weight',  'blocks.3.mhsa.k_mappings.3.weight',\n",
    "         'blocks.3.mhsa.k_mappings.4.weight',  'blocks.3.mhsa.k_mappings.5.weight',\n",
    "         'blocks.3.mhsa.k_mappings.6.weight',  'blocks.3.mhsa.k_mappings.7.weight',\n",
    "\n",
    "         'blocks.3.mhsa.v_mappings.0.weight',  'blocks.3.mhsa.v_mappings.1.weight',\n",
    "         'blocks.3.mhsa.v_mappings.2.weight',  'blocks.3.mhsa.v_mappings.3.weight',\n",
    "         'blocks.3.mhsa.v_mappings.4.weight',  'blocks.3.mhsa.v_mappings.5.weight',\n",
    "         'blocks.3.mhsa.v_mappings.6.weight',  'blocks.3.mhsa.v_mappings.7.weight',\n",
    "\n",
    "         'blocks.3.mlp.0.weight', 'blocks.3.mlp.2.weight',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         'blocks.4.mhsa.q_mappings.0.weight',  'blocks.4.mhsa.q_mappings.1.weight',\n",
    "         'blocks.4.mhsa.q_mappings.2.weight',  'blocks.4.mhsa.q_mappings.3.weight',\n",
    "         'blocks.4.mhsa.q_mappings.4.weight',  'blocks.4.mhsa.q_mappings.5.weight',\n",
    "         'blocks.4.mhsa.q_mappings.6.weight',  'blocks.4.mhsa.q_mappings.7.weight',\n",
    "\n",
    "         'blocks.4.mhsa.k_mappings.0.weight',  'blocks.4.mhsa.k_mappings.1.weight',\n",
    "         'blocks.4.mhsa.k_mappings.2.weight',  'blocks.4.mhsa.k_mappings.3.weight',\n",
    "         'blocks.4.mhsa.k_mappings.4.weight',  'blocks.4.mhsa.k_mappings.5.weight',\n",
    "         'blocks.4.mhsa.k_mappings.6.weight',  'blocks.4.mhsa.k_mappings.7.weight',\n",
    "\n",
    "         'blocks.4.mhsa.v_mappings.0.weight',  'blocks.4.mhsa.v_mappings.1.weight',\n",
    "         'blocks.4.mhsa.v_mappings.2.weight',  'blocks.4.mhsa.v_mappings.3.weight',\n",
    "         'blocks.4.mhsa.v_mappings.4.weight',  'blocks.4.mhsa.v_mappings.5.weight',\n",
    "         'blocks.4.mhsa.v_mappings.6.weight',  'blocks.4.mhsa.v_mappings.7.weight',\n",
    "\n",
    "         'blocks.4.mlp.0.weight', 'blocks.4.mlp.2.weight',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         'blocks.5.mhsa.q_mappings.0.weight',  'blocks.5.mhsa.q_mappings.1.weight',\n",
    "         'blocks.5.mhsa.q_mappings.2.weight',  'blocks.5.mhsa.q_mappings.3.weight',\n",
    "         'blocks.5.mhsa.q_mappings.4.weight',  'blocks.5.mhsa.q_mappings.5.weight',\n",
    "         'blocks.5.mhsa.q_mappings.6.weight',  'blocks.5.mhsa.q_mappings.7.weight',\n",
    "\n",
    "         'blocks.5.mhsa.k_mappings.0.weight',  'blocks.5.mhsa.k_mappings.1.weight',\n",
    "         'blocks.5.mhsa.k_mappings.2.weight',  'blocks.5.mhsa.k_mappings.3.weight',\n",
    "         'blocks.5.mhsa.k_mappings.4.weight',  'blocks.5.mhsa.k_mappings.5.weight',\n",
    "         'blocks.5.mhsa.k_mappings.6.weight',  'blocks.5.mhsa.k_mappings.7.weight',\n",
    "\n",
    "         'blocks.5.mhsa.v_mappings.0.weight',  'blocks.5.mhsa.v_mappings.1.weight',\n",
    "         'blocks.5.mhsa.v_mappings.2.weight',  'blocks.5.mhsa.v_mappings.3.weight',\n",
    "         'blocks.5.mhsa.v_mappings.4.weight',  'blocks.5.mhsa.v_mappings.5.weight',\n",
    "         'blocks.5.mhsa.v_mappings.6.weight',  'blocks.5.mhsa.v_mappings.7.weight',\n",
    "\n",
    "         'blocks.5.mlp.0.weight', 'blocks.5.mlp.2.weight',\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         'blocks.6.mhsa.q_mappings.0.weight',  'blocks.6.mhsa.q_mappings.1.weight',\n",
    "         'blocks.6.mhsa.q_mappings.2.weight',  'blocks.6.mhsa.q_mappings.3.weight',\n",
    "         'blocks.6.mhsa.q_mappings.4.weight',  'blocks.6.mhsa.q_mappings.5.weight',\n",
    "         'blocks.6.mhsa.q_mappings.6.weight',  'blocks.6.mhsa.q_mappings.7.weight',\n",
    "\n",
    "         'blocks.6.mhsa.k_mappings.0.weight',  'blocks.6.mhsa.k_mappings.1.weight',\n",
    "         'blocks.6.mhsa.k_mappings.2.weight',  'blocks.6.mhsa.k_mappings.3.weight',\n",
    "         'blocks.6.mhsa.k_mappings.4.weight',  'blocks.6.mhsa.k_mappings.5.weight',\n",
    "         'blocks.6.mhsa.k_mappings.6.weight',  'blocks.6.mhsa.k_mappings.7.weight',\n",
    "\n",
    "         'blocks.6.mhsa.v_mappings.0.weight',  'blocks.6.mhsa.v_mappings.1.weight',\n",
    "         'blocks.6.mhsa.v_mappings.2.weight',  'blocks.6.mhsa.v_mappings.3.weight',\n",
    "         'blocks.6.mhsa.v_mappings.4.weight',  'blocks.6.mhsa.v_mappings.5.weight',\n",
    "         'blocks.6.mhsa.v_mappings.6.weight',  'blocks.6.mhsa.v_mappings.7.weight',\n",
    "\n",
    "         'blocks.6.mlp.0.weight', 'blocks.6.mlp.2.weight'\n",
    "    ]\n",
    "RANK = -1\n",
    "SCALING = -1\n",
    "BRANCH_ACC = \"0.879\"\n",
    "\n",
    "# CUDA setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Model setup\n",
    "original =  ViT((1, 28, 28), n_patches=14, n_blocks=7, hidden_d=512, n_heads=8, out_d=10).to(device)\n",
    "model_original =  ViT((1, 28, 28), n_patches=14, n_blocks=7, hidden_d=512, n_heads=8, out_d=10).to(device)\n",
    "\n",
    "# Load state from a checkpoint into the GPU directly\n",
    "BRANCH_LOC = HDFP + \"/lobranch-snapshot/branchpoints/vitS/branch_{}.pt\".format(BRANCH_ACC)\n",
    "original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "model_original.load_state_dict(torch.load(BRANCH_LOC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['class_token', 'linear_mapper.weight', 'linear_mapper.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.mhsa.q_mappings.0.weight', 'blocks.0.mhsa.q_mappings.0.bias', 'blocks.0.mhsa.q_mappings.1.weight', 'blocks.0.mhsa.q_mappings.1.bias', 'blocks.0.mhsa.q_mappings.2.weight', 'blocks.0.mhsa.q_mappings.2.bias', 'blocks.0.mhsa.q_mappings.3.weight', 'blocks.0.mhsa.q_mappings.3.bias', 'blocks.0.mhsa.q_mappings.4.weight', 'blocks.0.mhsa.q_mappings.4.bias', 'blocks.0.mhsa.q_mappings.5.weight', 'blocks.0.mhsa.q_mappings.5.bias', 'blocks.0.mhsa.q_mappings.6.weight', 'blocks.0.mhsa.q_mappings.6.bias', 'blocks.0.mhsa.q_mappings.7.weight', 'blocks.0.mhsa.q_mappings.7.bias', 'blocks.0.mhsa.k_mappings.0.weight', 'blocks.0.mhsa.k_mappings.0.bias', 'blocks.0.mhsa.k_mappings.1.weight', 'blocks.0.mhsa.k_mappings.1.bias', 'blocks.0.mhsa.k_mappings.2.weight', 'blocks.0.mhsa.k_mappings.2.bias', 'blocks.0.mhsa.k_mappings.3.weight', 'blocks.0.mhsa.k_mappings.3.bias', 'blocks.0.mhsa.k_mappings.4.weight', 'blocks.0.mhsa.k_mappings.4.bias', 'blocks.0.mhsa.k_mappings.5.weight', 'blocks.0.mhsa.k_mappings.5.bias', 'blocks.0.mhsa.k_mappings.6.weight', 'blocks.0.mhsa.k_mappings.6.bias', 'blocks.0.mhsa.k_mappings.7.weight', 'blocks.0.mhsa.k_mappings.7.bias', 'blocks.0.mhsa.v_mappings.0.weight', 'blocks.0.mhsa.v_mappings.0.bias', 'blocks.0.mhsa.v_mappings.1.weight', 'blocks.0.mhsa.v_mappings.1.bias', 'blocks.0.mhsa.v_mappings.2.weight', 'blocks.0.mhsa.v_mappings.2.bias', 'blocks.0.mhsa.v_mappings.3.weight', 'blocks.0.mhsa.v_mappings.3.bias', 'blocks.0.mhsa.v_mappings.4.weight', 'blocks.0.mhsa.v_mappings.4.bias', 'blocks.0.mhsa.v_mappings.5.weight', 'blocks.0.mhsa.v_mappings.5.bias', 'blocks.0.mhsa.v_mappings.6.weight', 'blocks.0.mhsa.v_mappings.6.bias', 'blocks.0.mhsa.v_mappings.7.weight', 'blocks.0.mhsa.v_mappings.7.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.0.weight', 'blocks.0.mlp.0.bias', 'blocks.0.mlp.2.weight', 'blocks.0.mlp.2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.mhsa.q_mappings.0.weight', 'blocks.1.mhsa.q_mappings.0.bias', 'blocks.1.mhsa.q_mappings.1.weight', 'blocks.1.mhsa.q_mappings.1.bias', 'blocks.1.mhsa.q_mappings.2.weight', 'blocks.1.mhsa.q_mappings.2.bias', 'blocks.1.mhsa.q_mappings.3.weight', 'blocks.1.mhsa.q_mappings.3.bias', 'blocks.1.mhsa.q_mappings.4.weight', 'blocks.1.mhsa.q_mappings.4.bias', 'blocks.1.mhsa.q_mappings.5.weight', 'blocks.1.mhsa.q_mappings.5.bias', 'blocks.1.mhsa.q_mappings.6.weight', 'blocks.1.mhsa.q_mappings.6.bias', 'blocks.1.mhsa.q_mappings.7.weight', 'blocks.1.mhsa.q_mappings.7.bias', 'blocks.1.mhsa.k_mappings.0.weight', 'blocks.1.mhsa.k_mappings.0.bias', 'blocks.1.mhsa.k_mappings.1.weight', 'blocks.1.mhsa.k_mappings.1.bias', 'blocks.1.mhsa.k_mappings.2.weight', 'blocks.1.mhsa.k_mappings.2.bias', 'blocks.1.mhsa.k_mappings.3.weight', 'blocks.1.mhsa.k_mappings.3.bias', 'blocks.1.mhsa.k_mappings.4.weight', 'blocks.1.mhsa.k_mappings.4.bias', 'blocks.1.mhsa.k_mappings.5.weight', 'blocks.1.mhsa.k_mappings.5.bias', 'blocks.1.mhsa.k_mappings.6.weight', 'blocks.1.mhsa.k_mappings.6.bias', 'blocks.1.mhsa.k_mappings.7.weight', 'blocks.1.mhsa.k_mappings.7.bias', 'blocks.1.mhsa.v_mappings.0.weight', 'blocks.1.mhsa.v_mappings.0.bias', 'blocks.1.mhsa.v_mappings.1.weight', 'blocks.1.mhsa.v_mappings.1.bias', 'blocks.1.mhsa.v_mappings.2.weight', 'blocks.1.mhsa.v_mappings.2.bias', 'blocks.1.mhsa.v_mappings.3.weight', 'blocks.1.mhsa.v_mappings.3.bias', 'blocks.1.mhsa.v_mappings.4.weight', 'blocks.1.mhsa.v_mappings.4.bias', 'blocks.1.mhsa.v_mappings.5.weight', 'blocks.1.mhsa.v_mappings.5.bias', 'blocks.1.mhsa.v_mappings.6.weight', 'blocks.1.mhsa.v_mappings.6.bias', 'blocks.1.mhsa.v_mappings.7.weight', 'blocks.1.mhsa.v_mappings.7.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.0.weight', 'blocks.1.mlp.0.bias', 'blocks.1.mlp.2.weight', 'blocks.1.mlp.2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.mhsa.q_mappings.0.weight', 'blocks.2.mhsa.q_mappings.0.bias', 'blocks.2.mhsa.q_mappings.1.weight', 'blocks.2.mhsa.q_mappings.1.bias', 'blocks.2.mhsa.q_mappings.2.weight', 'blocks.2.mhsa.q_mappings.2.bias', 'blocks.2.mhsa.q_mappings.3.weight', 'blocks.2.mhsa.q_mappings.3.bias', 'blocks.2.mhsa.q_mappings.4.weight', 'blocks.2.mhsa.q_mappings.4.bias', 'blocks.2.mhsa.q_mappings.5.weight', 'blocks.2.mhsa.q_mappings.5.bias', 'blocks.2.mhsa.q_mappings.6.weight', 'blocks.2.mhsa.q_mappings.6.bias', 'blocks.2.mhsa.q_mappings.7.weight', 'blocks.2.mhsa.q_mappings.7.bias', 'blocks.2.mhsa.k_mappings.0.weight', 'blocks.2.mhsa.k_mappings.0.bias', 'blocks.2.mhsa.k_mappings.1.weight', 'blocks.2.mhsa.k_mappings.1.bias', 'blocks.2.mhsa.k_mappings.2.weight', 'blocks.2.mhsa.k_mappings.2.bias', 'blocks.2.mhsa.k_mappings.3.weight', 'blocks.2.mhsa.k_mappings.3.bias', 'blocks.2.mhsa.k_mappings.4.weight', 'blocks.2.mhsa.k_mappings.4.bias', 'blocks.2.mhsa.k_mappings.5.weight', 'blocks.2.mhsa.k_mappings.5.bias', 'blocks.2.mhsa.k_mappings.6.weight', 'blocks.2.mhsa.k_mappings.6.bias', 'blocks.2.mhsa.k_mappings.7.weight', 'blocks.2.mhsa.k_mappings.7.bias', 'blocks.2.mhsa.v_mappings.0.weight', 'blocks.2.mhsa.v_mappings.0.bias', 'blocks.2.mhsa.v_mappings.1.weight', 'blocks.2.mhsa.v_mappings.1.bias', 'blocks.2.mhsa.v_mappings.2.weight', 'blocks.2.mhsa.v_mappings.2.bias', 'blocks.2.mhsa.v_mappings.3.weight', 'blocks.2.mhsa.v_mappings.3.bias', 'blocks.2.mhsa.v_mappings.4.weight', 'blocks.2.mhsa.v_mappings.4.bias', 'blocks.2.mhsa.v_mappings.5.weight', 'blocks.2.mhsa.v_mappings.5.bias', 'blocks.2.mhsa.v_mappings.6.weight', 'blocks.2.mhsa.v_mappings.6.bias', 'blocks.2.mhsa.v_mappings.7.weight', 'blocks.2.mhsa.v_mappings.7.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.0.weight', 'blocks.2.mlp.0.bias', 'blocks.2.mlp.2.weight', 'blocks.2.mlp.2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.mhsa.q_mappings.0.weight', 'blocks.3.mhsa.q_mappings.0.bias', 'blocks.3.mhsa.q_mappings.1.weight', 'blocks.3.mhsa.q_mappings.1.bias', 'blocks.3.mhsa.q_mappings.2.weight', 'blocks.3.mhsa.q_mappings.2.bias', 'blocks.3.mhsa.q_mappings.3.weight', 'blocks.3.mhsa.q_mappings.3.bias', 'blocks.3.mhsa.q_mappings.4.weight', 'blocks.3.mhsa.q_mappings.4.bias', 'blocks.3.mhsa.q_mappings.5.weight', 'blocks.3.mhsa.q_mappings.5.bias', 'blocks.3.mhsa.q_mappings.6.weight', 'blocks.3.mhsa.q_mappings.6.bias', 'blocks.3.mhsa.q_mappings.7.weight', 'blocks.3.mhsa.q_mappings.7.bias', 'blocks.3.mhsa.k_mappings.0.weight', 'blocks.3.mhsa.k_mappings.0.bias', 'blocks.3.mhsa.k_mappings.1.weight', 'blocks.3.mhsa.k_mappings.1.bias', 'blocks.3.mhsa.k_mappings.2.weight', 'blocks.3.mhsa.k_mappings.2.bias', 'blocks.3.mhsa.k_mappings.3.weight', 'blocks.3.mhsa.k_mappings.3.bias', 'blocks.3.mhsa.k_mappings.4.weight', 'blocks.3.mhsa.k_mappings.4.bias', 'blocks.3.mhsa.k_mappings.5.weight', 'blocks.3.mhsa.k_mappings.5.bias', 'blocks.3.mhsa.k_mappings.6.weight', 'blocks.3.mhsa.k_mappings.6.bias', 'blocks.3.mhsa.k_mappings.7.weight', 'blocks.3.mhsa.k_mappings.7.bias', 'blocks.3.mhsa.v_mappings.0.weight', 'blocks.3.mhsa.v_mappings.0.bias', 'blocks.3.mhsa.v_mappings.1.weight', 'blocks.3.mhsa.v_mappings.1.bias', 'blocks.3.mhsa.v_mappings.2.weight', 'blocks.3.mhsa.v_mappings.2.bias', 'blocks.3.mhsa.v_mappings.3.weight', 'blocks.3.mhsa.v_mappings.3.bias', 'blocks.3.mhsa.v_mappings.4.weight', 'blocks.3.mhsa.v_mappings.4.bias', 'blocks.3.mhsa.v_mappings.5.weight', 'blocks.3.mhsa.v_mappings.5.bias', 'blocks.3.mhsa.v_mappings.6.weight', 'blocks.3.mhsa.v_mappings.6.bias', 'blocks.3.mhsa.v_mappings.7.weight', 'blocks.3.mhsa.v_mappings.7.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.0.weight', 'blocks.3.mlp.0.bias', 'blocks.3.mlp.2.weight', 'blocks.3.mlp.2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.mhsa.q_mappings.0.weight', 'blocks.4.mhsa.q_mappings.0.bias', 'blocks.4.mhsa.q_mappings.1.weight', 'blocks.4.mhsa.q_mappings.1.bias', 'blocks.4.mhsa.q_mappings.2.weight', 'blocks.4.mhsa.q_mappings.2.bias', 'blocks.4.mhsa.q_mappings.3.weight', 'blocks.4.mhsa.q_mappings.3.bias', 'blocks.4.mhsa.q_mappings.4.weight', 'blocks.4.mhsa.q_mappings.4.bias', 'blocks.4.mhsa.q_mappings.5.weight', 'blocks.4.mhsa.q_mappings.5.bias', 'blocks.4.mhsa.q_mappings.6.weight', 'blocks.4.mhsa.q_mappings.6.bias', 'blocks.4.mhsa.q_mappings.7.weight', 'blocks.4.mhsa.q_mappings.7.bias', 'blocks.4.mhsa.k_mappings.0.weight', 'blocks.4.mhsa.k_mappings.0.bias', 'blocks.4.mhsa.k_mappings.1.weight', 'blocks.4.mhsa.k_mappings.1.bias', 'blocks.4.mhsa.k_mappings.2.weight', 'blocks.4.mhsa.k_mappings.2.bias', 'blocks.4.mhsa.k_mappings.3.weight', 'blocks.4.mhsa.k_mappings.3.bias', 'blocks.4.mhsa.k_mappings.4.weight', 'blocks.4.mhsa.k_mappings.4.bias', 'blocks.4.mhsa.k_mappings.5.weight', 'blocks.4.mhsa.k_mappings.5.bias', 'blocks.4.mhsa.k_mappings.6.weight', 'blocks.4.mhsa.k_mappings.6.bias', 'blocks.4.mhsa.k_mappings.7.weight', 'blocks.4.mhsa.k_mappings.7.bias', 'blocks.4.mhsa.v_mappings.0.weight', 'blocks.4.mhsa.v_mappings.0.bias', 'blocks.4.mhsa.v_mappings.1.weight', 'blocks.4.mhsa.v_mappings.1.bias', 'blocks.4.mhsa.v_mappings.2.weight', 'blocks.4.mhsa.v_mappings.2.bias', 'blocks.4.mhsa.v_mappings.3.weight', 'blocks.4.mhsa.v_mappings.3.bias', 'blocks.4.mhsa.v_mappings.4.weight', 'blocks.4.mhsa.v_mappings.4.bias', 'blocks.4.mhsa.v_mappings.5.weight', 'blocks.4.mhsa.v_mappings.5.bias', 'blocks.4.mhsa.v_mappings.6.weight', 'blocks.4.mhsa.v_mappings.6.bias', 'blocks.4.mhsa.v_mappings.7.weight', 'blocks.4.mhsa.v_mappings.7.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.0.weight', 'blocks.4.mlp.0.bias', 'blocks.4.mlp.2.weight', 'blocks.4.mlp.2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.mhsa.q_mappings.0.weight', 'blocks.5.mhsa.q_mappings.0.bias', 'blocks.5.mhsa.q_mappings.1.weight', 'blocks.5.mhsa.q_mappings.1.bias', 'blocks.5.mhsa.q_mappings.2.weight', 'blocks.5.mhsa.q_mappings.2.bias', 'blocks.5.mhsa.q_mappings.3.weight', 'blocks.5.mhsa.q_mappings.3.bias', 'blocks.5.mhsa.q_mappings.4.weight', 'blocks.5.mhsa.q_mappings.4.bias', 'blocks.5.mhsa.q_mappings.5.weight', 'blocks.5.mhsa.q_mappings.5.bias', 'blocks.5.mhsa.q_mappings.6.weight', 'blocks.5.mhsa.q_mappings.6.bias', 'blocks.5.mhsa.q_mappings.7.weight', 'blocks.5.mhsa.q_mappings.7.bias', 'blocks.5.mhsa.k_mappings.0.weight', 'blocks.5.mhsa.k_mappings.0.bias', 'blocks.5.mhsa.k_mappings.1.weight', 'blocks.5.mhsa.k_mappings.1.bias', 'blocks.5.mhsa.k_mappings.2.weight', 'blocks.5.mhsa.k_mappings.2.bias', 'blocks.5.mhsa.k_mappings.3.weight', 'blocks.5.mhsa.k_mappings.3.bias', 'blocks.5.mhsa.k_mappings.4.weight', 'blocks.5.mhsa.k_mappings.4.bias', 'blocks.5.mhsa.k_mappings.5.weight', 'blocks.5.mhsa.k_mappings.5.bias', 'blocks.5.mhsa.k_mappings.6.weight', 'blocks.5.mhsa.k_mappings.6.bias', 'blocks.5.mhsa.k_mappings.7.weight', 'blocks.5.mhsa.k_mappings.7.bias', 'blocks.5.mhsa.v_mappings.0.weight', 'blocks.5.mhsa.v_mappings.0.bias', 'blocks.5.mhsa.v_mappings.1.weight', 'blocks.5.mhsa.v_mappings.1.bias', 'blocks.5.mhsa.v_mappings.2.weight', 'blocks.5.mhsa.v_mappings.2.bias', 'blocks.5.mhsa.v_mappings.3.weight', 'blocks.5.mhsa.v_mappings.3.bias', 'blocks.5.mhsa.v_mappings.4.weight', 'blocks.5.mhsa.v_mappings.4.bias', 'blocks.5.mhsa.v_mappings.5.weight', 'blocks.5.mhsa.v_mappings.5.bias', 'blocks.5.mhsa.v_mappings.6.weight', 'blocks.5.mhsa.v_mappings.6.bias', 'blocks.5.mhsa.v_mappings.7.weight', 'blocks.5.mhsa.v_mappings.7.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.0.weight', 'blocks.5.mlp.0.bias', 'blocks.5.mlp.2.weight', 'blocks.5.mlp.2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.mhsa.q_mappings.0.weight', 'blocks.6.mhsa.q_mappings.0.bias', 'blocks.6.mhsa.q_mappings.1.weight', 'blocks.6.mhsa.q_mappings.1.bias', 'blocks.6.mhsa.q_mappings.2.weight', 'blocks.6.mhsa.q_mappings.2.bias', 'blocks.6.mhsa.q_mappings.3.weight', 'blocks.6.mhsa.q_mappings.3.bias', 'blocks.6.mhsa.q_mappings.4.weight', 'blocks.6.mhsa.q_mappings.4.bias', 'blocks.6.mhsa.q_mappings.5.weight', 'blocks.6.mhsa.q_mappings.5.bias', 'blocks.6.mhsa.q_mappings.6.weight', 'blocks.6.mhsa.q_mappings.6.bias', 'blocks.6.mhsa.q_mappings.7.weight', 'blocks.6.mhsa.q_mappings.7.bias', 'blocks.6.mhsa.k_mappings.0.weight', 'blocks.6.mhsa.k_mappings.0.bias', 'blocks.6.mhsa.k_mappings.1.weight', 'blocks.6.mhsa.k_mappings.1.bias', 'blocks.6.mhsa.k_mappings.2.weight', 'blocks.6.mhsa.k_mappings.2.bias', 'blocks.6.mhsa.k_mappings.3.weight', 'blocks.6.mhsa.k_mappings.3.bias', 'blocks.6.mhsa.k_mappings.4.weight', 'blocks.6.mhsa.k_mappings.4.bias', 'blocks.6.mhsa.k_mappings.5.weight', 'blocks.6.mhsa.k_mappings.5.bias', 'blocks.6.mhsa.k_mappings.6.weight', 'blocks.6.mhsa.k_mappings.6.bias', 'blocks.6.mhsa.k_mappings.7.weight', 'blocks.6.mhsa.k_mappings.7.bias', 'blocks.6.mhsa.v_mappings.0.weight', 'blocks.6.mhsa.v_mappings.0.bias', 'blocks.6.mhsa.v_mappings.1.weight', 'blocks.6.mhsa.v_mappings.1.bias', 'blocks.6.mhsa.v_mappings.2.weight', 'blocks.6.mhsa.v_mappings.2.bias', 'blocks.6.mhsa.v_mappings.3.weight', 'blocks.6.mhsa.v_mappings.3.bias', 'blocks.6.mhsa.v_mappings.4.weight', 'blocks.6.mhsa.v_mappings.4.bias', 'blocks.6.mhsa.v_mappings.5.weight', 'blocks.6.mhsa.v_mappings.5.bias', 'blocks.6.mhsa.v_mappings.6.weight', 'blocks.6.mhsa.v_mappings.6.bias', 'blocks.6.mhsa.v_mappings.7.weight', 'blocks.6.mhsa.v_mappings.7.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.0.weight', 'blocks.6.mlp.0.bias', 'blocks.6.mlp.2.weight', 'blocks.6.mlp.2.bias', 'mlp.0.weight', 'mlp.0.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model_original.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = getBase(model_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0023, -0.0146, -0.0163,  ...,  0.1013,  0.0769,  0.0267],\n",
       "         [ 0.0247,  0.1231,  0.0782,  ..., -0.0570,  0.0177,  0.0170],\n",
       "         [ 0.0700,  0.0912, -0.0995,  ..., -0.0684, -0.0161,  0.0266],\n",
       "         ...,\n",
       "         [-0.1018, -0.0625, -0.0134,  ..., -0.1136, -0.1186,  0.0560],\n",
       "         [-0.0645, -0.1099,  0.0692,  ...,  0.0732,  0.1174, -0.0889],\n",
       "         [ 0.1082,  0.1057, -0.0511,  ...,  0.0626,  0.1135,  0.0233]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.1883e-01,  1.8452e-02,  7.1516e-02,  ...,  4.7337e-02,\n",
       "           2.8415e-02,  1.0106e-01],\n",
       "         [-5.5686e-02, -8.1730e-02,  7.3673e-02,  ..., -1.0128e-01,\n",
       "           1.0847e-01, -1.2321e-01],\n",
       "         [-5.1252e-02,  1.7183e-02,  1.2380e-01,  ...,  5.4581e-04,\n",
       "          -1.0457e-01,  9.2886e-02],\n",
       "         ...,\n",
       "         [ 7.3467e-02, -4.1369e-02, -1.2009e-01,  ...,  3.1768e-02,\n",
       "          -2.7438e-04,  6.0171e-02],\n",
       "         [-3.5405e-02,  7.9196e-03, -8.0665e-05,  ...,  1.0943e-01,\n",
       "           1.6662e-02,  1.0958e-01],\n",
       "         [ 6.9491e-02, -4.8954e-02, -4.6082e-02,  ..., -3.0283e-02,\n",
       "           6.9645e-02, -5.0751e-02]], device='cuda:0'),\n",
       " tensor([[ 0.1056, -0.0963,  0.0602,  ..., -0.0532,  0.0359, -0.0049],\n",
       "         [-0.1196,  0.0807, -0.0421,  ...,  0.0640,  0.1129,  0.0282],\n",
       "         [ 0.0284, -0.1215, -0.0266,  ..., -0.0471, -0.0077, -0.0334],\n",
       "         ...,\n",
       "         [ 0.1225, -0.0230,  0.0156,  ..., -0.0047, -0.1225,  0.0674],\n",
       "         [-0.0576, -0.0742, -0.0860,  ..., -0.0350, -0.0977,  0.0012],\n",
       "         [ 0.0136, -0.1097,  0.0607,  ...,  0.1117, -0.1089,  0.0064]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1134, -0.0650,  0.0319,  ...,  0.0335, -0.0993, -0.0964],\n",
       "         [ 0.1175, -0.1234, -0.1026,  ...,  0.1066, -0.0348,  0.0113],\n",
       "         [-0.0439, -0.0007,  0.0152,  ..., -0.0111,  0.0600,  0.0872],\n",
       "         ...,\n",
       "         [-0.0362,  0.1202,  0.1143,  ..., -0.0399, -0.0176,  0.0417],\n",
       "         [ 0.0331,  0.0248, -0.0355,  ...,  0.0968,  0.1149, -0.1190],\n",
       "         [-0.0918, -0.0261,  0.0989,  ...,  0.0112,  0.0416, -0.0960]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0119,  0.0452,  0.0080,  ...,  0.0470,  0.0467, -0.1150],\n",
       "         [-0.0654, -0.0876, -0.0578,  ..., -0.1113, -0.0703, -0.1078],\n",
       "         [-0.0753,  0.0245,  0.0635,  ..., -0.1182,  0.0822,  0.0177],\n",
       "         ...,\n",
       "         [-0.1027, -0.0041, -0.1083,  ...,  0.0842, -0.1129, -0.0219],\n",
       "         [ 0.0835,  0.0199, -0.1189,  ..., -0.0583,  0.0154, -0.0463],\n",
       "         [-0.0406,  0.0199, -0.0308,  ..., -0.0591, -0.0665,  0.0815]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0174,  0.0287, -0.0417,  ..., -0.0147,  0.0339, -0.0921],\n",
       "         [-0.0094,  0.0399,  0.0363,  ...,  0.1063, -0.1078,  0.0855],\n",
       "         [ 0.0190, -0.0978, -0.0167,  ..., -0.1248,  0.0432, -0.0594],\n",
       "         ...,\n",
       "         [-0.0805, -0.0095, -0.0130,  ...,  0.0461,  0.0209, -0.1050],\n",
       "         [-0.0597, -0.1022,  0.0049,  ..., -0.0256,  0.0977,  0.1159],\n",
       "         [ 0.0411, -0.1244, -0.0943,  ..., -0.0970, -0.0908,  0.0673]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1089,  0.0176, -0.0509,  ...,  0.0852,  0.0121, -0.0356],\n",
       "         [-0.0899,  0.1080, -0.0361,  ...,  0.0425, -0.0319, -0.0424],\n",
       "         [-0.0092, -0.0540,  0.0581,  ..., -0.1137,  0.0232,  0.0192],\n",
       "         ...,\n",
       "         [ 0.0273,  0.1173, -0.0762,  ..., -0.0402, -0.1238,  0.0791],\n",
       "         [-0.0897, -0.0703, -0.0072,  ...,  0.0110, -0.1143, -0.0036],\n",
       "         [-0.0991, -0.0663,  0.0650,  ...,  0.0594, -0.1158, -0.1246]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0594, -0.0993, -0.1062,  ...,  0.0009,  0.0094,  0.1221],\n",
       "         [-0.0558, -0.0062, -0.0869,  ..., -0.1164, -0.0721,  0.0726],\n",
       "         [ 0.0842, -0.0629,  0.1128,  ...,  0.1015,  0.0192,  0.0604],\n",
       "         ...,\n",
       "         [ 0.0791, -0.0502,  0.0338,  ..., -0.0143, -0.0287, -0.0925],\n",
       "         [-0.0057,  0.1183,  0.0007,  ...,  0.0138, -0.0299, -0.0478],\n",
       "         [ 0.0312, -0.0803, -0.0829,  ..., -0.0234, -0.0101,  0.0846]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0635,  0.0594, -0.0117,  ..., -0.0940,  0.0195,  0.0060],\n",
       "         [ 0.0580, -0.1067,  0.0439,  ..., -0.0374, -0.0382,  0.1046],\n",
       "         [-0.0303, -0.0297, -0.0948,  ..., -0.0419, -0.0238, -0.0173],\n",
       "         ...,\n",
       "         [ 0.0665,  0.0284, -0.0695,  ..., -0.0796,  0.0135, -0.0162],\n",
       "         [ 0.0685, -0.0664, -0.0457,  ..., -0.0591, -0.0318, -0.0802],\n",
       "         [ 0.0206,  0.0801, -0.1228,  ...,  0.0024,  0.0845, -0.1187]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0523,  0.0886, -0.0448,  ...,  0.1123, -0.0435,  0.1091],\n",
       "         [-0.0816,  0.0499, -0.1175,  ..., -0.0837,  0.0790,  0.0499],\n",
       "         [ 0.1109, -0.0102,  0.0545,  ...,  0.0049, -0.0293,  0.0968],\n",
       "         ...,\n",
       "         [-0.0008,  0.1161, -0.1228,  ..., -0.0633,  0.0648, -0.0274],\n",
       "         [ 0.1092,  0.0577, -0.1110,  ...,  0.0308,  0.0335, -0.1042],\n",
       "         [ 0.0552,  0.0572,  0.0427,  ...,  0.0587,  0.0587,  0.0016]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1114, -0.0845, -0.0328,  ..., -0.0097, -0.0146, -0.0137],\n",
       "         [ 0.0721, -0.0693,  0.1066,  ...,  0.0785, -0.0927, -0.0187],\n",
       "         [ 0.0870,  0.1088, -0.0321,  ...,  0.0676, -0.0415,  0.1092],\n",
       "         ...,\n",
       "         [-0.1200, -0.0442,  0.0654,  ...,  0.0658, -0.0235,  0.0159],\n",
       "         [-0.0921, -0.0512,  0.1177,  ...,  0.0386,  0.0662, -0.0557],\n",
       "         [ 0.0119, -0.0451,  0.0675,  ...,  0.0957,  0.0800,  0.0873]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0418,  0.1047,  0.0909,  ...,  0.0085,  0.0977,  0.0504],\n",
       "         [ 0.1108,  0.1093,  0.1115,  ...,  0.0002,  0.0803, -0.1119],\n",
       "         [-0.0694, -0.0238, -0.0702,  ..., -0.0327, -0.0192,  0.1105],\n",
       "         ...,\n",
       "         [-0.0773, -0.0800,  0.0798,  ...,  0.0789,  0.0687,  0.0973],\n",
       "         [ 0.0032,  0.0820,  0.1055,  ...,  0.0159, -0.1013,  0.0060],\n",
       "         [ 0.0145, -0.0912, -0.0381,  ..., -0.0188, -0.0561,  0.0875]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0569,  0.0618, -0.0762,  ..., -0.0610,  0.0991,  0.0137],\n",
       "         [ 0.0309,  0.0146,  0.0946,  ..., -0.0848, -0.0174, -0.0545],\n",
       "         [-0.1166,  0.0002, -0.1145,  ...,  0.0839, -0.0363,  0.0650],\n",
       "         ...,\n",
       "         [ 0.0007,  0.0464,  0.0021,  ...,  0.1043,  0.0224,  0.0069],\n",
       "         [ 0.1215, -0.0358,  0.0499,  ..., -0.0800, -0.0110,  0.0107],\n",
       "         [-0.0731, -0.0485, -0.0824,  ...,  0.0094, -0.0514,  0.1212]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0853,  0.0093,  0.1176,  ..., -0.0895,  0.0457, -0.1228],\n",
       "         [-0.0487, -0.1181, -0.0240,  ..., -0.0531,  0.0948, -0.0077],\n",
       "         [-0.0067,  0.0621,  0.0205,  ..., -0.1141,  0.0359, -0.0712],\n",
       "         ...,\n",
       "         [ 0.0265,  0.0473,  0.0990,  ...,  0.0884, -0.0358,  0.0132],\n",
       "         [-0.1189,  0.0351, -0.0396,  ...,  0.0123, -0.0012,  0.0670],\n",
       "         [-0.0567,  0.0249,  0.0761,  ...,  0.0124,  0.0594,  0.0542]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0137,  0.0738,  0.0182,  ...,  0.0045, -0.0232,  0.1143],\n",
       "         [-0.0514,  0.0492, -0.0073,  ...,  0.0727,  0.0906, -0.0803],\n",
       "         [ 0.0508,  0.0196,  0.0268,  ...,  0.0863, -0.0577, -0.1056],\n",
       "         ...,\n",
       "         [-0.0741,  0.0677, -0.0503,  ...,  0.0951,  0.0386, -0.0436],\n",
       "         [ 0.0837,  0.0882, -0.0782,  ...,  0.0405,  0.0506,  0.0503],\n",
       "         [-0.1181, -0.0643,  0.0317,  ..., -0.0331,  0.0167,  0.0369]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1016,  0.1123, -0.0501,  ...,  0.1101, -0.0475, -0.0224],\n",
       "         [-0.1002,  0.0959, -0.0210,  ...,  0.0677, -0.0332, -0.0755],\n",
       "         [-0.0373, -0.0007, -0.1118,  ..., -0.1230,  0.0272,  0.0447],\n",
       "         ...,\n",
       "         [-0.1219, -0.1170,  0.0335,  ..., -0.0780,  0.1122,  0.0506],\n",
       "         [-0.1160, -0.1090,  0.0933,  ..., -0.0537,  0.1090, -0.0422],\n",
       "         [-0.0878,  0.0807, -0.0456,  ..., -0.0596,  0.0446,  0.0699]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0498,  0.0395,  0.0736,  ...,  0.1124, -0.0066,  0.0471],\n",
       "         [ 0.0525, -0.0782, -0.0156,  ..., -0.0942, -0.0595,  0.1183],\n",
       "         [-0.1238,  0.0362,  0.1048,  ..., -0.0939, -0.0971, -0.0850],\n",
       "         ...,\n",
       "         [-0.0654,  0.0721,  0.0083,  ...,  0.0750,  0.0852,  0.1202],\n",
       "         [-0.0940,  0.1129,  0.0655,  ...,  0.0192,  0.0684, -0.0162],\n",
       "         [-0.0593,  0.0711, -0.0643,  ...,  0.0529, -0.0557, -0.0158]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0699,  0.0167,  0.0651,  ..., -0.0680,  0.0555, -0.0478],\n",
       "         [-0.0152,  0.0148,  0.0830,  ..., -0.0441, -0.0570, -0.0439],\n",
       "         [-0.0718, -0.0140,  0.0707,  ...,  0.0924, -0.1169, -0.0867],\n",
       "         ...,\n",
       "         [ 0.0310,  0.0331,  0.0144,  ..., -0.0215, -0.0152,  0.0852],\n",
       "         [ 0.0310, -0.0963,  0.1241,  ...,  0.0855, -0.0142,  0.0106],\n",
       "         [-0.0211, -0.0603, -0.0425,  ...,  0.1042, -0.0694, -0.1102]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 3.3061e-02,  1.3988e-02,  1.9662e-02,  ...,  1.1908e-01,\n",
       "           1.1813e-01,  7.0163e-03],\n",
       "         [-3.7652e-04, -4.9025e-02,  9.6697e-02,  ..., -2.8248e-02,\n",
       "          -1.2041e-01,  3.5737e-02],\n",
       "         [ 2.6530e-02, -1.1288e-01, -6.8427e-03,  ..., -4.9188e-02,\n",
       "          -1.5548e-02,  1.2571e-01],\n",
       "         ...,\n",
       "         [ 9.4605e-02,  1.0447e-01,  1.0284e-04,  ...,  4.6981e-02,\n",
       "          -6.6362e-02, -1.0623e-01],\n",
       "         [-3.8694e-02, -6.5639e-02,  1.4931e-02,  ..., -5.4153e-02,\n",
       "          -9.1999e-02, -1.4466e-02],\n",
       "         [-1.1638e-01,  8.1187e-02, -5.9491e-02,  ..., -3.5108e-02,\n",
       "          -6.7492e-02,  1.7690e-02]], device='cuda:0'),\n",
       " tensor([[-0.0179,  0.1063, -0.0855,  ...,  0.0733,  0.1046, -0.0902],\n",
       "         [-0.0714,  0.0394, -0.0836,  ...,  0.0081, -0.0805,  0.1077],\n",
       "         [ 0.0217,  0.0057, -0.0223,  ...,  0.1122, -0.0880,  0.1033],\n",
       "         ...,\n",
       "         [-0.0725,  0.0373,  0.0107,  ..., -0.0689, -0.1114, -0.0880],\n",
       "         [-0.1049, -0.0332, -0.0789,  ..., -0.0840, -0.1251, -0.0736],\n",
       "         [ 0.1017,  0.0389,  0.1276,  ..., -0.0227,  0.0422,  0.0061]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0320, -0.0384,  0.0981,  ...,  0.1131,  0.0162, -0.1169],\n",
       "         [ 0.0706,  0.0627,  0.0103,  ..., -0.0756,  0.0012, -0.0825],\n",
       "         [ 0.0288, -0.0235,  0.0377,  ...,  0.1201,  0.0291, -0.0266],\n",
       "         ...,\n",
       "         [ 0.0654, -0.0934,  0.1068,  ..., -0.0271,  0.1083,  0.0216],\n",
       "         [-0.0048,  0.0104, -0.0146,  ..., -0.0440,  0.0459,  0.0271],\n",
       "         [-0.1020, -0.1182,  0.0247,  ...,  0.0655,  0.0990,  0.1021]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0397,  0.1047, -0.1134,  ...,  0.0427,  0.0604,  0.0537],\n",
       "         [ 0.0686, -0.1031,  0.0295,  ..., -0.0434, -0.0020, -0.0923],\n",
       "         [-0.1082, -0.0107, -0.0348,  ...,  0.0273,  0.0929, -0.0976],\n",
       "         ...,\n",
       "         [ 0.1033,  0.0994,  0.0044,  ..., -0.0205, -0.1215, -0.1217],\n",
       "         [-0.0118,  0.0208,  0.0628,  ..., -0.0146,  0.0912, -0.0417],\n",
       "         [ 0.0912, -0.0224, -0.0881,  ..., -0.0458, -0.0545, -0.0911]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0462,  0.0347,  0.1233,  ...,  0.1111, -0.0081,  0.0418],\n",
       "         [ 0.0786, -0.0667,  0.0718,  ..., -0.0652,  0.0900,  0.0568],\n",
       "         [-0.0533,  0.0612,  0.0785,  ..., -0.0182, -0.0925,  0.1162],\n",
       "         ...,\n",
       "         [ 0.0006, -0.0171,  0.0608,  ..., -0.0937, -0.0097, -0.0559],\n",
       "         [-0.0621,  0.0833, -0.0457,  ...,  0.1094, -0.0681,  0.0497],\n",
       "         [-0.0120, -0.1135, -0.0237,  ...,  0.0613, -0.0909, -0.0525]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1141, -0.0645,  0.0966,  ..., -0.0217, -0.0326,  0.0640],\n",
       "         [-0.0195, -0.0636,  0.0167,  ...,  0.0543, -0.0057, -0.0893],\n",
       "         [-0.0042, -0.0752, -0.1254,  ..., -0.0569, -0.1168,  0.0005],\n",
       "         ...,\n",
       "         [-0.0712, -0.0602, -0.1149,  ...,  0.0205, -0.1099,  0.0318],\n",
       "         [-0.0206,  0.0775,  0.0220,  ..., -0.0578,  0.0596,  0.1128],\n",
       "         [-0.0545, -0.0316,  0.0023,  ..., -0.0838,  0.0971, -0.0112]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0011,  0.0164,  0.0397,  ...,  0.0363,  0.0173,  0.0199],\n",
       "         [-0.0183, -0.0327,  0.0329,  ..., -0.0305,  0.0243, -0.0011],\n",
       "         [-0.0058, -0.0145,  0.0269,  ..., -0.0243, -0.0341, -0.0335],\n",
       "         ...,\n",
       "         [-0.0131,  0.0170, -0.0143,  ...,  0.0377, -0.0320,  0.0292],\n",
       "         [ 0.0267, -0.0375, -0.0210,  ...,  0.0211, -0.0395, -0.0067],\n",
       "         [ 0.0071, -0.0263,  0.0229,  ..., -0.0426,  0.0073, -0.0121]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-1.8312e-02,  1.6145e-02,  6.4457e-05,  ...,  2.6063e-03,\n",
       "           1.1054e-02,  1.8778e-02],\n",
       "         [-1.7530e-02,  1.7663e-02,  1.8783e-02,  ...,  1.8028e-02,\n",
       "          -1.4111e-02, -1.5557e-02],\n",
       "         [ 1.5411e-02,  1.2158e-03, -6.4273e-03,  ...,  1.5045e-02,\n",
       "          -2.2384e-02,  1.8283e-02],\n",
       "         ...,\n",
       "         [-1.9284e-02,  2.1751e-02,  9.2916e-03,  ..., -2.4175e-03,\n",
       "           1.9177e-02, -1.2199e-02],\n",
       "         [-1.5349e-02,  1.3098e-02, -5.0742e-03,  ...,  1.2836e-02,\n",
       "          -8.0811e-03, -1.0090e-02],\n",
       "         [-2.1876e-02,  2.0689e-02,  1.0802e-02,  ..., -1.8674e-02,\n",
       "           1.3263e-03,  1.3841e-02]], device='cuda:0'),\n",
       " tensor([[ 0.0979,  0.0846, -0.0926,  ..., -0.0722,  0.0771,  0.0914],\n",
       "         [-0.0642, -0.1050, -0.1130,  ...,  0.0542,  0.1194,  0.1153],\n",
       "         [ 0.0731, -0.1077,  0.0400,  ...,  0.1211, -0.0064, -0.0966],\n",
       "         ...,\n",
       "         [-0.0097, -0.0391,  0.0650,  ..., -0.0765,  0.0853,  0.0138],\n",
       "         [ 0.0583, -0.0750,  0.0817,  ..., -0.0888,  0.0343,  0.0423],\n",
       "         [-0.0405,  0.0536,  0.1186,  ..., -0.0607,  0.0218,  0.1022]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0166, -0.1219,  0.0120,  ...,  0.1049, -0.0720, -0.0916],\n",
       "         [-0.1095, -0.0550,  0.0312,  ..., -0.1253, -0.0786, -0.0542],\n",
       "         [-0.0720, -0.0873,  0.0079,  ...,  0.1207, -0.0877, -0.0311],\n",
       "         ...,\n",
       "         [-0.1052, -0.0765,  0.0640,  ..., -0.0212, -0.0742,  0.0494],\n",
       "         [-0.0492, -0.0826,  0.0766,  ...,  0.0284, -0.0027,  0.1023],\n",
       "         [ 0.0041, -0.1206, -0.0350,  ..., -0.0906,  0.0626,  0.1122]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0182, -0.0899,  0.0205,  ...,  0.1248, -0.0216, -0.0636],\n",
       "         [ 0.0495,  0.0783, -0.0214,  ...,  0.0753, -0.0709,  0.0309],\n",
       "         [-0.0675,  0.0658,  0.1114,  ...,  0.0961, -0.1228, -0.0998],\n",
       "         ...,\n",
       "         [-0.0129,  0.0704,  0.0401,  ..., -0.0270,  0.0989,  0.1030],\n",
       "         [ 0.0711,  0.0728, -0.0786,  ..., -0.0756,  0.0678, -0.0541],\n",
       "         [ 0.0887,  0.0445, -0.0256,  ...,  0.1062, -0.0589, -0.0776]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0781, -0.0949,  0.0729,  ...,  0.0004, -0.0011, -0.0087],\n",
       "         [ 0.0634, -0.0929,  0.0687,  ...,  0.0929, -0.0698, -0.0142],\n",
       "         [-0.1164,  0.0265, -0.0784,  ...,  0.0197,  0.0312,  0.0324],\n",
       "         ...,\n",
       "         [ 0.1049, -0.0124,  0.1043,  ...,  0.0543, -0.0792,  0.0108],\n",
       "         [ 0.0386, -0.0976,  0.0732,  ...,  0.0097, -0.1025,  0.0805],\n",
       "         [-0.0887,  0.0146, -0.0915,  ..., -0.0372, -0.1082, -0.0840]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0320, -0.0879,  0.0916,  ..., -0.0956, -0.1212, -0.0084],\n",
       "         [ 0.1078, -0.0189, -0.1199,  ...,  0.1174,  0.0066, -0.1028],\n",
       "         [-0.0655,  0.1248,  0.0331,  ..., -0.0271,  0.0374,  0.0067],\n",
       "         ...,\n",
       "         [-0.0828,  0.0897,  0.1214,  ..., -0.0504, -0.0295, -0.0084],\n",
       "         [-0.0574, -0.0501, -0.1002,  ..., -0.0148,  0.0022,  0.0791],\n",
       "         [-0.0565, -0.1203,  0.1229,  ..., -0.0852,  0.0925,  0.0466]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0677, -0.0518, -0.0607,  ..., -0.0022,  0.1127, -0.0995],\n",
       "         [-0.0641, -0.0110,  0.0888,  ...,  0.0679,  0.0885, -0.1194],\n",
       "         [ 0.0844, -0.0230, -0.1208,  ..., -0.0170, -0.0963,  0.0973],\n",
       "         ...,\n",
       "         [-0.0433,  0.1082,  0.0100,  ..., -0.0085,  0.0032,  0.0215],\n",
       "         [-0.1176,  0.0434, -0.0196,  ..., -0.0753,  0.0523,  0.0435],\n",
       "         [ 0.0695, -0.0238, -0.0105,  ...,  0.0688, -0.0746, -0.0500]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0963, -0.0749,  0.0938,  ...,  0.0723,  0.0918,  0.0960],\n",
       "         [ 0.1223, -0.1103, -0.0940,  ...,  0.0458, -0.0048,  0.0621],\n",
       "         [ 0.0400, -0.0795, -0.0180,  ...,  0.0413, -0.0269, -0.1019],\n",
       "         ...,\n",
       "         [ 0.1067,  0.0413, -0.0381,  ...,  0.0532, -0.0768,  0.0603],\n",
       "         [-0.0220, -0.0777, -0.0320,  ...,  0.0251,  0.0845,  0.0344],\n",
       "         [-0.1246,  0.0069, -0.0242,  ..., -0.0318,  0.0603,  0.1009]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0904,  0.0022, -0.0986,  ..., -0.0302,  0.1078, -0.0113],\n",
       "         [-0.1052,  0.0440, -0.0544,  ...,  0.0361,  0.0951, -0.0266],\n",
       "         [-0.0946, -0.0434, -0.0016,  ...,  0.0440, -0.0923, -0.0289],\n",
       "         ...,\n",
       "         [-0.0066,  0.1243, -0.0263,  ..., -0.0967, -0.0723,  0.1101],\n",
       "         [ 0.0708, -0.0509, -0.1213,  ..., -0.0271,  0.1043,  0.0660],\n",
       "         [ 0.0866,  0.0357, -0.0909,  ...,  0.0718,  0.0699, -0.0082]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1154, -0.0989,  0.0899,  ...,  0.1053, -0.0123,  0.0998],\n",
       "         [ 0.0404,  0.0223, -0.0312,  ..., -0.0913,  0.1137,  0.0035],\n",
       "         [-0.0525, -0.0966, -0.0526,  ...,  0.1121, -0.0012,  0.0128],\n",
       "         ...,\n",
       "         [-0.0410,  0.0340,  0.0919,  ..., -0.1005, -0.0647, -0.0293],\n",
       "         [ 0.0522, -0.0449, -0.0196,  ...,  0.0603,  0.0968, -0.0685],\n",
       "         [-0.0868, -0.0940,  0.0351,  ...,  0.0701,  0.0248,  0.0276]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1139,  0.0535,  0.0270,  ..., -0.0145, -0.1222, -0.1222],\n",
       "         [ 0.1015, -0.0227,  0.0296,  ..., -0.0979,  0.0305,  0.0291],\n",
       "         [-0.0447,  0.0077,  0.0313,  ..., -0.0545, -0.0355, -0.0958],\n",
       "         ...,\n",
       "         [-0.0343,  0.1003,  0.0191,  ..., -0.0903,  0.0593, -0.1162],\n",
       "         [-0.0628, -0.1124,  0.0650,  ...,  0.0285,  0.0987,  0.0253],\n",
       "         [-0.0447,  0.0039, -0.1200,  ...,  0.0066, -0.1137,  0.0640]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0437, -0.1229,  0.0258,  ...,  0.0118,  0.0477,  0.1082],\n",
       "         [ 0.0309,  0.0800,  0.0257,  ..., -0.0061, -0.0298,  0.1098],\n",
       "         [ 0.0187, -0.0962,  0.0620,  ...,  0.1018,  0.0331,  0.0446],\n",
       "         ...,\n",
       "         [-0.0743, -0.0218,  0.0463,  ...,  0.0540,  0.0816, -0.0859],\n",
       "         [ 0.0227,  0.0980,  0.0103,  ..., -0.1037,  0.0137,  0.0722],\n",
       "         [-0.0606,  0.0363,  0.0869,  ..., -0.0061,  0.0393,  0.0860]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0214, -0.0742,  0.0609,  ..., -0.0248,  0.0745,  0.1151],\n",
       "         [-0.0555,  0.0884,  0.0029,  ...,  0.0574, -0.0341,  0.0273],\n",
       "         [ 0.0441, -0.1045,  0.0653,  ..., -0.0799, -0.1140, -0.0137],\n",
       "         ...,\n",
       "         [-0.0308, -0.0760,  0.0829,  ...,  0.1183, -0.1008,  0.1116],\n",
       "         [ 0.1048,  0.1084, -0.0878,  ..., -0.0924, -0.1078, -0.1092],\n",
       "         [ 0.0972, -0.1010, -0.0924,  ..., -0.0503,  0.0833,  0.0633]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0855, -0.0856,  0.1176,  ..., -0.0756,  0.0680,  0.1144],\n",
       "         [-0.0924,  0.0158,  0.0347,  ...,  0.0349, -0.0453,  0.0477],\n",
       "         [ 0.1140,  0.0027,  0.0516,  ...,  0.0802,  0.1068, -0.0518],\n",
       "         ...,\n",
       "         [-0.0729, -0.1020,  0.0528,  ..., -0.0621, -0.0977,  0.0642],\n",
       "         [-0.0736, -0.0808, -0.1251,  ..., -0.0300, -0.1121,  0.0820],\n",
       "         [-0.0997, -0.0828,  0.0309,  ...,  0.0422,  0.0655,  0.0167]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 6.1294e-03,  3.8183e-02, -2.1998e-02,  ..., -1.1122e-01,\n",
       "           4.1747e-02,  1.2179e-02],\n",
       "         [-8.4050e-02,  1.3863e-02,  6.0390e-02,  ..., -1.0883e-01,\n",
       "           1.1122e-01, -7.7887e-02],\n",
       "         [-2.5921e-02, -5.8625e-02,  7.3126e-05,  ..., -4.4402e-02,\n",
       "          -9.0622e-02,  4.0098e-02],\n",
       "         ...,\n",
       "         [-7.8609e-02,  2.4834e-02, -1.0533e-01,  ..., -9.6421e-02,\n",
       "          -5.0289e-02, -1.1917e-01],\n",
       "         [ 9.2333e-02,  6.3280e-02,  5.6957e-02,  ...,  2.6571e-02,\n",
       "          -4.0343e-02,  9.7468e-02],\n",
       "         [ 4.6745e-02, -7.0081e-02,  1.0364e-01,  ...,  1.0587e-01,\n",
       "           6.9057e-02,  1.9306e-02]], device='cuda:0'),\n",
       " tensor([[-0.0883, -0.1196, -0.0195,  ..., -0.0224,  0.0744,  0.0760],\n",
       "         [ 0.0749,  0.0471, -0.0096,  ...,  0.0872,  0.0454,  0.0586],\n",
       "         [-0.0421,  0.0716,  0.0379,  ..., -0.0774, -0.0268,  0.1150],\n",
       "         ...,\n",
       "         [ 0.0094,  0.0287,  0.0952,  ..., -0.0448,  0.0236,  0.0814],\n",
       "         [ 0.0991, -0.0203, -0.0420,  ...,  0.0897,  0.1187, -0.1076],\n",
       "         [-0.0309, -0.1249, -0.0438,  ..., -0.0808,  0.0744, -0.0869]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0442,  0.0745,  0.0436,  ..., -0.1123,  0.0751, -0.0900],\n",
       "         [ 0.0207, -0.0170,  0.1088,  ...,  0.0096, -0.0198, -0.0505],\n",
       "         [ 0.0816,  0.0460, -0.0256,  ..., -0.0533, -0.1166,  0.0279],\n",
       "         ...,\n",
       "         [-0.0648,  0.0774,  0.0401,  ...,  0.0997, -0.0761,  0.1127],\n",
       "         [-0.0533,  0.1137,  0.1112,  ..., -0.1102,  0.0197, -0.0819],\n",
       "         [-0.0582, -0.0897, -0.0758,  ...,  0.0201, -0.0292, -0.0982]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0209, -0.0434,  0.0796,  ..., -0.0540, -0.0763,  0.0362],\n",
       "         [ 0.1114,  0.0617, -0.0253,  ..., -0.1157, -0.0836, -0.0792],\n",
       "         [ 0.0304,  0.0259,  0.0441,  ...,  0.0289, -0.0638,  0.1028],\n",
       "         ...,\n",
       "         [-0.0774, -0.0233,  0.0168,  ..., -0.0487, -0.0580, -0.0011],\n",
       "         [ 0.0862, -0.0303,  0.0618,  ...,  0.0771, -0.0882, -0.0495],\n",
       "         [-0.0660, -0.0482, -0.0771,  ...,  0.0478,  0.1147, -0.0403]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0704,  0.0168, -0.0030,  ..., -0.0295,  0.0013,  0.0658],\n",
       "         [ 0.0172,  0.1125, -0.0215,  ...,  0.0290,  0.1201,  0.0081],\n",
       "         [ 0.0314,  0.1178,  0.0340,  ...,  0.0415,  0.0279, -0.0435],\n",
       "         ...,\n",
       "         [-0.0611,  0.0564, -0.0884,  ..., -0.1120,  0.1147,  0.0298],\n",
       "         [-0.0430,  0.1089, -0.1201,  ...,  0.0247,  0.0146, -0.0431],\n",
       "         [-0.0470,  0.0576, -0.0338,  ...,  0.0833, -0.0558, -0.0505]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0984, -0.0119, -0.0375,  ..., -0.0197,  0.0009,  0.0655],\n",
       "         [ 0.0597, -0.0525,  0.0871,  ..., -0.0417, -0.0852,  0.0871],\n",
       "         [ 0.1171, -0.0721, -0.1032,  ...,  0.0626,  0.0585,  0.0692],\n",
       "         ...,\n",
       "         [ 0.1256,  0.0119, -0.0062,  ...,  0.1251, -0.0701,  0.0637],\n",
       "         [ 0.1287,  0.0894,  0.0992,  ...,  0.1248,  0.0649, -0.1005],\n",
       "         [ 0.0810, -0.0024,  0.0253,  ...,  0.0357, -0.0687,  0.1006]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0362, -0.0038, -0.0599,  ...,  0.0966,  0.1214,  0.1245],\n",
       "         [-0.0320, -0.0462,  0.0139,  ..., -0.0468, -0.0309,  0.0173],\n",
       "         [-0.0693,  0.0270, -0.1221,  ...,  0.0760, -0.0206,  0.1201],\n",
       "         ...,\n",
       "         [ 0.0716, -0.0670, -0.0765,  ...,  0.0436,  0.0046, -0.1082],\n",
       "         [-0.0138, -0.1114,  0.0132,  ..., -0.0938, -0.0873, -0.0130],\n",
       "         [ 0.0495,  0.1023, -0.0729,  ...,  0.1218, -0.1244,  0.0650]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0659, -0.0356, -0.1132,  ...,  0.1109,  0.0515, -0.0970],\n",
       "         [-0.0691,  0.0372, -0.0905,  ...,  0.0242, -0.0016,  0.0763],\n",
       "         [ 0.0322, -0.1120,  0.1048,  ..., -0.0908,  0.0377, -0.0099],\n",
       "         ...,\n",
       "         [ 0.0805, -0.0297, -0.0189,  ..., -0.1110,  0.0193, -0.0689],\n",
       "         [-0.0162, -0.0764, -0.0086,  ..., -0.0346,  0.0338, -0.0402],\n",
       "         [-0.1070,  0.0678, -0.0166,  ..., -0.0870,  0.0323, -0.0210]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0738,  0.0477,  0.0495,  ..., -0.1045,  0.1236, -0.0408],\n",
       "         [-0.0898, -0.0832,  0.0258,  ..., -0.0068, -0.0956, -0.1230],\n",
       "         [ 0.0794, -0.0553,  0.0323,  ...,  0.0025, -0.0344, -0.1090],\n",
       "         ...,\n",
       "         [-0.0598, -0.0235,  0.0928,  ..., -0.0749,  0.1061,  0.0146],\n",
       "         [-0.0140,  0.0223, -0.0273,  ...,  0.0836, -0.0980, -0.0701],\n",
       "         [ 0.1208,  0.1074,  0.0399,  ..., -0.0014, -0.0900,  0.0769]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1224, -0.0498,  0.0704,  ..., -0.0562,  0.1232, -0.0154],\n",
       "         [-0.1122, -0.0266,  0.0766,  ..., -0.0743, -0.0832,  0.0890],\n",
       "         [ 0.0288,  0.0099, -0.0361,  ...,  0.0905, -0.0581, -0.0694],\n",
       "         ...,\n",
       "         [ 0.0855, -0.0492, -0.0053,  ...,  0.1044,  0.1030, -0.0213],\n",
       "         [ 0.0299, -0.0121, -0.0916,  ..., -0.0215, -0.0399, -0.0055],\n",
       "         [-0.0339,  0.0192,  0.0302,  ..., -0.0033, -0.0145, -0.0676]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0394, -0.0094, -0.0016,  ..., -0.0778, -0.0193, -0.0801],\n",
       "         [ 0.0152,  0.0161,  0.1205,  ..., -0.0311,  0.1113, -0.1020],\n",
       "         [ 0.0661, -0.1022,  0.0046,  ..., -0.0982,  0.0111, -0.1218],\n",
       "         ...,\n",
       "         [ 0.0823, -0.0796,  0.0127,  ...,  0.0031, -0.0968, -0.0630],\n",
       "         [-0.0992, -0.0626,  0.1242,  ...,  0.0088, -0.0941,  0.1156],\n",
       "         [-0.1166,  0.1238, -0.0161,  ...,  0.0203, -0.0574,  0.1044]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0331,  0.0001, -0.0329,  ...,  0.0224, -0.0024, -0.0022],\n",
       "         [ 0.0248,  0.0214, -0.0387,  ..., -0.0114,  0.0374, -0.0089],\n",
       "         [ 0.0043,  0.0125,  0.0335,  ...,  0.0198, -0.0171, -0.0008],\n",
       "         ...,\n",
       "         [-0.0001, -0.0349, -0.0054,  ..., -0.0079, -0.0215,  0.0298],\n",
       "         [ 0.0121,  0.0222, -0.0009,  ...,  0.0133,  0.0087, -0.0347],\n",
       "         [-0.0100, -0.0072, -0.0060,  ...,  0.0186, -0.0145, -0.0360]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0217, -0.0078,  0.0135,  ...,  0.0181, -0.0043,  0.0131],\n",
       "         [-0.0202, -0.0112, -0.0022,  ...,  0.0114,  0.0170, -0.0119],\n",
       "         [ 0.0022,  0.0131, -0.0135,  ..., -0.0089,  0.0119,  0.0047],\n",
       "         ...,\n",
       "         [-0.0208,  0.0130,  0.0177,  ..., -0.0053,  0.0127,  0.0197],\n",
       "         [-0.0223,  0.0130,  0.0203,  ..., -0.0008,  0.0171, -0.0164],\n",
       "         [ 0.0031,  0.0187,  0.0180,  ...,  0.0058,  0.0123, -0.0174]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0650,  0.0130,  0.0430,  ..., -0.0408, -0.0052,  0.1245],\n",
       "         [-0.0064, -0.0634,  0.1096,  ..., -0.0175, -0.0565, -0.0155],\n",
       "         [ 0.0016,  0.0906,  0.0479,  ...,  0.0964, -0.1152,  0.0311],\n",
       "         ...,\n",
       "         [-0.0155,  0.1086, -0.0936,  ...,  0.0608, -0.0431,  0.0488],\n",
       "         [ 0.0527,  0.1164,  0.0575,  ..., -0.0461, -0.0117,  0.0049],\n",
       "         [ 0.0489,  0.0131, -0.0838,  ...,  0.0238,  0.0322,  0.0398]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0480,  0.0246,  0.0339,  ...,  0.0022, -0.0560, -0.0839],\n",
       "         [-0.0287, -0.1087, -0.0463,  ...,  0.0537,  0.0193,  0.1135],\n",
       "         [ 0.0551,  0.0723, -0.0015,  ...,  0.0103, -0.0966, -0.1194],\n",
       "         ...,\n",
       "         [ 0.0450, -0.0214,  0.0947,  ...,  0.0313, -0.0352, -0.0651],\n",
       "         [ 0.0309, -0.0977,  0.0862,  ...,  0.0739, -0.0194, -0.0077],\n",
       "         [-0.0268, -0.0739,  0.0081,  ..., -0.0314, -0.0426,  0.0308]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0148, -0.0199,  0.0447,  ...,  0.0544, -0.0319, -0.0650],\n",
       "         [-0.0402,  0.0998,  0.0802,  ..., -0.1175,  0.0562,  0.0765],\n",
       "         [ 0.0862, -0.0406, -0.0736,  ..., -0.0781, -0.0714, -0.1179],\n",
       "         ...,\n",
       "         [-0.0067, -0.0772, -0.0160,  ..., -0.0521,  0.0366,  0.0033],\n",
       "         [ 0.0401, -0.0317, -0.1064,  ...,  0.0531,  0.0976, -0.0034],\n",
       "         [ 0.0203, -0.0070,  0.1128,  ...,  0.1027,  0.0060, -0.0454]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0111, -0.1028,  0.0143,  ...,  0.0726, -0.1097,  0.1199],\n",
       "         [-0.0399,  0.0807, -0.0718,  ...,  0.0253, -0.0725,  0.0479],\n",
       "         [-0.0149,  0.0817,  0.1057,  ...,  0.0309,  0.0838,  0.0433],\n",
       "         ...,\n",
       "         [-0.0096, -0.0606, -0.0749,  ..., -0.1014, -0.0256,  0.0288],\n",
       "         [-0.0448, -0.1009, -0.0930,  ..., -0.0617, -0.1244, -0.1232],\n",
       "         [-0.1137, -0.0132, -0.1040,  ...,  0.0028,  0.0325, -0.0761]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0833, -0.0659, -0.0522,  ...,  0.0950,  0.0461, -0.1182],\n",
       "         [ 0.0973, -0.0488,  0.1234,  ...,  0.0545, -0.0409, -0.0895],\n",
       "         [-0.1144,  0.0187,  0.0185,  ...,  0.0107,  0.1036,  0.0030],\n",
       "         ...,\n",
       "         [-0.0848,  0.1228, -0.0266,  ...,  0.1244, -0.1065, -0.1059],\n",
       "         [-0.1098,  0.0005,  0.0088,  ..., -0.0925, -0.0851, -0.0429],\n",
       "         [-0.1047,  0.0308, -0.0518,  ...,  0.0563,  0.0289, -0.1141]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1188, -0.0381, -0.1028,  ...,  0.0753, -0.0645,  0.1049],\n",
       "         [-0.0468, -0.0411,  0.1165,  ...,  0.0547,  0.0065, -0.0078],\n",
       "         [ 0.1114,  0.0411,  0.0149,  ...,  0.0009, -0.0465,  0.0174],\n",
       "         ...,\n",
       "         [ 0.0079, -0.0042,  0.0321,  ..., -0.1141,  0.0841,  0.0502],\n",
       "         [-0.1090, -0.0504, -0.1037,  ...,  0.0376,  0.1205, -0.0616],\n",
       "         [ 0.0197,  0.0974,  0.0533,  ..., -0.0653, -0.0732, -0.0089]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0471,  0.0741, -0.0957,  ...,  0.0438, -0.1206, -0.1229],\n",
       "         [ 0.0058,  0.1120,  0.0040,  ...,  0.1117,  0.0504, -0.0602],\n",
       "         [-0.0326,  0.0941, -0.0278,  ..., -0.0939,  0.0335,  0.1204],\n",
       "         ...,\n",
       "         [-0.0620, -0.1190,  0.0173,  ..., -0.1084,  0.1241,  0.0710],\n",
       "         [ 0.1011,  0.1238, -0.0694,  ...,  0.0884, -0.0426,  0.1122],\n",
       "         [-0.0208,  0.0152, -0.1087,  ..., -0.0897, -0.0971, -0.0923]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1011, -0.0486,  0.0730,  ...,  0.0039,  0.0603, -0.0018],\n",
       "         [-0.0623,  0.1226, -0.1109,  ..., -0.0832,  0.0059, -0.0005],\n",
       "         [ 0.1242,  0.0607, -0.0141,  ...,  0.0276, -0.0715,  0.0073],\n",
       "         ...,\n",
       "         [ 0.0522, -0.0448,  0.0308,  ..., -0.0936,  0.0734,  0.0550],\n",
       "         [ 0.0422, -0.0603, -0.0637,  ..., -0.0924, -0.0278, -0.0425],\n",
       "         [-0.1078, -0.0973, -0.0145,  ...,  0.0596,  0.0860, -0.0217]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0521,  0.0744, -0.0286,  ...,  0.0028, -0.0442, -0.0758],\n",
       "         [ 0.0345,  0.0112, -0.1140,  ..., -0.0494, -0.1164, -0.0308],\n",
       "         [ 0.0031, -0.1156,  0.0619,  ..., -0.1198, -0.0195,  0.1111],\n",
       "         ...,\n",
       "         [ 0.0104,  0.0817, -0.1182,  ..., -0.0143,  0.1160,  0.0968],\n",
       "         [-0.0912, -0.0440, -0.0169,  ...,  0.0335, -0.0887, -0.1173],\n",
       "         [ 0.1134, -0.1025, -0.0018,  ..., -0.0737, -0.0063, -0.1130]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0933, -0.0708, -0.1170,  ...,  0.1171,  0.0958, -0.1143],\n",
       "         [ 0.0619, -0.1019,  0.0605,  ...,  0.1147, -0.1204,  0.0601],\n",
       "         [ 0.0349,  0.0574,  0.0547,  ...,  0.0156, -0.1135,  0.0104],\n",
       "         ...,\n",
       "         [ 0.0055, -0.0006,  0.1021,  ...,  0.1239,  0.0139, -0.0647],\n",
       "         [ 0.0998,  0.1198,  0.1204,  ...,  0.0646, -0.1152,  0.0312],\n",
       "         [ 0.0759, -0.0180,  0.1011,  ...,  0.1024, -0.1156,  0.0588]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1033, -0.0073, -0.0687,  ...,  0.0037, -0.0342,  0.0445],\n",
       "         [-0.0229,  0.0660,  0.0734,  ..., -0.1044, -0.0595,  0.0671],\n",
       "         [-0.0554, -0.0465, -0.0147,  ...,  0.0081, -0.0542, -0.0184],\n",
       "         ...,\n",
       "         [ 0.0609, -0.0775, -0.1012,  ...,  0.0190,  0.0639,  0.0798],\n",
       "         [ 0.0110, -0.0608,  0.1095,  ...,  0.0870,  0.0233,  0.0553],\n",
       "         [ 0.0969,  0.0134, -0.0788,  ..., -0.1064,  0.0767,  0.0190]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0973, -0.0221, -0.1232,  ..., -0.0823,  0.0711,  0.0873],\n",
       "         [-0.0997,  0.0042, -0.0996,  ...,  0.0561, -0.0537,  0.0895],\n",
       "         [-0.0312, -0.0770,  0.0010,  ...,  0.0045, -0.0112,  0.1151],\n",
       "         ...,\n",
       "         [-0.0640, -0.0753,  0.1055,  ...,  0.0464,  0.0693,  0.0799],\n",
       "         [-0.0016, -0.0159, -0.1138,  ...,  0.0511, -0.0709, -0.0381],\n",
       "         [ 0.0965, -0.0458, -0.0139,  ...,  0.0673,  0.0521, -0.1143]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1030, -0.0638,  0.0288,  ...,  0.0036,  0.0162, -0.0585],\n",
       "         [-0.0246,  0.1239, -0.0024,  ...,  0.0864, -0.1195,  0.1238],\n",
       "         [ 0.1123,  0.0449,  0.0969,  ...,  0.0380,  0.0616,  0.1131],\n",
       "         ...,\n",
       "         [ 0.0680, -0.0705, -0.0349,  ...,  0.0402, -0.0089, -0.0579],\n",
       "         [ 0.0545, -0.0501,  0.1127,  ..., -0.0823,  0.0531, -0.0366],\n",
       "         [-0.0808, -0.0915,  0.0776,  ...,  0.0650,  0.1035,  0.0616]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0096, -0.0096, -0.0689,  ...,  0.1244,  0.0545,  0.0202],\n",
       "         [-0.0894,  0.0688, -0.0655,  ..., -0.0819, -0.0581,  0.0736],\n",
       "         [ 0.0083,  0.0270, -0.1140,  ...,  0.0905, -0.1228, -0.0204],\n",
       "         ...,\n",
       "         [-0.0672,  0.0158,  0.0021,  ...,  0.0516,  0.0336,  0.0812],\n",
       "         [ 0.0576, -0.0563, -0.0114,  ...,  0.1178,  0.1096,  0.0828],\n",
       "         [-0.1066,  0.0193, -0.0146,  ...,  0.0201,  0.0512,  0.0160]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0925, -0.0433, -0.0271,  ..., -0.0526, -0.1041, -0.0607],\n",
       "         [-0.0237,  0.0609,  0.0416,  ..., -0.0740, -0.0225,  0.0116],\n",
       "         [ 0.0655, -0.1018, -0.0816,  ..., -0.0204,  0.1193, -0.0347],\n",
       "         ...,\n",
       "         [-0.0981, -0.1209, -0.0163,  ...,  0.0539, -0.0027, -0.0741],\n",
       "         [-0.1119,  0.0927,  0.0293,  ...,  0.0513,  0.0254,  0.0005],\n",
       "         [ 0.0733, -0.0140, -0.0498,  ..., -0.0008,  0.0798,  0.0147]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0033, -0.0434,  0.0553,  ...,  0.0010, -0.0409,  0.1052],\n",
       "         [ 0.0386,  0.0780, -0.1205,  ..., -0.1072, -0.0745,  0.0032],\n",
       "         [-0.1213, -0.1198, -0.0753,  ...,  0.0047,  0.0865,  0.0827],\n",
       "         ...,\n",
       "         [-0.1203,  0.1159, -0.0314,  ..., -0.0418, -0.0979,  0.0673],\n",
       "         [ 0.0721,  0.0066,  0.0354,  ...,  0.0241,  0.0920,  0.0598],\n",
       "         [ 0.1037, -0.0232, -0.0155,  ..., -0.0484, -0.0630, -0.1162]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0642, -0.1103, -0.1081,  ...,  0.0777, -0.0105, -0.0324],\n",
       "         [-0.0568, -0.0684,  0.0223,  ...,  0.0695, -0.0653, -0.0741],\n",
       "         [ 0.1095, -0.0793,  0.0949,  ..., -0.0376,  0.0717, -0.1205],\n",
       "         ...,\n",
       "         [ 0.0035, -0.0141,  0.0894,  ...,  0.0327,  0.0987, -0.0067],\n",
       "         [ 0.1073, -0.1014, -0.0558,  ...,  0.1071,  0.0330, -0.0489],\n",
       "         [ 0.0284, -0.0630, -0.0818,  ..., -0.0520, -0.0919, -0.0737]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0981,  0.1097, -0.0249,  ..., -0.1141, -0.0345, -0.0562],\n",
       "         [-0.0232, -0.0133,  0.0087,  ...,  0.0740, -0.0348,  0.1086],\n",
       "         [ 0.1007, -0.1009,  0.0912,  ...,  0.0494, -0.0675,  0.0928],\n",
       "         ...,\n",
       "         [-0.0355, -0.0806, -0.0332,  ..., -0.1144,  0.1178, -0.0048],\n",
       "         [-0.0037, -0.0152,  0.0782,  ...,  0.0002,  0.0609, -0.0131],\n",
       "         [-0.0169,  0.0301, -0.0524,  ...,  0.0416,  0.0943, -0.0342]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0312,  0.1043,  0.0278,  ...,  0.0249,  0.0499, -0.0892],\n",
       "         [-0.0723,  0.0448, -0.1202,  ...,  0.1140, -0.0431,  0.0527],\n",
       "         [ 0.0840,  0.0957, -0.0920,  ..., -0.1119,  0.1133, -0.0927],\n",
       "         ...,\n",
       "         [ 0.1153,  0.0393, -0.0899,  ...,  0.0610, -0.0908, -0.0649],\n",
       "         [-0.0814, -0.1140, -0.0709,  ..., -0.0252,  0.0575,  0.1095],\n",
       "         [-0.1167,  0.1120, -0.0666,  ...,  0.0267,  0.0031, -0.0033]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0985,  0.0669, -0.0740,  ...,  0.0634,  0.0985, -0.1216],\n",
       "         [-0.0467, -0.0816,  0.0209,  ...,  0.0781, -0.0771,  0.0338],\n",
       "         [ 0.0931,  0.0200,  0.1135,  ..., -0.1235,  0.0504,  0.0982],\n",
       "         ...,\n",
       "         [ 0.0337,  0.0814,  0.0893,  ..., -0.0089, -0.0411,  0.0123],\n",
       "         [-0.0569, -0.0700, -0.0505,  ...,  0.0723,  0.0454, -0.0327],\n",
       "         [-0.0841,  0.0759,  0.1133,  ...,  0.1100,  0.0033,  0.0626]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0767,  0.0410,  0.0711,  ..., -0.0524, -0.0748, -0.0454],\n",
       "         [ 0.0797,  0.1169,  0.0959,  ..., -0.0383,  0.0399,  0.0570],\n",
       "         [-0.0085, -0.0698,  0.1071,  ...,  0.0059, -0.1062, -0.0064],\n",
       "         ...,\n",
       "         [-0.0995, -0.1212,  0.0743,  ..., -0.0083, -0.0936, -0.0820],\n",
       "         [-0.0102, -0.0809, -0.0486,  ...,  0.0249,  0.0756, -0.0471],\n",
       "         [ 0.0979,  0.0107, -0.0242,  ...,  0.0732,  0.0341, -0.0950]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0909,  0.0247,  0.0378,  ...,  0.1218,  0.1239,  0.0997],\n",
       "         [-0.0059,  0.1186, -0.1216,  ..., -0.1169,  0.0938, -0.1036],\n",
       "         [-0.1163,  0.0492,  0.0059,  ...,  0.1169, -0.1074,  0.0706],\n",
       "         ...,\n",
       "         [-0.0589, -0.0331,  0.0151,  ...,  0.0977,  0.0865, -0.0748],\n",
       "         [ 0.0046, -0.0170, -0.0822,  ..., -0.1094,  0.1070, -0.0958],\n",
       "         [-0.1183, -0.0738,  0.0476,  ..., -0.0224,  0.0018, -0.1081]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0371, -0.0898,  0.0434,  ..., -0.1064,  0.0717,  0.1073],\n",
       "         [ 0.1019, -0.0928, -0.1079,  ..., -0.0930, -0.0427,  0.0119],\n",
       "         [ 0.0815,  0.1205, -0.1133,  ..., -0.1238, -0.0005, -0.0430],\n",
       "         ...,\n",
       "         [ 0.1082,  0.0159,  0.0463,  ...,  0.0228,  0.0820, -0.0504],\n",
       "         [ 0.0260, -0.0131,  0.0642,  ..., -0.1022,  0.0295,  0.0475],\n",
       "         [-0.0228,  0.0770, -0.0825,  ..., -0.0065,  0.1145, -0.0723]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0075, -0.1055, -0.0681,  ..., -0.1206,  0.0497,  0.0105],\n",
       "         [ 0.0491,  0.1204,  0.0210,  ..., -0.0015, -0.0953, -0.1013],\n",
       "         [ 0.0844, -0.0875, -0.1210,  ..., -0.0229,  0.0653, -0.0226],\n",
       "         ...,\n",
       "         [-0.0454, -0.0298,  0.0785,  ..., -0.0672, -0.0506,  0.0861],\n",
       "         [ 0.1214,  0.0360,  0.1151,  ...,  0.0950, -0.0121,  0.1063],\n",
       "         [ 0.0840,  0.1045,  0.0027,  ..., -0.0809, -0.0770, -0.0659]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0358,  0.0267,  0.0386,  ..., -0.0427,  0.0416,  0.0094],\n",
       "         [ 0.0328, -0.0026, -0.0176,  ...,  0.0334, -0.0040,  0.0352],\n",
       "         [-0.0062, -0.0015, -0.0055,  ..., -0.0295,  0.0156,  0.0431],\n",
       "         ...,\n",
       "         [-0.0278, -0.0448,  0.0111,  ..., -0.0098, -0.0054,  0.0380],\n",
       "         [ 0.0204, -0.0202, -0.0380,  ...,  0.0304,  0.0424,  0.0019],\n",
       "         [-0.0306, -0.0099, -0.0327,  ...,  0.0239,  0.0395,  0.0364]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0007,  0.0184, -0.0085,  ...,  0.0174, -0.0200, -0.0192],\n",
       "         [-0.0215,  0.0179, -0.0017,  ...,  0.0137, -0.0010, -0.0209],\n",
       "         [ 0.0194, -0.0031,  0.0221,  ..., -0.0153,  0.0020, -0.0005],\n",
       "         ...,\n",
       "         [ 0.0189,  0.0094, -0.0209,  ...,  0.0173,  0.0152,  0.0155],\n",
       "         [-0.0044, -0.0148,  0.0113,  ..., -0.0064, -0.0004, -0.0172],\n",
       "         [-0.0180,  0.0200, -0.0078,  ..., -0.0021,  0.0079, -0.0205]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0665, -0.0214,  0.0881,  ...,  0.0965, -0.0075, -0.0437],\n",
       "         [ 0.0345, -0.0255, -0.1087,  ...,  0.0963,  0.1044, -0.0359],\n",
       "         [ 0.0010,  0.0502, -0.0653,  ...,  0.0080,  0.1209,  0.0761],\n",
       "         ...,\n",
       "         [ 0.0148,  0.0112, -0.0474,  ..., -0.0882,  0.0415,  0.0449],\n",
       "         [ 0.0576,  0.0465,  0.0092,  ...,  0.0651, -0.0340,  0.0569],\n",
       "         [-0.1237, -0.0633,  0.0082,  ...,  0.0392,  0.0544,  0.1253]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0275, -0.0139, -0.0752,  ..., -0.0047, -0.0029,  0.0116],\n",
       "         [ 0.0127, -0.0410, -0.0992,  ..., -0.0627,  0.0788, -0.0864],\n",
       "         [ 0.0819,  0.0150,  0.0696,  ...,  0.0080, -0.0734, -0.0663],\n",
       "         ...,\n",
       "         [ 0.0896,  0.0491, -0.1242,  ..., -0.0043, -0.0514, -0.1079],\n",
       "         [ 0.0840, -0.0380,  0.0191,  ..., -0.0059, -0.0595,  0.0787],\n",
       "         [ 0.0706,  0.0373, -0.0966,  ...,  0.0208, -0.0766, -0.0772]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1139, -0.0635,  0.0282,  ...,  0.0836,  0.1203,  0.0371],\n",
       "         [-0.1055, -0.0092, -0.0039,  ...,  0.1057, -0.1009, -0.0384],\n",
       "         [-0.0632,  0.0325, -0.0874,  ..., -0.1005,  0.0950, -0.0784],\n",
       "         ...,\n",
       "         [-0.1069,  0.0239,  0.0445,  ...,  0.0291,  0.0770,  0.0185],\n",
       "         [-0.0845, -0.0176, -0.0518,  ...,  0.0758, -0.0710, -0.0895],\n",
       "         [ 0.1050, -0.0690,  0.0618,  ...,  0.0947, -0.1226, -0.0091]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0498,  0.0007, -0.0121,  ...,  0.0521,  0.0189, -0.0159],\n",
       "         [ 0.0647,  0.0586,  0.1166,  ...,  0.1072, -0.0720, -0.0571],\n",
       "         [ 0.0735, -0.0343, -0.0464,  ...,  0.1025, -0.1109,  0.0124],\n",
       "         ...,\n",
       "         [ 0.0701,  0.0362, -0.1220,  ...,  0.0350,  0.0927, -0.0648],\n",
       "         [ 0.0436,  0.0083,  0.0674,  ...,  0.0320,  0.0729, -0.0063],\n",
       "         [-0.0332,  0.1227, -0.0841,  ...,  0.0568, -0.0422, -0.0119]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0171,  0.0744,  0.0627,  ..., -0.0715,  0.0106, -0.1211],\n",
       "         [ 0.0205,  0.0441,  0.0974,  ..., -0.0039, -0.0979, -0.0639],\n",
       "         [ 0.1246, -0.0366,  0.0944,  ...,  0.0493, -0.0143, -0.0423],\n",
       "         ...,\n",
       "         [ 0.0034,  0.0077, -0.1245,  ...,  0.0229,  0.0868, -0.1214],\n",
       "         [-0.0178,  0.0170,  0.1023,  ..., -0.0610, -0.0807,  0.0030],\n",
       "         [-0.0791,  0.0234, -0.1084,  ...,  0.0889,  0.0016,  0.0618]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0258, -0.0020, -0.0921,  ...,  0.0201,  0.0374,  0.0468],\n",
       "         [ 0.0196, -0.0915, -0.0567,  ...,  0.0615,  0.1140, -0.1080],\n",
       "         [ 0.1224, -0.0886, -0.0686,  ..., -0.0608, -0.0886, -0.0543],\n",
       "         ...,\n",
       "         [-0.0030,  0.1112, -0.1202,  ..., -0.0060, -0.0002,  0.0950],\n",
       "         [-0.0292, -0.0166, -0.1126,  ...,  0.0282,  0.1089, -0.0452],\n",
       "         [-0.0781,  0.0067,  0.1181,  ...,  0.0694, -0.0974, -0.0059]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0007, -0.0856, -0.0982,  ..., -0.1023,  0.0113, -0.0806],\n",
       "         [ 0.1105,  0.0983, -0.1006,  ..., -0.0930, -0.0236, -0.0134],\n",
       "         [-0.0006, -0.0361, -0.0201,  ..., -0.0262, -0.0697,  0.0942],\n",
       "         ...,\n",
       "         [-0.0077, -0.1036, -0.0858,  ..., -0.0342, -0.0326, -0.0599],\n",
       "         [-0.0753,  0.1071, -0.0447,  ..., -0.0474, -0.0852, -0.0541],\n",
       "         [-0.1205,  0.0463,  0.0756,  ...,  0.0444,  0.0167, -0.0122]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1247,  0.0321, -0.0566,  ...,  0.1103,  0.0959,  0.0246],\n",
       "         [ 0.0827,  0.0022, -0.0280,  ...,  0.0514, -0.0451, -0.0720],\n",
       "         [-0.0070,  0.0356, -0.0332,  ..., -0.0826,  0.0273, -0.1199],\n",
       "         ...,\n",
       "         [-0.0695, -0.0100, -0.0343,  ..., -0.0743,  0.1002, -0.0380],\n",
       "         [-0.1181, -0.0758,  0.0488,  ...,  0.0719, -0.0390, -0.1009],\n",
       "         [ 0.0231, -0.0105,  0.0749,  ..., -0.0982, -0.0561,  0.0284]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0939, -0.0723,  0.0431,  ..., -0.0982, -0.0959,  0.1167],\n",
       "         [-0.0271, -0.0605,  0.1173,  ...,  0.1034,  0.0109, -0.0822],\n",
       "         [ 0.0332,  0.0738, -0.0057,  ..., -0.1214, -0.0431, -0.0528],\n",
       "         ...,\n",
       "         [-0.0241, -0.1162,  0.0315,  ...,  0.0699, -0.0896, -0.1210],\n",
       "         [-0.0148, -0.0617, -0.1125,  ...,  0.0615, -0.0870, -0.0756],\n",
       "         [-0.1067,  0.0434, -0.0314,  ...,  0.0941, -0.0418,  0.0802]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1098, -0.0181,  0.0065,  ...,  0.0842,  0.0373, -0.0203],\n",
       "         [-0.0377, -0.0070, -0.0713,  ..., -0.0003,  0.0277, -0.1204],\n",
       "         [-0.0524,  0.0168,  0.0965,  ..., -0.0189,  0.0640,  0.0512],\n",
       "         ...,\n",
       "         [ 0.0016, -0.1071, -0.1080,  ...,  0.0997, -0.0243, -0.0612],\n",
       "         [ 0.0978,  0.0823,  0.0341,  ...,  0.1022,  0.1202,  0.0879],\n",
       "         [-0.0602, -0.0552, -0.0748,  ...,  0.1057, -0.1091,  0.0188]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0538,  0.0536,  0.1184,  ..., -0.0972,  0.0586,  0.0325],\n",
       "         [ 0.0652,  0.0395,  0.0426,  ...,  0.1128, -0.0605,  0.1098],\n",
       "         [ 0.0597,  0.0623, -0.0312,  ..., -0.0033, -0.0081,  0.0531],\n",
       "         ...,\n",
       "         [ 0.0584,  0.0169, -0.0661,  ..., -0.0597, -0.0605,  0.0876],\n",
       "         [ 0.0847, -0.0296, -0.0402,  ...,  0.1199, -0.0703,  0.0717],\n",
       "         [-0.0194, -0.0091, -0.0311,  ..., -0.0018,  0.1180, -0.0018]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0156,  0.0086,  0.0328,  ..., -0.0286, -0.1118,  0.0151],\n",
       "         [ 0.0853, -0.0507, -0.0154,  ..., -0.1121,  0.0019, -0.0801],\n",
       "         [ 0.0182,  0.0888,  0.0349,  ...,  0.0137, -0.0319, -0.0104],\n",
       "         ...,\n",
       "         [-0.1064,  0.0014,  0.0518,  ...,  0.0479,  0.0329, -0.0066],\n",
       "         [-0.0751, -0.0293, -0.1073,  ..., -0.0049,  0.0959, -0.1084],\n",
       "         [ 0.0805, -0.1155,  0.0797,  ...,  0.0628, -0.1173,  0.1064]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0352, -0.0541,  0.0594,  ...,  0.0172,  0.0321, -0.1006],\n",
       "         [-0.0618,  0.0560, -0.0124,  ..., -0.0238,  0.0187, -0.0869],\n",
       "         [ 0.1067, -0.0864,  0.0441,  ...,  0.1192,  0.0578,  0.1094],\n",
       "         ...,\n",
       "         [ 0.0071, -0.0108, -0.0697,  ...,  0.1023,  0.1141, -0.0147],\n",
       "         [ 0.0240,  0.0234, -0.0819,  ...,  0.0363, -0.0293,  0.0246],\n",
       "         [ 0.0101,  0.0321, -0.0950,  ..., -0.0262, -0.0575, -0.0615]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0852,  0.0607, -0.0715,  ..., -0.0390, -0.1021, -0.0137],\n",
       "         [-0.0697,  0.1115,  0.0114,  ..., -0.0616,  0.0830,  0.0329],\n",
       "         [ 0.0571,  0.1203,  0.1023,  ...,  0.0349,  0.0328,  0.0210],\n",
       "         ...,\n",
       "         [-0.1092, -0.0580,  0.0310,  ...,  0.0364,  0.0838, -0.0123],\n",
       "         [ 0.0320, -0.0752,  0.1191,  ...,  0.0505, -0.1203,  0.0976],\n",
       "         [ 0.0054, -0.0615, -0.1239,  ..., -0.0942, -0.0566, -0.1054]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0035, -0.0174, -0.0410,  ...,  0.0467, -0.0375, -0.0562],\n",
       "         [ 0.0653,  0.0635, -0.0743,  ..., -0.0462, -0.1166,  0.0803],\n",
       "         [ 0.0776, -0.0911, -0.0188,  ..., -0.0034,  0.0097,  0.1111],\n",
       "         ...,\n",
       "         [ 0.0746, -0.0669, -0.0564,  ..., -0.0153, -0.0157,  0.0158],\n",
       "         [-0.0924, -0.0573,  0.1199,  ..., -0.0611,  0.0164, -0.0752],\n",
       "         [ 0.0073, -0.0139,  0.0752,  ..., -0.0549,  0.1171,  0.0166]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0297, -0.0573, -0.0155,  ...,  0.0274,  0.1178, -0.0523],\n",
       "         [ 0.0878, -0.0156,  0.0439,  ..., -0.0739, -0.1241, -0.0021],\n",
       "         [ 0.1158,  0.1095,  0.0196,  ..., -0.1091,  0.0442,  0.0917],\n",
       "         ...,\n",
       "         [ 0.0865,  0.0724, -0.0888,  ..., -0.0126, -0.0466, -0.0748],\n",
       "         [-0.0654,  0.0348,  0.0105,  ..., -0.0722,  0.0881, -0.1184],\n",
       "         [ 0.0303, -0.0013,  0.0889,  ..., -0.0162,  0.0777,  0.0638]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0356, -0.1002, -0.0742,  ..., -0.0740,  0.0764,  0.0271],\n",
       "         [ 0.0289,  0.0913, -0.0739,  ..., -0.0225, -0.1208,  0.0908],\n",
       "         [-0.0660,  0.0119,  0.0110,  ..., -0.1105,  0.1179, -0.0953],\n",
       "         ...,\n",
       "         [ 0.0738,  0.0886,  0.0526,  ...,  0.0680, -0.0029,  0.0941],\n",
       "         [-0.0691, -0.0344, -0.0755,  ...,  0.1010, -0.0698, -0.1144],\n",
       "         [ 0.0532, -0.1221, -0.0201,  ...,  0.0998, -0.1178,  0.0482]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0215,  0.0676,  0.0897,  ...,  0.1126, -0.1180,  0.0298],\n",
       "         [-0.0592, -0.0430,  0.1238,  ..., -0.0208, -0.1095,  0.0917],\n",
       "         [-0.1059,  0.1248, -0.0981,  ..., -0.1217, -0.0144, -0.0050],\n",
       "         ...,\n",
       "         [-0.0058,  0.1252, -0.0725,  ...,  0.0752, -0.0039,  0.0766],\n",
       "         [-0.1241,  0.0025, -0.1001,  ..., -0.0386, -0.0927,  0.0034],\n",
       "         [ 0.0630,  0.0145,  0.0721,  ...,  0.0119,  0.0548,  0.0508]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0976,  0.0385, -0.0527,  ..., -0.0613,  0.0956, -0.0249],\n",
       "         [ 0.0690,  0.0451,  0.0564,  ..., -0.0056,  0.0854,  0.0613],\n",
       "         [ 0.0643,  0.0519,  0.0689,  ...,  0.0007,  0.0220,  0.0894],\n",
       "         ...,\n",
       "         [ 0.0658,  0.0050, -0.0610,  ...,  0.1253, -0.0105,  0.0530],\n",
       "         [-0.0039, -0.0759,  0.0763,  ...,  0.0715,  0.0015,  0.0707],\n",
       "         [-0.0882, -0.0346, -0.0374,  ..., -0.0956, -0.0269,  0.1038]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1073, -0.1118,  0.0913,  ..., -0.0638,  0.0546,  0.0370],\n",
       "         [ 0.0301,  0.0935, -0.0455,  ...,  0.0502,  0.0428, -0.1186],\n",
       "         [ 0.0065, -0.0775, -0.1213,  ...,  0.0911,  0.0758,  0.0028],\n",
       "         ...,\n",
       "         [ 0.0649,  0.0438,  0.0942,  ..., -0.0136, -0.0534,  0.0864],\n",
       "         [-0.1149,  0.0008,  0.0976,  ...,  0.0698, -0.1162, -0.0221],\n",
       "         [ 0.0961, -0.0843, -0.0607,  ...,  0.0366, -0.0567, -0.0902]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0840, -0.0386,  0.0240,  ...,  0.0790,  0.0968,  0.1104],\n",
       "         [-0.1173,  0.1096,  0.0627,  ..., -0.0626,  0.1032, -0.1042],\n",
       "         [ 0.1233,  0.0274, -0.0788,  ..., -0.0227, -0.0492, -0.1183],\n",
       "         ...,\n",
       "         [-0.1115, -0.0425, -0.0638,  ..., -0.0025,  0.0612, -0.0677],\n",
       "         [-0.0558, -0.0365,  0.0785,  ...,  0.0407,  0.0659,  0.0898],\n",
       "         [-0.0016, -0.0202,  0.0686,  ...,  0.0570, -0.0163, -0.0717]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0688,  0.1211,  0.1052,  ..., -0.0652, -0.0792, -0.0191],\n",
       "         [ 0.0606,  0.0408, -0.1027,  ...,  0.0222, -0.1069,  0.0537],\n",
       "         [-0.0128,  0.0362,  0.0782,  ...,  0.1162, -0.1218,  0.0082],\n",
       "         ...,\n",
       "         [-0.0281, -0.0704, -0.0315,  ...,  0.0417,  0.0212, -0.1208],\n",
       "         [-0.0783,  0.0103, -0.1230,  ...,  0.0212, -0.0100, -0.0251],\n",
       "         [ 0.0029, -0.0141,  0.0653,  ..., -0.0566,  0.0242, -0.0236]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0458,  0.1141,  0.0127,  ..., -0.1184,  0.1041, -0.0577],\n",
       "         [ 0.0569,  0.0992, -0.0386,  ..., -0.0007, -0.0086, -0.0212],\n",
       "         [-0.1071,  0.1246, -0.0434,  ...,  0.0777,  0.0762, -0.1041],\n",
       "         ...,\n",
       "         [-0.0081, -0.0888, -0.0062,  ..., -0.0493, -0.0060,  0.0170],\n",
       "         [-0.0542, -0.1209,  0.0083,  ..., -0.0625, -0.1186, -0.0335],\n",
       "         [ 0.1241,  0.1147,  0.0154,  ...,  0.0526, -0.0657,  0.1124]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0126,  0.1061, -0.0044,  ...,  0.0651,  0.1072,  0.0229],\n",
       "         [-0.1101,  0.0266, -0.0041,  ..., -0.0971,  0.0049,  0.0212],\n",
       "         [-0.0093, -0.0648, -0.0967,  ..., -0.0432, -0.0581,  0.0733],\n",
       "         ...,\n",
       "         [-0.0582, -0.0435, -0.0940,  ...,  0.0983, -0.0412,  0.1182],\n",
       "         [ 0.1109, -0.0418, -0.0954,  ..., -0.0332,  0.0258, -0.0300],\n",
       "         [-0.0649,  0.0973, -0.0612,  ..., -0.0726, -0.1127,  0.1026]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0206,  0.0172,  0.0401,  ..., -0.0057, -0.0031,  0.0014],\n",
       "         [-0.0390,  0.0160,  0.0198,  ...,  0.0437, -0.0032, -0.0274],\n",
       "         [-0.0146, -0.0025, -0.0216,  ..., -0.0218,  0.0111,  0.0233],\n",
       "         ...,\n",
       "         [-0.0053,  0.0344, -0.0409,  ..., -0.0421, -0.0054, -0.0096],\n",
       "         [ 0.0102,  0.0413, -0.0196,  ..., -0.0252, -0.0063,  0.0142],\n",
       "         [ 0.0224,  0.0281,  0.0258,  ...,  0.0394,  0.0236, -0.0112]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0211, -0.0156,  0.0171,  ...,  0.0163,  0.0018, -0.0191],\n",
       "         [ 0.0010,  0.0033, -0.0148,  ..., -0.0143, -0.0146, -0.0182],\n",
       "         [-0.0113,  0.0075, -0.0201,  ..., -0.0074, -0.0012, -0.0046],\n",
       "         ...,\n",
       "         [-0.0116, -0.0179, -0.0103,  ..., -0.0013,  0.0066,  0.0178],\n",
       "         [-0.0051,  0.0186,  0.0206,  ...,  0.0191,  0.0093,  0.0173],\n",
       "         [ 0.0195, -0.0140,  0.0100,  ...,  0.0172,  0.0186, -0.0047]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1052, -0.0429, -0.1121,  ..., -0.0750, -0.0499, -0.0802],\n",
       "         [-0.0832, -0.0369,  0.0927,  ..., -0.0371,  0.0997, -0.0721],\n",
       "         [ 0.0192,  0.0055, -0.0953,  ..., -0.0953,  0.0246, -0.0387],\n",
       "         ...,\n",
       "         [ 0.0580, -0.1077, -0.1030,  ...,  0.0828,  0.0850,  0.1125],\n",
       "         [ 0.0641,  0.1041, -0.0624,  ...,  0.0944,  0.1181,  0.1118],\n",
       "         [-0.0808, -0.0558,  0.0779,  ..., -0.0806,  0.0660, -0.0698]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0404, -0.1054,  0.0747,  ...,  0.1081,  0.0058,  0.0230],\n",
       "         [ 0.0133,  0.0603, -0.0660,  ...,  0.0959,  0.0264, -0.0668],\n",
       "         [ 0.1232, -0.0215,  0.0602,  ...,  0.1051, -0.0206, -0.1105],\n",
       "         ...,\n",
       "         [ 0.0559, -0.0965,  0.1209,  ..., -0.1080,  0.0768, -0.0311],\n",
       "         [-0.1190, -0.0602, -0.0007,  ..., -0.1216,  0.0742, -0.0160],\n",
       "         [ 0.1093,  0.0813, -0.0596,  ...,  0.0383,  0.0953,  0.0206]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0211,  0.1193,  0.1070,  ..., -0.0308,  0.0469, -0.1138],\n",
       "         [ 0.0637,  0.1084,  0.0469,  ...,  0.0185,  0.0960, -0.0426],\n",
       "         [-0.1186, -0.0758,  0.0422,  ...,  0.0946, -0.0231, -0.1039],\n",
       "         ...,\n",
       "         [-0.0534, -0.0830,  0.0603,  ..., -0.0152, -0.1002, -0.0823],\n",
       "         [-0.0287, -0.0257,  0.0908,  ...,  0.0169,  0.0410,  0.0270],\n",
       "         [ 0.1133, -0.0526,  0.0738,  ...,  0.0052,  0.0104,  0.1051]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0978, -0.0465,  0.0615,  ...,  0.0441,  0.0329, -0.0611],\n",
       "         [ 0.0170, -0.1116,  0.0406,  ..., -0.0757,  0.0088,  0.0564],\n",
       "         [ 0.0020,  0.1054, -0.0101,  ...,  0.0332,  0.1013, -0.0964],\n",
       "         ...,\n",
       "         [-0.0002, -0.0841, -0.0444,  ...,  0.0817,  0.0841, -0.0057],\n",
       "         [ 0.0919, -0.0566, -0.1046,  ..., -0.0828, -0.0181, -0.0189],\n",
       "         [-0.0871, -0.0324,  0.0993,  ..., -0.1072, -0.0246,  0.0783]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0572, -0.1209,  0.1206,  ..., -0.0868, -0.1229,  0.0698],\n",
       "         [-0.0124, -0.1111, -0.0040,  ...,  0.0721, -0.0370, -0.0842],\n",
       "         [ 0.0302, -0.0700,  0.0203,  ...,  0.0484, -0.0933, -0.0786],\n",
       "         ...,\n",
       "         [ 0.1143,  0.0381, -0.0792,  ..., -0.1036, -0.0345,  0.1096],\n",
       "         [-0.0432,  0.0442,  0.0966,  ...,  0.0917,  0.0492, -0.0721],\n",
       "         [-0.0656,  0.0743, -0.1024,  ...,  0.1152,  0.0944,  0.1029]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0345,  0.0598,  0.0597,  ..., -0.0911, -0.0661,  0.0612],\n",
       "         [-0.0451,  0.1131, -0.0664,  ...,  0.0061,  0.1141, -0.0024],\n",
       "         [ 0.0449, -0.0605, -0.1216,  ...,  0.0645, -0.0218, -0.1166],\n",
       "         ...,\n",
       "         [-0.0396, -0.0317,  0.1124,  ...,  0.0481,  0.1104,  0.0201],\n",
       "         [-0.0372, -0.0263,  0.0789,  ..., -0.0015,  0.0008, -0.1145],\n",
       "         [-0.0271, -0.0088,  0.0808,  ..., -0.0669,  0.0809,  0.0141]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0296,  0.0089,  0.0005,  ..., -0.0512, -0.0477,  0.0839],\n",
       "         [ 0.0449, -0.0545,  0.0178,  ...,  0.0049, -0.0091,  0.0099],\n",
       "         [ 0.0148, -0.0970, -0.0532,  ...,  0.1061,  0.1074,  0.0947],\n",
       "         ...,\n",
       "         [ 0.1083,  0.0457, -0.0671,  ..., -0.0852,  0.0816, -0.0428],\n",
       "         [-0.0612, -0.0889,  0.0755,  ..., -0.0285,  0.0223, -0.0223],\n",
       "         [-0.1046, -0.0105,  0.0233,  ...,  0.0589,  0.0347, -0.1236]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1240,  0.0465,  0.0620,  ...,  0.0422,  0.0804,  0.0663],\n",
       "         [-0.0961,  0.0571,  0.0237,  ...,  0.0497,  0.0719,  0.0575],\n",
       "         [-0.0912, -0.0174,  0.0128,  ...,  0.0337,  0.0970, -0.0797],\n",
       "         ...,\n",
       "         [-0.0700, -0.0578, -0.0878,  ...,  0.0185,  0.1160, -0.1099],\n",
       "         [-0.0670,  0.0221,  0.0598,  ...,  0.0015, -0.0816,  0.0700],\n",
       "         [-0.0566,  0.0501,  0.1139,  ..., -0.0186,  0.0220, -0.1124]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0972, -0.0931,  0.1047,  ...,  0.0492, -0.0944,  0.0427],\n",
       "         [ 0.0932, -0.0138,  0.0985,  ...,  0.0453, -0.0163,  0.0675],\n",
       "         [ 0.0354,  0.0985, -0.1058,  ...,  0.1001,  0.0626, -0.0804],\n",
       "         ...,\n",
       "         [ 0.0533, -0.1046,  0.0781,  ...,  0.0606, -0.0663,  0.0542],\n",
       "         [-0.0502, -0.0525,  0.0838,  ..., -0.0783, -0.0266,  0.0624],\n",
       "         [ 0.0010, -0.1127,  0.0410,  ..., -0.0230,  0.0490,  0.0140]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0853,  0.1079, -0.0993,  ..., -0.0067, -0.0347,  0.1015],\n",
       "         [-0.0274,  0.0385,  0.0244,  ..., -0.0886,  0.0074, -0.1159],\n",
       "         [ 0.0759, -0.1085, -0.0866,  ...,  0.0865, -0.1084, -0.1060],\n",
       "         ...,\n",
       "         [ 0.1224,  0.1219,  0.1122,  ..., -0.0505,  0.0523, -0.0893],\n",
       "         [ 0.0788, -0.0290, -0.0613,  ..., -0.0950,  0.0943,  0.0458],\n",
       "         [ 0.0568, -0.0989, -0.0817,  ..., -0.0117, -0.0756, -0.0824]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0330, -0.0036,  0.0693,  ...,  0.0943, -0.0834, -0.1108],\n",
       "         [-0.0365, -0.0756,  0.0440,  ...,  0.0834, -0.0703, -0.1213],\n",
       "         [ 0.0127,  0.1236,  0.0607,  ..., -0.1204, -0.0759, -0.0219],\n",
       "         ...,\n",
       "         [ 0.1104, -0.1258, -0.0968,  ...,  0.0210, -0.0686, -0.0907],\n",
       "         [-0.0621,  0.0389, -0.0064,  ..., -0.1113,  0.1038, -0.0444],\n",
       "         [-0.0841, -0.0871, -0.1002,  ..., -0.1241,  0.0525, -0.0776]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1134, -0.0666,  0.1196,  ...,  0.1088, -0.0796,  0.0803],\n",
       "         [ 0.1154,  0.0340, -0.0976,  ..., -0.0662, -0.1035,  0.1247],\n",
       "         [ 0.0925, -0.0436, -0.0840,  ..., -0.0537, -0.0861,  0.0411],\n",
       "         ...,\n",
       "         [ 0.0731,  0.1107,  0.0050,  ...,  0.0900,  0.1072, -0.0641],\n",
       "         [-0.1015, -0.0827,  0.1133,  ...,  0.0936,  0.1026,  0.0615],\n",
       "         [-0.0618,  0.0064, -0.1101,  ...,  0.0639, -0.0015, -0.1049]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0709, -0.0895, -0.0016,  ..., -0.0900, -0.1239, -0.0277],\n",
       "         [ 0.0825,  0.0909, -0.0622,  ...,  0.0982, -0.0444,  0.0406],\n",
       "         [-0.0754,  0.1249, -0.1050,  ..., -0.0320, -0.1219,  0.0601],\n",
       "         ...,\n",
       "         [ 0.0824, -0.0245, -0.0619,  ..., -0.0844, -0.0180,  0.0093],\n",
       "         [-0.1209, -0.0597,  0.1201,  ...,  0.0969, -0.0017, -0.1083],\n",
       "         [-0.0764, -0.0573,  0.0122,  ..., -0.0597,  0.0871, -0.0208]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0521,  0.1009, -0.0834,  ..., -0.1070,  0.0849,  0.1011],\n",
       "         [-0.0446,  0.0440, -0.0521,  ..., -0.0400,  0.0218, -0.1033],\n",
       "         [-0.0218,  0.0470,  0.0946,  ..., -0.0838,  0.0345, -0.0894],\n",
       "         ...,\n",
       "         [-0.0251, -0.1172,  0.0575,  ..., -0.0733, -0.0061, -0.0552],\n",
       "         [-0.0294, -0.0815,  0.0214,  ...,  0.0735,  0.0950,  0.0498],\n",
       "         [-0.0569, -0.0656,  0.0504,  ...,  0.0216, -0.0157,  0.0050]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1102, -0.1025, -0.0540,  ..., -0.0068,  0.0148,  0.1029],\n",
       "         [ 0.0808,  0.1065,  0.0645,  ..., -0.1041, -0.0878,  0.0857],\n",
       "         [ 0.0108,  0.0834, -0.0792,  ..., -0.0091, -0.0773,  0.0830],\n",
       "         ...,\n",
       "         [-0.1201, -0.0066,  0.0211,  ..., -0.1091,  0.1077,  0.0081],\n",
       "         [-0.1118,  0.1229, -0.0294,  ..., -0.0107,  0.0308, -0.0102],\n",
       "         [ 0.1049,  0.0552,  0.0603,  ...,  0.0902, -0.0510,  0.0444]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0264, -0.1177, -0.0368,  ...,  0.1029, -0.0938,  0.0925],\n",
       "         [ 0.0824,  0.1136, -0.1167,  ...,  0.0318,  0.0484,  0.0306],\n",
       "         [ 0.0150, -0.1143, -0.1148,  ...,  0.1210,  0.0165,  0.0432],\n",
       "         ...,\n",
       "         [-0.0441,  0.0181, -0.0048,  ...,  0.0597, -0.0233, -0.0842],\n",
       "         [ 0.0604, -0.1064,  0.0869,  ..., -0.0612, -0.0422,  0.0442],\n",
       "         [ 0.1056,  0.1178,  0.1065,  ..., -0.0686, -0.0963,  0.0705]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0523,  0.1235, -0.0700,  ..., -0.0720,  0.0838, -0.0430],\n",
       "         [-0.0691,  0.1103, -0.1169,  ...,  0.0261,  0.0761,  0.0703],\n",
       "         [-0.0712, -0.0609, -0.0772,  ..., -0.0019, -0.1152,  0.0803],\n",
       "         ...,\n",
       "         [ 0.0473,  0.0097, -0.1009,  ...,  0.0311, -0.0683, -0.1158],\n",
       "         [ 0.0309, -0.1240, -0.1118,  ..., -0.0524,  0.0265,  0.0146],\n",
       "         [ 0.0349,  0.0775, -0.0852,  ...,  0.0605, -0.1182,  0.0525]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0792, -0.0941, -0.0779,  ..., -0.0240,  0.0052, -0.0136],\n",
       "         [-0.0620, -0.0696, -0.1093,  ..., -0.0008,  0.0822,  0.1017],\n",
       "         [-0.0510, -0.0387, -0.0768,  ...,  0.0488, -0.0497,  0.0185],\n",
       "         ...,\n",
       "         [ 0.0914,  0.0059,  0.0261,  ..., -0.0266, -0.0476,  0.0982],\n",
       "         [ 0.1203, -0.1036, -0.0744,  ..., -0.0388,  0.0133,  0.0002],\n",
       "         [ 0.1205,  0.1114,  0.0183,  ..., -0.0116,  0.1154,  0.0304]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0534, -0.0347, -0.0469,  ..., -0.0233,  0.1180,  0.1019],\n",
       "         [-0.0828, -0.0788, -0.1140,  ..., -0.0709, -0.0084, -0.0853],\n",
       "         [ 0.0054,  0.0533,  0.1226,  ..., -0.0264,  0.0215,  0.0098],\n",
       "         ...,\n",
       "         [ 0.0080, -0.0078,  0.0305,  ...,  0.1204,  0.1125,  0.1236],\n",
       "         [ 0.0021,  0.0005,  0.0810,  ...,  0.0147, -0.0480,  0.1065],\n",
       "         [-0.1146, -0.0204, -0.0691,  ..., -0.1031,  0.0933, -0.0117]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0568, -0.1169, -0.0417,  ..., -0.0302,  0.0990,  0.0662],\n",
       "         [ 0.0088,  0.0554,  0.0871,  ..., -0.0945,  0.0264, -0.0514],\n",
       "         [-0.0317, -0.0090, -0.1171,  ...,  0.0650, -0.1248, -0.0962],\n",
       "         ...,\n",
       "         [-0.0581,  0.0999, -0.0660,  ..., -0.0388, -0.0711,  0.1205],\n",
       "         [-0.0948,  0.0628,  0.0645,  ...,  0.0973,  0.0783, -0.0839],\n",
       "         [-0.0424, -0.1012, -0.0611,  ..., -0.0756,  0.1035,  0.1224]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0770, -0.1066, -0.0567,  ..., -0.1086, -0.0488,  0.1203],\n",
       "         [ 0.1129,  0.0100,  0.1111,  ..., -0.0155, -0.0127,  0.0556],\n",
       "         [-0.0181,  0.1062,  0.0731,  ...,  0.0451, -0.0361, -0.0246],\n",
       "         ...,\n",
       "         [ 0.0843, -0.0795, -0.0069,  ...,  0.0577,  0.0363,  0.0197],\n",
       "         [-0.1180, -0.0699,  0.0023,  ..., -0.0460,  0.1201, -0.0061],\n",
       "         [-0.1149, -0.0878, -0.1080,  ..., -0.0871, -0.0522, -0.0286]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0201,  0.0964,  0.0254,  ..., -0.0994,  0.0100, -0.0317],\n",
       "         [ 0.0664,  0.0727, -0.0661,  ..., -0.1164,  0.0964,  0.0886],\n",
       "         [-0.1247, -0.0423,  0.1210,  ..., -0.0768,  0.0646, -0.0226],\n",
       "         ...,\n",
       "         [-0.1241,  0.0536,  0.1022,  ...,  0.1119, -0.0082, -0.1225],\n",
       "         [ 0.1082,  0.0449,  0.0200,  ...,  0.0166,  0.0860, -0.0085],\n",
       "         [-0.0820,  0.0852,  0.0649,  ...,  0.1067,  0.1126, -0.0666]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0379,  0.0970,  0.0226,  ..., -0.0907, -0.0740,  0.1130],\n",
       "         [-0.1066, -0.0086,  0.0767,  ...,  0.1124, -0.0244, -0.0628],\n",
       "         [ 0.1164, -0.1122,  0.0324,  ...,  0.0076,  0.0947,  0.1007],\n",
       "         ...,\n",
       "         [-0.0076, -0.0805, -0.0699,  ..., -0.0854,  0.0991, -0.0902],\n",
       "         [ 0.0747, -0.0226,  0.0168,  ..., -0.0593,  0.0361,  0.0913],\n",
       "         [-0.1072, -0.0413,  0.0378,  ..., -0.0624, -0.0894, -0.0697]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0404, -0.0466,  0.0250,  ..., -0.0841, -0.0873,  0.0511],\n",
       "         [ 0.0231, -0.0132,  0.0595,  ...,  0.1183, -0.0413,  0.0998],\n",
       "         [-0.1008, -0.0349, -0.0057,  ..., -0.0962, -0.0910,  0.0631],\n",
       "         ...,\n",
       "         [-0.0543, -0.0376,  0.0857,  ..., -0.0277,  0.0233,  0.1199],\n",
       "         [-0.0461, -0.1079, -0.0785,  ..., -0.0748,  0.0734,  0.1017],\n",
       "         [-0.1046,  0.0912,  0.0370,  ...,  0.0159,  0.0658,  0.0940]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0302,  0.0253,  0.0103,  ...,  0.0425,  0.0082,  0.0075],\n",
       "         [-0.0196, -0.0109,  0.0379,  ...,  0.0325, -0.0204,  0.0123],\n",
       "         [-0.0348,  0.0345,  0.0393,  ...,  0.0008, -0.0386, -0.0129],\n",
       "         ...,\n",
       "         [ 0.0311,  0.0124, -0.0021,  ..., -0.0327,  0.0331,  0.0217],\n",
       "         [ 0.0029,  0.0306, -0.0438,  ..., -0.0118, -0.0171, -0.0395],\n",
       "         [-0.0034,  0.0062, -0.0126,  ...,  0.0069, -0.0032,  0.0314]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0215, -0.0022,  0.0044,  ..., -0.0134,  0.0044, -0.0146],\n",
       "         [-0.0076,  0.0197,  0.0174,  ..., -0.0110,  0.0106, -0.0077],\n",
       "         [-0.0177, -0.0062,  0.0196,  ...,  0.0019,  0.0138, -0.0212],\n",
       "         ...,\n",
       "         [-0.0107, -0.0053, -0.0154,  ..., -0.0083,  0.0184,  0.0126],\n",
       "         [-0.0111,  0.0205,  0.0019,  ..., -0.0157, -0.0084, -0.0135],\n",
       "         [ 0.0190, -0.0025,  0.0054,  ..., -0.0176, -0.0009, -0.0154]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0813, -0.1167,  0.0502,  ...,  0.0998, -0.1072, -0.0063],\n",
       "         [ 0.0871, -0.0097, -0.0971,  ...,  0.1162,  0.0711,  0.0927],\n",
       "         [ 0.0502, -0.0937, -0.0761,  ..., -0.0148, -0.0486, -0.0656],\n",
       "         ...,\n",
       "         [-0.0163, -0.0652, -0.0883,  ..., -0.1154,  0.0297,  0.1085],\n",
       "         [ 0.0186, -0.1030,  0.0712,  ...,  0.1035, -0.0705, -0.0428],\n",
       "         [ 0.0162, -0.0899, -0.0359,  ...,  0.0086, -0.0685,  0.0215]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0572, -0.0010, -0.0418,  ..., -0.1036, -0.0911,  0.0122],\n",
       "         [-0.0451, -0.0513,  0.0291,  ...,  0.0866, -0.0480, -0.0021],\n",
       "         [ 0.0561,  0.1184, -0.0556,  ..., -0.0169, -0.1129,  0.1072],\n",
       "         ...,\n",
       "         [ 0.0878, -0.0583,  0.0779,  ..., -0.0584,  0.0514,  0.0817],\n",
       "         [ 0.0572, -0.0281, -0.0159,  ...,  0.0436, -0.0069, -0.0369],\n",
       "         [-0.0246, -0.0402, -0.1009,  ...,  0.0157,  0.0304, -0.0627]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0797, -0.0322,  0.0591,  ...,  0.0871,  0.0558, -0.0959],\n",
       "         [-0.1189,  0.0685, -0.1035,  ..., -0.0792, -0.1149, -0.0192],\n",
       "         [-0.0175, -0.0140,  0.1237,  ...,  0.0534, -0.0401, -0.0512],\n",
       "         ...,\n",
       "         [-0.0371,  0.1187, -0.1152,  ..., -0.1055,  0.1104,  0.0159],\n",
       "         [ 0.0792, -0.1175,  0.0915,  ...,  0.0396, -0.0275,  0.0833],\n",
       "         [ 0.0857, -0.1130,  0.0603,  ...,  0.0594, -0.0551,  0.1136]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0571, -0.0738,  0.0341,  ..., -0.1031,  0.1068,  0.1226],\n",
       "         [-0.0660, -0.0459,  0.0042,  ..., -0.0495, -0.1032, -0.0582],\n",
       "         [ 0.0588, -0.0103,  0.1118,  ...,  0.1038,  0.1234,  0.0843],\n",
       "         ...,\n",
       "         [-0.0260, -0.0805,  0.0975,  ..., -0.0394,  0.0491,  0.0385],\n",
       "         [ 0.0739,  0.0012, -0.0957,  ...,  0.0884,  0.0314, -0.0363],\n",
       "         [ 0.0317, -0.0241, -0.0389,  ...,  0.0215, -0.0147, -0.0099]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0968, -0.0473, -0.0887,  ...,  0.0394,  0.0801, -0.0349],\n",
       "         [-0.0532, -0.0522,  0.0022,  ...,  0.0832,  0.0338,  0.0012],\n",
       "         [ 0.0779,  0.0778, -0.0241,  ..., -0.0831,  0.0800,  0.0107],\n",
       "         ...,\n",
       "         [-0.0580, -0.1102,  0.0759,  ...,  0.0505,  0.1240,  0.1150],\n",
       "         [-0.0614, -0.0478,  0.1016,  ..., -0.1086, -0.0964,  0.0985],\n",
       "         [ 0.0178,  0.0481, -0.1051,  ..., -0.1130,  0.0543, -0.0165]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0146,  0.0817, -0.0737,  ...,  0.0069,  0.0299,  0.0128],\n",
       "         [ 0.1034, -0.0652,  0.1018,  ...,  0.0539,  0.0909,  0.1113],\n",
       "         [ 0.0789, -0.0710, -0.0096,  ..., -0.0328,  0.0416,  0.1066],\n",
       "         ...,\n",
       "         [ 0.0850,  0.0396, -0.0897,  ..., -0.0650, -0.0719, -0.0645],\n",
       "         [ 0.0615,  0.1031,  0.0395,  ...,  0.0359,  0.0815,  0.0155],\n",
       "         [-0.0924, -0.1022,  0.1207,  ..., -0.1192,  0.0484, -0.1153]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0676,  0.0365, -0.0101,  ...,  0.0309,  0.0467, -0.1180],\n",
       "         [-0.1033, -0.0534,  0.0294,  ..., -0.0471, -0.0346,  0.1157],\n",
       "         [-0.1014, -0.0871,  0.0981,  ..., -0.0274, -0.0735,  0.0667],\n",
       "         ...,\n",
       "         [-0.0023,  0.0650,  0.0148,  ..., -0.0620, -0.1147, -0.0345],\n",
       "         [-0.1103, -0.0360,  0.0022,  ..., -0.1049,  0.1119, -0.0241],\n",
       "         [ 0.0073, -0.0002, -0.0176,  ...,  0.1163,  0.0430,  0.1200]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0552,  0.0868,  0.0141,  ..., -0.0752,  0.0307,  0.0040],\n",
       "         [-0.0696, -0.0993, -0.0891,  ..., -0.1068,  0.0394,  0.0645],\n",
       "         [ 0.0061,  0.0548, -0.0319,  ...,  0.0637, -0.0923,  0.0198],\n",
       "         ...,\n",
       "         [ 0.0597,  0.0875, -0.1189,  ..., -0.0207, -0.0985, -0.0125],\n",
       "         [ 0.1001,  0.0079,  0.0297,  ..., -0.0893, -0.0381,  0.0661],\n",
       "         [ 0.0356, -0.0536, -0.0393,  ...,  0.1042,  0.1091,  0.0487]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0744,  0.0341, -0.0471,  ..., -0.1047, -0.0294, -0.0238],\n",
       "         [-0.0577,  0.0945, -0.1110,  ..., -0.0450, -0.0779, -0.1083],\n",
       "         [-0.0147,  0.0318,  0.0725,  ...,  0.0229, -0.1062, -0.0405],\n",
       "         ...,\n",
       "         [-0.0578, -0.0534, -0.0538,  ..., -0.0839, -0.0918,  0.0197],\n",
       "         [ 0.0224,  0.1143, -0.0541,  ..., -0.0604,  0.0110, -0.0186],\n",
       "         [ 0.0815, -0.0459, -0.0669,  ..., -0.0061, -0.0026, -0.0696]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0554,  0.0485,  0.0092,  ...,  0.1051, -0.0874, -0.0868],\n",
       "         [-0.0501, -0.1248,  0.0849,  ...,  0.0571, -0.0604, -0.0621],\n",
       "         [-0.0022, -0.0336,  0.0086,  ...,  0.1006,  0.0859,  0.1041],\n",
       "         ...,\n",
       "         [ 0.0575,  0.0757, -0.0786,  ..., -0.0788, -0.1184,  0.0510],\n",
       "         [ 0.1115,  0.0807, -0.0566,  ..., -0.0197, -0.0194, -0.0960],\n",
       "         [-0.1068,  0.0429,  0.0286,  ...,  0.0411, -0.0811,  0.1251]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0091, -0.0448,  0.0929,  ..., -0.0507,  0.0530,  0.0063],\n",
       "         [ 0.0236,  0.0703, -0.0780,  ...,  0.1074,  0.1209, -0.0076],\n",
       "         [-0.0902,  0.0695, -0.0144,  ...,  0.0311,  0.0491,  0.0737],\n",
       "         ...,\n",
       "         [-0.0972, -0.0526, -0.0799,  ...,  0.0657,  0.0242,  0.0037],\n",
       "         [ 0.1132,  0.1043, -0.1047,  ...,  0.0170, -0.0533,  0.0693],\n",
       "         [-0.1064, -0.0869,  0.0229,  ...,  0.0892, -0.0647, -0.0284]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1117, -0.1161, -0.0195,  ...,  0.0389, -0.0902, -0.0904],\n",
       "         [ 0.0975,  0.1029, -0.1109,  ...,  0.0555,  0.0387,  0.0858],\n",
       "         [ 0.0027,  0.0448,  0.0866,  ..., -0.0876, -0.0557,  0.0333],\n",
       "         ...,\n",
       "         [-0.0341,  0.0436, -0.0064,  ...,  0.0991,  0.1104,  0.0027],\n",
       "         [ 0.0826,  0.1087, -0.0510,  ...,  0.0977, -0.0686,  0.0827],\n",
       "         [ 0.0619, -0.0571,  0.0284,  ...,  0.0720, -0.0676, -0.1109]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0995,  0.0971, -0.0451,  ..., -0.0149,  0.1195,  0.0029],\n",
       "         [ 0.0169,  0.0551, -0.0766,  ..., -0.0213,  0.0935,  0.1036],\n",
       "         [ 0.0902,  0.0343,  0.1237,  ...,  0.0404,  0.1130, -0.0458],\n",
       "         ...,\n",
       "         [ 0.1150,  0.0649,  0.0567,  ..., -0.1092, -0.0849, -0.1053],\n",
       "         [ 0.0139, -0.0115,  0.0787,  ..., -0.1142,  0.0170,  0.0397],\n",
       "         [-0.1209, -0.0010,  0.0514,  ...,  0.0192,  0.0432, -0.0559]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0142,  0.0107,  0.0903,  ..., -0.0137,  0.0099,  0.0079],\n",
       "         [-0.0806,  0.0317, -0.0594,  ..., -0.0995, -0.0622, -0.0220],\n",
       "         [-0.0942, -0.0350, -0.0631,  ...,  0.1088, -0.0451,  0.1064],\n",
       "         ...,\n",
       "         [ 0.0787,  0.0985, -0.0085,  ...,  0.1027,  0.1169,  0.0963],\n",
       "         [ 0.1139,  0.0446, -0.1010,  ..., -0.0110,  0.0944, -0.0714],\n",
       "         [-0.0032,  0.0585, -0.0785,  ...,  0.0879,  0.0262, -0.0607]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0563, -0.1164,  0.0481,  ..., -0.0433, -0.0808,  0.1124],\n",
       "         [ 0.0474, -0.0307,  0.0893,  ...,  0.0318,  0.0824,  0.1012],\n",
       "         [-0.1024, -0.0348, -0.1237,  ...,  0.1228,  0.0459,  0.0424],\n",
       "         ...,\n",
       "         [ 0.0688, -0.0555,  0.0540,  ..., -0.0489, -0.1181, -0.1008],\n",
       "         [-0.0358, -0.0380,  0.0349,  ..., -0.0109, -0.0563, -0.1091],\n",
       "         [-0.0248, -0.1200, -0.0763,  ...,  0.1050,  0.1185, -0.0593]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0664, -0.0684, -0.0440,  ...,  0.0094,  0.1082,  0.0719],\n",
       "         [ 0.1147,  0.0528,  0.1007,  ..., -0.0668,  0.0277,  0.1130],\n",
       "         [-0.0471,  0.1152,  0.0199,  ..., -0.0621, -0.0804,  0.1134],\n",
       "         ...,\n",
       "         [ 0.0244,  0.0835,  0.0639,  ...,  0.0269,  0.0178,  0.0213],\n",
       "         [-0.0597,  0.1058, -0.0152,  ..., -0.0332, -0.0963, -0.0856],\n",
       "         [-0.0709, -0.0250, -0.0153,  ...,  0.0055,  0.0514,  0.0469]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0994, -0.0536, -0.1245,  ...,  0.1098,  0.1132,  0.0957],\n",
       "         [ 0.0149,  0.0027, -0.0009,  ..., -0.0865,  0.1059, -0.0286],\n",
       "         [ 0.0900,  0.0185,  0.1020,  ...,  0.0475,  0.1133,  0.1152],\n",
       "         ...,\n",
       "         [-0.1165, -0.0669,  0.0713,  ..., -0.0768, -0.0539,  0.1190],\n",
       "         [-0.0044,  0.0459, -0.0743,  ...,  0.0656, -0.1128,  0.0131],\n",
       "         [-0.0171, -0.0921,  0.1109,  ..., -0.0531,  0.0326, -0.0997]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0723,  0.1014,  0.0191,  ..., -0.0231, -0.0716, -0.0033],\n",
       "         [ 0.0754,  0.0894, -0.0189,  ..., -0.0214, -0.0807,  0.0456],\n",
       "         [-0.1203, -0.0129, -0.0933,  ..., -0.0543,  0.1067,  0.0762],\n",
       "         ...,\n",
       "         [ 0.0309, -0.0906,  0.0099,  ..., -0.1041, -0.0921,  0.0392],\n",
       "         [ 0.0629, -0.1024, -0.0037,  ..., -0.1066,  0.0281,  0.0435],\n",
       "         [-0.0943,  0.0661, -0.0572,  ..., -0.1168,  0.0081,  0.0712]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0670,  0.0264, -0.0215,  ..., -0.0473,  0.1031,  0.0603],\n",
       "         [ 0.0657, -0.0236,  0.0688,  ..., -0.0435,  0.0332, -0.0991],\n",
       "         [ 0.1096, -0.1112,  0.0334,  ..., -0.0949, -0.0047, -0.0610],\n",
       "         ...,\n",
       "         [ 0.0117, -0.1016,  0.0360,  ...,  0.0819,  0.0612, -0.0015],\n",
       "         [ 0.0119,  0.0797, -0.0692,  ..., -0.0926,  0.0955, -0.0083],\n",
       "         [ 0.0342, -0.0880,  0.0896,  ..., -0.1042,  0.0012,  0.1109]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0513,  0.0903, -0.0418,  ..., -0.0594, -0.0704,  0.1060],\n",
       "         [-0.1106, -0.0393,  0.0600,  ..., -0.0623,  0.0571,  0.0902],\n",
       "         [ 0.1044,  0.1143, -0.1070,  ...,  0.0222, -0.0807,  0.0282],\n",
       "         ...,\n",
       "         [-0.0267,  0.1195, -0.0173,  ...,  0.0958,  0.0793,  0.0527],\n",
       "         [-0.1126,  0.0666,  0.1106,  ..., -0.0294,  0.1169, -0.0519],\n",
       "         [ 0.0281,  0.0724, -0.1178,  ...,  0.1186,  0.0477,  0.0142]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0660, -0.0607, -0.1252,  ...,  0.0291, -0.0290,  0.1082],\n",
       "         [ 0.0702, -0.1256, -0.0434,  ...,  0.0830, -0.1021,  0.0352],\n",
       "         [-0.0933,  0.0497, -0.0188,  ..., -0.0273, -0.0921,  0.1035],\n",
       "         ...,\n",
       "         [-0.0224,  0.0771,  0.0754,  ..., -0.0839,  0.1072,  0.0343],\n",
       "         [ 0.0533,  0.0740,  0.1209,  ...,  0.0893,  0.0566,  0.0677],\n",
       "         [ 0.1120,  0.0603, -0.0341,  ...,  0.0767, -0.1260, -0.0491]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0588, -0.0208, -0.0035,  ..., -0.0591, -0.0717, -0.0269],\n",
       "         [-0.0745,  0.0107, -0.0410,  ..., -0.0075,  0.0546,  0.0359],\n",
       "         [ 0.0621,  0.0600,  0.1213,  ...,  0.0434, -0.0549,  0.0995],\n",
       "         ...,\n",
       "         [ 0.1129, -0.0965, -0.1080,  ...,  0.0512,  0.1077, -0.0495],\n",
       "         [-0.0663, -0.1094, -0.0567,  ..., -0.0554,  0.1138, -0.0551],\n",
       "         [ 0.0919,  0.0590,  0.1111,  ...,  0.0638, -0.0498,  0.0395]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1053, -0.0884,  0.0122,  ..., -0.0629, -0.0864, -0.1236],\n",
       "         [ 0.0816, -0.0343,  0.0271,  ...,  0.0783, -0.0759, -0.0488],\n",
       "         [ 0.1056, -0.0099, -0.0060,  ...,  0.1030,  0.0109, -0.0448],\n",
       "         ...,\n",
       "         [-0.0973, -0.1209, -0.1231,  ..., -0.0188, -0.1139,  0.1098],\n",
       "         [-0.1165,  0.0863,  0.0647,  ...,  0.0108, -0.1064,  0.0509],\n",
       "         [ 0.1019, -0.0019, -0.0993,  ..., -0.1169,  0.0438, -0.0820]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1060,  0.0396,  0.1025,  ..., -0.0330, -0.0106,  0.1054],\n",
       "         [ 0.1228,  0.0865, -0.0713,  ..., -0.1117, -0.0609, -0.0078],\n",
       "         [ 0.0133, -0.0636,  0.1052,  ..., -0.0899, -0.1225,  0.0959],\n",
       "         ...,\n",
       "         [-0.1096,  0.0353,  0.0519,  ..., -0.0316,  0.0967, -0.0030],\n",
       "         [ 0.0641,  0.0787, -0.0822,  ...,  0.0030,  0.0750, -0.0078],\n",
       "         [-0.1203,  0.1088, -0.1074,  ...,  0.1130,  0.0756,  0.0601]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0377,  0.0106,  0.0011,  ..., -0.0017, -0.0030, -0.0254],\n",
       "         [-0.0002,  0.0364, -0.0151,  ..., -0.0047, -0.0378, -0.0251],\n",
       "         [-0.0024,  0.0342,  0.0021,  ...,  0.0075,  0.0173,  0.0244],\n",
       "         ...,\n",
       "         [ 0.0263,  0.0312, -0.0334,  ...,  0.0067, -0.0426, -0.0197],\n",
       "         [ 0.0308,  0.0206,  0.0290,  ..., -0.0237,  0.0165, -0.0384],\n",
       "         [-0.0043,  0.0145, -0.0397,  ..., -0.0050,  0.0387, -0.0363]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0132,  0.0183, -0.0109,  ..., -0.0114,  0.0209, -0.0216],\n",
       "         [-0.0075,  0.0133,  0.0136,  ..., -0.0094,  0.0182, -0.0030],\n",
       "         [-0.0138, -0.0143,  0.0076,  ...,  0.0003, -0.0002,  0.0012],\n",
       "         ...,\n",
       "         [ 0.0027, -0.0231, -0.0002,  ..., -0.0177, -0.0142, -0.0026],\n",
       "         [ 0.0124, -0.0011, -0.0142,  ...,  0.0211,  0.0077,  0.0126],\n",
       "         [-0.0174, -0.0093,  0.0059,  ...,  0.0007, -0.0136,  0.0037]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1103,  0.1079,  0.0492,  ...,  0.0200,  0.0702,  0.1220],\n",
       "         [-0.0085, -0.0406, -0.0699,  ...,  0.0177, -0.0717, -0.0021],\n",
       "         [-0.0961, -0.0584,  0.0950,  ...,  0.0855,  0.0773,  0.1159],\n",
       "         ...,\n",
       "         [-0.0013,  0.0903, -0.0384,  ..., -0.1065, -0.1118, -0.0892],\n",
       "         [ 0.0681, -0.0732, -0.1113,  ..., -0.0603,  0.1120, -0.0097],\n",
       "         [ 0.0796,  0.0939, -0.0389,  ...,  0.0807,  0.0253, -0.0632]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0746, -0.0851,  0.1121,  ...,  0.0799, -0.0578,  0.0885],\n",
       "         [ 0.1250, -0.0353,  0.0349,  ...,  0.0535,  0.0201,  0.0255],\n",
       "         [ 0.0138,  0.0154,  0.0773,  ...,  0.0440,  0.0641,  0.0632],\n",
       "         ...,\n",
       "         [-0.0730, -0.0276, -0.0927,  ..., -0.0548,  0.1223, -0.1193],\n",
       "         [ 0.0405,  0.0733,  0.0423,  ...,  0.1067,  0.1096, -0.0656],\n",
       "         [-0.1091, -0.0848, -0.0246,  ...,  0.1032,  0.0817,  0.1236]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0789,  0.0685, -0.0196,  ...,  0.0466, -0.0418,  0.0809],\n",
       "         [-0.0235, -0.0476,  0.0793,  ...,  0.0409,  0.0666, -0.1190],\n",
       "         [ 0.1150, -0.1041, -0.0096,  ..., -0.0388, -0.1046, -0.0473],\n",
       "         ...,\n",
       "         [ 0.1222, -0.0687, -0.0999,  ...,  0.0511, -0.0506,  0.0930],\n",
       "         [ 0.0556, -0.0795, -0.0250,  ..., -0.0032, -0.0366,  0.0635],\n",
       "         [-0.0445, -0.0517, -0.0652,  ...,  0.1070, -0.1231, -0.0424]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0123,  0.0390,  0.0541,  ...,  0.0476,  0.0802,  0.0286],\n",
       "         [-0.0036, -0.0009, -0.1187,  ...,  0.0899,  0.0084,  0.1155],\n",
       "         [ 0.0614,  0.0177, -0.0387,  ..., -0.1080,  0.0247, -0.1232],\n",
       "         ...,\n",
       "         [ 0.0307, -0.1008,  0.1066,  ..., -0.0775, -0.0122, -0.0927],\n",
       "         [ 0.0502,  0.1192, -0.0698,  ...,  0.0766, -0.0358,  0.0507],\n",
       "         [ 0.0214,  0.0812,  0.0727,  ...,  0.1127, -0.1159, -0.0738]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0280,  0.0813, -0.0110,  ...,  0.0609,  0.1244, -0.0049],\n",
       "         [-0.0303,  0.0108,  0.0807,  ..., -0.1241,  0.1078, -0.0276],\n",
       "         [ 0.0744, -0.0797,  0.0700,  ...,  0.0493, -0.0745, -0.0606],\n",
       "         ...,\n",
       "         [-0.1153, -0.1191, -0.1151,  ...,  0.1064,  0.1067, -0.0335],\n",
       "         [ 0.1031,  0.1063, -0.1200,  ..., -0.1150, -0.0626, -0.0179],\n",
       "         [-0.0568,  0.0840,  0.1088,  ...,  0.1016, -0.0810,  0.0818]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0882, -0.0189, -0.0203,  ..., -0.1078,  0.0001,  0.0744],\n",
       "         [ 0.0437, -0.0648,  0.0470,  ...,  0.0911,  0.0036,  0.0575],\n",
       "         [-0.0448, -0.1177, -0.0960,  ...,  0.0167, -0.1230, -0.0244],\n",
       "         ...,\n",
       "         [-0.0644, -0.1168,  0.0446,  ...,  0.0572,  0.1185,  0.0365],\n",
       "         [ 0.1176,  0.0214, -0.0871,  ..., -0.0578, -0.0460, -0.0392],\n",
       "         [-0.0110, -0.1201,  0.0482,  ...,  0.0493,  0.1055, -0.1060]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0056, -0.1090, -0.0957,  ..., -0.0138,  0.0468,  0.0479],\n",
       "         [-0.1221, -0.0937, -0.0865,  ...,  0.1081, -0.1064,  0.0451],\n",
       "         [-0.0942, -0.1003, -0.0708,  ..., -0.0237,  0.0780, -0.0194],\n",
       "         ...,\n",
       "         [ 0.0561, -0.0394, -0.0133,  ..., -0.0700,  0.1121,  0.0482],\n",
       "         [-0.0844,  0.0061, -0.1119,  ...,  0.0783, -0.1241, -0.0058],\n",
       "         [-0.0338,  0.0884,  0.0750,  ...,  0.0318, -0.0625, -0.0502]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0091, -0.0489,  0.0686,  ...,  0.0562, -0.0264,  0.0878],\n",
       "         [ 0.1049,  0.0099, -0.0997,  ...,  0.0324, -0.0031, -0.0170],\n",
       "         [-0.1051,  0.1230,  0.0735,  ..., -0.0194,  0.1097, -0.0347],\n",
       "         ...,\n",
       "         [ 0.0229, -0.0221, -0.0774,  ...,  0.0097, -0.1057, -0.0085],\n",
       "         [ 0.0336,  0.0463,  0.0200,  ...,  0.0101,  0.0977, -0.0333],\n",
       "         [-0.0554,  0.0026,  0.0314,  ..., -0.0573,  0.0182, -0.0414]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0063, -0.0407,  0.0067,  ...,  0.0046,  0.0156,  0.0298],\n",
       "         [-0.0844, -0.0418, -0.1049,  ...,  0.1234,  0.0213, -0.0880],\n",
       "         [ 0.1071,  0.0980, -0.1248,  ..., -0.0581, -0.0996,  0.0344],\n",
       "         ...,\n",
       "         [-0.0119, -0.0699,  0.0261,  ...,  0.1054,  0.1032, -0.0503],\n",
       "         [-0.0481, -0.0314,  0.0266,  ..., -0.0638,  0.0050, -0.0478],\n",
       "         [ 0.0852, -0.0261, -0.0686,  ..., -0.0943,  0.0163,  0.0404]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0281,  0.0045,  0.0077,  ..., -0.0823,  0.0961,  0.0468],\n",
       "         [ 0.0060,  0.0836,  0.0555,  ...,  0.1123,  0.1091,  0.0819],\n",
       "         [ 0.0704, -0.0897,  0.0015,  ..., -0.0894,  0.1162, -0.0428],\n",
       "         ...,\n",
       "         [ 0.0921, -0.0315, -0.0112,  ..., -0.0888,  0.0439, -0.0193],\n",
       "         [-0.0921, -0.0847,  0.1105,  ...,  0.0048, -0.0243, -0.0419],\n",
       "         [ 0.0832, -0.1055, -0.1058,  ...,  0.0653, -0.0400,  0.1089]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0262,  0.0112, -0.0973,  ...,  0.0137, -0.1121,  0.0467],\n",
       "         [ 0.0022, -0.0388, -0.0739,  ..., -0.0286, -0.0664, -0.0963],\n",
       "         [ 0.0456,  0.1230,  0.0152,  ..., -0.1188, -0.0604, -0.1149],\n",
       "         ...,\n",
       "         [-0.1154,  0.0190, -0.0525,  ...,  0.0437, -0.1000,  0.0777],\n",
       "         [ 0.0082,  0.0743, -0.0190,  ...,  0.0664, -0.0079,  0.0822],\n",
       "         [-0.0530, -0.0415, -0.0148,  ...,  0.0720,  0.0596,  0.0200]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0463, -0.0059,  0.0773,  ...,  0.0797,  0.0770,  0.0674],\n",
       "         [-0.0267, -0.0408,  0.0952,  ...,  0.0364, -0.1205, -0.0180],\n",
       "         [ 0.0747, -0.0546, -0.0626,  ..., -0.0471, -0.0460, -0.0621],\n",
       "         ...,\n",
       "         [-0.0447,  0.0074,  0.0993,  ..., -0.0976,  0.0245, -0.0922],\n",
       "         [-0.0230, -0.0339, -0.1167,  ...,  0.0566,  0.0565, -0.0070],\n",
       "         [ 0.1156,  0.0219, -0.0278,  ...,  0.0637, -0.0058,  0.0733]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1118,  0.0023, -0.0575,  ...,  0.0925,  0.0436,  0.1124],\n",
       "         [-0.0415, -0.0228,  0.0545,  ...,  0.0979,  0.0904,  0.0470],\n",
       "         [ 0.0812, -0.1224,  0.0766,  ...,  0.0858,  0.0755,  0.1137],\n",
       "         ...,\n",
       "         [-0.1024,  0.0446,  0.0048,  ...,  0.1183, -0.0571, -0.0443],\n",
       "         [ 0.0459,  0.0560, -0.1114,  ..., -0.1022,  0.0939,  0.0431],\n",
       "         [-0.0307,  0.1150, -0.0538,  ...,  0.0175,  0.1080, -0.0151]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0050, -0.0265,  0.0569,  ...,  0.0967,  0.0919, -0.0085],\n",
       "         [-0.0689, -0.0567,  0.1186,  ..., -0.0134, -0.0615,  0.0887],\n",
       "         [-0.0187,  0.0903, -0.0058,  ...,  0.0547, -0.1237,  0.0726],\n",
       "         ...,\n",
       "         [ 0.1105,  0.0794, -0.0878,  ..., -0.0261,  0.0162,  0.0685],\n",
       "         [-0.1134, -0.0741,  0.0771,  ...,  0.0707,  0.0118,  0.0853],\n",
       "         [ 0.0037, -0.0507, -0.0297,  ...,  0.0421,  0.0425, -0.0783]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0210, -0.0343,  0.0565,  ..., -0.0405, -0.0074, -0.0404],\n",
       "         [-0.0888,  0.0634, -0.0613,  ...,  0.0566,  0.1108, -0.0311],\n",
       "         [-0.1017,  0.0739,  0.1174,  ..., -0.1040,  0.1022,  0.0852],\n",
       "         ...,\n",
       "         [ 0.0331, -0.0891,  0.1132,  ...,  0.0269,  0.1118, -0.0403],\n",
       "         [-0.0994, -0.0331, -0.1131,  ..., -0.1017, -0.0178, -0.0618],\n",
       "         [-0.0159,  0.0631, -0.0615,  ...,  0.0367, -0.0124, -0.0116]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0582, -0.0541,  0.0368,  ...,  0.1223,  0.0002,  0.1053],\n",
       "         [ 0.1205, -0.0472, -0.0779,  ...,  0.0935,  0.1058,  0.0031],\n",
       "         [ 0.1237,  0.0471, -0.0454,  ...,  0.0917,  0.0270, -0.0093],\n",
       "         ...,\n",
       "         [ 0.0827,  0.0416, -0.0173,  ..., -0.0484, -0.0554,  0.0612],\n",
       "         [-0.0922, -0.0594, -0.0719,  ..., -0.0671,  0.0077,  0.0956],\n",
       "         [ 0.0910,  0.0306,  0.0670,  ...,  0.0384, -0.0884,  0.0179]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0492, -0.0768,  0.0141,  ...,  0.0225, -0.0532,  0.0452],\n",
       "         [-0.0389,  0.0492,  0.0845,  ..., -0.0864, -0.0929,  0.0075],\n",
       "         [ 0.0709,  0.0433,  0.0764,  ..., -0.0745,  0.0540,  0.1117],\n",
       "         ...,\n",
       "         [ 0.0785, -0.0911, -0.0554,  ..., -0.0300,  0.0209, -0.0232],\n",
       "         [ 0.0936, -0.0873,  0.0138,  ...,  0.1177, -0.0070,  0.0192],\n",
       "         [-0.1208, -0.1138,  0.1153,  ...,  0.0750,  0.0150, -0.0688]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0317,  0.0196, -0.0829,  ..., -0.1001,  0.0682,  0.1197],\n",
       "         [ 0.0298, -0.0532, -0.0527,  ...,  0.0422, -0.0825, -0.0767],\n",
       "         [-0.0234,  0.0986,  0.0149,  ...,  0.0839, -0.0718,  0.0464],\n",
       "         ...,\n",
       "         [-0.1186, -0.0267, -0.0527,  ...,  0.1186,  0.0522,  0.0396],\n",
       "         [-0.0363,  0.0987, -0.0236,  ..., -0.1147, -0.0135, -0.0108],\n",
       "         [-0.0528,  0.0466, -0.0174,  ...,  0.1081,  0.0880, -0.0612]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1180, -0.0062, -0.0147,  ...,  0.0415, -0.0990,  0.0452],\n",
       "         [ 0.1084, -0.0462,  0.0689,  ...,  0.0681,  0.0160, -0.0523],\n",
       "         [ 0.0066,  0.1070, -0.0190,  ...,  0.1243,  0.0505, -0.0364],\n",
       "         ...,\n",
       "         [ 0.0338, -0.0381,  0.0089,  ...,  0.0260, -0.1164,  0.1070],\n",
       "         [-0.0212,  0.0693, -0.0537,  ..., -0.0931,  0.0739, -0.0097],\n",
       "         [ 0.0826, -0.0542,  0.0418,  ...,  0.1110, -0.0588, -0.1082]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1158, -0.1011,  0.0248,  ...,  0.0664,  0.0272,  0.0555],\n",
       "         [ 0.0045, -0.0148,  0.0745,  ..., -0.0044,  0.0245, -0.0481],\n",
       "         [ 0.0025, -0.0968, -0.0170,  ..., -0.0304,  0.0540,  0.1001],\n",
       "         ...,\n",
       "         [ 0.1150,  0.0833,  0.0229,  ...,  0.0666,  0.0259,  0.0032],\n",
       "         [ 0.0115,  0.0907,  0.0701,  ...,  0.0703, -0.0120, -0.0322],\n",
       "         [ 0.0713, -0.0471, -0.0535,  ...,  0.0080,  0.0432, -0.0419]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.1904e-01, -7.8128e-02, -9.7811e-02,  ..., -5.0225e-02,\n",
       "           1.1457e-01, -7.8025e-02],\n",
       "         [ 6.8291e-02,  4.8937e-03,  2.3236e-02,  ..., -6.6214e-02,\n",
       "          -3.8738e-02, -6.1257e-03],\n",
       "         [ 5.3902e-02, -7.6785e-02, -5.3668e-02,  ...,  1.0144e-01,\n",
       "          -5.5772e-02,  8.4026e-02],\n",
       "         ...,\n",
       "         [ 2.7213e-02, -4.2583e-02, -7.8449e-02,  ..., -2.6678e-06,\n",
       "           1.1713e-01,  4.5567e-02],\n",
       "         [ 6.1735e-02,  4.4322e-02, -3.5703e-02,  ...,  2.7186e-02,\n",
       "          -1.2163e-01, -6.5338e-03],\n",
       "         [ 3.7045e-02,  1.1377e-01, -9.7005e-02,  ...,  2.1470e-02,\n",
       "          -4.8989e-03, -4.1872e-02]], device='cuda:0'),\n",
       " tensor([[-0.1079,  0.0307, -0.0567,  ..., -0.0410, -0.0649,  0.1020],\n",
       "         [ 0.0003,  0.0574,  0.0909,  ..., -0.0957, -0.0713,  0.0967],\n",
       "         [ 0.0752, -0.0657,  0.1104,  ...,  0.0696, -0.1139,  0.1242],\n",
       "         ...,\n",
       "         [ 0.0593,  0.0732, -0.0902,  ...,  0.0219, -0.0528,  0.0781],\n",
       "         [ 0.1241, -0.0752,  0.0855,  ..., -0.0248, -0.0423, -0.0231],\n",
       "         [-0.1194,  0.0092,  0.0184,  ...,  0.1122,  0.0753, -0.0087]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0845, -0.1238, -0.1164,  ..., -0.0997,  0.0301, -0.1243],\n",
       "         [-0.0674, -0.0661, -0.0792,  ..., -0.0636,  0.1250, -0.0428],\n",
       "         [ 0.1041,  0.0942,  0.0990,  ...,  0.0635,  0.0481, -0.1167],\n",
       "         ...,\n",
       "         [-0.1203,  0.0938, -0.0164,  ..., -0.0531,  0.1166, -0.0324],\n",
       "         [-0.1023, -0.0207,  0.0340,  ..., -0.0458, -0.0675,  0.0593],\n",
       "         [-0.0460,  0.0739, -0.0132,  ...,  0.0831, -0.0910, -0.0071]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0137, -0.0144, -0.0958,  ...,  0.0993,  0.0259, -0.1093],\n",
       "         [ 0.0145,  0.1222,  0.0909,  ...,  0.0453, -0.0858,  0.0737],\n",
       "         [ 0.1225,  0.0368,  0.1000,  ...,  0.0414,  0.0487, -0.0397],\n",
       "         ...,\n",
       "         [ 0.0192, -0.0779, -0.0629,  ...,  0.0308,  0.0447, -0.0170],\n",
       "         [ 0.0816, -0.0425,  0.0371,  ...,  0.1138,  0.0704, -0.0016],\n",
       "         [-0.0443, -0.0885, -0.0334,  ..., -0.0880,  0.0272,  0.0271]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0299,  0.0380,  0.0204,  ..., -0.0113, -0.0230,  0.0137],\n",
       "         [-0.0226,  0.0027, -0.0170,  ...,  0.0123,  0.0171,  0.0186],\n",
       "         [-0.0036,  0.0161,  0.0426,  ..., -0.0184,  0.0236,  0.0054],\n",
       "         ...,\n",
       "         [-0.0351, -0.0046,  0.0173,  ..., -0.0019,  0.0211,  0.0319],\n",
       "         [ 0.0415,  0.0147,  0.0278,  ..., -0.0409, -0.0010, -0.0073],\n",
       "         [ 0.0046,  0.0002,  0.0430,  ...,  0.0264,  0.0100,  0.0099]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0202,  0.0090,  0.0212,  ..., -0.0067,  0.0004, -0.0166],\n",
       "         [ 0.0052, -0.0078, -0.0016,  ...,  0.0109, -0.0011, -0.0015],\n",
       "         [-0.0061, -0.0098, -0.0157,  ...,  0.0202,  0.0150,  0.0029],\n",
       "         ...,\n",
       "         [ 0.0021, -0.0053,  0.0198,  ...,  0.0213,  0.0049,  0.0023],\n",
       "         [-0.0032,  0.0063, -0.0052,  ...,  0.0007, -0.0048,  0.0110],\n",
       "         [ 0.0028, -0.0146,  0.0134,  ...,  0.0178, -0.0089, -0.0123]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.0386, -0.0792,  0.1009, -0.0159,  0.1214,  0.0793,  0.1194, -0.0307,\n",
       "         -0.0972,  0.1185,  0.0126,  0.0814, -0.0493, -0.0587, -0.1017, -0.1085,\n",
       "         -0.1190, -0.0011, -0.0407,  0.0977, -0.0347,  0.0697, -0.0090, -0.0658,\n",
       "         -0.0900, -0.0026,  0.0679,  0.0673, -0.0944, -0.1005,  0.0027, -0.0590,\n",
       "         -0.1099,  0.0175,  0.0300,  0.0435, -0.0792,  0.1143, -0.1065, -0.0656,\n",
       "         -0.0511,  0.0877, -0.0720,  0.1166, -0.0792,  0.1130,  0.0481,  0.1244,\n",
       "         -0.0421,  0.1001, -0.0304,  0.0928, -0.0863, -0.0036, -0.0715,  0.0336,\n",
       "         -0.0191, -0.0158,  0.0206, -0.0480,  0.0074, -0.0432,  0.0653, -0.0714],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1237,  0.0761,  0.0385, -0.1072, -0.0332,  0.0683, -0.0435, -0.0507,\n",
       "         -0.0075, -0.0942,  0.0538,  0.1158, -0.1095, -0.0263,  0.0348, -0.0767,\n",
       "         -0.0151, -0.0372, -0.0060, -0.0775,  0.0949,  0.0858, -0.0761, -0.0225,\n",
       "          0.0973,  0.0118, -0.0961, -0.0508, -0.1088, -0.0549, -0.0780,  0.0380,\n",
       "          0.0477, -0.1031,  0.0264, -0.0975, -0.0127,  0.0178, -0.0757,  0.0732,\n",
       "         -0.0467,  0.0312,  0.0936, -0.0921, -0.0707, -0.0029, -0.0043,  0.0952,\n",
       "         -0.0276, -0.0092,  0.0793, -0.0533, -0.0349,  0.0488, -0.0751,  0.0917,\n",
       "         -0.0748, -0.1112,  0.0132, -0.1033,  0.0379, -0.0916, -0.0132,  0.0203],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0817, -0.0260, -0.0213, -0.0156, -0.0369, -0.1054,  0.0057, -0.0331,\n",
       "         -0.1101,  0.1036, -0.0121,  0.0219,  0.0764,  0.0336, -0.0249,  0.0579,\n",
       "         -0.0099,  0.0733,  0.0619, -0.0614,  0.0319, -0.1003, -0.0108, -0.0535,\n",
       "         -0.0769,  0.0927,  0.0488, -0.1096, -0.0787,  0.0597, -0.0540, -0.0709,\n",
       "          0.0978, -0.0577, -0.0091,  0.0525, -0.0920, -0.0802,  0.0663,  0.0038,\n",
       "         -0.1061,  0.0659,  0.1139,  0.0381, -0.0127, -0.0160, -0.0489, -0.0401,\n",
       "         -0.0910,  0.0019, -0.0995, -0.0700,  0.0077,  0.0472,  0.0374,  0.0645,\n",
       "         -0.1008,  0.0549, -0.0380, -0.0288,  0.1276,  0.0140, -0.0045, -0.0638],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1189, -0.1145, -0.0922, -0.0963, -0.0441,  0.0698,  0.0031, -0.0645,\n",
       "          0.0298,  0.0293,  0.0414, -0.0401,  0.0597, -0.0572, -0.0056, -0.0464,\n",
       "          0.0244, -0.0700,  0.1126,  0.0946,  0.0475,  0.0498,  0.1238,  0.1104,\n",
       "          0.1059, -0.0149, -0.0619, -0.0258, -0.0703, -0.0447, -0.0076,  0.1144,\n",
       "          0.0831,  0.0383,  0.0533,  0.1240,  0.1166, -0.0796,  0.0419,  0.0528,\n",
       "          0.0883, -0.1073,  0.0787, -0.0266, -0.0522,  0.0144,  0.0779, -0.0896,\n",
       "         -0.1054, -0.0213, -0.0718,  0.0335,  0.0068, -0.0776, -0.0653,  0.0122,\n",
       "         -0.0053, -0.1136, -0.0347, -0.1167, -0.0806,  0.0762, -0.0667,  0.0778],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0281,  0.0291,  0.0801, -0.0119,  0.0154, -0.0951,  0.1141, -0.0317,\n",
       "          0.0067,  0.0938, -0.1227, -0.0959,  0.0316,  0.0866,  0.0155, -0.0278,\n",
       "          0.0990, -0.0605,  0.0914,  0.0255,  0.0998, -0.0694, -0.1179,  0.0671,\n",
       "         -0.0394, -0.1030, -0.0060,  0.0708, -0.1003,  0.0464,  0.0015, -0.0735,\n",
       "         -0.0258,  0.0340, -0.1059, -0.1095,  0.0273,  0.0859,  0.0679, -0.1005,\n",
       "          0.0497, -0.0094, -0.0242,  0.0642, -0.1101,  0.0019,  0.0941,  0.0477,\n",
       "         -0.0528, -0.1056, -0.1139,  0.1139,  0.1033,  0.0570,  0.0078,  0.1168,\n",
       "         -0.0365, -0.0866,  0.0634, -0.0773, -0.0901, -0.0002,  0.0716, -0.0048],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0717,  0.0616, -0.0009,  0.0564,  0.0161,  0.0572, -0.1003, -0.1140,\n",
       "          0.0389,  0.0220,  0.0369, -0.0516, -0.0763,  0.1200,  0.0559, -0.1194,\n",
       "         -0.0151,  0.1124, -0.0258, -0.0845, -0.0708,  0.0207, -0.0590,  0.0983,\n",
       "          0.0846,  0.0606,  0.0707,  0.0399,  0.0715, -0.0804,  0.1069, -0.0834,\n",
       "         -0.1223, -0.0626,  0.0585, -0.0372, -0.0018,  0.0671,  0.0480,  0.1091,\n",
       "         -0.0978,  0.0327, -0.0753, -0.0026, -0.0400,  0.0316,  0.0534, -0.0653,\n",
       "         -0.1123,  0.0853,  0.0694, -0.0066,  0.0445, -0.0601,  0.0156, -0.0779,\n",
       "          0.0264,  0.0754, -0.0045,  0.0887, -0.0477,  0.0597,  0.1159,  0.0250],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0329,  0.0561, -0.0094, -0.0765, -0.1178,  0.0028,  0.0322, -0.0172,\n",
       "         -0.0255,  0.1018,  0.0957,  0.0489,  0.0643,  0.0311,  0.0749,  0.0525,\n",
       "          0.0064, -0.0816,  0.0927,  0.1010, -0.0088,  0.0382,  0.0521, -0.0891,\n",
       "         -0.0652, -0.1092, -0.1171,  0.1202,  0.0811,  0.0406,  0.0291, -0.0750,\n",
       "          0.1201,  0.0174,  0.0313,  0.0131,  0.0097, -0.0896,  0.0231, -0.1041,\n",
       "         -0.0110,  0.0569, -0.0993,  0.0099,  0.0628, -0.0196,  0.0143,  0.0135,\n",
       "          0.0507, -0.0571, -0.0344,  0.0142,  0.0333, -0.1020,  0.0069,  0.0715,\n",
       "          0.0187, -0.0282, -0.0573,  0.0634, -0.0046,  0.1212,  0.0557, -0.0424],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1023,  0.0718,  0.0386,  0.0071, -0.0783,  0.0261,  0.0710,  0.0551,\n",
       "          0.0427,  0.0790, -0.0187,  0.0123,  0.0658, -0.0063, -0.0658,  0.0338,\n",
       "         -0.0144, -0.1200, -0.0154,  0.0544, -0.0496, -0.0319,  0.0589,  0.1103,\n",
       "          0.0070, -0.0065,  0.0063, -0.0621,  0.0055,  0.0341, -0.0795, -0.0690,\n",
       "         -0.0847,  0.0190,  0.0518,  0.0719,  0.0577, -0.1136, -0.0283,  0.0425,\n",
       "         -0.0236, -0.1103, -0.0254, -0.0113, -0.0645, -0.0150,  0.0772, -0.0663,\n",
       "          0.0067, -0.0988,  0.0916,  0.0376,  0.0415, -0.0587, -0.0338, -0.0419,\n",
       "          0.0650,  0.0999,  0.0002,  0.0893, -0.0517, -0.1068, -0.0566,  0.0470],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0648, -0.0073,  0.0260,  0.0784, -0.0197, -0.0263, -0.0160,  0.1099,\n",
       "         -0.0698,  0.1061, -0.0482, -0.0465,  0.0328, -0.0908, -0.1072, -0.0441,\n",
       "         -0.0535, -0.1226,  0.0785, -0.0358, -0.0678,  0.0441,  0.0608, -0.0809,\n",
       "          0.0967, -0.0290,  0.1130,  0.0435,  0.0809, -0.0573, -0.0670,  0.0873,\n",
       "          0.0361,  0.0950, -0.0199,  0.0407,  0.0574,  0.0577,  0.1125,  0.0367,\n",
       "         -0.0155,  0.0993, -0.0940,  0.0315, -0.0024,  0.1130,  0.0591, -0.0168,\n",
       "         -0.1151, -0.0590,  0.0970,  0.0146,  0.1173, -0.1222,  0.0618, -0.0827,\n",
       "         -0.1243, -0.0734,  0.1223,  0.0589, -0.0445,  0.0191, -0.0979, -0.1107],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0818, -0.0119,  0.0093, -0.0563,  0.0377,  0.0783, -0.0183,  0.0713,\n",
       "         -0.0786, -0.0352,  0.0785,  0.0981,  0.0759,  0.0156,  0.0997, -0.0025,\n",
       "          0.1013, -0.0037, -0.1011, -0.1056, -0.0002, -0.0530, -0.0181, -0.0936,\n",
       "         -0.0828,  0.0037, -0.0763, -0.1102,  0.0278,  0.0673,  0.0507, -0.0041,\n",
       "          0.0964, -0.0078,  0.1188, -0.1085,  0.0346, -0.0616, -0.0793, -0.0547,\n",
       "          0.0520, -0.0081, -0.0562,  0.0082, -0.0120, -0.0541, -0.0835, -0.0110,\n",
       "         -0.0293, -0.0204,  0.0996, -0.0419,  0.0651,  0.0806, -0.0772,  0.1239,\n",
       "          0.0459, -0.0661,  0.0108,  0.0745, -0.0975, -0.0653,  0.0293,  0.0808],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0469, -0.0561, -0.0569, -0.0481, -0.0272, -0.0103, -0.1126,  0.0606,\n",
       "          0.0352,  0.1165, -0.1193,  0.0600, -0.0880, -0.1096, -0.0312,  0.0213,\n",
       "         -0.0524, -0.0802, -0.1067,  0.0757,  0.0456,  0.0863,  0.0695,  0.0893,\n",
       "          0.1036,  0.0751, -0.0174, -0.0885, -0.0447, -0.0214,  0.0337, -0.0664,\n",
       "          0.1204,  0.0900,  0.0590,  0.0429, -0.0980, -0.0448, -0.0977,  0.0437,\n",
       "         -0.0088, -0.0007, -0.0971,  0.0917,  0.0350,  0.1047, -0.0078, -0.0563,\n",
       "          0.0266, -0.0348, -0.0702,  0.0172,  0.1004,  0.0435, -0.0182, -0.0166,\n",
       "         -0.1040, -0.0782, -0.1008,  0.1189,  0.0610,  0.1014,  0.0317,  0.0516],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0334, -0.0388,  0.1032,  0.0925,  0.1023,  0.0655,  0.1032,  0.0473,\n",
       "         -0.1240, -0.1111,  0.0669, -0.1098, -0.0090,  0.0284, -0.0166, -0.0211,\n",
       "         -0.0891, -0.0194, -0.0518,  0.1228,  0.0896, -0.0097,  0.1217,  0.0572,\n",
       "         -0.1240, -0.1158,  0.1011,  0.0911, -0.1175, -0.0222,  0.0223, -0.0018,\n",
       "          0.0647,  0.0453, -0.0198,  0.0364,  0.1178,  0.1216,  0.0111,  0.0459,\n",
       "          0.0269, -0.0660,  0.0929,  0.1049, -0.0402,  0.0731,  0.1224, -0.0068,\n",
       "         -0.0232,  0.0179, -0.1174,  0.0588,  0.1027, -0.1234, -0.0321,  0.0941,\n",
       "          0.0404,  0.1219,  0.0095,  0.0284, -0.0917, -0.0647, -0.1013,  0.0760],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0338,  0.0249, -0.0545, -0.0312, -0.0346,  0.0525,  0.0696,  0.0726,\n",
       "          0.0480,  0.0866, -0.1190, -0.0630, -0.0094,  0.0227,  0.0338,  0.1126,\n",
       "         -0.1213,  0.0274,  0.0368, -0.0546, -0.1121, -0.1153,  0.1165, -0.0692,\n",
       "         -0.1152,  0.0771,  0.0417,  0.0117, -0.0308, -0.0220,  0.0840,  0.0758,\n",
       "          0.0172, -0.0335, -0.0086, -0.0717, -0.1185, -0.0174, -0.0427,  0.0175,\n",
       "          0.0453,  0.1139, -0.0311, -0.0659, -0.0893,  0.0400,  0.0915, -0.0240,\n",
       "          0.0277,  0.1124,  0.0636,  0.1229, -0.0512,  0.0926, -0.0091, -0.1155,\n",
       "          0.1022,  0.0671, -0.0511, -0.0522,  0.1169, -0.0922, -0.0757, -0.1047],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1094, -0.0265,  0.0032,  0.0013,  0.1162,  0.0623,  0.1202,  0.0444,\n",
       "          0.0521, -0.0132,  0.0656, -0.1042,  0.0540, -0.0442,  0.0626,  0.1084,\n",
       "          0.1013, -0.1047,  0.1179,  0.0186,  0.0733,  0.0707, -0.0526, -0.0622,\n",
       "         -0.0175,  0.0052,  0.0588,  0.0390,  0.1244,  0.0928, -0.1049, -0.0468,\n",
       "          0.0726, -0.0844, -0.1142, -0.0140,  0.0510, -0.1065,  0.0916,  0.1036,\n",
       "          0.1065,  0.1173,  0.0696,  0.0430, -0.0040,  0.1214,  0.1097,  0.0481,\n",
       "         -0.0251,  0.0553, -0.1105,  0.1083,  0.1105,  0.0913,  0.0179, -0.0382,\n",
       "         -0.0449,  0.0371, -0.0331,  0.0357,  0.0696, -0.0351, -0.0726,  0.0164],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0975,  0.0390, -0.0800,  0.0084, -0.0370, -0.1220,  0.0926,  0.0411,\n",
       "         -0.0961,  0.0506, -0.0076,  0.0650,  0.0977, -0.0860, -0.0062, -0.0599,\n",
       "         -0.0467, -0.1190, -0.0394,  0.0827, -0.1025,  0.0860, -0.1049,  0.0576,\n",
       "          0.0869, -0.0546, -0.1014,  0.0426, -0.0229, -0.0621, -0.1206,  0.0885,\n",
       "         -0.1004,  0.0944,  0.0544, -0.0741, -0.0505,  0.0644, -0.1187, -0.0244,\n",
       "         -0.1014, -0.0461, -0.0356, -0.0430,  0.0796,  0.0675, -0.0569,  0.0866,\n",
       "         -0.0570,  0.1166, -0.0177,  0.1129,  0.1163,  0.1223, -0.0253,  0.0449,\n",
       "         -0.0044, -0.0509,  0.1076,  0.0258,  0.1014, -0.0754, -0.1193, -0.0603],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0303, -0.0945,  0.0067, -0.1056, -0.0040,  0.1067,  0.0651,  0.0352,\n",
       "          0.0193, -0.0852,  0.0623,  0.0574,  0.0480, -0.0827, -0.0748,  0.1232,\n",
       "         -0.0092,  0.0286, -0.1235, -0.0798,  0.0331,  0.0352,  0.0969,  0.1048,\n",
       "          0.0565, -0.1157, -0.0860,  0.0104,  0.0713,  0.0041, -0.1117,  0.0909,\n",
       "          0.1099, -0.0675,  0.0295,  0.0486,  0.0638,  0.0763, -0.0935,  0.0438,\n",
       "          0.0432,  0.0830,  0.0137, -0.0303, -0.1158,  0.0079,  0.0426,  0.0412,\n",
       "         -0.0982,  0.0213,  0.0603,  0.1083, -0.0334, -0.1198,  0.0721,  0.1177,\n",
       "          0.0180, -0.0142,  0.0603,  0.0323, -0.0181, -0.0600,  0.1187, -0.0929],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0313, -0.1186,  0.0708, -0.0534, -0.0746,  0.0739,  0.0521, -0.0508,\n",
       "          0.0219,  0.0211, -0.0518, -0.0734,  0.0374, -0.0458,  0.1094, -0.0525,\n",
       "          0.0528, -0.0283, -0.0431,  0.0184,  0.0127, -0.0537,  0.0697,  0.0099,\n",
       "          0.0706, -0.0614, -0.0051,  0.0149,  0.0368, -0.1104,  0.0399, -0.0273,\n",
       "         -0.0863,  0.0862,  0.0375,  0.0423,  0.0456,  0.0608, -0.1170,  0.0792,\n",
       "          0.0230, -0.0265,  0.1076,  0.0949, -0.0289,  0.0797, -0.0308, -0.0943,\n",
       "          0.0898,  0.1067,  0.0946, -0.1236,  0.0186,  0.0558, -0.0061,  0.1095,\n",
       "         -0.0339, -0.0084,  0.0883, -0.1216, -0.1042,  0.0750, -0.0086, -0.0305],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1250, -0.0761,  0.0647,  0.0362,  0.0443,  0.0335,  0.0507, -0.1024,\n",
       "         -0.0894, -0.0425, -0.0613, -0.0830, -0.0173, -0.0162, -0.1059, -0.0279,\n",
       "          0.1248, -0.0829, -0.0649,  0.0091,  0.0310, -0.0415, -0.0778, -0.0714,\n",
       "          0.0972,  0.0102,  0.0544,  0.0815, -0.0679,  0.1186, -0.0402, -0.0485,\n",
       "          0.0617,  0.1241,  0.0698, -0.0334,  0.1237,  0.0972, -0.0102,  0.0781,\n",
       "          0.1037,  0.0690,  0.0198,  0.0682, -0.1063,  0.0959,  0.1061, -0.0282,\n",
       "          0.0774,  0.0742, -0.0224, -0.1107,  0.0528, -0.0528, -0.0937, -0.0630,\n",
       "         -0.0556, -0.0592, -0.0031, -0.0319, -0.0061,  0.0656,  0.1162, -0.1105],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0347,  0.0058,  0.0622,  0.0634,  0.0040, -0.0184,  0.0632, -0.0561,\n",
       "          0.0717,  0.0286,  0.0766,  0.0265,  0.1240,  0.0680, -0.1250, -0.0718,\n",
       "          0.0675,  0.0108, -0.0976,  0.0179,  0.0947, -0.0143,  0.0703, -0.0472,\n",
       "         -0.0539, -0.0987,  0.0051, -0.0997, -0.0444,  0.0669,  0.0426,  0.1281,\n",
       "          0.0868, -0.0320,  0.0626,  0.1039,  0.1108,  0.1226, -0.0495, -0.1159,\n",
       "          0.0759, -0.0537, -0.0327, -0.0707, -0.0461,  0.0694,  0.0340, -0.0514,\n",
       "          0.0415,  0.0093, -0.0646, -0.0691, -0.0288, -0.0767,  0.0347,  0.1016,\n",
       "          0.1281,  0.0903, -0.1159,  0.0268, -0.0104,  0.1159, -0.0915,  0.0466],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1088, -0.0817, -0.0149, -0.0592, -0.1038, -0.0347, -0.0659, -0.1144,\n",
       "         -0.0537,  0.0580,  0.0695,  0.0119, -0.0029,  0.0411, -0.0077, -0.0742,\n",
       "         -0.0226,  0.1285,  0.1127, -0.0811,  0.0711, -0.0792, -0.0595, -0.0577,\n",
       "         -0.0238,  0.1200, -0.0496, -0.0711,  0.0955,  0.0659,  0.1187,  0.0624,\n",
       "         -0.0953,  0.0315,  0.0867, -0.0260,  0.0342,  0.1203, -0.0433,  0.0087,\n",
       "         -0.0850, -0.0556, -0.0773,  0.0845, -0.0666, -0.0159,  0.0490,  0.1235,\n",
       "         -0.0151, -0.0655,  0.0763, -0.0862, -0.1001, -0.0748, -0.0279,  0.0870,\n",
       "         -0.1225,  0.0328, -0.0407,  0.0559, -0.1192,  0.0774, -0.0827,  0.0424],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1035,  0.0727,  0.0687,  0.0957, -0.0806, -0.1216, -0.0734,  0.0209,\n",
       "          0.0798, -0.0432,  0.0410,  0.0720, -0.1271,  0.0070,  0.0956, -0.1106,\n",
       "          0.0003, -0.1135, -0.1170, -0.0458,  0.1035,  0.0764, -0.0807,  0.1154,\n",
       "          0.1137,  0.0632, -0.0837, -0.1055, -0.0973, -0.1202,  0.0145,  0.0362,\n",
       "          0.0449, -0.0894, -0.0051, -0.0584, -0.0892,  0.0756,  0.0211, -0.0614,\n",
       "          0.0883,  0.1019,  0.0929, -0.0114, -0.0770, -0.0144, -0.0529, -0.0097,\n",
       "          0.0627, -0.0378,  0.0206, -0.0627, -0.1055, -0.0691, -0.1202,  0.1229,\n",
       "          0.1102, -0.0509,  0.0903, -0.0922, -0.0395,  0.0566, -0.0150, -0.0064],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0701, -0.1130, -0.0103, -0.1158, -0.1234,  0.0270,  0.0679,  0.0852,\n",
       "          0.0837, -0.0098, -0.0843, -0.0289, -0.0247, -0.1172,  0.0589, -0.0524,\n",
       "         -0.0163,  0.0451,  0.0544,  0.0353, -0.0861,  0.0248,  0.0795,  0.0457,\n",
       "         -0.0434, -0.0625, -0.0781, -0.0022,  0.0497,  0.0460,  0.0270, -0.0732,\n",
       "         -0.0084,  0.1021, -0.0410,  0.0462, -0.1176, -0.0239,  0.0052, -0.0255,\n",
       "          0.1169, -0.0527,  0.0105, -0.0647, -0.1202,  0.0202,  0.0522, -0.0533,\n",
       "          0.0951,  0.0540,  0.0928, -0.0983,  0.0979, -0.0782,  0.0318,  0.0716,\n",
       "          0.0132, -0.1098,  0.0487,  0.0897, -0.0148, -0.0728, -0.0966, -0.0146],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0487,  0.0318,  0.0441, -0.0562, -0.1173,  0.1196, -0.0954, -0.0500,\n",
       "         -0.0992,  0.0010, -0.0453, -0.0881, -0.1209,  0.0191, -0.0405, -0.1101,\n",
       "          0.0410,  0.1159, -0.0265, -0.0507, -0.1181, -0.0224, -0.0587,  0.0660,\n",
       "         -0.0897,  0.0640,  0.0112, -0.1223, -0.0612, -0.0532,  0.1151,  0.0425,\n",
       "         -0.0631,  0.0053, -0.0945, -0.0436, -0.1102,  0.0565,  0.1208,  0.0964,\n",
       "         -0.0110, -0.0058, -0.0497,  0.0938,  0.0751,  0.1115, -0.1026, -0.0298,\n",
       "         -0.0010,  0.0784,  0.0210, -0.0558,  0.1069, -0.0325,  0.0245, -0.0940,\n",
       "          0.1001, -0.0669, -0.1057,  0.1020,  0.0499,  0.0717, -0.0418, -0.0851],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1073,  0.0625, -0.0836, -0.0815, -0.0701, -0.0276, -0.0725,  0.0074,\n",
       "          0.0811, -0.0417,  0.0805,  0.0017, -0.0965, -0.0381, -0.1094,  0.0559,\n",
       "          0.0187,  0.0634,  0.0068, -0.1064, -0.0238,  0.0334,  0.0849, -0.0080,\n",
       "          0.1254, -0.0633,  0.0337, -0.0856,  0.0536,  0.1022, -0.0045, -0.0081,\n",
       "         -0.0187, -0.0704,  0.1134,  0.0701,  0.1239,  0.0641,  0.0275,  0.0408,\n",
       "          0.0837, -0.1150,  0.0752, -0.0369,  0.0980,  0.0365, -0.1019, -0.0119,\n",
       "          0.0115,  0.0248,  0.0883, -0.0378,  0.0653, -0.0056,  0.1000, -0.0850,\n",
       "         -0.1139,  0.0551,  0.0420, -0.0920, -0.1061,  0.0610, -0.0958, -0.0290],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0281,  0.0212, -0.0273,  ...,  0.0436, -0.0111,  0.0039],\n",
       "        device='cuda:0'),\n",
       " tensor([-1.0009e-02,  3.6995e-03, -1.2228e-02, -2.5463e-04,  7.2851e-03,\n",
       "         -1.0316e-02,  7.0803e-03, -1.1467e-02,  1.3033e-02, -5.4170e-03,\n",
       "          4.0815e-03,  7.9978e-03, -6.9237e-03, -1.3585e-02, -8.8148e-03,\n",
       "         -8.3134e-03, -1.5488e-02, -1.9294e-02,  2.6025e-02, -2.1740e-03,\n",
       "          1.5750e-03,  7.2372e-03, -1.2965e-02,  1.6731e-03,  2.4731e-03,\n",
       "          1.9819e-02,  2.7620e-02,  3.9019e-03,  1.9577e-03,  5.2498e-03,\n",
       "          6.3831e-03, -7.8901e-03, -9.1576e-03, -2.2353e-03, -1.5709e-02,\n",
       "          1.5308e-02, -2.4794e-02, -1.4107e-02,  2.0723e-02,  3.1665e-03,\n",
       "          1.3015e-03,  1.9752e-02,  9.7131e-03,  2.0629e-02,  1.0153e-02,\n",
       "          6.1163e-03,  6.1957e-03,  5.2394e-03, -2.1486e-02, -1.2297e-02,\n",
       "         -1.6164e-02,  1.8558e-02,  4.5402e-03,  1.6184e-02, -1.9341e-03,\n",
       "          1.3398e-02, -2.0647e-02,  1.8326e-02,  3.0557e-04, -1.3195e-02,\n",
       "          1.0425e-02, -1.1242e-02, -2.3366e-02, -1.1644e-02,  7.1266e-03,\n",
       "          2.5639e-02,  5.0378e-03, -4.9477e-03,  7.2269e-03, -7.1921e-03,\n",
       "         -1.4578e-02, -1.4473e-02,  2.2248e-03, -9.3772e-03, -1.7022e-02,\n",
       "         -1.1156e-02, -1.2325e-02,  3.0703e-03,  1.0889e-02,  1.8343e-02,\n",
       "         -1.9407e-02, -1.1281e-02, -2.8285e-03, -1.4558e-02, -1.3327e-02,\n",
       "         -1.0627e-02,  1.4436e-02,  1.2290e-03, -1.4250e-02,  5.3295e-03,\n",
       "          2.1498e-02, -1.4060e-02, -1.5495e-02,  3.8138e-03,  2.4518e-02,\n",
       "          5.1327e-03,  2.6025e-03, -2.3286e-02,  1.6812e-02,  2.2052e-03,\n",
       "         -3.6021e-03,  1.7738e-02,  1.7641e-02,  1.7489e-02, -1.1774e-02,\n",
       "          2.0214e-02,  1.7774e-02, -1.1559e-02, -1.1725e-02,  1.2250e-02,\n",
       "         -3.6072e-03,  1.5220e-02, -7.2193e-03, -7.5380e-03,  1.0489e-02,\n",
       "          2.1202e-02,  1.7603e-02,  1.6681e-02, -1.8979e-02, -2.0826e-02,\n",
       "         -1.1792e-02, -1.1555e-02, -1.3207e-02,  1.8267e-02, -2.7166e-03,\n",
       "          1.0720e-02,  4.8348e-03, -2.0809e-02,  9.4919e-03, -1.1405e-02,\n",
       "         -7.5291e-03,  1.8997e-02, -8.1827e-03,  1.0465e-02, -1.7298e-03,\n",
       "         -2.0002e-02, -3.1709e-03,  1.8903e-02,  1.0198e-02, -2.3169e-02,\n",
       "          5.6379e-04,  1.7113e-02,  1.0671e-04, -1.9760e-02, -1.5957e-02,\n",
       "          1.2070e-02, -1.1301e-02, -5.8632e-03,  4.9821e-03, -6.8246e-03,\n",
       "         -1.7769e-02,  1.5608e-02, -4.0697e-03, -1.0883e-02, -1.8786e-02,\n",
       "         -3.4907e-03, -1.1731e-02,  7.9208e-03,  1.2967e-02,  1.9336e-03,\n",
       "          2.0155e-02,  2.3203e-02,  1.4799e-02, -1.2828e-02,  2.6553e-03,\n",
       "         -1.2007e-02,  6.3316e-03, -2.0144e-02,  7.4857e-03, -2.5890e-03,\n",
       "         -1.4883e-03,  4.1579e-03,  1.9039e-02, -2.9225e-03,  2.6195e-02,\n",
       "          1.7544e-02,  9.5101e-03,  7.4626e-03,  1.2252e-02, -8.5872e-03,\n",
       "         -1.5143e-02,  1.6183e-02, -1.4929e-04, -2.3258e-02, -1.7170e-02,\n",
       "         -8.4413e-03, -1.1274e-02,  1.6760e-02, -5.3103e-03, -2.2008e-03,\n",
       "          1.9596e-02,  5.0601e-04,  2.1921e-02, -5.9017e-03,  2.0102e-02,\n",
       "         -1.0186e-02,  1.1437e-02,  1.8039e-02,  5.2844e-03, -2.0221e-02,\n",
       "         -1.2884e-02,  1.5718e-02,  1.8638e-02,  1.2913e-02,  1.8331e-02,\n",
       "          1.4154e-02, -2.1230e-02, -6.1002e-03,  1.9798e-02,  1.8887e-02,\n",
       "          8.8677e-03,  9.7802e-03, -6.6979e-03,  6.9438e-03,  1.4667e-02,\n",
       "          1.9516e-02, -8.0031e-03,  1.7803e-02,  8.7441e-03,  9.5665e-04,\n",
       "          2.1680e-02, -1.4423e-02, -7.0470e-03,  2.0917e-02, -2.2702e-02,\n",
       "          1.6017e-02, -1.0386e-02, -3.3461e-03, -1.5101e-02, -1.1993e-02,\n",
       "         -1.2636e-02, -1.3212e-02, -2.7796e-03,  2.5027e-02,  1.3074e-02,\n",
       "          3.3540e-03,  3.1211e-03, -5.7260e-03,  9.8569e-03,  6.3051e-03,\n",
       "         -1.2479e-02,  2.8574e-03,  1.2517e-02, -6.7422e-03, -4.3045e-03,\n",
       "         -1.1681e-03, -3.8494e-03,  3.9526e-03, -4.1898e-03, -1.9347e-02,\n",
       "         -8.6952e-03,  2.3517e-03,  1.2258e-02,  9.1966e-03,  8.0140e-03,\n",
       "          1.5872e-02, -1.4824e-02, -9.0665e-03,  1.8400e-02, -1.0425e-02,\n",
       "          1.0377e-02,  7.7354e-03, -1.9773e-02,  1.9203e-03,  1.2053e-02,\n",
       "          1.6222e-02, -1.7322e-02,  8.4902e-04,  1.0009e-02, -3.4820e-03,\n",
       "         -3.7105e-03, -4.4405e-03, -8.9508e-03,  1.3354e-02, -1.9658e-02,\n",
       "         -1.7183e-02, -2.2907e-02,  5.1716e-03, -1.6884e-02,  6.5741e-03,\n",
       "         -1.9278e-02,  3.5800e-03,  2.4035e-02, -8.5276e-03,  1.6556e-03,\n",
       "         -8.3393e-03, -1.0131e-02,  1.8295e-02, -3.0637e-03,  4.6794e-05,\n",
       "         -1.5654e-02, -2.1938e-02,  9.4119e-04,  1.0174e-04,  1.6250e-04,\n",
       "          2.1292e-04,  1.6897e-02, -5.6649e-03,  2.1602e-02, -6.4311e-03,\n",
       "          1.2390e-02, -2.2044e-02,  1.0968e-02,  2.4265e-03,  3.5867e-04,\n",
       "         -1.1959e-02,  1.4368e-02, -5.5107e-03,  1.2782e-02,  2.3094e-03,\n",
       "          6.3756e-04, -1.4686e-02,  1.4700e-02, -3.3739e-03,  1.1302e-03,\n",
       "          4.3045e-03,  1.4895e-02,  4.7352e-03,  2.2088e-02, -2.2916e-02,\n",
       "         -1.5031e-03, -1.5876e-02, -1.5191e-02,  1.5871e-02,  7.8098e-04,\n",
       "         -8.2703e-03,  1.5437e-03,  8.9219e-03,  4.9297e-03, -7.3326e-03,\n",
       "          7.1885e-03, -6.8332e-03,  5.8759e-03,  4.3847e-03,  1.7365e-02,\n",
       "          9.7753e-03, -1.6438e-02, -1.7860e-02,  2.1129e-02,  9.6424e-03,\n",
       "         -1.0192e-02, -9.8111e-03, -1.3754e-03,  2.0838e-03,  1.1178e-02,\n",
       "         -6.1860e-03,  2.0096e-02, -1.7919e-02, -2.9151e-03,  4.3670e-03,\n",
       "          1.0153e-02,  4.4964e-04, -1.5854e-02, -1.4919e-02,  1.2744e-02,\n",
       "         -1.7434e-02, -1.4805e-03, -3.7836e-03, -6.2089e-03, -9.6045e-03,\n",
       "          1.7376e-02, -6.9916e-03, -1.3336e-02,  1.5464e-02,  1.9423e-02,\n",
       "          1.5585e-02,  2.0673e-02,  6.3584e-03,  2.1027e-02,  1.7058e-02,\n",
       "         -5.5657e-03, -9.3203e-03, -2.7190e-03, -2.2482e-02, -4.8301e-03,\n",
       "         -1.9429e-02, -2.8460e-03,  2.0327e-02, -9.8931e-03,  9.3687e-03,\n",
       "         -8.3899e-03, -6.5168e-03, -1.0496e-03, -3.1556e-03, -7.2378e-03,\n",
       "          1.6470e-02,  1.8016e-03,  1.7505e-02,  1.5645e-02,  8.3646e-03,\n",
       "         -1.1621e-03,  1.4580e-02, -8.1962e-04, -1.3235e-02,  1.7694e-02,\n",
       "         -1.1659e-02,  9.4444e-03,  1.3211e-02,  6.5546e-03, -7.7398e-03,\n",
       "         -2.0700e-02,  5.2076e-03, -9.3420e-03,  4.7168e-03, -6.4729e-03,\n",
       "          1.4213e-02,  1.0681e-02, -2.6002e-02,  1.1451e-02,  1.4233e-02,\n",
       "         -1.6079e-03,  1.3440e-02, -9.3813e-03, -8.3554e-03,  1.6303e-02,\n",
       "          3.0080e-03,  4.3584e-03, -1.9776e-02, -1.8643e-02,  1.5804e-02,\n",
       "          7.6718e-03,  1.4110e-02,  3.5703e-03, -1.0817e-02,  1.0155e-02,\n",
       "         -1.2580e-02,  9.8345e-03,  6.5007e-04, -1.7105e-03,  5.2113e-03,\n",
       "          1.7545e-03, -1.2789e-02,  2.1782e-02,  7.4351e-05, -1.1683e-02,\n",
       "          1.5420e-02, -1.5882e-02, -1.7619e-03,  1.9315e-02,  6.2140e-03,\n",
       "         -1.5326e-02,  1.8940e-02, -2.0222e-02, -1.4436e-02, -1.3621e-02,\n",
       "         -7.8524e-04,  2.0635e-02,  1.8575e-02,  8.8671e-03,  1.8523e-02,\n",
       "          1.3273e-02,  3.0776e-03, -1.8680e-02, -6.0683e-03,  1.8395e-02,\n",
       "         -1.7150e-02,  1.9919e-02,  1.6724e-02, -1.1036e-02, -1.4158e-02,\n",
       "         -1.3665e-02, -6.9420e-03, -8.6047e-03,  1.1535e-02,  1.5450e-02,\n",
       "          7.9415e-03,  1.1336e-02, -1.3370e-02,  1.2384e-03,  5.1192e-03,\n",
       "          2.1988e-02, -1.0752e-02, -5.5126e-03, -8.1927e-03,  1.0167e-02,\n",
       "         -2.4290e-02, -2.0928e-02,  6.6537e-03,  2.3475e-02, -2.7837e-02,\n",
       "          9.4913e-03,  1.3583e-02,  1.1303e-03,  2.0740e-02, -3.4879e-03,\n",
       "          4.3654e-03,  1.5842e-02,  1.1304e-02, -1.5697e-02, -1.8705e-02,\n",
       "         -6.6658e-04, -1.5170e-02,  1.6792e-02,  8.7635e-03,  4.8782e-03,\n",
       "         -7.1680e-03,  4.7660e-03, -1.9612e-02, -1.6257e-02,  1.6045e-03,\n",
       "         -6.4951e-03, -9.0678e-03, -5.7252e-04, -1.2889e-02,  8.6111e-03,\n",
       "         -1.8738e-02, -8.4858e-04, -9.4580e-03,  2.9678e-03, -1.3419e-02,\n",
       "         -1.4071e-02, -1.3682e-02], device='cuda:0'),\n",
       " tensor([-0.0019, -0.0064, -0.0712,  0.1128,  0.1089,  0.0413, -0.0164, -0.0172,\n",
       "          0.0802,  0.0957, -0.0844,  0.0269,  0.0912, -0.1145, -0.0603,  0.0266,\n",
       "         -0.0278,  0.0746, -0.0128,  0.0953,  0.0705,  0.1185,  0.0496,  0.0832,\n",
       "         -0.0120,  0.0618, -0.0977,  0.1168, -0.1023,  0.0021,  0.0004,  0.1068,\n",
       "          0.0037,  0.0176,  0.0482, -0.0375, -0.0657, -0.0778, -0.0021, -0.0198,\n",
       "          0.0248,  0.0463, -0.0674,  0.0364,  0.0666, -0.0439, -0.0342,  0.0571,\n",
       "         -0.0112, -0.0975, -0.0714, -0.1025, -0.0238, -0.0209,  0.0471, -0.0289,\n",
       "          0.0907,  0.1141, -0.1093,  0.0675,  0.0853, -0.0278, -0.0352, -0.1157],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0334,  0.0407,  0.0128,  0.0255, -0.1193, -0.0324, -0.0465,  0.0348,\n",
       "          0.0118,  0.0698, -0.1021, -0.0341, -0.0689, -0.0752,  0.0387,  0.0964,\n",
       "         -0.0545, -0.1235, -0.1144,  0.1161,  0.0644,  0.0553, -0.0506, -0.1144,\n",
       "         -0.0953,  0.0331, -0.0487,  0.0674,  0.0590,  0.0697, -0.0047, -0.1093,\n",
       "          0.0720, -0.0690, -0.0235, -0.0180,  0.0054,  0.0095,  0.0899,  0.0974,\n",
       "          0.0850,  0.1228, -0.0992, -0.0694,  0.1043,  0.0849,  0.0273, -0.1041,\n",
       "          0.0003,  0.1036,  0.0851, -0.0841, -0.0572, -0.0090, -0.1068, -0.0680,\n",
       "          0.0387,  0.0899, -0.0609,  0.0547, -0.1109, -0.0372, -0.0686,  0.1163],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0842,  0.0104,  0.0800, -0.0608, -0.0512,  0.1094, -0.0200,  0.0259,\n",
       "          0.0665, -0.0352, -0.0750, -0.0878, -0.1116, -0.0518,  0.0941,  0.0676,\n",
       "          0.0374,  0.0714, -0.0412,  0.0180, -0.0634,  0.0177,  0.1245, -0.0955,\n",
       "         -0.0346, -0.0745,  0.0434, -0.0843,  0.0748,  0.1213, -0.0151,  0.0641,\n",
       "          0.0725,  0.0373, -0.0465,  0.0894,  0.0385,  0.1096, -0.0279, -0.0546,\n",
       "         -0.1286, -0.0265, -0.0859, -0.0133, -0.0929,  0.1018,  0.0019, -0.0064,\n",
       "          0.0942,  0.0299,  0.0413, -0.0273, -0.0315,  0.0954,  0.0550,  0.1008,\n",
       "          0.1190,  0.0098, -0.0247, -0.0116, -0.0251,  0.0322,  0.0647,  0.0650],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1021,  0.1151, -0.0413, -0.0324,  0.0470, -0.0030,  0.0911,  0.0847,\n",
       "          0.1235, -0.0956, -0.0748, -0.1014,  0.1147, -0.0729,  0.0043, -0.0114,\n",
       "          0.0569, -0.0642,  0.0652, -0.0476,  0.1193, -0.0122, -0.0770,  0.0224,\n",
       "          0.0330,  0.0331, -0.0155, -0.0453,  0.0691, -0.0978,  0.0754,  0.0341,\n",
       "         -0.0398, -0.0035, -0.0686,  0.0096,  0.0326, -0.0232,  0.0640, -0.0718,\n",
       "          0.0848, -0.0458,  0.1141, -0.0041, -0.0554, -0.0293,  0.0802, -0.1165,\n",
       "         -0.0785, -0.0217, -0.1003, -0.0230, -0.1176, -0.0303, -0.1010, -0.1185,\n",
       "         -0.0065,  0.0673,  0.1232,  0.1140, -0.0497, -0.0473,  0.1076, -0.0713],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0532,  0.1058, -0.0356, -0.0414,  0.1101,  0.0086,  0.0787, -0.0444,\n",
       "         -0.0741,  0.0049, -0.0595,  0.0371,  0.0672,  0.0962,  0.0923,  0.0376,\n",
       "          0.0572,  0.0316, -0.0202,  0.0645, -0.0224,  0.0669, -0.0891, -0.0302,\n",
       "          0.0617, -0.0939, -0.0941, -0.0564, -0.0093,  0.0917, -0.0288,  0.1017,\n",
       "         -0.0110, -0.0240, -0.0792, -0.0503,  0.1013, -0.0304, -0.0838,  0.0083,\n",
       "          0.0078,  0.0120,  0.0625,  0.0561,  0.0622,  0.0349,  0.0169,  0.1081,\n",
       "         -0.0105,  0.0643,  0.1094,  0.0539,  0.1023, -0.0139,  0.0333, -0.0069,\n",
       "         -0.1079,  0.0812, -0.1166,  0.0503, -0.1002,  0.1116,  0.1187, -0.1207],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1134,  0.1097, -0.0353, -0.0241, -0.0561, -0.1242, -0.0922,  0.1243,\n",
       "         -0.0863,  0.0319,  0.0443, -0.0755, -0.1215, -0.0814,  0.0840,  0.0691,\n",
       "         -0.0717, -0.0753, -0.0750, -0.0828, -0.0173,  0.0393, -0.0523, -0.0676,\n",
       "         -0.0396,  0.1115, -0.0806, -0.0050,  0.0482,  0.0737,  0.0748, -0.0791,\n",
       "          0.0831, -0.1108, -0.0093, -0.0699,  0.0852, -0.1124, -0.0733,  0.1232,\n",
       "         -0.0665,  0.1120,  0.0524, -0.0065, -0.0902, -0.0359, -0.0543, -0.1086,\n",
       "         -0.0258, -0.0775, -0.0993,  0.0452,  0.1054,  0.1140,  0.1243, -0.0980,\n",
       "          0.0483, -0.0179, -0.0710,  0.0361, -0.1160,  0.0547,  0.1223, -0.1218],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1191,  0.0931,  0.0712,  0.0060, -0.0554, -0.0209,  0.0616,  0.0332,\n",
       "         -0.0372, -0.0035,  0.0363,  0.0803,  0.0797,  0.1146, -0.0517, -0.1030,\n",
       "          0.1070, -0.0537,  0.1224, -0.0019,  0.0161,  0.0881,  0.0837,  0.0931,\n",
       "         -0.0887,  0.0663, -0.0842,  0.0040, -0.0966, -0.1114, -0.1248,  0.0919,\n",
       "         -0.0054, -0.0914,  0.0943, -0.1092, -0.0671, -0.0215, -0.0763,  0.0737,\n",
       "         -0.0640,  0.0688,  0.1120,  0.0326,  0.1196,  0.0765,  0.0517,  0.0213,\n",
       "          0.0085, -0.0862,  0.0311, -0.0415, -0.1112, -0.0479,  0.0647, -0.0105,\n",
       "         -0.0931, -0.0252, -0.0246,  0.1014,  0.0039,  0.0535,  0.0532, -0.1035],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0323,  0.0847, -0.1112,  0.1199, -0.1027,  0.0704,  0.0181, -0.1240,\n",
       "         -0.0310,  0.0495,  0.0638, -0.0550, -0.1037,  0.1121, -0.1174, -0.0286,\n",
       "          0.0918, -0.0570,  0.0436,  0.0822,  0.0167,  0.1148, -0.0117,  0.1028,\n",
       "         -0.0306,  0.0508, -0.0591, -0.0776, -0.0879,  0.0411,  0.0848,  0.1041,\n",
       "         -0.0310,  0.0004, -0.0179, -0.0767, -0.0972,  0.0685, -0.0941,  0.0946,\n",
       "          0.0113, -0.0218, -0.0318, -0.0658,  0.0278, -0.1216, -0.0955,  0.0568,\n",
       "          0.1062,  0.0287, -0.0261,  0.0448,  0.1098,  0.0566, -0.0499,  0.0911,\n",
       "          0.0447, -0.0491,  0.0278,  0.0054,  0.1202,  0.0176,  0.1122,  0.0452],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0727,  0.1238,  0.1111,  0.0604,  0.0438, -0.0422,  0.1157,  0.0859,\n",
       "          0.0197,  0.0118, -0.0310,  0.0960,  0.0548,  0.0895,  0.0410,  0.0844,\n",
       "         -0.0604,  0.0909,  0.1135,  0.0964, -0.1191,  0.0591, -0.0560,  0.0924,\n",
       "         -0.0211, -0.1219, -0.0208,  0.0174, -0.0597, -0.1114, -0.0776,  0.0020,\n",
       "         -0.0382, -0.0483, -0.0170,  0.0929,  0.1143, -0.0135,  0.0522,  0.0540,\n",
       "          0.0959,  0.0916, -0.0738,  0.0702,  0.1061,  0.0984,  0.1225,  0.0087,\n",
       "          0.0452,  0.0891, -0.0613, -0.0470,  0.1166,  0.0597,  0.0584,  0.0736,\n",
       "          0.0705,  0.0138,  0.0976,  0.0119,  0.0176, -0.0018,  0.0914,  0.0281],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1133,  0.0583, -0.0500, -0.0436,  0.0057,  0.0170, -0.1167,  0.1077,\n",
       "          0.0988, -0.0687, -0.1233, -0.0612,  0.0544, -0.0565, -0.0932,  0.0372,\n",
       "          0.0359, -0.0890,  0.0577,  0.0316,  0.1214,  0.0193,  0.0025, -0.1046,\n",
       "         -0.0905, -0.0269, -0.0573, -0.0070, -0.0717, -0.0909, -0.0026,  0.0420,\n",
       "          0.1161,  0.0818, -0.0582, -0.1248,  0.0240,  0.0289,  0.0829, -0.0590,\n",
       "          0.0780,  0.1100, -0.1225,  0.0254,  0.0413,  0.1063, -0.0396,  0.0057,\n",
       "          0.0534,  0.1146, -0.0609,  0.0889,  0.0824, -0.1198,  0.0266,  0.0014,\n",
       "         -0.0140, -0.0761,  0.0768,  0.0360,  0.0345, -0.0490, -0.0253,  0.1043],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0822,  0.1174,  0.0732, -0.0949, -0.0374,  0.0213, -0.0940,  0.0057,\n",
       "         -0.1206, -0.0327, -0.0412,  0.0609,  0.0061, -0.0669,  0.0344,  0.0089,\n",
       "         -0.0659, -0.0685, -0.0345,  0.1176, -0.0368, -0.0931,  0.0963, -0.0314,\n",
       "          0.1131, -0.0899,  0.0957, -0.1143,  0.0704, -0.0264,  0.1239,  0.0362,\n",
       "          0.0451, -0.1063, -0.1244,  0.0864,  0.0782,  0.0820,  0.0540, -0.0363,\n",
       "          0.0406, -0.0560, -0.1186, -0.1162,  0.0738, -0.1233, -0.0417, -0.1246,\n",
       "          0.0462, -0.0878, -0.0240, -0.1139,  0.0083,  0.0503, -0.0123,  0.1129,\n",
       "         -0.0444,  0.0109,  0.0144, -0.0795,  0.0351, -0.0680,  0.1247,  0.1024],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1228,  0.0933, -0.0590, -0.0330,  0.0535,  0.0974, -0.0987, -0.0346,\n",
       "          0.0320, -0.0929, -0.0616, -0.1148,  0.0938,  0.0237, -0.0255, -0.0087,\n",
       "         -0.0315, -0.0892,  0.0384, -0.0359,  0.1081,  0.0937,  0.0530, -0.0075,\n",
       "          0.0073,  0.0839,  0.0188, -0.0738, -0.0373,  0.0841,  0.1132,  0.1005,\n",
       "         -0.0615, -0.0324, -0.0722,  0.0557, -0.0562, -0.0293, -0.0470, -0.0940,\n",
       "          0.0614, -0.0939, -0.0804,  0.1047,  0.0669, -0.0975, -0.0511, -0.0134,\n",
       "          0.0242,  0.0786, -0.0858, -0.0613,  0.1124,  0.1244,  0.0389,  0.0236,\n",
       "          0.0074,  0.0062, -0.0649,  0.0016,  0.0779,  0.0319, -0.0223,  0.0274],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0687, -0.0512, -0.1232, -0.0519, -0.0348,  0.0812, -0.0027, -0.0206,\n",
       "          0.1084,  0.0374,  0.0434, -0.0932, -0.1079,  0.0612,  0.1014,  0.0579,\n",
       "         -0.0170, -0.0710, -0.0210,  0.0689, -0.1167,  0.0287,  0.0836,  0.1185,\n",
       "          0.0050,  0.0790,  0.1060, -0.0820,  0.0576,  0.1096, -0.0302, -0.0344,\n",
       "          0.0904, -0.0452, -0.0788, -0.0390,  0.0637,  0.0792,  0.0483, -0.0831,\n",
       "         -0.0889, -0.0457, -0.0329,  0.0990, -0.0033,  0.0814, -0.1203, -0.0306,\n",
       "         -0.1113,  0.0214,  0.0666, -0.1038,  0.1243, -0.0610, -0.0908,  0.0234,\n",
       "          0.1208,  0.0710,  0.0546,  0.0203,  0.0724, -0.0875,  0.0256,  0.0231],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0229,  0.0098, -0.0337, -0.0943,  0.0694,  0.0035, -0.0840, -0.0554,\n",
       "          0.0724,  0.0941, -0.0341,  0.0756,  0.0346,  0.0030,  0.0061,  0.0280,\n",
       "         -0.0706,  0.0318, -0.1148, -0.1057, -0.0722,  0.0793, -0.0195,  0.0427,\n",
       "          0.0916, -0.0626,  0.0305, -0.0872,  0.1115,  0.0568,  0.0227,  0.0661,\n",
       "         -0.0952, -0.0371, -0.0076,  0.1129, -0.0166, -0.0832, -0.1249,  0.0146,\n",
       "         -0.0224,  0.0815, -0.0704,  0.1178,  0.0093,  0.0524,  0.0908,  0.0216,\n",
       "          0.0205,  0.0284,  0.1177, -0.0150,  0.0665,  0.0026,  0.0821,  0.1208,\n",
       "          0.0130, -0.0118,  0.1196, -0.0122,  0.0780, -0.0899,  0.0283,  0.0717],\n",
       "        device='cuda:0'),\n",
       " tensor([ 9.6208e-02, -5.2028e-02,  4.6900e-02,  1.8840e-02, -4.6190e-03,\n",
       "         -1.2472e-01,  3.8285e-02,  2.6462e-02,  1.2128e-01,  1.1765e-01,\n",
       "         -1.0508e-02,  1.0457e-01, -3.6022e-02, -1.6172e-02, -1.2412e-02,\n",
       "          6.2825e-02, -2.8457e-02, -1.0286e-01, -1.2118e-01, -1.1021e-01,\n",
       "          1.0191e-01,  1.0934e-01, -1.2739e-03,  1.2332e-04, -4.7247e-02,\n",
       "         -9.3314e-02,  7.8011e-02, -3.8017e-02, -7.7638e-02,  5.1855e-03,\n",
       "          6.1148e-02,  4.1855e-02,  8.8357e-02, -6.3954e-02, -8.3219e-02,\n",
       "          2.7402e-02,  3.2543e-02, -4.5369e-02,  4.6396e-02, -3.4178e-02,\n",
       "         -5.2602e-02, -5.7602e-02, -9.7968e-03, -9.0158e-02, -2.1926e-03,\n",
       "          1.1002e-01,  8.2764e-02,  1.0018e-01, -7.4633e-02,  1.2150e-01,\n",
       "          7.2561e-02,  8.6771e-02,  1.0450e-01, -3.5513e-02, -8.4286e-02,\n",
       "         -3.9486e-02, -9.9927e-02, -3.2209e-03,  1.1509e-01,  1.2453e-01,\n",
       "          9.6552e-02,  1.0106e-01,  9.1592e-02,  7.7922e-02], device='cuda:0'),\n",
       " tensor([ 0.0332, -0.0223,  0.0789, -0.0731,  0.0969,  0.0257, -0.0806, -0.1002,\n",
       "          0.0972,  0.0974, -0.0425,  0.0469, -0.0541,  0.0632,  0.1146,  0.0696,\n",
       "         -0.0753, -0.0007, -0.0663,  0.0962, -0.0443,  0.0555,  0.1191,  0.0456,\n",
       "          0.0371, -0.0759,  0.0784,  0.1016,  0.0137,  0.0855, -0.0236,  0.1001,\n",
       "         -0.0899, -0.1110,  0.0503, -0.0136, -0.0794,  0.1185, -0.0756,  0.0940,\n",
       "          0.0386, -0.0327,  0.1181,  0.1195,  0.0095, -0.1165, -0.1063,  0.1206,\n",
       "          0.0690, -0.1218, -0.0179,  0.0624, -0.0008,  0.0876,  0.0426, -0.1204,\n",
       "         -0.0822, -0.0309, -0.0992, -0.0567,  0.0835,  0.0416,  0.0797, -0.0580],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0556, -0.0409, -0.0554, -0.0214, -0.0577, -0.0281,  0.0136,  0.0912,\n",
       "          0.1222, -0.0037, -0.1038,  0.0193, -0.0775, -0.0688, -0.0458,  0.0180,\n",
       "          0.1135,  0.1210, -0.0541,  0.0747, -0.0061, -0.0139,  0.1128, -0.0701,\n",
       "          0.1097, -0.0123,  0.1225, -0.0223,  0.1165,  0.0881, -0.0897, -0.0119,\n",
       "         -0.0092, -0.0851, -0.0016,  0.1193,  0.0051,  0.0824, -0.1117, -0.0157,\n",
       "          0.1233, -0.0379,  0.1172,  0.0357,  0.1007,  0.0998, -0.1089, -0.0607,\n",
       "         -0.0653,  0.0007,  0.0747, -0.0871,  0.0956,  0.0465,  0.0890,  0.0652,\n",
       "          0.0315,  0.0871,  0.0857,  0.0181,  0.0637, -0.0304, -0.1223,  0.0640],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0588,  0.0345, -0.1142, -0.0562,  0.0312,  0.0597, -0.0077, -0.0983,\n",
       "         -0.0086, -0.0679, -0.0493, -0.0237,  0.1080, -0.0032,  0.0514, -0.0918,\n",
       "          0.0985, -0.0997,  0.0721, -0.0413, -0.0474,  0.0992,  0.0504,  0.0290,\n",
       "         -0.0355, -0.0951, -0.1190,  0.0892,  0.0225,  0.0328,  0.0620,  0.0745,\n",
       "          0.0792,  0.0945, -0.0035,  0.0114, -0.0512,  0.0493,  0.1047, -0.0494,\n",
       "          0.0330, -0.1053, -0.1134,  0.1120,  0.0574,  0.0788,  0.1163, -0.1051,\n",
       "         -0.1178, -0.0155, -0.0483,  0.0804,  0.0661, -0.0042,  0.0957, -0.0770,\n",
       "         -0.0812,  0.0935,  0.1200, -0.1112,  0.0040,  0.0537,  0.0330, -0.1213],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1049, -0.1007, -0.0454, -0.1130,  0.1257, -0.0973,  0.0163, -0.0489,\n",
       "         -0.0689,  0.0798,  0.0409, -0.0101, -0.1140,  0.0877,  0.0541, -0.0691,\n",
       "         -0.0791, -0.0770,  0.0383,  0.0962, -0.0760,  0.0768, -0.0309,  0.0517,\n",
       "          0.0481, -0.0197, -0.0773,  0.0977, -0.0220,  0.1182,  0.0578, -0.1087,\n",
       "          0.0219,  0.0520,  0.0091, -0.0099,  0.0125,  0.0349,  0.0625,  0.0942,\n",
       "         -0.0722, -0.1111, -0.0134, -0.0617, -0.1112,  0.0078, -0.0471, -0.0513,\n",
       "          0.0206, -0.0784,  0.0431,  0.0701, -0.0502, -0.0476,  0.1251,  0.0108,\n",
       "         -0.0019, -0.0608, -0.0317,  0.1100, -0.0842,  0.1209,  0.1171, -0.0448],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1218, -0.0190,  0.0367, -0.0155,  0.0234, -0.0828, -0.1102,  0.1143,\n",
       "         -0.0257,  0.1073,  0.0415,  0.0520,  0.0906,  0.1114, -0.0481, -0.0421,\n",
       "          0.1090,  0.1187,  0.0040,  0.0883, -0.0112,  0.0242, -0.1043,  0.1047,\n",
       "         -0.0946,  0.0672,  0.0295, -0.0682,  0.0935,  0.0725,  0.0660, -0.0536,\n",
       "         -0.0520, -0.0205, -0.1099, -0.1037,  0.0770, -0.0940, -0.0171,  0.0354,\n",
       "         -0.0606, -0.0575,  0.0716, -0.0391,  0.1236,  0.1087, -0.1156, -0.0399,\n",
       "          0.0394, -0.0219,  0.0384, -0.0339,  0.0207, -0.0626, -0.0289, -0.1148,\n",
       "          0.1226,  0.0819,  0.1097, -0.0346,  0.0345, -0.0006,  0.0874, -0.0494],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0761, -0.0549, -0.0166, -0.0818, -0.0193,  0.0422, -0.0309, -0.0200,\n",
       "         -0.0289,  0.1189,  0.0730, -0.1201, -0.0923,  0.0002, -0.1018,  0.0608,\n",
       "          0.0081,  0.0917,  0.0696, -0.0259, -0.0848,  0.0559,  0.1062,  0.1211,\n",
       "          0.0994, -0.0169,  0.0722, -0.0226,  0.0219, -0.0694, -0.0402, -0.0005,\n",
       "          0.0941, -0.1005, -0.0440,  0.0809,  0.0836, -0.0434,  0.0608,  0.0035,\n",
       "         -0.0955,  0.0796,  0.0427, -0.0651, -0.1023,  0.0209, -0.1026, -0.0128,\n",
       "          0.1216,  0.0754, -0.1156,  0.1115,  0.0903, -0.1265,  0.0146,  0.1224,\n",
       "          0.0770, -0.1170, -0.0618, -0.0946, -0.0018,  0.1048,  0.1242, -0.0274],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0487, -0.1077, -0.0647, -0.0238, -0.0109, -0.0698, -0.0611, -0.0951,\n",
       "         -0.0445,  0.0921,  0.1053, -0.0412, -0.0483, -0.0152, -0.1167, -0.0687,\n",
       "          0.0389, -0.0612,  0.0937, -0.0797, -0.0659, -0.1029,  0.0358,  0.0767,\n",
       "          0.0018,  0.0458, -0.0904, -0.0801,  0.0926,  0.0100, -0.0229,  0.0920,\n",
       "         -0.0765, -0.0966,  0.0282, -0.0831, -0.0383,  0.1198, -0.1260,  0.0229,\n",
       "         -0.0291,  0.0109,  0.0676, -0.0197, -0.1105, -0.0722,  0.1032,  0.0663,\n",
       "         -0.1027,  0.0779, -0.0231, -0.0590, -0.1167,  0.0445,  0.0257, -0.0388,\n",
       "          0.0912,  0.0675,  0.0055,  0.0549,  0.0176, -0.1126,  0.0586,  0.0850],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0214,  0.0934, -0.0679, -0.0751, -0.0726, -0.0193,  0.0165, -0.0873,\n",
       "          0.0019, -0.0219, -0.0999, -0.1042, -0.0521, -0.0340, -0.0680,  0.0654,\n",
       "          0.0706,  0.0812,  0.0189,  0.0768,  0.0526, -0.1286,  0.1233, -0.0768,\n",
       "          0.0620, -0.0610,  0.0300, -0.0083,  0.0346, -0.0222,  0.0721,  0.1128,\n",
       "          0.0998, -0.0390,  0.0257, -0.1223, -0.0952, -0.0805, -0.1087,  0.1009,\n",
       "         -0.0198, -0.1231,  0.0158, -0.0288,  0.0156, -0.1222,  0.0172, -0.0105,\n",
       "         -0.0446,  0.0835, -0.0423,  0.0298,  0.1150,  0.0177, -0.0141,  0.0063,\n",
       "          0.0821,  0.0886,  0.0330,  0.0889, -0.0251,  0.1014, -0.0355,  0.0470],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0008,  0.0149, -0.0341,  0.1148,  0.0821,  0.0576,  0.0008,  0.0641,\n",
       "         -0.0412, -0.0054, -0.1116, -0.1099, -0.1067,  0.1122,  0.0686,  0.0599,\n",
       "         -0.0525,  0.0485,  0.0620,  0.0482, -0.0981, -0.1263,  0.0167,  0.0622,\n",
       "          0.1208,  0.0912, -0.0768, -0.0651,  0.0473, -0.0956, -0.0797, -0.0595,\n",
       "          0.1222, -0.0456,  0.0502,  0.0752,  0.1116, -0.0070, -0.0027, -0.0889,\n",
       "          0.0653, -0.0962, -0.0795,  0.0023,  0.0796,  0.0264, -0.0883,  0.0797,\n",
       "         -0.0453,  0.0884,  0.0867,  0.1259,  0.0395,  0.0876,  0.0874,  0.0479,\n",
       "          0.1034, -0.0803, -0.0414,  0.0140,  0.0372,  0.0260, -0.0924, -0.0697],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0298,  0.0307, -0.0008,  ..., -0.0301,  0.0127, -0.0204],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0080,  0.0076,  0.0002, -0.0187, -0.0091,  0.0171, -0.0159,  0.0064,\n",
       "         -0.0132, -0.0180, -0.0112,  0.0131,  0.0125,  0.0257,  0.0183,  0.0032,\n",
       "          0.0077, -0.0130,  0.0100, -0.0241, -0.0088,  0.0112,  0.0094, -0.0090,\n",
       "          0.0186, -0.0197, -0.0009, -0.0175, -0.0104, -0.0122,  0.0142,  0.0068,\n",
       "         -0.0084,  0.0096, -0.0135,  0.0242,  0.0004, -0.0159, -0.0170, -0.0215,\n",
       "         -0.0031, -0.0157, -0.0203, -0.0186,  0.0155,  0.0017, -0.0154,  0.0078,\n",
       "          0.0103,  0.0021, -0.0095, -0.0105, -0.0006, -0.0110, -0.0076, -0.0044,\n",
       "         -0.0080,  0.0028, -0.0114, -0.0075,  0.0016,  0.0068,  0.0197,  0.0182,\n",
       "         -0.0040,  0.0080, -0.0029, -0.0121, -0.0137, -0.0017, -0.0038,  0.0045,\n",
       "         -0.0031, -0.0203,  0.0002, -0.0198, -0.0025, -0.0024, -0.0228, -0.0071,\n",
       "          0.0089, -0.0196, -0.0169, -0.0093, -0.0164,  0.0053,  0.0041, -0.0127,\n",
       "         -0.0160,  0.0035,  0.0218,  0.0009,  0.0050,  0.0204,  0.0063,  0.0108,\n",
       "          0.0089, -0.0213,  0.0200,  0.0097,  0.0071,  0.0132,  0.0110,  0.0085,\n",
       "         -0.0008, -0.0102, -0.0132,  0.0149, -0.0177, -0.0030, -0.0013, -0.0173,\n",
       "          0.0003,  0.0091, -0.0113, -0.0083, -0.0141,  0.0027,  0.0055,  0.0098,\n",
       "         -0.0030, -0.0217,  0.0170,  0.0180,  0.0111,  0.0142,  0.0180, -0.0158,\n",
       "         -0.0123,  0.0016,  0.0214,  0.0176, -0.0055,  0.0164,  0.0027,  0.0160,\n",
       "          0.0068,  0.0188, -0.0173,  0.0048,  0.0212, -0.0244,  0.0117, -0.0145,\n",
       "         -0.0207, -0.0001, -0.0064, -0.0121,  0.0120, -0.0194, -0.0181, -0.0193,\n",
       "          0.0139, -0.0161, -0.0152, -0.0031, -0.0037, -0.0132, -0.0042,  0.0117,\n",
       "         -0.0211,  0.0206,  0.0202, -0.0212,  0.0198,  0.0170, -0.0143,  0.0138,\n",
       "          0.0159, -0.0066,  0.0018, -0.0006,  0.0221,  0.0060,  0.0021,  0.0163,\n",
       "         -0.0090,  0.0009,  0.0007, -0.0113,  0.0165,  0.0079, -0.0156,  0.0055,\n",
       "         -0.0202, -0.0075,  0.0159, -0.0059,  0.0186,  0.0046, -0.0153,  0.0010,\n",
       "         -0.0087,  0.0190,  0.0096, -0.0079,  0.0224,  0.0090, -0.0124,  0.0146,\n",
       "          0.0137, -0.0003,  0.0083,  0.0135,  0.0113,  0.0014, -0.0163,  0.0015,\n",
       "          0.0007, -0.0085, -0.0092, -0.0111, -0.0097,  0.0082,  0.0073, -0.0046,\n",
       "         -0.0212,  0.0056,  0.0200,  0.0193,  0.0193, -0.0009,  0.0036,  0.0052,\n",
       "          0.0047,  0.0200, -0.0176,  0.0158,  0.0119, -0.0096, -0.0107, -0.0133,\n",
       "          0.0121, -0.0190, -0.0075, -0.0066,  0.0196, -0.0051,  0.0062, -0.0172,\n",
       "          0.0173,  0.0015,  0.0189, -0.0202,  0.0048, -0.0172, -0.0076, -0.0191,\n",
       "         -0.0017,  0.0100, -0.0149, -0.0169,  0.0137, -0.0155,  0.0201,  0.0119,\n",
       "         -0.0199,  0.0102, -0.0015, -0.0182, -0.0193,  0.0152,  0.0073, -0.0064,\n",
       "         -0.0026, -0.0028, -0.0125,  0.0158, -0.0158,  0.0098,  0.0207, -0.0098,\n",
       "          0.0153,  0.0039, -0.0068, -0.0200, -0.0188, -0.0182, -0.0069,  0.0022,\n",
       "         -0.0046,  0.0012,  0.0201,  0.0196,  0.0015,  0.0158, -0.0212, -0.0163,\n",
       "         -0.0011,  0.0140, -0.0128, -0.0134, -0.0182,  0.0153,  0.0209,  0.0032,\n",
       "         -0.0008, -0.0185, -0.0177, -0.0033, -0.0157,  0.0185, -0.0059, -0.0054,\n",
       "         -0.0221,  0.0156,  0.0069,  0.0141, -0.0105, -0.0061,  0.0127,  0.0019,\n",
       "         -0.0140,  0.0108, -0.0214, -0.0015,  0.0007, -0.0211, -0.0126, -0.0056,\n",
       "          0.0125, -0.0057,  0.0102, -0.0095, -0.0137,  0.0012,  0.0135, -0.0005,\n",
       "          0.0077,  0.0025, -0.0213, -0.0135, -0.0131, -0.0082, -0.0151,  0.0039,\n",
       "          0.0131, -0.0043,  0.0149,  0.0083,  0.0036,  0.0181, -0.0141,  0.0083,\n",
       "          0.0099, -0.0070, -0.0109, -0.0018, -0.0070,  0.0214, -0.0074, -0.0126,\n",
       "         -0.0029, -0.0204,  0.0101,  0.0136,  0.0140,  0.0104, -0.0070, -0.0037,\n",
       "          0.0137, -0.0149,  0.0212,  0.0135, -0.0005,  0.0191,  0.0051,  0.0130,\n",
       "          0.0144,  0.0015, -0.0067, -0.0183, -0.0126,  0.0156,  0.0112, -0.0096,\n",
       "          0.0051,  0.0012,  0.0015, -0.0089, -0.0045,  0.0002, -0.0115,  0.0165,\n",
       "         -0.0138, -0.0139, -0.0178,  0.0037,  0.0109,  0.0126, -0.0054, -0.0195,\n",
       "          0.0097, -0.0135,  0.0200,  0.0160,  0.0015,  0.0038,  0.0020,  0.0067,\n",
       "          0.0100,  0.0155,  0.0087, -0.0165, -0.0091,  0.0089,  0.0157, -0.0077,\n",
       "          0.0172, -0.0104,  0.0004, -0.0171, -0.0028, -0.0070,  0.0144,  0.0075,\n",
       "         -0.0112, -0.0090, -0.0087, -0.0158,  0.0174, -0.0132,  0.0024, -0.0205,\n",
       "         -0.0233,  0.0149, -0.0017,  0.0068,  0.0213, -0.0212,  0.0214,  0.0175,\n",
       "          0.0068,  0.0127,  0.0120,  0.0203,  0.0055, -0.0120,  0.0140, -0.0129,\n",
       "          0.0074, -0.0168,  0.0212,  0.0112,  0.0062, -0.0096,  0.0181,  0.0075,\n",
       "          0.0110, -0.0055, -0.0084,  0.0186,  0.0012, -0.0188, -0.0208,  0.0125,\n",
       "         -0.0165, -0.0113,  0.0160, -0.0056, -0.0042,  0.0055,  0.0156, -0.0136,\n",
       "          0.0089,  0.0020,  0.0154,  0.0056,  0.0061, -0.0164,  0.0003,  0.0106,\n",
       "          0.0203,  0.0032,  0.0046, -0.0219,  0.0017, -0.0096,  0.0225,  0.0002,\n",
       "         -0.0114,  0.0163, -0.0086, -0.0169, -0.0120, -0.0015,  0.0110, -0.0178,\n",
       "         -0.0226, -0.0070, -0.0139,  0.0099,  0.0046, -0.0054, -0.0088, -0.0210,\n",
       "         -0.0070, -0.0030,  0.0117, -0.0191,  0.0060, -0.0196,  0.0141,  0.0217,\n",
       "         -0.0034, -0.0139, -0.0193,  0.0103,  0.0121, -0.0190, -0.0064, -0.0120],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0946, -0.0662,  0.0294, -0.0431,  0.0398,  0.0112, -0.0439,  0.1056,\n",
       "         -0.1100, -0.1180, -0.0500, -0.0882, -0.1175, -0.1232,  0.0478, -0.0465,\n",
       "          0.0521, -0.0555, -0.0457,  0.0174,  0.0024,  0.0894, -0.0002, -0.0153,\n",
       "          0.0013, -0.0948, -0.0806, -0.0349, -0.0356, -0.0762,  0.0246,  0.1106,\n",
       "         -0.0985,  0.0674,  0.1215,  0.0554,  0.0423,  0.0330, -0.1213, -0.1140,\n",
       "          0.0640,  0.0793, -0.0287, -0.0792,  0.0655, -0.0534, -0.0270,  0.0056,\n",
       "         -0.0413,  0.0742,  0.0692,  0.0129, -0.1044,  0.0955,  0.0751, -0.0026,\n",
       "         -0.0262,  0.0086,  0.0257,  0.0788, -0.0607,  0.0195, -0.0947,  0.0133],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0788, -0.1202,  0.0007, -0.0837, -0.0699,  0.0221, -0.0871, -0.0683,\n",
       "         -0.0002,  0.0067,  0.0167, -0.0261,  0.0231, -0.0642,  0.0869, -0.0512,\n",
       "          0.0074,  0.0064, -0.0612,  0.1095, -0.0295, -0.1142, -0.1138,  0.0917,\n",
       "         -0.0683,  0.0013,  0.0193, -0.0208,  0.0563, -0.0576, -0.0844, -0.0239,\n",
       "         -0.0221,  0.0227, -0.0109,  0.0460, -0.0494,  0.0479, -0.0485, -0.0267,\n",
       "         -0.0027,  0.0453, -0.1236,  0.0161,  0.1216,  0.0348,  0.0907,  0.0386,\n",
       "          0.0267,  0.1153, -0.0259, -0.0527,  0.0395, -0.0714,  0.0852, -0.0320,\n",
       "          0.0315, -0.0957, -0.1085,  0.1199, -0.1240,  0.1050, -0.1010, -0.0229],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0636,  0.0857, -0.0937,  0.0823,  0.0867, -0.0816,  0.0661,  0.1212,\n",
       "         -0.0568,  0.1218, -0.0015,  0.0390,  0.0834,  0.0741, -0.1004, -0.0236,\n",
       "          0.0662, -0.1040, -0.0415,  0.0696, -0.1246, -0.0523,  0.0813, -0.0583,\n",
       "          0.0960,  0.0073,  0.1118, -0.0043, -0.0937,  0.0350, -0.0885, -0.0183,\n",
       "          0.0503,  0.0221,  0.0306,  0.0364,  0.0081,  0.0775, -0.0603, -0.0039,\n",
       "          0.0651, -0.0875,  0.0879, -0.0888, -0.0220,  0.0955,  0.1226, -0.1161,\n",
       "          0.0440, -0.1039,  0.0723, -0.0509,  0.0576, -0.0632,  0.0978,  0.0613,\n",
       "         -0.1275, -0.0018, -0.0329,  0.0217,  0.0883,  0.0048, -0.0947,  0.0522],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0650,  0.0124,  0.0205,  0.0131, -0.0968, -0.0699,  0.0209, -0.0969,\n",
       "          0.0731, -0.0580, -0.1013, -0.0023, -0.0860, -0.0908,  0.0619,  0.0064,\n",
       "          0.0768,  0.1091,  0.0731,  0.0959,  0.0679, -0.0404, -0.0836,  0.0464,\n",
       "         -0.0894,  0.0435, -0.0458,  0.0505, -0.0974,  0.0870,  0.1205, -0.0786,\n",
       "         -0.0499, -0.0193,  0.0924, -0.0697, -0.0999, -0.0295, -0.0716,  0.0461,\n",
       "         -0.0675,  0.0245, -0.0623,  0.0249, -0.0252, -0.0310, -0.1129, -0.0240,\n",
       "         -0.0851, -0.0509,  0.1049,  0.0480, -0.0628,  0.0414,  0.0605,  0.1014,\n",
       "         -0.0550,  0.0209, -0.0599,  0.0764,  0.0538, -0.0018, -0.0521,  0.1145],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0904, -0.0286, -0.0683,  0.0662,  0.0309, -0.1237, -0.0869,  0.0612,\n",
       "         -0.1077,  0.1001, -0.0717, -0.0064, -0.0882, -0.0701,  0.0547, -0.0064,\n",
       "          0.0329, -0.0413,  0.0705, -0.0239,  0.1209, -0.0201, -0.1136,  0.0738,\n",
       "         -0.0841, -0.0678,  0.1201, -0.0803,  0.0701, -0.0389,  0.0762, -0.0622,\n",
       "         -0.1230,  0.0201, -0.0868,  0.0913, -0.0849,  0.0438, -0.0172, -0.1219,\n",
       "         -0.0140,  0.0379, -0.0189,  0.0191,  0.0282, -0.1075, -0.0716,  0.0796,\n",
       "         -0.0773, -0.0254,  0.0385,  0.0159, -0.0337,  0.1208, -0.0233, -0.0078,\n",
       "         -0.0978,  0.0284,  0.0272, -0.1194, -0.0646,  0.0934, -0.0858, -0.0022],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0552, -0.0576, -0.0006, -0.0701, -0.0698, -0.1227,  0.0506, -0.0173,\n",
       "          0.1037, -0.0841, -0.0355,  0.0220,  0.0441, -0.1023,  0.0530, -0.1190,\n",
       "          0.0717, -0.0916,  0.0323,  0.1130, -0.0439, -0.0280, -0.0243,  0.0140,\n",
       "         -0.0295, -0.0384,  0.0489, -0.0936,  0.1070,  0.1000, -0.0690,  0.0441,\n",
       "         -0.0676,  0.0521,  0.0393,  0.0629, -0.1095,  0.0783, -0.0254,  0.0569,\n",
       "         -0.0379,  0.0132,  0.1037,  0.0903, -0.0507, -0.0741,  0.0987, -0.0986,\n",
       "         -0.0588, -0.1170, -0.1168,  0.0463,  0.0915, -0.0826,  0.1211,  0.0357,\n",
       "         -0.0659, -0.0645,  0.0841,  0.0887, -0.0471,  0.1086, -0.0324, -0.0953],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1027,  0.1175, -0.0354, -0.0341, -0.0791, -0.0279,  0.0373,  0.0817,\n",
       "          0.1107,  0.0323, -0.0723, -0.0507, -0.1231, -0.0025, -0.0933,  0.0510,\n",
       "         -0.0674,  0.0479, -0.0609, -0.1167,  0.1222,  0.1168,  0.0964, -0.0965,\n",
       "         -0.0340,  0.1155,  0.0732,  0.0704,  0.0917,  0.1239, -0.0128, -0.0064,\n",
       "          0.0344,  0.0078, -0.0172, -0.0070, -0.0243, -0.0059, -0.0671, -0.0112,\n",
       "          0.0112,  0.0731,  0.0878, -0.0225,  0.0063,  0.1021, -0.0698, -0.0103,\n",
       "         -0.0149, -0.0022, -0.0747, -0.0101, -0.0185,  0.0336,  0.0942,  0.0412,\n",
       "         -0.0321, -0.0263, -0.0037, -0.0244, -0.0967,  0.0606, -0.0245,  0.0767],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0632,  0.0459,  0.0999, -0.0553,  0.0491, -0.0616, -0.0204, -0.0728,\n",
       "         -0.0204,  0.0394, -0.0711, -0.0538, -0.0756, -0.0588, -0.0592, -0.0625,\n",
       "         -0.0285,  0.0544,  0.0828,  0.0996,  0.0944,  0.0620, -0.0593, -0.0693,\n",
       "          0.1185, -0.1087,  0.0707,  0.0622, -0.1235,  0.0900,  0.1065, -0.0588,\n",
       "         -0.0983, -0.0039,  0.0868, -0.0488,  0.0441, -0.0284, -0.0344,  0.0857,\n",
       "          0.0306, -0.0240, -0.0148, -0.1217,  0.0833,  0.0207,  0.0577, -0.0573,\n",
       "          0.1134,  0.0445, -0.0490, -0.1129, -0.1024,  0.0267, -0.0549, -0.0451,\n",
       "          0.0053,  0.0796,  0.0988, -0.0296,  0.0287,  0.1054,  0.1029, -0.1174],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0317, -0.1097, -0.0317,  0.1035,  0.0034, -0.0291, -0.0319,  0.0850,\n",
       "          0.0404, -0.0503,  0.1133,  0.0451, -0.0062,  0.0591,  0.1177,  0.0894,\n",
       "         -0.0955, -0.0337,  0.0097, -0.0390, -0.0535,  0.1199, -0.1146,  0.0334,\n",
       "         -0.0318,  0.0880,  0.0197, -0.0735,  0.0142, -0.1004,  0.0128, -0.0640,\n",
       "         -0.1161,  0.0361,  0.1230,  0.0013,  0.0385,  0.0838,  0.0841, -0.0749,\n",
       "         -0.0556, -0.0060,  0.1057,  0.1002, -0.1151,  0.0932,  0.0060,  0.1245,\n",
       "         -0.0247,  0.0555, -0.0565,  0.0867,  0.0187,  0.0693, -0.0582, -0.0580,\n",
       "         -0.0494,  0.0253,  0.1067,  0.0612,  0.1143, -0.0038, -0.0453,  0.0453],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0769,  0.0238,  0.0492,  0.0335,  0.1034, -0.0482,  0.0297,  0.1069,\n",
       "          0.1204,  0.0554,  0.1210, -0.0934,  0.0144,  0.0799, -0.0952,  0.0655,\n",
       "          0.1109,  0.0804,  0.1236, -0.0909,  0.0918, -0.0669,  0.0493,  0.0213,\n",
       "          0.0999,  0.0534, -0.0647,  0.0188,  0.0928,  0.1157, -0.1162,  0.0972,\n",
       "          0.0959, -0.0840, -0.0806,  0.0404,  0.0470, -0.1210, -0.0796,  0.0223,\n",
       "          0.0749, -0.0223,  0.0145, -0.0549, -0.0642, -0.0009,  0.0626,  0.0650,\n",
       "         -0.1139,  0.0086,  0.1123,  0.0124, -0.0714, -0.0106, -0.0302,  0.0884,\n",
       "         -0.0721,  0.0987,  0.0726, -0.1184,  0.0028, -0.0547, -0.0883, -0.0002],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0744,  0.0612,  0.0966,  0.0570,  0.0688, -0.0150, -0.0656, -0.0523,\n",
       "         -0.1121, -0.0558,  0.0535, -0.0422, -0.0352, -0.0690, -0.0028,  0.0518,\n",
       "         -0.0872,  0.0869,  0.0814, -0.0603, -0.1243,  0.1158, -0.1073, -0.0125,\n",
       "         -0.0862,  0.0439,  0.1250,  0.0756, -0.0073, -0.0731,  0.0090, -0.0964,\n",
       "          0.0041,  0.0272, -0.1222, -0.1137,  0.0005,  0.0490, -0.0935, -0.0197,\n",
       "          0.0685,  0.0953, -0.0012, -0.1008, -0.0306,  0.0028,  0.0719,  0.0760,\n",
       "          0.0471,  0.0815, -0.0412, -0.1123,  0.1091,  0.0559,  0.0630,  0.1051,\n",
       "         -0.0038,  0.0751, -0.0807,  0.0586,  0.0093, -0.1180,  0.0356,  0.0116],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0587, -0.1038, -0.0733,  0.0470, -0.0595, -0.0340,  0.0786, -0.0913,\n",
       "         -0.1046,  0.0846, -0.0915, -0.0379,  0.0645,  0.0626, -0.0553, -0.0191,\n",
       "         -0.0346,  0.0590, -0.0386, -0.1005,  0.0619,  0.0487, -0.0234,  0.0936,\n",
       "          0.0852, -0.0632, -0.0427,  0.1025,  0.0782,  0.0443, -0.1031,  0.1189,\n",
       "          0.0901,  0.0957, -0.0851,  0.0952, -0.0138, -0.0347, -0.0668,  0.0740,\n",
       "          0.0159, -0.1122,  0.0889,  0.1228,  0.0150,  0.0694, -0.0200,  0.0272,\n",
       "         -0.0292, -0.0700, -0.0795, -0.0171, -0.0734, -0.1073, -0.0428, -0.0305,\n",
       "         -0.1040,  0.0145, -0.0080, -0.0657,  0.0126, -0.0258,  0.1051, -0.0198],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0397, -0.1008, -0.0792, -0.1075, -0.1247,  0.1235,  0.0088, -0.0537,\n",
       "          0.0026, -0.0632,  0.0569, -0.0729,  0.0942,  0.0149, -0.1158,  0.0756,\n",
       "         -0.0049,  0.0528,  0.1180, -0.0267,  0.0330,  0.0669, -0.0388,  0.0458,\n",
       "          0.0941, -0.0220, -0.0312, -0.0493, -0.0949, -0.0748, -0.1153, -0.0206,\n",
       "         -0.0377, -0.0843,  0.0860,  0.0499,  0.1025, -0.0699,  0.0073, -0.0422,\n",
       "          0.0750,  0.0380,  0.0931,  0.0207,  0.0938, -0.0363,  0.1017, -0.0719,\n",
       "          0.0022,  0.0193, -0.0880, -0.0807, -0.0450,  0.0546, -0.0919,  0.0102,\n",
       "          0.0357, -0.1146,  0.0359,  0.0324,  0.0326, -0.0693,  0.1227, -0.0283],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0590, -0.1010, -0.0744,  0.0083, -0.0873, -0.0984,  0.0553, -0.0366,\n",
       "         -0.0315,  0.0799,  0.0561, -0.1163,  0.0521,  0.0427,  0.0009,  0.0406,\n",
       "         -0.0647,  0.0566,  0.0288,  0.0369,  0.0647,  0.0834,  0.0870,  0.0627,\n",
       "          0.0114, -0.0586,  0.0640,  0.0531, -0.0407,  0.0866,  0.0149,  0.0626,\n",
       "         -0.0655,  0.0309, -0.1094,  0.0815,  0.0365, -0.0086,  0.0013, -0.0857,\n",
       "         -0.0676,  0.0360, -0.0308, -0.0269,  0.1208,  0.0839, -0.0462,  0.0642,\n",
       "         -0.0999,  0.0091, -0.0662,  0.0338,  0.0731,  0.0031,  0.0630,  0.0769,\n",
       "         -0.1113, -0.0390,  0.0892, -0.0582,  0.0901,  0.0027, -0.0132, -0.0925],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1152, -0.0320,  0.0054,  0.0084,  0.0773,  0.0345, -0.1238,  0.0034,\n",
       "          0.0979,  0.0033,  0.1240, -0.1061,  0.0356, -0.1190, -0.0275, -0.0578,\n",
       "          0.0498, -0.0233, -0.0774,  0.0883, -0.0940, -0.0722,  0.0813,  0.0377,\n",
       "          0.0168,  0.0978,  0.1238, -0.0402,  0.0969,  0.0353,  0.0355, -0.0837,\n",
       "         -0.0220,  0.0761, -0.0138,  0.0778,  0.0124, -0.0505, -0.0296, -0.1049,\n",
       "         -0.0269, -0.0013, -0.0404, -0.0900, -0.0193, -0.0031,  0.0580, -0.0103,\n",
       "          0.0621, -0.1001,  0.0724,  0.0897, -0.0928,  0.0367, -0.0739, -0.0891,\n",
       "          0.0631, -0.0825, -0.0360,  0.1171, -0.1003,  0.0348,  0.0777, -0.0176],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1145, -0.0172, -0.0538,  0.0541, -0.0553,  0.0138,  0.0824, -0.1071,\n",
       "          0.0399,  0.0445, -0.0152,  0.0766, -0.0788,  0.0414,  0.0887,  0.0626,\n",
       "          0.0395,  0.0878,  0.0898,  0.0918, -0.0304, -0.0460,  0.1176,  0.0172,\n",
       "         -0.0631, -0.0751,  0.0568,  0.0256, -0.1002,  0.0807,  0.1046, -0.0556,\n",
       "          0.0551,  0.0779, -0.0260, -0.0092,  0.0469, -0.0259, -0.1139, -0.0288,\n",
       "          0.0911, -0.0231, -0.0644,  0.0517,  0.0434,  0.0117,  0.1061, -0.0808,\n",
       "          0.0012, -0.0825,  0.0611, -0.0200, -0.0382, -0.0409,  0.0568, -0.1150,\n",
       "          0.1084,  0.0009,  0.0273, -0.0840, -0.0857,  0.0249,  0.0414, -0.0797],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0444, -0.1129,  0.1154, -0.0454, -0.1172, -0.1151,  0.1217, -0.0953,\n",
       "          0.0027,  0.0956,  0.0446, -0.0769, -0.0725, -0.0362,  0.0212, -0.1119,\n",
       "         -0.0616,  0.0883,  0.1199, -0.0992,  0.0502,  0.0714,  0.0164, -0.0381,\n",
       "         -0.0304, -0.0078, -0.1166, -0.0962,  0.0516,  0.0668,  0.0744, -0.0931,\n",
       "          0.0831, -0.0314, -0.0852, -0.1085,  0.0685, -0.0072,  0.1202, -0.1210,\n",
       "          0.0726,  0.0946,  0.0005,  0.0244, -0.0601, -0.0271,  0.0312, -0.0024,\n",
       "         -0.0569,  0.1040, -0.0563,  0.1139,  0.1045,  0.0038, -0.1003, -0.0250,\n",
       "          0.0681,  0.0303,  0.0143,  0.0931,  0.0854,  0.1219,  0.0062,  0.0654],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0157, -0.0754,  0.0280, -0.0673, -0.0983,  0.0693,  0.0420, -0.1124,\n",
       "          0.0104,  0.0754, -0.0137,  0.0287,  0.0949,  0.0678, -0.0329, -0.0371,\n",
       "         -0.0415,  0.1255,  0.0685,  0.0553, -0.0053, -0.0789, -0.1063,  0.1026,\n",
       "          0.0201,  0.0093,  0.1109, -0.0603,  0.1165, -0.0971,  0.0169,  0.0726,\n",
       "         -0.0022,  0.0507,  0.0807, -0.1223, -0.0425, -0.0191,  0.0065,  0.0562,\n",
       "         -0.0213,  0.0635,  0.0744,  0.0014,  0.0060, -0.1276,  0.0934,  0.0320,\n",
       "         -0.0087,  0.0058, -0.0251,  0.0490,  0.1080,  0.1097, -0.0691,  0.1050,\n",
       "         -0.1084, -0.0034, -0.0160,  0.0257, -0.0014,  0.1193,  0.1156, -0.1090],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1153,  0.0153, -0.1124,  0.0481, -0.1188,  0.0744, -0.0517, -0.1059,\n",
       "         -0.1060,  0.0782, -0.0739, -0.0607, -0.0506,  0.0710,  0.0953,  0.0277,\n",
       "         -0.0992, -0.0998, -0.0782,  0.0018,  0.0116,  0.0914,  0.0574,  0.0058,\n",
       "          0.1017,  0.1034,  0.1030, -0.0112, -0.1146, -0.0592,  0.0597, -0.0158,\n",
       "         -0.0949, -0.0635,  0.0173, -0.1022,  0.0535,  0.0301, -0.0420,  0.1121,\n",
       "         -0.0906, -0.0075, -0.0517, -0.1096,  0.1211, -0.0280, -0.1020, -0.0444,\n",
       "          0.1134, -0.1047,  0.0305,  0.1213, -0.0142,  0.0098,  0.0830, -0.0926,\n",
       "         -0.0691,  0.1168,  0.1147, -0.1039,  0.0675,  0.0247,  0.0024, -0.0293],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1160,  0.0205,  0.0829, -0.0647,  0.0115, -0.0018,  0.0173, -0.1066,\n",
       "          0.1219, -0.0122,  0.0833,  0.0861, -0.0585, -0.0649, -0.1103,  0.1112,\n",
       "          0.1109,  0.0880,  0.0858,  0.0350, -0.0772,  0.0742,  0.0662, -0.0026,\n",
       "          0.1219, -0.1088,  0.0731,  0.1144, -0.0867,  0.0224, -0.0020,  0.0325,\n",
       "         -0.0244, -0.1102, -0.0525, -0.0925,  0.1022,  0.0629, -0.0338, -0.0572,\n",
       "          0.0812,  0.0883, -0.1182, -0.0095,  0.0756, -0.1142,  0.0490,  0.1148,\n",
       "         -0.0998, -0.1152,  0.0646, -0.0709,  0.0902, -0.0695, -0.0429,  0.0369,\n",
       "         -0.0199,  0.0920, -0.0601, -0.0963,  0.0144, -0.0540, -0.1125,  0.0895],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1174, -0.0711, -0.1172,  0.0954, -0.0352, -0.0976,  0.0897,  0.0218,\n",
       "         -0.1206,  0.0358, -0.0783, -0.0402, -0.0157, -0.0435, -0.1073, -0.0811,\n",
       "         -0.0367,  0.0422,  0.0170,  0.0584,  0.0672,  0.0180, -0.1020,  0.0598,\n",
       "          0.1108,  0.0856,  0.0027,  0.0972,  0.1068,  0.0685, -0.0994, -0.0808,\n",
       "          0.0898,  0.0005, -0.0400, -0.1065, -0.0023,  0.0429,  0.0158, -0.0163,\n",
       "          0.0788,  0.1194, -0.0897,  0.0050, -0.0325, -0.0255, -0.0378,  0.0885,\n",
       "         -0.0027, -0.0274,  0.0611,  0.0080,  0.0062,  0.0649, -0.0384, -0.1194,\n",
       "          0.0192, -0.1006,  0.0590, -0.1073, -0.0605, -0.0870,  0.0364, -0.1059],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0673, -0.0770, -0.0447,  0.0865, -0.0581,  0.0926,  0.0918, -0.0274,\n",
       "         -0.0688,  0.0355, -0.0138,  0.0556,  0.0402,  0.0533,  0.0405,  0.0335,\n",
       "         -0.0718,  0.0209,  0.0586,  0.0149,  0.0348,  0.0054,  0.0499,  0.0972,\n",
       "         -0.0348,  0.0114, -0.0061,  0.0921,  0.0575,  0.0327,  0.0916,  0.1040,\n",
       "         -0.0125, -0.0133, -0.0315,  0.0855, -0.0684,  0.0973,  0.0015,  0.0346,\n",
       "         -0.1094, -0.0019,  0.1143, -0.0201,  0.0298,  0.1055,  0.0214,  0.1008,\n",
       "         -0.0008,  0.0250,  0.0715,  0.1183, -0.0325,  0.0340,  0.0364,  0.0318,\n",
       "          0.0014,  0.0101,  0.0264, -0.0363, -0.1246, -0.0746, -0.0169, -0.0136],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1004, -0.0858,  0.0686, -0.0434,  0.0703, -0.0081, -0.0471, -0.0016,\n",
       "          0.0218, -0.1193, -0.0678, -0.0684,  0.0389, -0.0349, -0.0292, -0.0213,\n",
       "          0.0209,  0.0476,  0.0801,  0.0518,  0.0929, -0.0796, -0.0048,  0.0882,\n",
       "         -0.0592,  0.0159,  0.0897,  0.0107,  0.0380,  0.1222,  0.0554,  0.0272,\n",
       "          0.1142,  0.0042,  0.0370, -0.0410, -0.0825, -0.0334, -0.0661,  0.0792,\n",
       "          0.0466, -0.0618,  0.0964, -0.0030, -0.0787, -0.0697,  0.0357,  0.0174,\n",
       "          0.0202,  0.0712, -0.0509, -0.0807,  0.1238,  0.0411, -0.0342,  0.0224,\n",
       "         -0.0961,  0.0516,  0.0550,  0.1080, -0.0072, -0.0413,  0.0948, -0.0504],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0734,  0.0765,  0.0125, -0.0979, -0.1080, -0.0549, -0.0083,  0.0137,\n",
       "         -0.1099,  0.0976, -0.0572, -0.0444, -0.1062,  0.0873, -0.0393,  0.1027,\n",
       "         -0.0218,  0.1072,  0.0885,  0.1175,  0.0333, -0.1097,  0.0974, -0.0931,\n",
       "         -0.1174, -0.0386,  0.0720,  0.1123, -0.0662, -0.0009, -0.0477,  0.0606,\n",
       "          0.0564,  0.0639, -0.0098,  0.0022,  0.0486, -0.0938, -0.1199, -0.1253,\n",
       "          0.0239,  0.0493,  0.1095, -0.0122,  0.0044,  0.0101,  0.0478, -0.0848,\n",
       "         -0.0301,  0.1016, -0.0902, -0.0716,  0.1226, -0.0708, -0.0315,  0.0945,\n",
       "         -0.1087,  0.0691,  0.0781, -0.0371,  0.1110,  0.1209,  0.0338,  0.0224],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0340,  0.0012,  0.0039,  ...,  0.0383,  0.0423, -0.0003],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0140,  0.0041,  0.0071,  0.0134, -0.0107,  0.0153, -0.0209,  0.0055,\n",
       "         -0.0157, -0.0199,  0.0182,  0.0167,  0.0034,  0.0130, -0.0129, -0.0002,\n",
       "         -0.0076,  0.0147,  0.0200,  0.0116,  0.0023,  0.0230, -0.0204,  0.0069,\n",
       "         -0.0198, -0.0097,  0.0064, -0.0031, -0.0045, -0.0095,  0.0163, -0.0146,\n",
       "          0.0007,  0.0156, -0.0125, -0.0030,  0.0188,  0.0124, -0.0158,  0.0164,\n",
       "         -0.0172,  0.0190, -0.0071, -0.0060,  0.0072,  0.0134, -0.0129,  0.0144,\n",
       "          0.0099,  0.0137, -0.0121, -0.0149, -0.0130,  0.0083,  0.0037, -0.0124,\n",
       "          0.0074, -0.0022, -0.0074,  0.0191,  0.0096, -0.0055,  0.0222,  0.0205,\n",
       "          0.0147, -0.0202,  0.0029,  0.0156,  0.0221, -0.0013, -0.0018,  0.0126,\n",
       "         -0.0205, -0.0099, -0.0196, -0.0119,  0.0056,  0.0105,  0.0003,  0.0099,\n",
       "         -0.0202,  0.0067, -0.0195, -0.0165, -0.0091, -0.0005,  0.0207, -0.0090,\n",
       "          0.0126, -0.0060, -0.0185,  0.0114, -0.0068,  0.0015,  0.0061,  0.0152,\n",
       "          0.0083,  0.0050,  0.0119, -0.0038,  0.0213, -0.0158, -0.0211, -0.0060,\n",
       "          0.0150, -0.0133,  0.0125,  0.0189, -0.0022, -0.0093,  0.0205,  0.0055,\n",
       "         -0.0156, -0.0207,  0.0213, -0.0003,  0.0115, -0.0065,  0.0091,  0.0092,\n",
       "         -0.0058, -0.0193, -0.0085,  0.0127, -0.0028, -0.0179, -0.0022,  0.0057,\n",
       "         -0.0018,  0.0127, -0.0120,  0.0086,  0.0062, -0.0061, -0.0186, -0.0172,\n",
       "         -0.0216,  0.0048,  0.0128,  0.0037, -0.0057, -0.0143,  0.0139,  0.0213,\n",
       "          0.0091,  0.0164, -0.0166, -0.0162,  0.0043,  0.0069,  0.0129, -0.0129,\n",
       "         -0.0020, -0.0134,  0.0133, -0.0182, -0.0195, -0.0180,  0.0157, -0.0134,\n",
       "          0.0063,  0.0162,  0.0210, -0.0026, -0.0009, -0.0077,  0.0136, -0.0062,\n",
       "         -0.0212, -0.0181,  0.0055, -0.0094,  0.0043, -0.0101, -0.0095, -0.0034,\n",
       "         -0.0103, -0.0043, -0.0077, -0.0009, -0.0088, -0.0077,  0.0103, -0.0123,\n",
       "          0.0145, -0.0168,  0.0047, -0.0135,  0.0234,  0.0166, -0.0124, -0.0098,\n",
       "          0.0106,  0.0145, -0.0174,  0.0161,  0.0151, -0.0109,  0.0106, -0.0024,\n",
       "          0.0187,  0.0173, -0.0179,  0.0056, -0.0119,  0.0099, -0.0050, -0.0211,\n",
       "         -0.0038,  0.0148, -0.0031, -0.0192,  0.0168, -0.0229,  0.0126,  0.0037,\n",
       "          0.0210, -0.0170, -0.0151,  0.0126,  0.0182,  0.0094, -0.0092,  0.0058,\n",
       "          0.0130, -0.0052, -0.0041, -0.0096, -0.0052, -0.0081, -0.0026, -0.0219,\n",
       "          0.0062,  0.0192, -0.0050, -0.0030, -0.0197,  0.0016, -0.0098, -0.0080,\n",
       "         -0.0040,  0.0002,  0.0021, -0.0016,  0.0115, -0.0068,  0.0052, -0.0151,\n",
       "          0.0099, -0.0194,  0.0137, -0.0151,  0.0087,  0.0118,  0.0152,  0.0124,\n",
       "         -0.0111,  0.0061,  0.0091,  0.0054,  0.0099, -0.0080, -0.0153, -0.0068,\n",
       "          0.0113,  0.0157, -0.0058, -0.0190,  0.0137, -0.0054,  0.0193, -0.0176,\n",
       "         -0.0032,  0.0094,  0.0014, -0.0151,  0.0205,  0.0064, -0.0055, -0.0131,\n",
       "          0.0217,  0.0180, -0.0109,  0.0158,  0.0206,  0.0058, -0.0204, -0.0135,\n",
       "          0.0180,  0.0164,  0.0135,  0.0028, -0.0143,  0.0191,  0.0145, -0.0018,\n",
       "          0.0208,  0.0206, -0.0054,  0.0118, -0.0022,  0.0144,  0.0167,  0.0094,\n",
       "         -0.0089, -0.0153,  0.0096,  0.0185, -0.0124, -0.0188, -0.0106, -0.0144,\n",
       "          0.0021, -0.0148,  0.0186,  0.0174,  0.0221,  0.0094,  0.0060, -0.0118,\n",
       "          0.0049, -0.0189,  0.0036,  0.0059,  0.0091, -0.0203, -0.0174,  0.0001,\n",
       "          0.0009,  0.0122, -0.0170,  0.0218,  0.0185,  0.0004, -0.0102, -0.0103,\n",
       "          0.0071, -0.0029,  0.0177,  0.0104, -0.0108, -0.0018,  0.0008, -0.0189,\n",
       "         -0.0194,  0.0098,  0.0156, -0.0087, -0.0155, -0.0120, -0.0008, -0.0105,\n",
       "          0.0200,  0.0091,  0.0038,  0.0033,  0.0207, -0.0120, -0.0208, -0.0019,\n",
       "         -0.0180,  0.0035, -0.0174,  0.0194,  0.0075, -0.0033, -0.0190, -0.0097,\n",
       "          0.0118,  0.0055,  0.0111, -0.0177,  0.0085, -0.0141, -0.0202, -0.0068,\n",
       "         -0.0020, -0.0017,  0.0121, -0.0117, -0.0185,  0.0186, -0.0070, -0.0126,\n",
       "          0.0121,  0.0071,  0.0029,  0.0196,  0.0166,  0.0191, -0.0216, -0.0155,\n",
       "          0.0118,  0.0098, -0.0068,  0.0177,  0.0193, -0.0162, -0.0206, -0.0109,\n",
       "         -0.0140, -0.0183,  0.0018, -0.0149, -0.0133,  0.0062,  0.0048, -0.0162,\n",
       "         -0.0034, -0.0059, -0.0091,  0.0008, -0.0017, -0.0159,  0.0115, -0.0157,\n",
       "         -0.0162,  0.0152, -0.0018,  0.0065, -0.0126, -0.0028, -0.0132, -0.0123,\n",
       "         -0.0089, -0.0187,  0.0060, -0.0075,  0.0063,  0.0194,  0.0194, -0.0047,\n",
       "         -0.0094,  0.0073, -0.0133, -0.0201, -0.0119,  0.0185,  0.0016, -0.0174,\n",
       "          0.0186,  0.0058,  0.0100,  0.0031,  0.0049, -0.0131,  0.0041,  0.0187,\n",
       "          0.0141, -0.0123, -0.0034,  0.0200,  0.0107, -0.0184, -0.0098,  0.0012,\n",
       "          0.0150, -0.0220,  0.0176,  0.0005,  0.0005,  0.0002, -0.0161, -0.0084,\n",
       "          0.0141,  0.0175, -0.0044,  0.0166,  0.0016,  0.0152, -0.0094, -0.0230,\n",
       "          0.0020, -0.0056,  0.0050,  0.0152,  0.0035,  0.0101, -0.0188, -0.0057,\n",
       "          0.0110, -0.0106, -0.0004,  0.0117,  0.0102,  0.0108,  0.0023, -0.0058,\n",
       "         -0.0071,  0.0143,  0.0112,  0.0069,  0.0205, -0.0211,  0.0058, -0.0188,\n",
       "         -0.0047,  0.0113, -0.0144, -0.0147,  0.0030, -0.0112,  0.0185, -0.0199,\n",
       "         -0.0190,  0.0084,  0.0021, -0.0061,  0.0160, -0.0131, -0.0135,  0.0006],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0419, -0.0769,  0.0544, -0.0713, -0.0920,  0.0920, -0.0479,  0.0604,\n",
       "          0.0669, -0.0179, -0.1172,  0.0166,  0.0269, -0.0818, -0.0707,  0.0451,\n",
       "         -0.0121,  0.1138, -0.0236, -0.0842,  0.0416, -0.1050,  0.0730,  0.0052,\n",
       "         -0.0514, -0.1087,  0.1121, -0.0531, -0.0568,  0.0992, -0.0397, -0.1009,\n",
       "          0.1098, -0.0872,  0.0276,  0.0892,  0.1160,  0.0315,  0.1027, -0.1149,\n",
       "         -0.0578,  0.0149,  0.0915, -0.1180, -0.0728,  0.0498, -0.0882, -0.0638,\n",
       "          0.0303,  0.0638,  0.1117, -0.1224,  0.0049,  0.0811, -0.0329,  0.0711,\n",
       "          0.1168,  0.1029, -0.1252, -0.1216, -0.0223, -0.1087,  0.0515,  0.0729],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0439,  0.0887,  0.0800, -0.0076,  0.0698,  0.0619,  0.0362,  0.0060,\n",
       "          0.0749, -0.1027,  0.0131,  0.0591, -0.0990,  0.0887, -0.0847,  0.1024,\n",
       "         -0.0189,  0.0303,  0.0105,  0.1117, -0.1157,  0.0373,  0.0187,  0.0172,\n",
       "         -0.0160, -0.0533,  0.0069, -0.0389, -0.0653,  0.0791,  0.0818, -0.0775,\n",
       "          0.0182,  0.1158,  0.0535, -0.1095, -0.1071,  0.0671, -0.0653, -0.0846,\n",
       "          0.0296,  0.0276,  0.0416, -0.0223, -0.0894, -0.0335, -0.1092,  0.0212,\n",
       "          0.1118, -0.0784, -0.0881,  0.0428, -0.0332, -0.0067, -0.1173,  0.0315,\n",
       "          0.0195,  0.1198,  0.0596, -0.1203, -0.1165, -0.0582, -0.0057, -0.0587],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0879,  0.1172,  0.0017,  0.0238, -0.0648,  0.0642, -0.0143, -0.0396,\n",
       "          0.0051, -0.0037,  0.0933, -0.1202,  0.0253, -0.1233, -0.0640, -0.0278,\n",
       "         -0.1035, -0.1087, -0.1011,  0.1169, -0.1090,  0.0225, -0.1236,  0.1001,\n",
       "         -0.0060, -0.0359, -0.0984, -0.0765, -0.0616,  0.0636,  0.0890,  0.0339,\n",
       "          0.0922,  0.0785,  0.1257,  0.0773, -0.0192,  0.0675, -0.0872, -0.0599,\n",
       "         -0.1195, -0.0107, -0.1096,  0.0519,  0.0832, -0.0751,  0.0503,  0.1130,\n",
       "          0.0257,  0.1003, -0.1109,  0.0282, -0.0248, -0.0741,  0.0091, -0.0221,\n",
       "         -0.0128, -0.0644, -0.0778,  0.0218, -0.0105,  0.0372, -0.0981, -0.0200],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0979, -0.1229, -0.1010, -0.0989, -0.0706, -0.0868, -0.1002,  0.0078,\n",
       "         -0.1120,  0.0984, -0.0377, -0.1096, -0.0703,  0.0633,  0.0996,  0.0359,\n",
       "          0.0640, -0.0252,  0.0658,  0.1027,  0.0654,  0.0816,  0.0611, -0.0730,\n",
       "         -0.0769, -0.0370, -0.0453, -0.0346, -0.0632,  0.0645,  0.0981, -0.0578,\n",
       "          0.0703, -0.0021, -0.0648, -0.0120,  0.1177,  0.0084,  0.0646, -0.0576,\n",
       "          0.1102,  0.1193,  0.0676,  0.0545,  0.1001,  0.0857,  0.0848,  0.1090,\n",
       "          0.0606,  0.1066,  0.0268, -0.0809, -0.0569,  0.1142,  0.1144,  0.0733,\n",
       "         -0.0696,  0.1140,  0.0370, -0.0902, -0.0174,  0.1082,  0.0547,  0.1170],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0931,  0.1140,  0.0610, -0.1137,  0.1219, -0.1225, -0.0726,  0.0393,\n",
       "         -0.0155, -0.0237, -0.0189, -0.0535, -0.0757, -0.1063, -0.0267,  0.0540,\n",
       "          0.0218, -0.0962,  0.0364,  0.1001, -0.1254, -0.0512,  0.0323, -0.0534,\n",
       "         -0.0220,  0.0688,  0.1118,  0.1028, -0.0020,  0.0893,  0.1095, -0.0858,\n",
       "          0.0318, -0.0047,  0.0090,  0.0620,  0.1085, -0.0801, -0.0274, -0.0010,\n",
       "         -0.0992,  0.0032,  0.1026, -0.0816, -0.0040,  0.1173,  0.0185, -0.0166,\n",
       "         -0.1100, -0.0564,  0.0760, -0.0216, -0.0524,  0.0598,  0.1033,  0.0608,\n",
       "          0.0823,  0.0212, -0.0639, -0.0722,  0.0149, -0.0965, -0.0290,  0.0725],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0843,  0.1244,  0.0059, -0.0647,  0.1161,  0.0441,  0.0244, -0.0847,\n",
       "         -0.0347,  0.0778, -0.0129, -0.0111,  0.0137,  0.1141, -0.0924, -0.0459,\n",
       "          0.0253, -0.0755,  0.1129,  0.0767,  0.0758, -0.0455,  0.1206, -0.0100,\n",
       "          0.0114,  0.0794,  0.0372, -0.1195,  0.0284, -0.0152, -0.0241, -0.1025,\n",
       "         -0.0438,  0.0631, -0.0799, -0.0309, -0.0698,  0.0554, -0.0048, -0.0976,\n",
       "          0.0645,  0.0460, -0.0214, -0.1074,  0.0188, -0.0307,  0.0066,  0.0087,\n",
       "          0.0391, -0.0684,  0.0350, -0.0775,  0.0131, -0.0490, -0.0941,  0.1199,\n",
       "          0.1165,  0.0512,  0.1120,  0.0149,  0.0213,  0.0313,  0.0524, -0.0080],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1222,  0.0502,  0.1241,  0.0330,  0.0902, -0.0917, -0.0520, -0.0383,\n",
       "          0.0025,  0.0428,  0.0417, -0.0095, -0.1029, -0.0690, -0.0869, -0.0483,\n",
       "         -0.0951, -0.0975,  0.0079, -0.0289, -0.1018, -0.0019,  0.0136,  0.1174,\n",
       "          0.0732, -0.0122, -0.0861, -0.0307,  0.0287, -0.0345,  0.0507,  0.0627,\n",
       "         -0.1166, -0.1097,  0.0353, -0.0508,  0.0641,  0.0591,  0.0389, -0.0681,\n",
       "          0.0845, -0.0943,  0.0335,  0.0061,  0.0906, -0.0171, -0.0089,  0.0266,\n",
       "          0.0758,  0.1175,  0.0427, -0.0425,  0.0838, -0.0275, -0.0239,  0.0784,\n",
       "          0.0133, -0.0486, -0.0378,  0.0571,  0.0587,  0.0775, -0.1162, -0.0340],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0920, -0.0553, -0.0119,  0.0711, -0.0282,  0.0288,  0.0539, -0.0827,\n",
       "          0.0909,  0.0969,  0.0086, -0.0171, -0.0805,  0.0392,  0.0819, -0.0675,\n",
       "          0.1233, -0.0138, -0.0324,  0.1024,  0.0185,  0.0228, -0.0210,  0.0904,\n",
       "         -0.0780, -0.1147,  0.0752,  0.0755,  0.0892,  0.0037, -0.1080,  0.1160,\n",
       "         -0.1196, -0.1073, -0.1187, -0.0712, -0.0480, -0.0139, -0.0490,  0.0612,\n",
       "         -0.1112,  0.0224,  0.0534, -0.0862, -0.1184, -0.1216, -0.0503, -0.1181,\n",
       "         -0.0635, -0.0200,  0.0849, -0.1238,  0.0511, -0.0088, -0.1187,  0.1131,\n",
       "         -0.0163,  0.0851, -0.0823,  0.0271, -0.0285, -0.0587, -0.0709,  0.1165],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0844, -0.0333, -0.0760, -0.0957, -0.0784, -0.0487, -0.0353, -0.1091,\n",
       "         -0.0971, -0.0906, -0.0112,  0.0497, -0.1211,  0.0210,  0.0649,  0.0725,\n",
       "         -0.0296, -0.0842,  0.0970, -0.0090, -0.0930,  0.0222,  0.0794,  0.0525,\n",
       "          0.0380, -0.0733, -0.0741, -0.0476,  0.0992,  0.1005,  0.0392, -0.1223,\n",
       "         -0.1110, -0.0552, -0.1126, -0.0699, -0.1100,  0.0281,  0.1126, -0.0088,\n",
       "         -0.0680, -0.0835, -0.0936,  0.1103, -0.0982, -0.0801, -0.0136, -0.1004,\n",
       "         -0.1244,  0.0067,  0.0656, -0.0603,  0.0449,  0.1063,  0.0559,  0.0946,\n",
       "         -0.0487,  0.0100, -0.0067, -0.0391, -0.1190,  0.0985,  0.0020,  0.0911],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0698,  0.0561,  0.1198, -0.0923,  0.1194,  0.1062,  0.0641, -0.0470,\n",
       "         -0.1062,  0.0775,  0.0076,  0.0559, -0.1198, -0.0898, -0.0927,  0.0603,\n",
       "          0.0509,  0.0897, -0.0574,  0.0871,  0.1018,  0.0812,  0.1079,  0.0839,\n",
       "         -0.0960,  0.0725, -0.0627,  0.0193, -0.0879,  0.0170,  0.0034,  0.1218,\n",
       "          0.0561,  0.1012, -0.0362,  0.0301,  0.0311, -0.1031,  0.0828,  0.0245,\n",
       "         -0.0695, -0.0169,  0.0192, -0.0951, -0.1016, -0.1099,  0.0253,  0.0829,\n",
       "         -0.0859, -0.0225,  0.0010,  0.0589, -0.0834, -0.0709,  0.0187, -0.0299,\n",
       "          0.1246, -0.0833,  0.1031, -0.0745, -0.0176,  0.0459, -0.0478, -0.0072],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0098,  0.0753, -0.0861, -0.1082,  0.0166, -0.1166, -0.0151, -0.0730,\n",
       "          0.0201,  0.0377,  0.0979,  0.0956, -0.1089,  0.0596,  0.0946, -0.1011,\n",
       "         -0.0033, -0.0350,  0.0640,  0.1123, -0.1100,  0.0404,  0.0674, -0.0859,\n",
       "         -0.0186, -0.0632,  0.1142, -0.0559, -0.0392, -0.0882,  0.0460, -0.0367,\n",
       "         -0.0507,  0.0154,  0.0959,  0.0530,  0.0541, -0.0179, -0.0598,  0.1051,\n",
       "         -0.0432, -0.0649, -0.0493, -0.0489, -0.0547, -0.0707,  0.0773, -0.1078,\n",
       "         -0.0841,  0.0113,  0.0004,  0.0589, -0.0286,  0.0439, -0.0384,  0.0331,\n",
       "         -0.0681, -0.0825, -0.1051,  0.0067,  0.0648, -0.1020,  0.0565,  0.0132],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0412, -0.0092,  0.0340,  0.0511, -0.0049,  0.0391,  0.0256, -0.0074,\n",
       "          0.0696, -0.0099, -0.0364,  0.0355, -0.0209, -0.0195,  0.0311, -0.0914,\n",
       "          0.0611, -0.0550,  0.0887,  0.0355,  0.0889, -0.0461,  0.0992,  0.0846,\n",
       "          0.0163,  0.0392,  0.0354, -0.0144, -0.0073, -0.0480, -0.0832, -0.0646,\n",
       "          0.1166,  0.0426, -0.0912,  0.0998,  0.1056,  0.1200,  0.0073,  0.0423,\n",
       "         -0.0098,  0.0682,  0.0824,  0.0294, -0.0811,  0.1141, -0.0478, -0.1200,\n",
       "          0.1203, -0.0435,  0.0933, -0.0441,  0.0378, -0.1112,  0.0346,  0.0318,\n",
       "          0.0218,  0.0905,  0.0245,  0.0036,  0.0156, -0.0824, -0.0690,  0.0289],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0064, -0.1029,  0.0767,  0.0085,  0.0337,  0.0725,  0.1198, -0.0015,\n",
       "          0.1108, -0.0066,  0.1004, -0.0421,  0.0715,  0.0921, -0.1210,  0.0399,\n",
       "         -0.1040,  0.0561, -0.0075,  0.0678,  0.1032,  0.0791,  0.1094, -0.0066,\n",
       "         -0.0160, -0.0812, -0.0050,  0.0350, -0.0387, -0.0874,  0.0273, -0.0713,\n",
       "         -0.0145, -0.0917, -0.0307, -0.0167, -0.0695, -0.0156,  0.1126, -0.0011,\n",
       "         -0.1210, -0.0894,  0.0861, -0.0892, -0.0795, -0.0636,  0.0628, -0.0487,\n",
       "         -0.0585, -0.1119, -0.0172, -0.1211,  0.0994, -0.0591,  0.0736, -0.1144,\n",
       "         -0.0629,  0.0194,  0.0107, -0.0120,  0.0620,  0.1058,  0.0825, -0.0501],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1014,  0.0960, -0.0990, -0.0289,  0.0288,  0.0130,  0.0975, -0.1217,\n",
       "          0.0975, -0.0784, -0.0609,  0.0095,  0.0408, -0.0906,  0.0458,  0.1228,\n",
       "         -0.0188, -0.0704, -0.0692,  0.0139,  0.1068, -0.1096,  0.1138, -0.0095,\n",
       "         -0.1079, -0.0861,  0.0101,  0.0225, -0.0803,  0.0018,  0.0713,  0.0498,\n",
       "         -0.0553, -0.0750, -0.0324,  0.1021,  0.0442,  0.1190, -0.0951,  0.0592,\n",
       "         -0.0777,  0.0894,  0.0456, -0.0167,  0.0645, -0.0219,  0.0062, -0.0127,\n",
       "          0.0728,  0.0338, -0.0810, -0.0629, -0.1179,  0.0202,  0.0373, -0.1059,\n",
       "          0.0516, -0.0302,  0.1213, -0.0257, -0.0661, -0.1249,  0.1187,  0.0667],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0547,  0.1080,  0.1106,  0.1218, -0.0967, -0.0966, -0.0547,  0.0221,\n",
       "          0.0396, -0.0872, -0.1098,  0.1075,  0.0546,  0.0558,  0.0639, -0.0688,\n",
       "          0.0415,  0.0086,  0.1066,  0.1008, -0.0241, -0.0839,  0.1112, -0.0434,\n",
       "         -0.0973,  0.1070,  0.0153,  0.1000,  0.0439,  0.0386, -0.0262,  0.0904,\n",
       "         -0.0291,  0.0549, -0.0316, -0.0691, -0.0384,  0.1053,  0.0946, -0.1165,\n",
       "         -0.0176,  0.1132,  0.0195,  0.0511,  0.0524, -0.0950,  0.1200, -0.0158,\n",
       "          0.1067,  0.0083, -0.1171,  0.0992,  0.1018, -0.0126, -0.0175, -0.0118,\n",
       "          0.1168,  0.0488, -0.0496,  0.0476,  0.0364, -0.0349,  0.0672,  0.1108],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0723,  0.0841,  0.0049, -0.0999, -0.1071, -0.0798,  0.0212,  0.1164,\n",
       "         -0.0254, -0.0803, -0.0487, -0.1160,  0.0868,  0.0585,  0.0294,  0.1184,\n",
       "         -0.0646, -0.1242,  0.0335,  0.0856, -0.0036, -0.1162, -0.0983,  0.0015,\n",
       "         -0.0948, -0.0448, -0.0132,  0.0730, -0.0174, -0.1161, -0.1087, -0.0173,\n",
       "          0.0775, -0.0899,  0.0420,  0.0784, -0.0861, -0.0611,  0.1149, -0.1151,\n",
       "         -0.0258, -0.0041,  0.0231,  0.0390, -0.1082,  0.0573,  0.1081,  0.0857,\n",
       "         -0.0107,  0.0928, -0.0224,  0.0901, -0.1149,  0.1077,  0.0959,  0.0192,\n",
       "          0.0170, -0.0074, -0.1044,  0.0714,  0.0128, -0.1006, -0.1094,  0.0595],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0820, -0.1213, -0.0206,  0.0120,  0.0699, -0.0327,  0.0543,  0.0112,\n",
       "          0.0692,  0.0144,  0.0373, -0.0224,  0.1213, -0.1181,  0.0562,  0.1118,\n",
       "          0.1016,  0.0042,  0.0712,  0.0370, -0.0484, -0.0218,  0.0565, -0.0980,\n",
       "         -0.0205, -0.0068,  0.0924,  0.0657,  0.0997,  0.0901, -0.0980,  0.0391,\n",
       "          0.0484,  0.0172, -0.0173,  0.0527, -0.0196,  0.0507,  0.1235, -0.0281,\n",
       "         -0.0774,  0.0267,  0.0818,  0.0309,  0.0153,  0.0706, -0.0969, -0.1171,\n",
       "         -0.0963, -0.0376, -0.0382,  0.0108, -0.0872, -0.0274, -0.0674, -0.0303,\n",
       "          0.0619,  0.0340, -0.0077, -0.0103,  0.0717,  0.0829,  0.0999, -0.0398],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0296,  0.0821, -0.1033, -0.0362, -0.1229, -0.0632, -0.0806, -0.0495,\n",
       "         -0.0977, -0.1241,  0.0965, -0.0370, -0.0316,  0.1232, -0.0371,  0.0173,\n",
       "         -0.0836,  0.0889,  0.0843, -0.0136, -0.1025,  0.0691, -0.0167, -0.0851,\n",
       "          0.0014,  0.0651,  0.0267,  0.0082, -0.0018,  0.1139,  0.0723,  0.0610,\n",
       "         -0.1101, -0.0797, -0.0927,  0.0039, -0.1205,  0.0717, -0.0071,  0.0315,\n",
       "         -0.1196, -0.1197,  0.0193, -0.0754,  0.0216,  0.1112, -0.0101,  0.0380,\n",
       "         -0.1084, -0.1125, -0.0031, -0.1045,  0.0748, -0.0062, -0.0466, -0.0699,\n",
       "          0.0073, -0.0822, -0.0866,  0.0950,  0.0864, -0.0266, -0.0734,  0.0283],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0782, -0.0506,  0.1049,  0.0235, -0.0365, -0.0965, -0.0363, -0.1113,\n",
       "         -0.1007,  0.0348,  0.1241,  0.0296, -0.0774,  0.0408,  0.0192, -0.0175,\n",
       "          0.0536, -0.0677,  0.0474,  0.0950,  0.0105,  0.0459,  0.0640,  0.0454,\n",
       "         -0.0988, -0.0573,  0.1159, -0.1034, -0.0928,  0.0013, -0.0946, -0.1130,\n",
       "         -0.0332,  0.0052,  0.0053,  0.0241,  0.0197, -0.0303,  0.0241, -0.0249,\n",
       "          0.1105, -0.1115,  0.0196, -0.0343,  0.0497,  0.1205,  0.1107,  0.0441,\n",
       "         -0.0316, -0.0213,  0.0651,  0.1190, -0.0134,  0.0985, -0.0998, -0.0806,\n",
       "          0.0424,  0.0857, -0.0050,  0.0743, -0.0509, -0.0687,  0.1218, -0.0457],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0473, -0.0020, -0.1122,  0.1006,  0.0769,  0.0236, -0.0963, -0.0574,\n",
       "          0.1100, -0.0726, -0.1125, -0.1168, -0.0717,  0.0474,  0.1075, -0.1008,\n",
       "          0.0578, -0.0368,  0.0737,  0.0654, -0.0389, -0.1013,  0.0763, -0.1100,\n",
       "         -0.0628,  0.0504, -0.0809, -0.0326, -0.0107, -0.0850, -0.0006, -0.0088,\n",
       "          0.0679,  0.1041, -0.1072,  0.0880,  0.0825,  0.0041,  0.0598, -0.1176,\n",
       "         -0.0467,  0.0537, -0.0201, -0.0467, -0.0184, -0.0926, -0.0887,  0.0923,\n",
       "         -0.0210, -0.0305, -0.0459,  0.0638, -0.0227, -0.0828, -0.1128,  0.0881,\n",
       "          0.0013,  0.0487, -0.0810, -0.0219, -0.0525, -0.0758, -0.0490, -0.0514],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0079,  0.0156, -0.0320, -0.0428, -0.0813, -0.0961, -0.0914, -0.0948,\n",
       "         -0.0639,  0.0207,  0.1032, -0.0646,  0.0882, -0.0323, -0.0549, -0.0624,\n",
       "          0.0742,  0.0095,  0.0501, -0.0847,  0.0994, -0.0007,  0.0282, -0.0048,\n",
       "         -0.0236,  0.0559,  0.1002, -0.1249, -0.0356,  0.0217,  0.0917,  0.1046,\n",
       "         -0.0137, -0.0450,  0.1022,  0.1244, -0.1105,  0.0539, -0.0873,  0.1074,\n",
       "         -0.0250,  0.0076,  0.0270, -0.1019,  0.1065,  0.0326,  0.1121,  0.0880,\n",
       "          0.0116,  0.0719, -0.0135,  0.0913, -0.0259,  0.0088,  0.1088,  0.0488,\n",
       "         -0.0465,  0.0343, -0.0009, -0.0273, -0.1185,  0.0127,  0.0878,  0.1190],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0195, -0.0609,  0.0179,  0.0405,  0.0199,  0.0370,  0.0545, -0.0439,\n",
       "         -0.0024, -0.0228, -0.0449, -0.0296,  0.0497,  0.0088, -0.0318,  0.0019,\n",
       "         -0.0087,  0.0213, -0.0573, -0.0412,  0.0196,  0.0390, -0.1189, -0.0546,\n",
       "         -0.0535,  0.0932, -0.1013, -0.0947,  0.0033, -0.0811,  0.0311,  0.1006,\n",
       "         -0.1107, -0.1047, -0.0152, -0.0379, -0.0628, -0.0161,  0.0125, -0.0239,\n",
       "          0.0220,  0.0349,  0.0212,  0.0656,  0.0943, -0.0255, -0.0197,  0.0903,\n",
       "          0.0952,  0.0382, -0.1238,  0.0609, -0.0695, -0.0804,  0.0396,  0.1179,\n",
       "          0.0992, -0.0767, -0.0315,  0.0963,  0.1108,  0.0708,  0.0668,  0.0493],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0243,  0.0847, -0.0116, -0.0408,  0.0558,  0.0860,  0.0887,  0.0333,\n",
       "         -0.0639, -0.0239,  0.0796, -0.0008, -0.0902,  0.0230, -0.0502,  0.0098,\n",
       "          0.0470,  0.0248, -0.1193, -0.0780, -0.0920,  0.1117,  0.0037, -0.0372,\n",
       "         -0.0963, -0.0231,  0.0214, -0.1063,  0.0134,  0.0246,  0.0180, -0.1177,\n",
       "         -0.1069, -0.0370,  0.0088,  0.0455,  0.0535,  0.0775, -0.0538,  0.1202,\n",
       "         -0.0837,  0.1132,  0.0957, -0.0509, -0.1067,  0.1009,  0.0428, -0.0536,\n",
       "          0.1125, -0.0021, -0.0798, -0.1203,  0.0366, -0.0860, -0.0904,  0.0637,\n",
       "          0.0911,  0.1122, -0.0112, -0.0633,  0.0237,  0.0301, -0.1111, -0.0709],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0400, -0.0622, -0.0973,  0.0695,  0.0156, -0.0200, -0.1184,  0.1215,\n",
       "          0.0051, -0.1240, -0.1139,  0.0909, -0.0462,  0.0313, -0.0390,  0.1227,\n",
       "         -0.0286, -0.0426,  0.1030,  0.0692, -0.0012, -0.0692,  0.0232,  0.0827,\n",
       "          0.0538,  0.0306, -0.0040, -0.0980,  0.0675,  0.1190, -0.0843, -0.0696,\n",
       "         -0.0137,  0.0476,  0.0375, -0.0073, -0.0784, -0.0386,  0.1146,  0.1171,\n",
       "         -0.1128,  0.0305,  0.0648, -0.0961, -0.0576,  0.1078, -0.0986,  0.0896,\n",
       "         -0.0112,  0.0394,  0.0414, -0.0256,  0.0982, -0.1036, -0.0825, -0.0725,\n",
       "          0.0578, -0.0998,  0.0167,  0.0138, -0.0868, -0.0556,  0.0062,  0.0019],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0239, -0.0344, -0.0057,  ..., -0.0197,  0.0436,  0.0233],\n",
       "        device='cuda:0'),\n",
       " tensor([ 1.3737e-02, -6.9278e-03,  2.7035e-03, -2.5610e-03, -1.9774e-02,\n",
       "          2.4807e-03,  4.0140e-03, -1.0150e-02,  1.2783e-03,  1.8711e-02,\n",
       "         -2.0444e-02,  4.3295e-03,  1.6778e-02, -3.0057e-03,  1.3001e-02,\n",
       "          1.3265e-02, -4.8917e-03, -2.0241e-02,  1.4784e-02,  3.0086e-03,\n",
       "         -1.4629e-02, -1.9214e-02, -1.2761e-03,  1.9485e-02,  1.9303e-02,\n",
       "          1.1535e-02,  1.4159e-02, -1.3135e-02,  1.9493e-02,  1.2833e-02,\n",
       "         -1.1991e-02, -7.1874e-03, -5.4990e-03, -8.7533e-03,  1.0797e-02,\n",
       "          1.0546e-02, -1.4659e-02,  4.4420e-03,  1.6477e-02,  1.8594e-03,\n",
       "          2.1981e-02, -2.4001e-03, -1.3137e-02, -1.8246e-03,  2.2191e-02,\n",
       "         -1.8666e-02, -1.1255e-02,  7.7151e-03, -1.9098e-02, -1.7029e-02,\n",
       "          2.4777e-04,  2.0971e-02, -1.7517e-02,  2.3551e-03,  1.5257e-02,\n",
       "          9.7303e-04,  9.0931e-03,  8.4014e-03,  4.0066e-04,  1.7393e-02,\n",
       "         -1.2661e-02,  1.4757e-02,  1.0394e-02,  1.5446e-02, -6.8926e-03,\n",
       "         -1.1881e-02, -6.7921e-03, -2.4112e-03,  4.0403e-03, -1.9859e-03,\n",
       "          9.6470e-04, -1.1699e-02, -1.7814e-02,  9.9479e-03, -1.5239e-02,\n",
       "          3.4959e-03, -7.9994e-03,  1.8674e-02,  1.5099e-02,  1.6497e-02,\n",
       "         -9.4564e-03,  1.6015e-02,  2.1602e-02, -8.5707e-03,  9.1130e-03,\n",
       "         -1.0779e-02, -1.9404e-02,  8.5154e-03, -1.9540e-02,  6.6968e-03,\n",
       "          2.1086e-02,  5.2848e-03,  7.8827e-04, -1.1774e-02, -1.7551e-03,\n",
       "          9.2989e-03,  1.6823e-02,  1.6158e-02,  1.2335e-02, -1.3442e-02,\n",
       "         -1.3348e-03,  6.0704e-03, -1.3871e-03, -7.4857e-03, -9.3272e-03,\n",
       "         -1.0951e-02, -5.5047e-03, -1.2809e-02,  1.0320e-02,  1.7823e-02,\n",
       "         -2.0192e-02, -1.7796e-02,  3.3609e-03,  2.0084e-02, -8.8934e-03,\n",
       "         -7.2329e-03, -2.1335e-02,  4.1730e-03,  6.8963e-03,  1.4205e-02,\n",
       "          1.0061e-02,  4.9865e-04,  1.0611e-02, -1.8768e-02,  1.8770e-02,\n",
       "          1.5932e-02,  1.9505e-02,  1.0877e-02,  4.4507e-03, -3.2310e-03,\n",
       "          6.8586e-03, -8.1254e-03,  5.2978e-03,  1.9825e-04,  1.2337e-02,\n",
       "          1.3679e-02, -8.3655e-03,  8.5532e-04,  5.3961e-03, -1.8678e-02,\n",
       "          1.3087e-02,  1.0705e-02, -5.8952e-03, -1.2096e-02, -1.5722e-03,\n",
       "         -1.5205e-02,  2.0013e-02, -1.5222e-02,  2.0398e-02,  8.2853e-03,\n",
       "          7.2382e-03,  1.4898e-02, -1.0941e-02,  1.1828e-02, -1.3725e-02,\n",
       "          2.1761e-02,  1.3352e-02,  1.8337e-02,  1.3949e-02,  1.0651e-02,\n",
       "         -1.7795e-02,  2.0038e-02, -9.8831e-05, -4.3575e-03, -8.7552e-03,\n",
       "         -2.1624e-02,  2.2790e-02, -1.6070e-02, -1.7776e-02,  1.2720e-02,\n",
       "          1.0452e-02, -1.3892e-03, -1.0481e-02,  5.2442e-03,  1.7046e-02,\n",
       "         -1.8770e-03, -1.7876e-02, -1.3574e-02,  2.4357e-03, -2.1137e-02,\n",
       "          9.6019e-03, -2.6700e-03, -1.0574e-02,  2.2674e-02, -4.7669e-03,\n",
       "         -1.5869e-02, -1.9897e-02, -2.1596e-02,  1.9875e-02, -1.2951e-02,\n",
       "         -1.3629e-02,  1.5265e-02, -2.1491e-02, -1.3618e-02, -1.4255e-03,\n",
       "          2.0180e-02,  1.5269e-02, -1.2560e-02, -3.5600e-03,  1.9830e-02,\n",
       "          6.8164e-03,  1.3413e-02, -1.6426e-02,  2.0185e-02,  1.3792e-02,\n",
       "          5.8258e-03, -3.9086e-04, -1.5064e-02, -1.1683e-02, -1.6755e-02,\n",
       "          1.8739e-02,  3.6108e-03,  1.1256e-02,  5.1078e-03, -9.9688e-03,\n",
       "         -2.2495e-02, -1.3390e-03,  1.6093e-02,  1.2995e-02,  4.9839e-03,\n",
       "         -6.9997e-03, -1.8876e-02, -1.8358e-02, -1.0376e-02, -1.0218e-02,\n",
       "          7.6358e-03, -7.2552e-03,  6.2911e-03,  1.3078e-02,  1.8588e-02,\n",
       "          1.5860e-02,  1.5135e-02, -2.0424e-02,  7.3286e-03, -3.6474e-04,\n",
       "          6.0303e-03, -9.9539e-03,  2.0393e-02,  8.8970e-03,  1.8353e-02,\n",
       "         -4.3666e-03,  8.3458e-03, -1.9094e-02, -1.5566e-02, -1.4050e-02,\n",
       "          2.0925e-02, -5.6508e-03,  1.5042e-03, -2.8157e-03, -1.2956e-02,\n",
       "          1.5759e-02, -1.2731e-02,  4.5410e-07,  1.4047e-02,  2.0646e-02,\n",
       "          2.0627e-02, -1.3145e-02,  1.9526e-02,  7.3162e-04,  1.3960e-02,\n",
       "          1.8110e-02, -1.7584e-02,  2.0770e-02,  1.1402e-02, -1.7738e-02,\n",
       "         -1.6558e-02,  7.1139e-03,  1.6522e-02,  7.1842e-03,  2.1478e-02,\n",
       "          1.6118e-02, -1.8708e-02, -1.7028e-02,  1.9894e-02, -1.0628e-02,\n",
       "         -1.3932e-02, -1.5239e-02, -5.5280e-03,  1.9522e-02,  9.4079e-04,\n",
       "         -1.7482e-02, -1.7317e-02, -8.4088e-03,  2.1448e-02, -8.2433e-03,\n",
       "          1.9434e-02, -1.2335e-02, -3.8325e-04,  1.1253e-02, -2.1491e-02,\n",
       "          8.4838e-03, -1.0104e-02,  2.0457e-02,  1.4453e-02, -1.4154e-02,\n",
       "          7.3616e-04,  9.5541e-03,  8.8188e-04,  9.8065e-03, -1.8578e-02,\n",
       "          1.3764e-02, -2.5577e-03,  2.9948e-03,  2.0304e-02, -1.2320e-02,\n",
       "          1.1493e-02, -2.2783e-04,  8.5140e-03,  4.5577e-03,  1.8351e-03,\n",
       "          7.6970e-03, -2.1303e-02, -2.1597e-02,  1.8703e-02,  1.6385e-02,\n",
       "          1.3855e-02, -1.9224e-02,  9.4727e-03, -1.7841e-02, -4.4763e-03,\n",
       "         -6.5182e-03,  1.8200e-02, -1.2724e-02,  1.7060e-02, -1.4665e-02,\n",
       "         -1.0093e-02,  5.4241e-03, -5.3003e-03, -3.2801e-03, -1.4646e-02,\n",
       "         -2.0228e-02,  6.0595e-03,  2.0824e-02, -1.3452e-02, -1.3438e-02,\n",
       "          3.0826e-03,  5.5390e-03,  1.3320e-02, -1.7075e-03, -8.5058e-03,\n",
       "         -2.1445e-03, -2.6991e-03, -7.4519e-03, -3.4611e-03, -1.2906e-02,\n",
       "          1.5131e-02, -1.3186e-02, -2.0436e-02, -4.2793e-03, -4.8633e-03,\n",
       "         -1.9869e-03,  1.9276e-02,  2.0409e-02, -8.9095e-03,  3.6874e-03,\n",
       "         -7.7828e-03, -9.6546e-03,  2.1192e-02, -3.5653e-03, -2.0370e-02,\n",
       "          2.0688e-02,  1.8759e-02, -8.1480e-03, -1.6241e-02, -9.1520e-03,\n",
       "          9.4979e-03, -2.0288e-02, -3.7271e-03,  1.8383e-02, -1.6374e-02,\n",
       "          1.1351e-02,  8.3199e-03, -5.5591e-03, -4.6395e-03, -1.4410e-02,\n",
       "          1.7444e-02,  1.1684e-02, -1.8429e-02,  4.1647e-03, -1.5747e-02,\n",
       "         -2.6883e-03, -2.0400e-02, -2.1566e-02, -1.7743e-02,  1.5604e-02,\n",
       "          8.0606e-03, -9.1783e-03, -1.1087e-02,  1.5422e-02, -7.7380e-03,\n",
       "         -3.7987e-03, -8.1059e-03, -1.0424e-02,  3.8563e-06, -1.2134e-03,\n",
       "         -1.4861e-02,  1.8548e-02,  2.7565e-03, -1.0748e-02,  4.5364e-03,\n",
       "          1.5265e-02, -1.2278e-02,  4.8126e-03,  1.3118e-02,  1.7168e-02,\n",
       "         -3.7564e-03, -1.0448e-02, -1.6462e-02,  1.5093e-02, -1.2057e-02,\n",
       "         -8.7547e-04, -1.0703e-02,  9.4399e-03, -9.3838e-04, -1.6257e-02,\n",
       "         -3.3731e-03,  1.5448e-02, -1.0709e-02, -1.4142e-03,  4.5573e-03,\n",
       "          1.0809e-02,  1.3271e-02, -1.7146e-02, -8.0341e-03,  8.5817e-04,\n",
       "         -1.5120e-02, -1.8251e-02,  9.4735e-03,  3.5809e-03,  6.8325e-03,\n",
       "          3.9824e-03, -7.8491e-03, -1.6773e-03, -1.6588e-02,  2.1899e-02,\n",
       "          2.2049e-03,  6.4137e-03, -8.1894e-03,  6.8667e-03,  1.6779e-02,\n",
       "         -8.0088e-03, -1.7321e-02, -6.9101e-04,  1.7551e-02, -1.3678e-02,\n",
       "          1.6839e-02,  1.1033e-02,  3.3053e-03, -1.8696e-02,  2.1732e-02,\n",
       "          1.1342e-02, -1.3251e-03,  1.0773e-02,  3.9624e-03,  1.2543e-02,\n",
       "         -5.4297e-05, -1.1537e-02, -1.1690e-02, -7.2247e-03, -3.4906e-04,\n",
       "         -7.2068e-03,  4.1726e-04,  1.8014e-03,  7.9730e-03, -3.5983e-03,\n",
       "         -2.8346e-03, -6.1673e-03,  1.8076e-02,  6.0355e-03, -5.8081e-03,\n",
       "         -1.0873e-02, -2.2194e-02,  1.3805e-02,  1.1292e-02,  1.6456e-02,\n",
       "          1.3140e-02, -1.4260e-02, -1.0431e-02, -9.7422e-03,  1.5776e-02,\n",
       "         -2.2073e-02, -2.0101e-03, -9.3207e-03, -1.9710e-02,  1.7316e-02,\n",
       "         -1.2434e-02, -1.0360e-02, -2.1452e-02,  7.2855e-03, -3.3532e-03,\n",
       "         -9.6942e-03,  6.7468e-03, -1.7099e-02,  6.8226e-03,  1.5377e-02,\n",
       "         -1.8397e-03,  6.8518e-03, -2.1849e-02,  3.1097e-04, -6.4911e-03,\n",
       "         -5.4105e-03,  6.6961e-03,  7.6637e-03, -2.3371e-03,  5.0593e-03,\n",
       "          5.6786e-03, -1.7176e-02,  1.2140e-02, -4.6006e-03, -1.6800e-02,\n",
       "          2.6346e-03,  9.7755e-03], device='cuda:0'),\n",
       " tensor([ 0.0937, -0.0801,  0.0291, -0.0724, -0.0052, -0.0984, -0.0662,  0.1231,\n",
       "          0.0594,  0.0977,  0.0789, -0.0045,  0.0888,  0.1014, -0.0911, -0.0931,\n",
       "         -0.1023, -0.0005,  0.0688,  0.0924,  0.0415, -0.1232,  0.0348, -0.0276,\n",
       "         -0.1147,  0.1230, -0.0871, -0.1019, -0.0902,  0.0189, -0.0470, -0.1136,\n",
       "         -0.0019, -0.0736, -0.0807,  0.0857,  0.0655, -0.0602, -0.0542, -0.1241,\n",
       "          0.0190, -0.1077, -0.1091,  0.0442, -0.0973, -0.1117,  0.1188, -0.0251,\n",
       "         -0.0816,  0.0319,  0.0728,  0.0244, -0.0026, -0.0764,  0.0556, -0.0058,\n",
       "          0.0960,  0.0032,  0.0878, -0.0595, -0.0702, -0.0192,  0.1184,  0.1196],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1228,  0.1082, -0.0113, -0.0124, -0.0535, -0.1180,  0.0237,  0.1242,\n",
       "         -0.0021, -0.0573, -0.1057,  0.1223,  0.1232, -0.0406,  0.0581,  0.1192,\n",
       "          0.0991,  0.1004,  0.0095, -0.0799, -0.0913, -0.0548, -0.0764,  0.0293,\n",
       "         -0.0775,  0.0802, -0.0651,  0.0274, -0.0229, -0.0173, -0.0650,  0.0494,\n",
       "         -0.1030,  0.0259,  0.0740,  0.0606,  0.0388, -0.0895, -0.0040,  0.0401,\n",
       "          0.0904, -0.0896,  0.0416,  0.0695, -0.1092,  0.0651, -0.1174,  0.0242,\n",
       "         -0.0771,  0.0420, -0.1092,  0.0616, -0.0317, -0.0933, -0.0597, -0.0055,\n",
       "          0.1067, -0.0183,  0.1095, -0.0485, -0.1018,  0.1218, -0.0761, -0.1200],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0153, -0.0603, -0.0017,  0.0617,  0.0680,  0.0407, -0.0519, -0.0409,\n",
       "          0.0844, -0.1126, -0.0564,  0.0428,  0.0062,  0.0575,  0.0607, -0.0034,\n",
       "         -0.0629, -0.0812,  0.0407, -0.0954,  0.0440,  0.0976, -0.0019,  0.1184,\n",
       "         -0.0859, -0.0876,  0.0489, -0.0394, -0.0293,  0.0099,  0.0830,  0.0082,\n",
       "         -0.0920, -0.0750, -0.1183, -0.0978, -0.0839,  0.0393, -0.1207, -0.0462,\n",
       "          0.0256,  0.0169, -0.0829, -0.1211, -0.0012, -0.1229,  0.0452, -0.0028,\n",
       "          0.0074, -0.1156,  0.1113, -0.0164, -0.0759, -0.0727,  0.0191, -0.0674,\n",
       "         -0.0249,  0.0648, -0.0939,  0.0346,  0.0627, -0.0067,  0.0923,  0.0426],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0435,  0.0614,  0.0175,  0.0657, -0.1054,  0.1172, -0.1160,  0.0809,\n",
       "         -0.0694, -0.1200,  0.1195, -0.0545,  0.0651, -0.0673,  0.0372, -0.0351,\n",
       "         -0.1148, -0.0573, -0.0169,  0.0027, -0.0104, -0.0514, -0.0721, -0.1044,\n",
       "         -0.0120,  0.1087,  0.0342, -0.0779, -0.0247, -0.0919, -0.1204, -0.0584,\n",
       "          0.0371, -0.0607, -0.0419,  0.0133,  0.0463,  0.0847, -0.0993,  0.0086,\n",
       "          0.0276, -0.0245,  0.0862, -0.0355,  0.0816, -0.0238,  0.0655,  0.1093,\n",
       "         -0.0702,  0.1090, -0.0707,  0.0606, -0.0840,  0.0462, -0.0088, -0.0850,\n",
       "          0.0068, -0.0157, -0.0278, -0.0638,  0.0103,  0.0713, -0.0506,  0.0534],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0730,  0.0455, -0.0262,  0.0082,  0.0787, -0.1198, -0.1150, -0.0335,\n",
       "          0.1145, -0.0677, -0.0126, -0.1209,  0.0445,  0.1145, -0.0639, -0.1053,\n",
       "         -0.0675, -0.0109, -0.0305,  0.0416, -0.0915,  0.0458, -0.1159,  0.1078,\n",
       "         -0.1067, -0.1246, -0.0820,  0.0745, -0.1050, -0.0979, -0.0656,  0.0672,\n",
       "         -0.0576, -0.0377, -0.1204, -0.1036,  0.0813,  0.0061, -0.0402, -0.0914,\n",
       "          0.0977,  0.0014, -0.0585, -0.1025,  0.0764, -0.0779, -0.0399,  0.0977,\n",
       "         -0.0142, -0.0663, -0.0167,  0.0531,  0.0397, -0.0236, -0.0807, -0.0941,\n",
       "          0.1217,  0.0781,  0.0791, -0.1204, -0.0964, -0.0290,  0.1155, -0.0701],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0700, -0.0908, -0.0183,  0.0212,  0.0492,  0.0234,  0.0887, -0.0189,\n",
       "         -0.0226,  0.0120, -0.1044, -0.0734,  0.0213, -0.0449, -0.0810, -0.0262,\n",
       "         -0.0775,  0.0961, -0.0959, -0.0489, -0.0192, -0.0176, -0.0537, -0.0422,\n",
       "         -0.0807,  0.0570, -0.0210,  0.0616,  0.0983, -0.0246, -0.0517,  0.0264,\n",
       "         -0.1249,  0.0735,  0.0400,  0.0145, -0.0361,  0.0612,  0.0327, -0.0228,\n",
       "         -0.1008, -0.0618, -0.1034, -0.0205, -0.1198, -0.0153, -0.1225, -0.1022,\n",
       "          0.0371, -0.1101,  0.0874,  0.0164, -0.0544, -0.1194, -0.0176, -0.0042,\n",
       "          0.1142,  0.0350, -0.1162, -0.0314,  0.0219, -0.0190, -0.0234, -0.0906],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0039, -0.0201, -0.1045, -0.0199, -0.0115, -0.1043, -0.0102, -0.0702,\n",
       "         -0.1164, -0.0287, -0.1031,  0.0814,  0.0493,  0.0447, -0.0634, -0.0125,\n",
       "          0.0910, -0.0326,  0.0328,  0.0363, -0.0465,  0.0411,  0.0110, -0.1223,\n",
       "         -0.0995, -0.0914,  0.0894, -0.0260, -0.1175,  0.0841,  0.0370,  0.0180,\n",
       "         -0.0687, -0.0433,  0.1103,  0.0216,  0.0451, -0.0500, -0.1211, -0.0185,\n",
       "          0.0765, -0.0933,  0.0163, -0.0065,  0.1151,  0.0140,  0.0921,  0.1131,\n",
       "          0.0427, -0.0251, -0.0084,  0.0006, -0.0308,  0.0744,  0.0580, -0.0740,\n",
       "         -0.0433, -0.0716,  0.0509,  0.1128, -0.0359,  0.0766,  0.0067, -0.1236],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0819,  0.0817, -0.0257, -0.0586,  0.0829,  0.0063, -0.0135, -0.0368,\n",
       "         -0.0021,  0.0968, -0.0063, -0.0927, -0.0933, -0.0463,  0.0249,  0.0424,\n",
       "         -0.0998,  0.0021, -0.0346,  0.0612, -0.0938,  0.0858, -0.0358,  0.1102,\n",
       "          0.0648,  0.0638,  0.0002,  0.0769,  0.0766, -0.1058,  0.1239, -0.0716,\n",
       "          0.0477,  0.1035, -0.0958,  0.0603, -0.1002,  0.0032,  0.0899, -0.0834,\n",
       "         -0.0443,  0.0553,  0.0517, -0.0932,  0.0096,  0.0793, -0.1004, -0.1241,\n",
       "          0.0983, -0.0869,  0.0932, -0.1220, -0.0189, -0.1080,  0.0957, -0.1216,\n",
       "         -0.0082, -0.0407, -0.1073,  0.0738, -0.0047,  0.0535, -0.0246, -0.0215],\n",
       "        device='cuda:0'),\n",
       " tensor([-6.5111e-02,  1.1137e-01, -1.1653e-01,  2.0677e-02,  5.0932e-02,\n",
       "          7.5048e-02, -1.0442e-01, -4.3693e-02, -7.4372e-05,  6.9625e-02,\n",
       "          8.6520e-02, -3.7234e-02,  1.2367e-01, -2.9938e-02, -3.3645e-02,\n",
       "         -3.8603e-02, -1.0198e-01, -3.7700e-02, -4.3075e-02,  1.1008e-01,\n",
       "          3.6041e-02, -5.9833e-02,  5.6907e-02, -1.0134e-01, -5.0594e-02,\n",
       "          4.2945e-02, -3.6436e-02,  6.6051e-02, -1.9462e-02,  4.7156e-02,\n",
       "          9.0807e-02,  8.8097e-02,  2.4438e-03, -4.5501e-02, -3.7286e-02,\n",
       "         -1.1615e-01, -1.2890e-02,  7.0736e-02,  6.5323e-02,  1.7815e-02,\n",
       "         -3.4972e-02, -1.9368e-02, -6.4442e-03, -1.5115e-02,  6.7933e-02,\n",
       "          4.3808e-02,  7.8665e-02,  8.1203e-02,  5.7503e-02,  3.2282e-02,\n",
       "          7.3231e-02, -8.2483e-02,  2.2200e-03, -1.2388e-01, -7.7492e-04,\n",
       "         -3.9283e-02,  3.0615e-02, -5.5727e-02,  1.1533e-01,  3.6108e-03,\n",
       "         -6.5125e-02, -8.2772e-02,  3.2111e-02, -1.1361e-01], device='cuda:0'),\n",
       " tensor([-0.0416, -0.0752,  0.0002,  0.0600, -0.0176,  0.0372,  0.0405, -0.0124,\n",
       "          0.0540,  0.0903, -0.0328, -0.0239, -0.0381, -0.0645,  0.0969, -0.0725,\n",
       "         -0.0158,  0.0985,  0.0961,  0.0633,  0.0672, -0.0485, -0.0363, -0.1216,\n",
       "         -0.1137, -0.0658,  0.0547, -0.1188,  0.0429, -0.0106, -0.0043,  0.0738,\n",
       "         -0.0048,  0.0703,  0.0010, -0.0603,  0.1063,  0.0512, -0.0263, -0.0821,\n",
       "          0.1011, -0.0945,  0.0434,  0.0734, -0.0563,  0.0749, -0.0063, -0.0911,\n",
       "          0.0744,  0.0834,  0.1062,  0.0966, -0.0765, -0.0814, -0.0776,  0.0768,\n",
       "         -0.0295,  0.0760,  0.1028, -0.1244,  0.0947, -0.0473, -0.0997,  0.0836],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0100, -0.0222,  0.0063, -0.0658, -0.0504,  0.1088,  0.1077,  0.1208,\n",
       "          0.0789, -0.1015,  0.0576, -0.0720,  0.1192,  0.1115, -0.0827,  0.0241,\n",
       "          0.0956,  0.0816,  0.1035, -0.0294,  0.0442,  0.0253,  0.0264, -0.0408,\n",
       "         -0.1142,  0.1094,  0.0654,  0.0907,  0.0506,  0.0222,  0.0801, -0.0105,\n",
       "          0.0455,  0.0922, -0.0760, -0.0859,  0.0680,  0.0166,  0.0241,  0.1117,\n",
       "          0.0900,  0.0316, -0.0595,  0.0735,  0.0896, -0.0283, -0.1132,  0.0705,\n",
       "          0.1112,  0.0768, -0.0359,  0.0492,  0.0706, -0.0395, -0.0772, -0.0644,\n",
       "         -0.0734,  0.1192, -0.0921, -0.0446,  0.0382, -0.0080,  0.0807,  0.0105],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0405,  0.0681, -0.0402,  0.0491, -0.0143,  0.0264, -0.0267,  0.1172,\n",
       "          0.0325,  0.0054,  0.0150,  0.0711,  0.0659,  0.0857,  0.0355, -0.0111,\n",
       "          0.0140, -0.0916,  0.0100, -0.0427,  0.0148,  0.0555,  0.0195, -0.1042,\n",
       "         -0.0541,  0.0255, -0.1112,  0.1029,  0.0648,  0.0779,  0.0688,  0.1121,\n",
       "         -0.0098, -0.0342,  0.0502,  0.0020, -0.0435, -0.0409,  0.0222, -0.1040,\n",
       "          0.0959,  0.0525, -0.0650, -0.0343,  0.0363, -0.0498, -0.0583, -0.0120,\n",
       "          0.1196,  0.0205,  0.0611, -0.0082,  0.0439, -0.1096, -0.0288, -0.0092,\n",
       "         -0.0278,  0.1127, -0.1202,  0.0526,  0.1083,  0.0123,  0.1059, -0.1056],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0925, -0.0147,  0.0148, -0.0790,  0.0196, -0.0502, -0.0222, -0.0119,\n",
       "         -0.0595, -0.1094,  0.0695, -0.0530, -0.0762, -0.0775, -0.0792,  0.1012,\n",
       "          0.0210,  0.0545, -0.0139, -0.0354,  0.0980, -0.0709,  0.1130,  0.0534,\n",
       "         -0.0794, -0.0481, -0.0229, -0.0761,  0.0858,  0.1151, -0.1034, -0.1188,\n",
       "          0.0810, -0.0893,  0.1167, -0.1214,  0.0203, -0.0511,  0.0509,  0.1128,\n",
       "          0.0932, -0.0140,  0.1011, -0.0589, -0.0700,  0.0556,  0.0172, -0.0244,\n",
       "          0.0455,  0.0169,  0.0175,  0.0828, -0.0620, -0.0282,  0.0084, -0.0299,\n",
       "         -0.1068, -0.0456,  0.0447,  0.0443,  0.0777,  0.1100, -0.0744,  0.1126],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0079,  0.0445, -0.0729,  0.0632,  0.0010,  0.0220, -0.0313, -0.0777,\n",
       "         -0.1026,  0.0108,  0.0922,  0.0984,  0.0440,  0.0040, -0.0485,  0.0869,\n",
       "         -0.1021,  0.0779,  0.0302,  0.0102,  0.0309,  0.1053,  0.0525, -0.0172,\n",
       "         -0.1141,  0.0385, -0.1108, -0.0421, -0.0935, -0.0634,  0.0578, -0.0985,\n",
       "         -0.0660,  0.0767, -0.0033,  0.0729,  0.1234,  0.0273, -0.0645,  0.0564,\n",
       "          0.0478,  0.0842, -0.1246,  0.1088,  0.0787, -0.0029, -0.0397,  0.0853,\n",
       "          0.1230, -0.0148,  0.0287,  0.1056,  0.1114, -0.0872,  0.0137,  0.0902,\n",
       "          0.0142, -0.1060, -0.1102, -0.0397, -0.0133, -0.0065,  0.0924, -0.0315],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0102,  0.0146,  0.0957,  0.0652,  0.1225, -0.0445,  0.1038, -0.0442,\n",
       "          0.0030,  0.0414, -0.1141,  0.0515, -0.0046,  0.0858, -0.0446,  0.0438,\n",
       "          0.0244,  0.0621, -0.0960, -0.1049, -0.0167, -0.0515, -0.0106, -0.0372,\n",
       "         -0.0282,  0.0311, -0.1235,  0.0106, -0.1140, -0.0105, -0.0065, -0.1072,\n",
       "         -0.0848,  0.0247,  0.0469, -0.0593, -0.0735, -0.0325, -0.0422, -0.0621,\n",
       "          0.0967,  0.0138,  0.0939,  0.1127,  0.0669,  0.0372,  0.0142, -0.0558,\n",
       "          0.0323,  0.0064, -0.0087,  0.0010, -0.0456, -0.0113,  0.0009, -0.0291,\n",
       "         -0.0809,  0.0458,  0.0460,  0.0410, -0.0551,  0.1028,  0.1171, -0.0174],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1240,  0.0748, -0.0595, -0.0580,  0.1155,  0.0388, -0.0721, -0.0632,\n",
       "         -0.1188,  0.0193,  0.0679,  0.0026,  0.1101,  0.1236,  0.1164, -0.1177,\n",
       "          0.0189, -0.0694, -0.0287,  0.0955, -0.1147,  0.0596,  0.0762, -0.0389,\n",
       "         -0.0482, -0.0382,  0.0658, -0.0214,  0.0525, -0.0080,  0.0452, -0.0428,\n",
       "          0.0907,  0.0218, -0.1218, -0.0705, -0.1173,  0.0497,  0.0432, -0.0151,\n",
       "         -0.0556,  0.0722, -0.1231,  0.0571, -0.0719,  0.0730,  0.0276,  0.1010,\n",
       "         -0.1060, -0.0764, -0.0757,  0.1019,  0.1090, -0.1216,  0.0164,  0.0846,\n",
       "         -0.0887, -0.0054,  0.0278, -0.1103,  0.0414,  0.0919, -0.0112,  0.0702],\n",
       "        device='cuda:0'),\n",
       " tensor([ 2.3933e-02, -8.4702e-02, -1.0231e-01,  9.4477e-02,  1.2174e-01,\n",
       "          3.5154e-02,  1.0371e-01,  1.1588e-01,  5.8243e-02, -7.6764e-02,\n",
       "          5.1893e-02, -3.6383e-02, -1.1623e-01,  5.4290e-02,  1.2177e-01,\n",
       "          1.8309e-02, -5.4397e-03, -7.0723e-02,  3.2741e-02,  1.0489e-02,\n",
       "          7.8677e-02,  8.7526e-02, -1.1479e-01,  1.0871e-01, -3.2198e-02,\n",
       "         -8.4458e-03,  5.9708e-02, -1.7788e-02, -3.0468e-02, -4.7693e-02,\n",
       "         -6.6695e-02, -9.7315e-02,  1.1080e-02,  1.1981e-01, -1.1882e-01,\n",
       "          5.2236e-02,  8.7601e-02, -7.5635e-02, -8.2318e-02, -1.5044e-02,\n",
       "          4.3149e-02, -5.4685e-02, -7.1652e-02, -5.1186e-03,  3.6949e-02,\n",
       "          5.4139e-02, -1.0734e-01,  3.5289e-02, -6.2137e-02,  2.6057e-02,\n",
       "          9.3029e-05,  5.5069e-02, -4.9752e-03,  9.8240e-02,  2.5207e-02,\n",
       "          5.8232e-02,  7.4038e-02,  4.5762e-02,  4.1130e-02, -3.8290e-02,\n",
       "          6.7110e-02,  1.0821e-01, -1.0010e-01, -8.2215e-02], device='cuda:0'),\n",
       " tensor([ 0.0625, -0.1188,  0.0765, -0.0284, -0.1218, -0.0573,  0.1185, -0.0499,\n",
       "          0.0083,  0.0418,  0.1143, -0.1133,  0.0726,  0.0873,  0.0337, -0.0171,\n",
       "         -0.0499,  0.0998, -0.0323,  0.0235, -0.0021, -0.0388, -0.0651, -0.0527,\n",
       "         -0.0440,  0.0704, -0.0047,  0.1147,  0.0078,  0.0427,  0.0475, -0.0480,\n",
       "          0.0554,  0.0626, -0.0908, -0.0817, -0.0138, -0.0329, -0.0414,  0.0281,\n",
       "          0.1135, -0.0859, -0.1100,  0.0956,  0.0347, -0.0645, -0.0024,  0.1152,\n",
       "          0.0033, -0.0283,  0.0108, -0.0341, -0.0597,  0.1185, -0.0957, -0.0874,\n",
       "         -0.0014,  0.0294, -0.1067,  0.1167, -0.0898,  0.0356,  0.0339, -0.0639],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0839,  0.0465, -0.0901, -0.0319, -0.1229, -0.0440,  0.0297, -0.1223,\n",
       "          0.0366,  0.0431, -0.0562,  0.1174,  0.0798, -0.1019, -0.0720,  0.0242,\n",
       "         -0.0779, -0.0546,  0.0339, -0.1117,  0.0264, -0.0132, -0.1065,  0.0590,\n",
       "         -0.0913, -0.0580, -0.0969,  0.0976,  0.0181,  0.0148,  0.1162,  0.1095,\n",
       "         -0.0710, -0.0288, -0.0147,  0.0609,  0.0811, -0.0360,  0.0459, -0.0020,\n",
       "         -0.0993,  0.0258,  0.0610, -0.0819, -0.1198, -0.0434, -0.0603,  0.0850,\n",
       "          0.1082,  0.0124,  0.0953, -0.0385, -0.0404,  0.0604, -0.1186,  0.0790,\n",
       "          0.0430, -0.0908,  0.0530,  0.0221,  0.0954, -0.0329, -0.0199, -0.0242],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1151,  0.0268, -0.0920, -0.0427,  0.0410, -0.0317, -0.0864, -0.0586,\n",
       "          0.0221, -0.0787,  0.1024,  0.0209,  0.0836,  0.0355, -0.0913, -0.0128,\n",
       "          0.0908, -0.0526,  0.0735, -0.1222,  0.0158,  0.0473, -0.0089,  0.0270,\n",
       "         -0.0677,  0.0649, -0.0896, -0.0809,  0.0791,  0.0155, -0.0188, -0.0504,\n",
       "         -0.0752,  0.1191, -0.0043,  0.0511, -0.0290, -0.0993, -0.1075, -0.0258,\n",
       "          0.0812, -0.0050,  0.0929, -0.1006,  0.1096,  0.1077, -0.1054, -0.0868,\n",
       "          0.0640,  0.1158,  0.0593, -0.0589,  0.0073, -0.0210, -0.0921,  0.0641,\n",
       "         -0.0481,  0.0779, -0.0659,  0.0004,  0.0589,  0.1217,  0.0315,  0.0154],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0221,  0.1166,  0.1043, -0.0924,  0.0089, -0.0188,  0.1088,  0.0598,\n",
       "          0.1068,  0.0967,  0.0312,  0.0951, -0.1165, -0.1126,  0.0354, -0.1020,\n",
       "         -0.0166,  0.1124,  0.0869, -0.0141,  0.0945, -0.0472,  0.0051,  0.1033,\n",
       "         -0.0627,  0.1198, -0.0426, -0.0759,  0.0459, -0.0477,  0.1058,  0.0784,\n",
       "         -0.0611,  0.0039,  0.0062,  0.0343,  0.0828,  0.0779, -0.0105, -0.0033,\n",
       "          0.0849,  0.0576,  0.0821,  0.1124, -0.0051, -0.0286,  0.0737, -0.0007,\n",
       "         -0.0481,  0.0148,  0.0726, -0.0535,  0.1207,  0.0297,  0.0657,  0.0149,\n",
       "          0.0930,  0.0807,  0.0032,  0.0726, -0.0561,  0.0938, -0.0224, -0.0952],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1132,  0.0975,  0.0410,  0.0988, -0.0146, -0.0071,  0.0071,  0.0373,\n",
       "         -0.0531, -0.0376, -0.0740,  0.0794, -0.0194, -0.0321, -0.0287, -0.0949,\n",
       "         -0.0746, -0.0669, -0.1086, -0.0120,  0.0004,  0.0393,  0.0490,  0.0836,\n",
       "          0.1036, -0.0295,  0.0957,  0.0423, -0.0990, -0.0442, -0.1049,  0.0321,\n",
       "          0.1108,  0.0434, -0.0158,  0.1243, -0.0837,  0.1213,  0.0642, -0.0224,\n",
       "         -0.0096, -0.0561, -0.0544,  0.0156,  0.0750,  0.0218,  0.1232, -0.0915,\n",
       "          0.0727,  0.0197,  0.0266, -0.0655, -0.0627, -0.0220,  0.0743,  0.0460,\n",
       "         -0.1065, -0.1170,  0.0235, -0.0539,  0.0836, -0.0191,  0.0677,  0.0167],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0009, -0.0083,  0.0050,  0.0663, -0.0211, -0.0130,  0.0893,  0.0988,\n",
       "          0.0260,  0.0007,  0.0091,  0.0277,  0.0478,  0.0482, -0.0636, -0.0702,\n",
       "         -0.0407, -0.0211, -0.0974,  0.0357, -0.0309, -0.1222,  0.0696,  0.1139,\n",
       "          0.0421,  0.1198, -0.0246,  0.0999,  0.1015, -0.0661,  0.1053,  0.1168,\n",
       "         -0.0629, -0.0127, -0.0953, -0.0982, -0.0032, -0.0836, -0.0884, -0.0016,\n",
       "         -0.0341, -0.0386, -0.0583,  0.0842, -0.0454,  0.0937, -0.0466,  0.0160,\n",
       "         -0.1070, -0.0914, -0.0912, -0.0807, -0.0504, -0.0627,  0.0802,  0.0757,\n",
       "         -0.0287,  0.0772,  0.0154, -0.0153,  0.0586, -0.0771,  0.0154,  0.0530],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0296,  0.0309,  0.0906, -0.0791, -0.0188, -0.0563, -0.0466, -0.0382,\n",
       "         -0.0208,  0.0043,  0.0801,  0.0801,  0.0890, -0.1054,  0.0890,  0.0723,\n",
       "         -0.0196, -0.0565,  0.0795,  0.1170, -0.0005, -0.0428,  0.1091,  0.1019,\n",
       "          0.1092, -0.0010, -0.1027,  0.0719,  0.0785, -0.0016,  0.0737,  0.0541,\n",
       "         -0.0412, -0.0503,  0.0971, -0.0140,  0.0540,  0.0725,  0.0438,  0.0871,\n",
       "          0.0953, -0.1007, -0.0686,  0.0134,  0.0052,  0.0423,  0.0499,  0.0127,\n",
       "         -0.0710, -0.0622,  0.0553, -0.0188, -0.1101,  0.0579, -0.0341,  0.0719,\n",
       "         -0.0017,  0.0735,  0.0285, -0.0515,  0.1165, -0.0378, -0.0567,  0.0522],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0171,  0.0067,  0.0175,  ..., -0.0408, -0.0413,  0.0389],\n",
       "        device='cuda:0'),\n",
       " tensor([-6.6628e-03,  7.3048e-04, -5.7660e-03, -1.0389e-02, -1.6880e-02,\n",
       "          6.9787e-03, -6.5232e-03, -2.0424e-02,  1.1076e-02, -6.6668e-03,\n",
       "          1.7980e-02, -2.0969e-02,  4.0357e-03, -1.9349e-02,  7.6369e-03,\n",
       "          1.2302e-02,  5.0200e-03,  1.2006e-02,  1.1848e-02, -5.9651e-04,\n",
       "          1.1857e-02,  1.4660e-02, -1.7515e-02,  6.1028e-03, -1.7276e-02,\n",
       "         -1.7489e-02,  1.9108e-02, -1.9796e-02, -9.0046e-03,  3.7938e-03,\n",
       "          2.4590e-03,  4.4199e-03,  2.1801e-02,  6.1190e-03,  2.2616e-03,\n",
       "          2.1651e-02, -1.0787e-02, -1.6055e-02, -1.8893e-02, -8.7005e-03,\n",
       "          5.3441e-03,  1.1017e-02,  1.6260e-02,  1.7532e-02,  1.2104e-02,\n",
       "          3.8137e-03,  2.0486e-02,  1.7778e-02, -7.4211e-03,  4.9142e-03,\n",
       "          1.6986e-02, -5.1861e-03,  2.0279e-02, -2.0772e-03,  4.7998e-03,\n",
       "          1.8658e-02, -5.4760e-04, -5.1298e-03,  1.8482e-02,  1.3440e-02,\n",
       "         -6.5205e-03, -1.8423e-02, -7.4373e-03, -2.1557e-02,  1.9003e-02,\n",
       "          1.0770e-02,  4.2524e-03,  6.7834e-03, -2.1787e-02,  3.1544e-03,\n",
       "          7.7734e-04,  1.4408e-02,  9.7917e-03,  2.2513e-03,  1.5715e-02,\n",
       "          1.3901e-02,  1.3201e-02,  9.2618e-03,  4.8358e-03, -1.1540e-02,\n",
       "          9.7027e-03,  1.5497e-02,  2.2304e-02,  1.2855e-02,  1.0371e-02,\n",
       "         -6.8385e-03,  1.2149e-02, -2.1628e-02, -1.6592e-03, -1.8850e-02,\n",
       "         -1.6578e-02,  5.6776e-03, -1.9782e-02,  3.3141e-03, -1.6732e-02,\n",
       "         -2.6384e-03, -9.6082e-03,  1.1966e-02, -2.1024e-02, -1.5366e-02,\n",
       "         -2.0557e-02, -1.6150e-02, -7.1706e-03,  1.0649e-02,  2.8976e-03,\n",
       "          7.1623e-03,  7.6432e-03, -2.7093e-03,  4.3747e-03, -8.7468e-04,\n",
       "         -2.1050e-02, -1.5066e-02, -2.0715e-02, -1.6680e-02, -1.9801e-02,\n",
       "          2.4693e-03, -1.4694e-02,  2.1402e-02,  1.6888e-02,  5.7284e-04,\n",
       "          1.2390e-02,  1.9368e-02,  2.2142e-02, -2.1407e-02, -1.3699e-03,\n",
       "         -4.4419e-03, -2.0280e-02,  6.8083e-03, -1.1486e-02,  1.8316e-02,\n",
       "          1.2587e-02,  1.9169e-02,  1.6585e-02,  1.6228e-02,  2.1478e-02,\n",
       "          1.7410e-02, -6.9259e-03, -1.0198e-02, -1.2254e-03,  3.8474e-03,\n",
       "         -1.6663e-02, -1.1997e-02,  9.6026e-03,  5.4337e-03,  7.9104e-03,\n",
       "          1.5388e-02,  1.4222e-02,  1.5469e-02, -1.0060e-02,  1.3724e-02,\n",
       "         -1.7064e-02,  6.4530e-03, -2.1626e-02, -6.0258e-03, -1.1992e-02,\n",
       "          9.1073e-03,  2.0974e-02, -1.6828e-02,  4.2973e-03,  2.1339e-02,\n",
       "          1.6424e-02, -2.7499e-03, -3.9738e-03, -1.9379e-02,  1.4638e-02,\n",
       "          1.0682e-02,  3.1450e-03, -1.3144e-02, -1.7505e-02,  7.3689e-03,\n",
       "         -2.2427e-02,  2.2058e-02, -1.3924e-02,  7.4533e-03, -2.0381e-02,\n",
       "          1.6850e-02, -1.1940e-02,  1.1972e-02, -1.9669e-02,  5.2401e-04,\n",
       "          1.5868e-02, -9.9219e-03,  1.4530e-02,  1.6396e-02, -2.1582e-03,\n",
       "         -2.8484e-03, -1.6649e-02,  2.5064e-03, -6.4729e-03,  1.1813e-02,\n",
       "         -1.0619e-02, -9.3904e-03, -2.0790e-03, -3.3636e-03,  4.5224e-03,\n",
       "         -9.8863e-03,  3.6657e-03, -4.3980e-03, -5.7767e-03,  5.6000e-03,\n",
       "         -1.2792e-02, -1.0238e-02,  2.0874e-02,  1.7278e-02, -3.7358e-03,\n",
       "          1.6290e-02,  1.5902e-02, -4.3733e-03,  1.6302e-02,  9.7893e-06,\n",
       "          1.9254e-02,  1.5795e-03,  5.1129e-03,  6.9303e-03, -1.6339e-02,\n",
       "         -9.9231e-03, -1.0252e-02, -5.8964e-03, -5.2631e-03,  8.8760e-03,\n",
       "         -1.5729e-02,  1.1396e-02, -1.2187e-02, -1.5260e-03, -1.5104e-02,\n",
       "         -1.9719e-03, -3.1059e-03,  9.3356e-03,  1.6609e-02, -1.7802e-02,\n",
       "          1.8675e-03, -1.8189e-02,  1.7341e-02,  9.6334e-03, -1.9079e-02,\n",
       "         -2.0928e-03, -1.9557e-02,  1.8410e-02, -7.8487e-03, -1.4004e-02,\n",
       "          4.1292e-03,  1.2451e-02, -1.8694e-03, -1.4978e-02, -2.6579e-03,\n",
       "         -1.2037e-02, -3.4566e-03, -5.9397e-04,  1.8361e-02, -1.6569e-02,\n",
       "          9.1682e-03,  1.2595e-02, -1.7327e-02, -1.9046e-02, -2.5766e-03,\n",
       "         -8.9816e-03, -9.8008e-03, -1.1418e-02,  1.6567e-02,  2.9863e-03,\n",
       "         -7.9067e-03,  4.4889e-03, -1.0039e-02, -8.0623e-03, -9.5101e-03,\n",
       "         -1.4609e-02,  1.3278e-02,  4.4944e-03,  1.0751e-02,  1.7256e-02,\n",
       "          6.9159e-03, -2.0356e-02, -1.8655e-02, -7.6954e-03,  1.6080e-02,\n",
       "         -1.5635e-02, -1.2196e-02,  1.1803e-03,  1.2732e-04, -1.6707e-02,\n",
       "          2.1263e-02,  6.8584e-03, -1.5455e-02,  8.6644e-03, -2.4818e-03,\n",
       "         -1.6152e-02,  1.2561e-02,  1.8935e-02, -1.2397e-02,  1.4184e-03,\n",
       "          1.5445e-02, -4.3135e-03,  3.0376e-04, -2.1548e-02,  6.1110e-03,\n",
       "         -2.0630e-03,  1.5816e-02,  2.0895e-03,  1.8580e-02,  3.9236e-03,\n",
       "          9.0186e-03,  2.0396e-02,  1.8250e-02,  1.0109e-02, -1.0074e-02,\n",
       "          1.4018e-02,  1.9199e-02,  1.9686e-02, -2.0602e-02,  7.2849e-03,\n",
       "         -9.8537e-03, -1.2691e-02,  6.7128e-03,  2.0136e-02, -2.1372e-02,\n",
       "          1.8801e-02,  1.0500e-02, -1.2748e-02, -9.7876e-03,  1.8929e-02,\n",
       "          6.7616e-03,  6.9531e-03, -4.4978e-03, -1.2515e-02, -1.5391e-02,\n",
       "          1.7264e-02, -5.6085e-03, -9.4135e-03, -6.3800e-03, -1.3257e-02,\n",
       "         -1.6585e-02,  1.8784e-02, -6.2993e-04, -1.8357e-03,  1.6130e-02,\n",
       "          6.8719e-03,  3.8121e-03, -1.5950e-02,  1.6010e-02,  1.6076e-03,\n",
       "          2.2266e-02, -2.1305e-02, -7.4702e-04,  1.4898e-02,  1.8498e-02,\n",
       "         -4.4582e-03,  1.6119e-02,  1.3177e-02, -3.0635e-03, -1.9972e-02,\n",
       "         -1.1121e-02,  8.8389e-03,  1.2926e-02, -3.7993e-03,  4.2814e-03,\n",
       "         -1.3436e-02, -2.0392e-02, -1.6254e-02, -2.1725e-02, -1.4979e-02,\n",
       "          5.0961e-03,  6.6835e-03,  7.8584e-03,  2.2219e-02, -1.7877e-03,\n",
       "          1.0644e-02, -8.1845e-03,  1.2831e-02,  1.5596e-02,  1.7432e-02,\n",
       "          9.2156e-04,  1.3392e-02, -1.6039e-02,  1.4984e-02,  1.6981e-04,\n",
       "          8.2317e-03,  3.7983e-03,  1.1406e-02,  2.1249e-02,  7.9328e-03,\n",
       "          1.8967e-02, -4.7535e-03, -1.2624e-02,  1.6395e-02, -2.5325e-03,\n",
       "         -1.2569e-02,  5.0734e-03,  7.2349e-04, -8.7056e-03,  4.4270e-03,\n",
       "          1.0292e-02,  1.6763e-02,  9.5186e-03,  7.7950e-03,  8.8453e-04,\n",
       "         -1.1951e-02,  1.7294e-02, -1.0399e-02, -1.9606e-02,  1.3381e-02,\n",
       "         -2.0843e-02,  2.0287e-02, -1.9708e-02,  2.0788e-02,  1.2220e-02,\n",
       "          1.1741e-02,  1.7148e-02,  4.4136e-03, -8.8149e-03, -2.5168e-03,\n",
       "         -1.0709e-02,  1.2353e-02,  1.3556e-02,  7.0266e-03, -6.1438e-03,\n",
       "          4.7964e-03,  2.0469e-02, -8.9189e-04,  1.3315e-02,  1.0190e-02,\n",
       "         -1.1709e-02,  1.4254e-04, -5.8561e-03,  2.0354e-02,  1.4363e-02,\n",
       "          2.0531e-02, -1.0039e-03, -2.0172e-02, -2.7839e-04,  1.1311e-02,\n",
       "         -5.8850e-03, -3.4326e-03, -8.3885e-03,  5.4021e-03,  1.3282e-02,\n",
       "          4.1738e-04,  1.6369e-02,  2.1247e-02,  1.0552e-02, -8.9184e-03,\n",
       "         -1.8915e-02, -1.6124e-02, -5.6581e-03,  1.4761e-02,  1.4044e-02,\n",
       "         -1.3763e-02, -8.3014e-03, -2.1804e-02, -1.9281e-02, -9.8110e-03,\n",
       "          8.3896e-03, -7.1059e-03,  1.0083e-02,  2.2485e-02,  6.4132e-03,\n",
       "          1.4462e-03,  7.0105e-03, -1.9897e-02,  1.3497e-02, -8.1328e-03,\n",
       "          6.5143e-04, -2.1885e-02, -1.0853e-02, -6.1759e-03,  1.2016e-02,\n",
       "          1.2427e-02, -2.2415e-02, -8.4770e-03,  1.5435e-02, -6.8552e-03,\n",
       "          1.1263e-02, -1.8677e-02,  2.0356e-02,  1.3181e-02, -1.6039e-02,\n",
       "         -9.6272e-03, -1.4901e-02, -2.8943e-03,  2.0741e-02, -1.0486e-02,\n",
       "         -1.2978e-02, -2.0141e-03, -4.7777e-03,  7.9751e-03, -1.2839e-02,\n",
       "         -8.2865e-03, -9.4424e-03, -4.7139e-03,  5.9376e-03, -7.1535e-03,\n",
       "         -5.4200e-04, -1.1714e-02,  6.7577e-03,  2.1306e-03,  4.9434e-03,\n",
       "         -1.5883e-02,  2.0998e-02,  1.4561e-02, -7.7462e-03,  6.1813e-03,\n",
       "         -1.7269e-02,  1.5882e-03, -4.1997e-03,  2.5126e-03,  7.1989e-04,\n",
       "         -1.7696e-02,  2.1082e-02,  1.1991e-03, -1.4257e-02,  1.4092e-03,\n",
       "          2.2320e-03,  1.0020e-03], device='cuda:0'),\n",
       " tensor([ 0.0532, -0.0732, -0.0055,  0.0487,  0.0213, -0.0021, -0.0456,  0.0133,\n",
       "         -0.1099, -0.0867,  0.0564,  0.0493, -0.1205,  0.0122,  0.0383, -0.0930,\n",
       "          0.0373, -0.0858,  0.0882,  0.0868, -0.0740, -0.0531,  0.0271,  0.0034,\n",
       "         -0.0775, -0.0782,  0.0087,  0.0226, -0.0135,  0.1136,  0.0672,  0.1011,\n",
       "         -0.0827,  0.0124, -0.0379, -0.0408,  0.0229,  0.0737, -0.1229,  0.0834,\n",
       "          0.1017, -0.0864,  0.0742, -0.0710, -0.0474, -0.1141,  0.0642,  0.0630,\n",
       "          0.0229,  0.0397,  0.0572, -0.0541,  0.1124,  0.1185,  0.0610, -0.0596,\n",
       "          0.0113, -0.0646, -0.1166, -0.1128, -0.0821, -0.0939, -0.0653, -0.0631],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1028, -0.0763,  0.0364, -0.0149,  0.0376, -0.0607, -0.0549,  0.0727,\n",
       "          0.0977, -0.0102, -0.1000, -0.0897,  0.0224,  0.0016, -0.0784,  0.0476,\n",
       "         -0.1012, -0.0864, -0.0899, -0.0427,  0.0797, -0.0534, -0.0942, -0.0251,\n",
       "         -0.0260, -0.0454,  0.0668,  0.0831,  0.0140,  0.0168, -0.0352,  0.0974,\n",
       "         -0.0853, -0.0131, -0.0901,  0.1088,  0.0183,  0.0855,  0.0514,  0.0876,\n",
       "          0.0436,  0.0931,  0.1153, -0.0857, -0.0850, -0.0438, -0.0527,  0.0227,\n",
       "          0.0011, -0.0124,  0.0867,  0.0886,  0.0180,  0.0484,  0.1204, -0.1030,\n",
       "          0.0159, -0.0732,  0.0389,  0.0097, -0.0074,  0.0521, -0.0150,  0.1239],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0736, -0.0850,  0.0110,  0.0019,  0.0864, -0.0061, -0.0359,  0.0738,\n",
       "          0.0719, -0.0435, -0.0050, -0.1158,  0.0132,  0.0346, -0.1237, -0.0526,\n",
       "         -0.1126, -0.0919, -0.0945, -0.0396,  0.1042, -0.0997, -0.1208, -0.0745,\n",
       "          0.0398, -0.0327, -0.0365, -0.0325,  0.0211,  0.0245,  0.0893, -0.1192,\n",
       "         -0.1177,  0.0276, -0.0929,  0.1194,  0.0609, -0.0319, -0.0119, -0.0883,\n",
       "          0.1205, -0.0448,  0.1155,  0.0291, -0.0236, -0.0918,  0.0096, -0.1032,\n",
       "          0.0181, -0.1223, -0.0208, -0.0701,  0.1220,  0.1038, -0.0829, -0.0427,\n",
       "          0.0680,  0.1195, -0.0784, -0.0823,  0.1138,  0.0920, -0.0419,  0.1160],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0408, -0.0969,  0.0145,  0.0378,  0.1135,  0.1112,  0.0980,  0.0346,\n",
       "          0.0013, -0.0529, -0.1191,  0.0995,  0.1102, -0.0432, -0.0202, -0.0803,\n",
       "          0.0279,  0.1236, -0.1165,  0.0376, -0.1155, -0.1054,  0.0640,  0.0368,\n",
       "          0.0207, -0.1051, -0.0369, -0.0643, -0.0001,  0.0646,  0.0475, -0.1243,\n",
       "          0.0196,  0.0713,  0.0985, -0.0872, -0.0359, -0.1166,  0.0776,  0.1185,\n",
       "         -0.0415, -0.0525,  0.1146,  0.0269,  0.0414,  0.0497, -0.0540,  0.0358,\n",
       "         -0.0811,  0.0631, -0.1068,  0.0537,  0.0394, -0.0184,  0.0526,  0.0793,\n",
       "         -0.0697,  0.0669,  0.0359,  0.0926, -0.0347, -0.0296,  0.0649,  0.0144],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0814,  0.1017,  0.1219, -0.0985,  0.1097,  0.1058,  0.0699,  0.1172,\n",
       "          0.0172,  0.0049,  0.0549,  0.1088, -0.0210, -0.0359,  0.0643, -0.0952,\n",
       "         -0.0688,  0.0828, -0.0785,  0.0333,  0.0279,  0.0725, -0.0312,  0.0716,\n",
       "          0.0285, -0.0395,  0.0029,  0.0676, -0.0594, -0.0007, -0.0141,  0.0424,\n",
       "          0.0226, -0.1118, -0.0458, -0.0411, -0.0473,  0.0931, -0.1091,  0.0708,\n",
       "         -0.0458, -0.0513, -0.0694,  0.0595,  0.1045,  0.0169, -0.1121,  0.0612,\n",
       "         -0.0496, -0.0859,  0.0214, -0.0267,  0.0003, -0.0022, -0.0770,  0.0071,\n",
       "          0.0123, -0.1156, -0.1063, -0.0564,  0.0844, -0.0413, -0.0789,  0.1159],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0818,  0.0339, -0.0010, -0.0237,  0.0658, -0.0918, -0.0390, -0.1153,\n",
       "          0.1170,  0.1126,  0.0635,  0.0692,  0.0152,  0.0647, -0.0234, -0.1050,\n",
       "          0.0674, -0.1029,  0.0687,  0.0783,  0.0317,  0.0511, -0.0505, -0.0502,\n",
       "          0.0519, -0.1045,  0.0935,  0.0106,  0.0671,  0.0365,  0.0840, -0.0953,\n",
       "         -0.0416,  0.0008,  0.0806,  0.1054,  0.0283, -0.0553, -0.0699, -0.0021,\n",
       "          0.0623, -0.1076, -0.1035,  0.0396, -0.0692,  0.1214,  0.0881,  0.1235,\n",
       "          0.0146, -0.0719, -0.0878, -0.0805, -0.1162, -0.0315, -0.1107,  0.0263,\n",
       "         -0.1181, -0.0369,  0.0008,  0.1134, -0.1149,  0.0783,  0.0994, -0.0927],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0990,  0.1026, -0.0328,  0.0168, -0.0919, -0.0514,  0.0634,  0.1155,\n",
       "         -0.0449, -0.0578,  0.0771, -0.0558,  0.0230, -0.0182, -0.1232,  0.0925,\n",
       "          0.0056, -0.0053, -0.0566, -0.0054,  0.0909, -0.1094, -0.0275,  0.0198,\n",
       "         -0.0937, -0.0851,  0.1086,  0.0766,  0.0171, -0.0214,  0.0224, -0.1014,\n",
       "          0.0927, -0.0986,  0.1172,  0.0959,  0.0252, -0.0347, -0.1163, -0.0921,\n",
       "          0.0597,  0.1129,  0.0141, -0.0216, -0.1246,  0.0570, -0.0543,  0.0236,\n",
       "         -0.0894,  0.1131,  0.1196, -0.0474, -0.1073,  0.1218,  0.1201,  0.0607,\n",
       "          0.0741, -0.0960,  0.0738,  0.0585, -0.1082, -0.0075,  0.0699, -0.0479],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1088, -0.0238,  0.1224, -0.0060, -0.0948, -0.0716,  0.0354, -0.0725,\n",
       "          0.0950, -0.0215,  0.0682,  0.0158, -0.0940,  0.0047, -0.0092,  0.0706,\n",
       "          0.0595, -0.0585, -0.0194,  0.0809,  0.0660, -0.0448,  0.0297,  0.0686,\n",
       "          0.0333,  0.0732, -0.1229,  0.0555,  0.0525,  0.0486,  0.0762, -0.0465,\n",
       "          0.0700,  0.0965,  0.0553,  0.1010,  0.0557,  0.1155, -0.1004, -0.0830,\n",
       "         -0.0863, -0.1179, -0.0763,  0.0256, -0.0746, -0.0378,  0.1217,  0.0019,\n",
       "          0.0651, -0.0334,  0.0256,  0.1140,  0.0706,  0.0860,  0.1064, -0.1037,\n",
       "          0.1088,  0.0620, -0.1148, -0.0147,  0.0630,  0.1016, -0.0421,  0.0985],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1066,  0.0561,  0.1243,  0.0722,  0.1191,  0.0625,  0.0990,  0.1196,\n",
       "         -0.0827,  0.0880,  0.0513, -0.0687,  0.0497, -0.0006, -0.0857,  0.0249,\n",
       "         -0.1038,  0.0586,  0.0807, -0.0370, -0.0289,  0.0700, -0.0907,  0.0725,\n",
       "          0.0158,  0.0740, -0.0663,  0.0284, -0.0596,  0.0250,  0.0412,  0.0185,\n",
       "          0.1005,  0.0271,  0.0066,  0.1110, -0.0469, -0.0184, -0.0750,  0.1170,\n",
       "          0.0208,  0.0746,  0.0504,  0.0488,  0.1114, -0.1052, -0.1220, -0.0164,\n",
       "         -0.0591, -0.0213, -0.0114,  0.0795, -0.0421,  0.0300, -0.1048, -0.1232,\n",
       "          0.0822,  0.0514,  0.1242,  0.0403, -0.0389,  0.0578, -0.0137, -0.1240],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1073,  0.0144, -0.0311,  0.0488, -0.0580, -0.0924, -0.1244, -0.0040,\n",
       "         -0.1170, -0.0366, -0.0053, -0.1010,  0.1151, -0.1154,  0.0921,  0.0125,\n",
       "         -0.0728,  0.0529,  0.0884,  0.0180, -0.0105,  0.0020, -0.0502,  0.1119,\n",
       "         -0.0649,  0.0207, -0.0427, -0.0532,  0.0126,  0.0998,  0.0658,  0.0549,\n",
       "          0.0596,  0.0221,  0.0329,  0.0747,  0.0205,  0.1132, -0.0818, -0.1190,\n",
       "          0.1144,  0.0286, -0.0231,  0.0762,  0.0188,  0.0932, -0.0215, -0.1151,\n",
       "         -0.1000, -0.0267, -0.1179, -0.1129, -0.0328,  0.0372, -0.0817, -0.1126,\n",
       "         -0.0869,  0.0243,  0.0270,  0.0655,  0.0955, -0.0069, -0.1229,  0.0717],\n",
       "        device='cuda:0'),\n",
       " tensor([-9.9362e-02,  2.5005e-02, -1.1979e-02, -5.4523e-02,  1.1214e-02,\n",
       "         -1.1078e-01, -1.4452e-02, -2.1559e-02, -1.0518e-02, -6.7158e-02,\n",
       "          7.3047e-02,  1.8185e-02, -8.6488e-02, -3.1796e-02,  1.1300e-01,\n",
       "          8.7567e-02, -1.5687e-02,  6.6515e-02,  2.7978e-02,  2.8272e-02,\n",
       "          6.5926e-03, -3.1165e-02,  1.1823e-01, -1.2244e-01, -6.4886e-02,\n",
       "          5.2728e-02,  1.0363e-01, -2.3097e-04,  6.4412e-02, -3.4082e-03,\n",
       "         -1.0288e-01,  1.1584e-01, -7.8530e-02,  5.6842e-02,  5.0619e-05,\n",
       "          3.3827e-02,  7.5172e-02, -4.9954e-02,  1.0957e-01, -1.2312e-01,\n",
       "          4.6254e-02,  1.2180e-01, -1.6245e-02, -1.0093e-01,  8.2206e-02,\n",
       "          1.2972e-02, -1.1581e-01, -5.9956e-02, -1.1831e-01,  2.8843e-02,\n",
       "         -3.1527e-02, -1.1881e-01, -3.7788e-02, -6.3459e-02, -1.1357e-01,\n",
       "         -2.3332e-02,  6.7335e-02,  3.0626e-02,  9.7734e-02, -1.0808e-01,\n",
       "         -1.0631e-01,  8.4367e-04, -1.0175e-01,  2.3698e-02], device='cuda:0'),\n",
       " tensor([ 7.0167e-02,  8.1523e-02, -9.2583e-02, -1.1034e-01, -1.1698e-01,\n",
       "         -3.0508e-02,  7.4271e-02,  8.7974e-03, -4.9529e-02,  2.2723e-02,\n",
       "         -8.2562e-02,  6.1228e-02,  3.7860e-02, -7.6141e-03, -2.3001e-02,\n",
       "         -5.0545e-05, -8.8511e-02,  6.5592e-02, -3.0811e-02,  5.8769e-02,\n",
       "          6.6290e-02,  2.9609e-02, -1.4622e-02, -1.9840e-02, -2.2499e-03,\n",
       "          2.6810e-02, -7.3784e-02, -4.7568e-02,  7.3994e-02, -9.2896e-02,\n",
       "         -3.3567e-02,  6.7734e-02,  8.9054e-03,  1.9664e-02,  5.7005e-02,\n",
       "          4.4777e-03, -5.6563e-02, -9.3589e-02, -6.5402e-02,  1.0590e-01,\n",
       "          9.1544e-02, -8.1740e-02,  6.4920e-02, -4.4956e-02, -7.1414e-02,\n",
       "          1.2355e-01,  2.4915e-02, -1.9298e-02, -1.1381e-01,  8.1987e-03,\n",
       "         -8.3705e-02, -1.1974e-01,  3.0327e-02,  1.6125e-02, -5.5071e-02,\n",
       "         -1.9942e-02,  1.2087e-01,  2.2588e-02, -1.0681e-01, -7.3480e-03,\n",
       "          1.2134e-01, -7.1388e-02,  8.8854e-02, -9.2011e-02], device='cuda:0'),\n",
       " tensor([-0.0307, -0.0686, -0.0439,  0.0678, -0.0634,  0.0154, -0.0888, -0.0390,\n",
       "          0.1006, -0.0134,  0.1158,  0.0122,  0.0689,  0.0615, -0.0564, -0.0973,\n",
       "          0.0136,  0.0694, -0.0889,  0.0935, -0.0533,  0.0415,  0.0798, -0.0025,\n",
       "         -0.0748,  0.0449, -0.0414,  0.1123,  0.1114, -0.0797,  0.1244, -0.0078,\n",
       "          0.0142,  0.0366, -0.0800, -0.0320, -0.0242, -0.1122, -0.0370,  0.0469,\n",
       "          0.0947,  0.1125,  0.0504,  0.0178,  0.0490,  0.0480,  0.0069, -0.1110,\n",
       "          0.0508,  0.0700, -0.0727,  0.1110,  0.0388,  0.0943,  0.0685, -0.0115,\n",
       "         -0.0088,  0.0613, -0.0216,  0.1098,  0.0080,  0.0673, -0.0341,  0.0847],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0907, -0.0569,  0.0904,  0.0730,  0.0819, -0.0823,  0.0370,  0.0458,\n",
       "         -0.1096, -0.0158,  0.0724,  0.0420, -0.0702,  0.1168,  0.1071, -0.0194,\n",
       "          0.0280,  0.0216, -0.0886,  0.0477, -0.0498, -0.1111,  0.0727, -0.0894,\n",
       "         -0.1157,  0.1194, -0.0910,  0.0565, -0.0957,  0.0462,  0.0930,  0.1198,\n",
       "          0.0083,  0.0457,  0.1039,  0.0451, -0.0428,  0.0953,  0.0486,  0.0215,\n",
       "         -0.0016, -0.0833,  0.0806,  0.0397,  0.0625,  0.0367,  0.1010,  0.0578,\n",
       "          0.0047,  0.0993, -0.0960, -0.1037, -0.0223,  0.0019, -0.1075,  0.0299,\n",
       "         -0.0427,  0.0379, -0.0397,  0.1050, -0.0674,  0.0084,  0.0022,  0.0638],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1012,  0.0469,  0.0789, -0.1057, -0.1075, -0.0322,  0.0907, -0.0058,\n",
       "         -0.0423,  0.0827, -0.0276, -0.0670, -0.0099, -0.0174,  0.0647, -0.0871,\n",
       "         -0.0228,  0.0342, -0.0278, -0.1151, -0.0963, -0.0587,  0.0727, -0.0894,\n",
       "         -0.0208, -0.0149, -0.1042, -0.1245, -0.0304, -0.0974,  0.0521, -0.1079,\n",
       "         -0.0396, -0.0542,  0.0852, -0.0657,  0.1143, -0.1069, -0.0735,  0.0865,\n",
       "         -0.1063,  0.1146,  0.1236,  0.1162,  0.0387,  0.0267, -0.0307,  0.0570,\n",
       "         -0.1184,  0.0363,  0.0183, -0.0053, -0.0295,  0.0561, -0.0627,  0.0003,\n",
       "          0.0451, -0.0155,  0.1070, -0.1097,  0.0929, -0.0685,  0.0758, -0.0863],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0155,  0.1140,  0.0775, -0.0234,  0.0028, -0.1048, -0.0897,  0.0564,\n",
       "          0.1167, -0.0478,  0.0726, -0.0928,  0.1035,  0.1031,  0.0450, -0.0244,\n",
       "          0.0247,  0.0732, -0.0807, -0.0063,  0.0349, -0.0081, -0.0415,  0.0715,\n",
       "         -0.0501, -0.0741, -0.0863, -0.0663, -0.0251, -0.0118,  0.0921, -0.0535,\n",
       "          0.0816,  0.0810,  0.0898,  0.0928, -0.0305, -0.0469, -0.1218,  0.1117,\n",
       "          0.0739,  0.0285,  0.0997, -0.0560, -0.1005,  0.1195, -0.0774, -0.0083,\n",
       "          0.0893,  0.0468,  0.0295, -0.0732,  0.1205, -0.0461, -0.0071,  0.1194,\n",
       "         -0.0840, -0.0145, -0.1198,  0.0862,  0.0596,  0.0432,  0.0211, -0.1173],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0646,  0.1111, -0.0094,  0.0444, -0.0494,  0.0837,  0.0428,  0.0765,\n",
       "          0.1181, -0.0067,  0.0616,  0.0856, -0.0070,  0.0552,  0.1177, -0.1113,\n",
       "         -0.0771, -0.0388, -0.0873,  0.0237,  0.1242,  0.0004,  0.1094, -0.0343,\n",
       "          0.1079,  0.0872, -0.0815, -0.0794,  0.0882, -0.1199,  0.0325, -0.0885,\n",
       "          0.0239,  0.0558,  0.1051,  0.0345,  0.0651, -0.0163, -0.0389,  0.0529,\n",
       "         -0.0344, -0.1121, -0.0125, -0.0346, -0.1085, -0.1183,  0.0361, -0.1226,\n",
       "         -0.0553, -0.0321, -0.0286,  0.0737,  0.0508,  0.1012,  0.0410, -0.0835,\n",
       "          0.0664,  0.1123,  0.0851,  0.0856, -0.0709,  0.0772,  0.0314, -0.0430],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0339, -0.0749, -0.0996, -0.0910,  0.0665,  0.0230, -0.0667,  0.0069,\n",
       "         -0.1187,  0.0141,  0.0011, -0.0088,  0.0770, -0.0127,  0.0860, -0.0467,\n",
       "          0.0011, -0.0242,  0.1140,  0.1038, -0.1136, -0.1120, -0.0762, -0.1210,\n",
       "         -0.0681, -0.0695,  0.0616, -0.0617,  0.1138, -0.1194, -0.0014, -0.0977,\n",
       "         -0.1009,  0.0782,  0.0817, -0.0532, -0.0051, -0.0860, -0.0470, -0.0196,\n",
       "         -0.1032,  0.0689, -0.0745,  0.1001, -0.0607, -0.0747, -0.1246, -0.0479,\n",
       "         -0.0051, -0.1142,  0.0026, -0.0552, -0.0080,  0.1176, -0.1145, -0.1209,\n",
       "         -0.0336,  0.0558,  0.0387,  0.0710, -0.0628, -0.0906, -0.1039,  0.0140],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0510, -0.1132, -0.0420, -0.0255,  0.0190, -0.0709,  0.1100,  0.0995,\n",
       "          0.0625,  0.0118, -0.0116, -0.0602, -0.0954,  0.0065,  0.0057,  0.0961,\n",
       "         -0.0210,  0.0013, -0.0126, -0.0216,  0.0277, -0.0572,  0.1217,  0.1132,\n",
       "          0.0872,  0.0420,  0.0390,  0.0657,  0.0518,  0.0200, -0.0249,  0.0472,\n",
       "          0.1221, -0.0882, -0.0786, -0.1233, -0.0046, -0.0305, -0.0337,  0.0489,\n",
       "         -0.0333, -0.0965,  0.0847, -0.0441,  0.1173, -0.0534, -0.0063,  0.0533,\n",
       "          0.0394, -0.1173, -0.0196, -0.1064, -0.0072, -0.1172,  0.1121, -0.0080,\n",
       "          0.1023,  0.0257, -0.0262, -0.1191,  0.0757, -0.1164, -0.0880,  0.0521],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0398, -0.0628, -0.0494, -0.0804,  0.0496, -0.0541,  0.0712,  0.0708,\n",
       "          0.0501,  0.0087, -0.0999, -0.0603, -0.1092,  0.0711, -0.0239,  0.0556,\n",
       "         -0.0193, -0.1058,  0.0683,  0.0230,  0.0049,  0.0396, -0.0548,  0.0117,\n",
       "          0.0350,  0.0390, -0.0994,  0.0020,  0.0971,  0.0860, -0.1146,  0.1065,\n",
       "          0.0237, -0.0235, -0.0975,  0.0299, -0.0064,  0.0277,  0.0466, -0.0599,\n",
       "         -0.0449, -0.1057,  0.0863,  0.1003, -0.0150,  0.0879, -0.0066, -0.0126,\n",
       "         -0.0693,  0.0387,  0.0801, -0.0163,  0.1069, -0.1122,  0.0937,  0.0570,\n",
       "          0.0773, -0.1009,  0.0424, -0.0246,  0.0302, -0.1079, -0.0054,  0.0543],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1042, -0.0688, -0.1226, -0.0236,  0.0076,  0.0394, -0.0902,  0.0558,\n",
       "         -0.1083, -0.0743,  0.0870,  0.0412, -0.0291, -0.0804,  0.0615,  0.0305,\n",
       "         -0.0209, -0.0723,  0.0750,  0.1110,  0.1015,  0.0871,  0.0726, -0.0045,\n",
       "          0.1157,  0.0435,  0.0280, -0.0438,  0.0842,  0.0165,  0.0265, -0.0938,\n",
       "          0.0015, -0.0193,  0.1123,  0.1245, -0.0357,  0.0574,  0.0728, -0.0726,\n",
       "          0.0371,  0.0122, -0.0966,  0.0276,  0.1137, -0.0865, -0.1189,  0.0976,\n",
       "          0.0610,  0.0403, -0.0922, -0.0991, -0.1209, -0.0273, -0.0497, -0.0237,\n",
       "         -0.1129, -0.1042,  0.0313,  0.1090, -0.0327, -0.0187, -0.0374, -0.0975],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0132, -0.1042, -0.0917, -0.0042, -0.0312,  0.0757,  0.0824, -0.0029,\n",
       "          0.1018, -0.0960,  0.0083,  0.0952,  0.0248, -0.0652, -0.0867,  0.0586,\n",
       "          0.1117,  0.0747, -0.0800, -0.0379, -0.0675,  0.0337,  0.1050,  0.0126,\n",
       "          0.0101, -0.0697,  0.0543,  0.0986,  0.0653, -0.1116, -0.1048,  0.1007,\n",
       "         -0.0824,  0.0329,  0.1111, -0.0311,  0.0524, -0.0783, -0.0417, -0.0714,\n",
       "         -0.0695,  0.0250,  0.0386,  0.0507,  0.0143,  0.1062, -0.0112, -0.0257,\n",
       "         -0.0775, -0.0393,  0.0377, -0.0436,  0.0126, -0.0639, -0.1149,  0.1006,\n",
       "         -0.0112, -0.0259,  0.0972,  0.1188, -0.0132, -0.0777,  0.0309,  0.0375],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0352, -0.0108,  0.0335,  0.0320, -0.0514, -0.0734, -0.1234,  0.0340,\n",
       "          0.0696,  0.0121,  0.0907, -0.1072, -0.0907, -0.1182,  0.1226, -0.0919,\n",
       "         -0.1130, -0.0737,  0.0279, -0.0249,  0.0865, -0.0649, -0.0517, -0.0133,\n",
       "          0.0006, -0.0697,  0.0832, -0.0159,  0.0876,  0.0022, -0.0628,  0.1039,\n",
       "          0.0870,  0.0398,  0.0147,  0.0621,  0.0126, -0.0902, -0.0432,  0.0101,\n",
       "          0.1123, -0.0862,  0.0166, -0.0842,  0.0435, -0.1238,  0.0501,  0.0405,\n",
       "          0.1117, -0.0017,  0.0579, -0.0267, -0.0783,  0.0592, -0.0701, -0.0159,\n",
       "          0.0697, -0.1002,  0.0800, -0.0327, -0.0048, -0.0822,  0.0665,  0.0930],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0364,  0.0003,  0.0544,  0.0323, -0.0392, -0.0383,  0.0806,  0.0505,\n",
       "          0.0104,  0.0737,  0.0351,  0.0095, -0.0653, -0.0039,  0.0462,  0.0088,\n",
       "         -0.0863,  0.0355,  0.0707,  0.0546,  0.0848, -0.0569, -0.0961,  0.0165,\n",
       "         -0.0435,  0.0972,  0.0933, -0.0038, -0.0794, -0.0044,  0.0484, -0.1025,\n",
       "         -0.1236, -0.1099,  0.0154, -0.1072, -0.0256,  0.0382,  0.1023, -0.0872,\n",
       "          0.0764,  0.1056,  0.1220,  0.0432,  0.0344, -0.0242,  0.0769, -0.0465,\n",
       "          0.0544, -0.0935,  0.0316, -0.0084,  0.0848, -0.0573, -0.0548, -0.0213,\n",
       "         -0.0553,  0.0963,  0.0382,  0.1017,  0.0368, -0.1249, -0.1124, -0.1003],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0084,  0.0385, -0.0353,  ..., -0.0126, -0.0398,  0.0271],\n",
       "        device='cuda:0'),\n",
       " tensor([ 1.7603e-02,  4.0050e-03, -1.7854e-02,  1.9513e-02,  5.2888e-03,\n",
       "          1.9540e-02,  6.6170e-03, -1.5938e-02,  4.9819e-03,  3.3981e-03,\n",
       "          1.3003e-02, -1.8183e-02, -1.7962e-02, -6.3907e-03,  1.4858e-02,\n",
       "         -1.2818e-02, -8.4494e-03, -2.1742e-02,  1.3429e-02, -5.8032e-03,\n",
       "          2.1003e-02,  1.1537e-02,  2.0426e-02, -1.4276e-02, -1.7932e-02,\n",
       "          1.5824e-03,  2.2373e-02, -7.6890e-03,  5.6752e-03, -2.0816e-02,\n",
       "          7.4761e-04,  1.7622e-02, -1.4905e-02, -1.9997e-02, -5.0112e-03,\n",
       "          1.6471e-02, -2.0228e-02, -2.0126e-03,  9.1376e-03,  1.9258e-02,\n",
       "          2.9221e-03, -3.3497e-03,  1.6875e-02, -1.8270e-02, -7.8936e-03,\n",
       "          1.2259e-03,  5.3103e-03, -1.0055e-02, -9.5436e-03,  9.7799e-03,\n",
       "          8.2365e-03,  1.6100e-02,  2.7333e-03,  6.8917e-04, -8.4017e-03,\n",
       "          1.2206e-04, -1.8357e-02, -1.2686e-02,  1.0969e-02, -1.3248e-02,\n",
       "          5.6485e-03, -3.8530e-03,  2.0868e-02,  1.7507e-02, -2.0209e-02,\n",
       "          2.1937e-02, -1.8455e-02, -1.7700e-03, -8.0283e-04, -3.1746e-03,\n",
       "         -1.2628e-02, -5.6129e-03,  9.8550e-03,  8.9538e-03, -7.0623e-03,\n",
       "          1.8529e-02, -2.1097e-02,  1.0744e-02,  1.3808e-02, -3.0189e-03,\n",
       "          3.2740e-03, -1.4022e-02, -1.1680e-02,  1.0841e-02, -5.3807e-04,\n",
       "         -1.9935e-02,  1.9081e-02, -9.0860e-04,  1.8861e-02, -1.9601e-02,\n",
       "         -7.9412e-03,  1.8322e-02, -7.0244e-03,  1.4218e-02, -2.2337e-02,\n",
       "          1.7846e-02, -1.6649e-02,  4.5040e-03, -1.6464e-03,  1.9049e-02,\n",
       "          7.6807e-04, -9.9385e-04,  3.7975e-03,  1.9947e-03, -1.0428e-02,\n",
       "         -4.2405e-04,  4.4141e-03, -1.9152e-02, -1.6586e-03, -2.5315e-03,\n",
       "         -8.6443e-03,  1.4493e-02, -1.8626e-02,  2.0048e-02, -8.6183e-04,\n",
       "          2.7834e-03, -1.5560e-02,  5.4958e-03, -3.9149e-03,  3.3255e-03,\n",
       "         -1.8522e-03, -6.4854e-03, -8.0427e-03, -6.1805e-03, -1.1828e-04,\n",
       "         -1.1219e-02, -1.2350e-02,  8.9735e-03,  1.8914e-02, -8.7319e-03,\n",
       "          7.8580e-03,  1.7138e-02,  7.2052e-03, -9.6023e-03, -7.3679e-03,\n",
       "         -2.2600e-02,  1.5926e-02, -2.2677e-03, -6.6904e-03, -1.5779e-02,\n",
       "         -2.0324e-02, -1.5739e-02, -2.0631e-02,  1.8646e-02,  1.6815e-02,\n",
       "          3.4998e-03,  1.6039e-02, -1.1939e-02,  7.1857e-03, -1.5943e-02,\n",
       "         -1.0601e-02, -6.3164e-03,  1.3350e-02,  1.7374e-02, -9.7142e-03,\n",
       "          1.2895e-02,  5.3795e-03,  1.7582e-02, -1.0640e-02, -1.3642e-02,\n",
       "          5.2608e-03, -1.6119e-03, -2.0658e-02,  2.2659e-03, -1.5098e-02,\n",
       "         -2.0256e-02,  1.4151e-02,  9.8310e-03, -9.6616e-03, -2.2080e-03,\n",
       "         -1.8233e-03,  4.4321e-03,  1.3661e-02,  7.9020e-03, -1.4578e-02,\n",
       "         -5.9874e-03,  8.9166e-03, -1.3366e-02, -1.0276e-02,  1.9293e-03,\n",
       "         -1.1715e-02,  3.2126e-03, -6.9659e-03, -7.7082e-04,  2.0965e-04,\n",
       "         -3.3545e-03,  1.4045e-02, -3.1280e-03,  4.6989e-03,  2.4399e-03,\n",
       "          6.6949e-03, -1.0071e-03, -1.4339e-02,  2.1264e-02, -6.3790e-04,\n",
       "          1.0277e-02, -8.1471e-03, -1.9561e-02,  1.2654e-03,  1.5645e-02,\n",
       "          1.9837e-02, -1.4624e-02,  1.5477e-02, -9.6544e-03, -1.3253e-02,\n",
       "          1.4458e-02,  4.6586e-03,  1.9784e-02,  1.8979e-02, -1.1919e-02,\n",
       "         -1.2247e-02,  1.5310e-02, -7.8002e-03,  4.7347e-03,  9.6403e-04,\n",
       "         -9.0151e-03,  3.0444e-03,  5.7526e-03, -1.9237e-02,  1.3157e-02,\n",
       "          1.8319e-02,  3.1481e-03,  6.1397e-03, -1.5263e-02,  2.7539e-03,\n",
       "          1.1601e-02, -5.6770e-03,  3.5981e-03, -1.6264e-02, -8.8612e-03,\n",
       "          8.2384e-03,  1.5061e-02,  9.9758e-05, -2.1912e-02, -2.0285e-02,\n",
       "         -1.4424e-02,  1.7879e-02,  7.4587e-03,  4.0704e-03, -2.0156e-02,\n",
       "          1.9963e-02,  1.1481e-02,  2.0001e-02,  1.8317e-03, -1.8793e-02,\n",
       "          1.5546e-02,  1.6686e-02, -8.8916e-03,  2.0856e-02,  1.3289e-02,\n",
       "          5.9438e-03,  1.4933e-02,  1.3689e-02, -1.9715e-02,  1.5203e-02,\n",
       "          1.2931e-02, -6.5010e-03,  2.0544e-03, -1.5573e-03, -5.5264e-03,\n",
       "         -1.0163e-02, -7.5690e-04,  1.4938e-02,  2.8660e-03, -7.2827e-03,\n",
       "         -7.9321e-04,  1.7262e-02, -1.6428e-02, -9.9665e-03, -1.1768e-02,\n",
       "          1.4162e-02, -1.1138e-02,  2.0148e-02, -1.6705e-02, -9.4949e-03,\n",
       "          1.1257e-02, -1.7799e-02, -1.9317e-02, -1.9464e-03, -1.6365e-02,\n",
       "         -9.9342e-03, -9.9654e-03, -4.5312e-03,  2.0583e-02, -1.2699e-02,\n",
       "          1.5546e-02, -5.6433e-03, -8.3750e-03,  1.9543e-02,  3.7044e-03,\n",
       "          4.1269e-04, -2.1685e-02,  1.9188e-02,  5.9651e-03, -9.4744e-03,\n",
       "         -7.6010e-03,  1.8110e-04, -5.6675e-03, -1.2979e-02,  3.5991e-03,\n",
       "          1.0394e-02,  7.3215e-04,  1.6073e-02,  1.9495e-02,  1.2494e-02,\n",
       "          1.5260e-02,  9.8570e-03, -1.4131e-02,  4.3020e-03,  1.3844e-02,\n",
       "          1.2622e-02,  1.9039e-02, -1.6238e-02,  1.3255e-02,  1.1149e-02,\n",
       "          4.3335e-03, -1.7655e-02, -9.7670e-03, -1.8078e-02,  7.2443e-03,\n",
       "         -1.2640e-02,  1.2656e-02, -2.0742e-02,  1.4376e-02, -2.5227e-04,\n",
       "          1.4156e-02,  1.1092e-02, -1.0364e-02, -8.3528e-03,  5.8090e-03,\n",
       "         -1.2977e-02, -6.7560e-03,  2.6577e-03,  1.0759e-02, -2.1735e-02,\n",
       "         -1.8120e-02, -1.1288e-02,  1.8985e-02, -1.0602e-02, -6.1377e-03,\n",
       "          1.7353e-02, -9.4195e-03,  1.4228e-04, -1.8282e-02,  1.6819e-02,\n",
       "          6.2592e-03,  1.8394e-02,  5.8274e-03,  3.9621e-03,  1.7421e-04,\n",
       "          8.8530e-03,  1.8640e-03, -4.1685e-03, -5.3435e-03,  5.7458e-03,\n",
       "         -1.9442e-02, -1.6495e-02, -1.5623e-03,  1.9050e-02,  1.4441e-02,\n",
       "         -2.1700e-04,  1.3188e-02,  9.1291e-03, -3.9242e-03, -2.1920e-02,\n",
       "          1.6635e-02, -1.1134e-02,  7.2972e-03,  1.7962e-02,  1.4194e-02,\n",
       "          1.2301e-02, -6.6630e-03,  8.9998e-03,  6.4007e-03,  3.8126e-03,\n",
       "          6.3053e-04, -7.2445e-03,  1.5530e-03, -2.0786e-02,  5.7268e-03,\n",
       "          9.4573e-04, -1.9411e-02, -4.5755e-03,  1.2141e-02, -3.8224e-04,\n",
       "         -2.0847e-02, -1.9918e-02,  1.0198e-02, -9.6393e-03,  2.6268e-03,\n",
       "         -7.4430e-03,  1.8339e-02, -2.1262e-02,  5.3799e-03, -9.9870e-03,\n",
       "         -9.8207e-03,  3.8141e-03,  4.2269e-03, -1.2333e-02,  6.3783e-03,\n",
       "         -8.3188e-03,  7.9053e-04,  2.1423e-02,  1.2710e-02,  4.1594e-04,\n",
       "         -1.9861e-02, -1.7364e-02, -2.0196e-02,  8.8733e-03,  1.6733e-02,\n",
       "          1.9919e-03, -1.2674e-02, -3.5952e-03, -3.9144e-03,  2.6195e-04,\n",
       "          2.0139e-02,  2.1020e-02, -1.5696e-02, -1.7793e-02,  9.0675e-03,\n",
       "          1.6789e-02, -1.2053e-02, -7.0110e-04, -1.0604e-02, -1.9054e-02,\n",
       "         -1.9138e-02, -2.9335e-03, -1.6904e-02, -2.1349e-02, -1.7474e-02,\n",
       "         -2.0572e-02, -7.3663e-03,  9.7110e-03, -6.4124e-03,  6.4640e-03,\n",
       "          1.3780e-02,  2.0486e-03, -2.7568e-03, -1.1496e-02,  1.7013e-03,\n",
       "          1.3373e-02,  1.9962e-02,  1.4715e-02,  9.1687e-03,  1.3742e-02,\n",
       "          7.9653e-04,  8.8522e-03, -4.3847e-03,  1.3998e-03, -9.2069e-03,\n",
       "         -8.0079e-03,  1.0562e-02,  5.2175e-03,  3.8380e-03,  2.1273e-02,\n",
       "         -4.3588e-03, -1.0131e-02, -2.0108e-02, -1.1037e-02,  8.7219e-03,\n",
       "         -1.1617e-02,  1.7910e-02, -2.5755e-03, -1.0990e-02,  1.9306e-02,\n",
       "         -2.1419e-02,  1.0898e-02, -1.5300e-02,  2.9444e-03, -3.0256e-03,\n",
       "          1.4632e-02, -1.6264e-02,  1.3698e-02,  8.3883e-03, -2.1573e-02,\n",
       "          1.2031e-02,  2.0680e-02,  1.0111e-02,  3.7586e-03,  5.6312e-03,\n",
       "         -1.6362e-02, -1.8418e-02,  2.8555e-03, -1.5194e-02,  1.1465e-02,\n",
       "          1.0722e-02,  2.0099e-02, -7.1424e-03,  1.1794e-02, -2.1519e-02,\n",
       "         -6.5731e-03, -4.7421e-03, -1.4802e-02, -1.8429e-02, -1.6909e-02,\n",
       "          1.2465e-03,  1.6352e-02,  1.2038e-02, -1.5520e-02,  2.0893e-02,\n",
       "          5.8813e-03, -1.9621e-03,  1.7261e-02, -1.4093e-02,  1.6316e-03,\n",
       "         -1.9742e-02, -2.1709e-02, -1.0332e-02,  1.2039e-02,  1.8652e-03,\n",
       "         -2.0204e-02,  1.0657e-02], device='cuda:0'),\n",
       " tensor([-0.0958,  0.0707,  0.0192,  0.0018, -0.0477, -0.0577,  0.0002, -0.0192,\n",
       "         -0.0503,  0.0190,  0.0662,  0.0637,  0.1139,  0.0172, -0.0779, -0.0640,\n",
       "         -0.0895, -0.0040,  0.0013,  0.1184, -0.0427, -0.0980, -0.0679,  0.0587,\n",
       "          0.0809, -0.0327,  0.0522, -0.0108, -0.0310, -0.1234,  0.0801,  0.0796,\n",
       "          0.0726,  0.0412, -0.0192, -0.1032, -0.0469,  0.0371,  0.0537,  0.0943,\n",
       "         -0.1239,  0.0973, -0.0241, -0.1151,  0.0563, -0.0593, -0.1004,  0.0692,\n",
       "         -0.0932, -0.0225,  0.0366, -0.0688, -0.1193,  0.0550, -0.0085, -0.1049,\n",
       "         -0.0578,  0.0420, -0.0815, -0.0447, -0.0333, -0.1204,  0.1002,  0.0013],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0884, -0.0400, -0.0866, -0.0166,  0.0623, -0.0473, -0.1061, -0.0128,\n",
       "          0.0223,  0.0730,  0.1043, -0.0033, -0.0037,  0.1213,  0.0185, -0.0619,\n",
       "         -0.0683,  0.1047,  0.0326, -0.0675,  0.0509,  0.0791,  0.0891, -0.0252,\n",
       "          0.0059,  0.0020, -0.0619, -0.0688, -0.1236, -0.0261,  0.0998,  0.1011,\n",
       "         -0.0629, -0.0153, -0.0189,  0.0722,  0.0188,  0.0195, -0.0738,  0.1037,\n",
       "          0.0022,  0.0821, -0.0996, -0.0211, -0.0703,  0.1026,  0.0003, -0.0727,\n",
       "          0.0574, -0.0009,  0.0335,  0.0384,  0.1223,  0.1044,  0.0162,  0.0189,\n",
       "         -0.0885, -0.0885,  0.0832,  0.1204, -0.1039,  0.1214, -0.1038,  0.0433],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1056, -0.1134, -0.0256,  0.0101, -0.0131,  0.0326, -0.1120,  0.0652,\n",
       "          0.0602,  0.1043, -0.0353, -0.0706,  0.1112,  0.0420, -0.0479,  0.0223,\n",
       "          0.1242, -0.0932, -0.0838, -0.0717,  0.1074,  0.1095, -0.0345,  0.0915,\n",
       "         -0.0448,  0.0219,  0.0969, -0.0804,  0.0580,  0.0884, -0.1204, -0.1119,\n",
       "          0.0389, -0.1028, -0.0530,  0.0831, -0.0437,  0.1018, -0.0561,  0.0702,\n",
       "          0.0350,  0.1005, -0.1240,  0.0528, -0.0401,  0.0565,  0.0400,  0.0299,\n",
       "          0.0512, -0.0827, -0.0138,  0.0107,  0.0839, -0.0270,  0.0683, -0.1236,\n",
       "          0.0572,  0.0897, -0.1085, -0.0935,  0.0875,  0.0409, -0.0831, -0.0650],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1027,  0.0551,  0.0597, -0.0452, -0.0300,  0.0361, -0.0972,  0.0863,\n",
       "          0.0596,  0.0602, -0.0306,  0.1197,  0.1209, -0.0432,  0.0042, -0.0329,\n",
       "         -0.0172,  0.0546, -0.0405,  0.0073,  0.1059, -0.0928,  0.0218, -0.0510,\n",
       "          0.0715, -0.0395,  0.0805, -0.0588,  0.0827,  0.0283,  0.1098,  0.1026,\n",
       "          0.0322, -0.0757,  0.1135, -0.1067,  0.0505, -0.0802,  0.1079,  0.0842,\n",
       "         -0.1085, -0.0079, -0.0665, -0.0185, -0.0505,  0.1229, -0.0620, -0.0801,\n",
       "          0.1008,  0.1175,  0.0454,  0.0831,  0.0092,  0.0090, -0.1204,  0.1147,\n",
       "          0.0325, -0.0526, -0.1181,  0.0306, -0.0288, -0.1082,  0.0781,  0.0104],\n",
       "        device='cuda:0'),\n",
       " tensor([ 7.0395e-02, -3.1986e-02,  3.4638e-02, -6.9859e-02,  8.9995e-02,\n",
       "         -7.3056e-02,  3.3299e-03,  7.4211e-02, -9.1269e-02, -1.0615e-01,\n",
       "          7.1957e-02,  2.3148e-02, -5.5038e-02,  6.2861e-02, -1.8012e-02,\n",
       "          1.0144e-02,  7.7493e-02, -3.6553e-02, -2.3036e-02, -1.1213e-01,\n",
       "          4.0593e-02, -1.0669e-01,  1.2071e-01, -1.1401e-01, -7.9598e-02,\n",
       "         -8.5435e-02,  8.8895e-02, -1.0581e-01, -9.7772e-02,  7.2493e-02,\n",
       "         -6.7594e-03, -8.0363e-02, -1.6709e-02, -1.1967e-01, -1.1946e-01,\n",
       "         -8.9432e-02, -8.6111e-02,  1.1003e-01,  2.6296e-02,  1.1842e-01,\n",
       "         -2.2537e-02,  1.5678e-02, -8.4648e-02, -3.1902e-02,  6.7874e-02,\n",
       "         -1.6314e-02,  5.3559e-03, -1.0072e-01,  9.7569e-02, -1.1364e-01,\n",
       "         -5.1344e-02,  9.1953e-02, -5.5645e-02, -6.9392e-03,  6.1635e-02,\n",
       "          9.6270e-02,  3.7231e-03,  7.1731e-02, -8.1860e-02, -9.7471e-02,\n",
       "         -1.1534e-01, -4.2280e-05,  8.7554e-02, -5.3005e-02], device='cuda:0'),\n",
       " tensor([ 0.1085, -0.1249,  0.0158, -0.1001,  0.0134,  0.0796, -0.1112, -0.0886,\n",
       "          0.0224,  0.1143, -0.0838,  0.1017,  0.0629, -0.0231, -0.0364,  0.0160,\n",
       "         -0.0244,  0.0441,  0.0183, -0.0136, -0.0442, -0.0654,  0.0632,  0.0090,\n",
       "          0.0971,  0.0026, -0.0536,  0.0654,  0.0912, -0.0775,  0.1081,  0.0582,\n",
       "         -0.0889,  0.0738,  0.1238,  0.1128,  0.0648, -0.0298, -0.0305, -0.0057,\n",
       "         -0.0723, -0.0116, -0.1110,  0.0235, -0.0240, -0.0430,  0.1034,  0.0138,\n",
       "         -0.0069,  0.0748,  0.0223, -0.0851, -0.0797,  0.0535, -0.0971,  0.0021,\n",
       "         -0.0401,  0.0467, -0.1123,  0.1148,  0.1149, -0.0773,  0.0834, -0.0574],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0492, -0.1109,  0.1097, -0.0530, -0.0352,  0.0805, -0.0764, -0.0075,\n",
       "         -0.0425, -0.1024, -0.0671,  0.0125,  0.0108, -0.0218, -0.0916, -0.0502,\n",
       "         -0.0457,  0.0544, -0.0733, -0.0650, -0.0640, -0.0832, -0.0499,  0.0804,\n",
       "         -0.0351,  0.0664,  0.0420, -0.0728, -0.0521, -0.1018,  0.0047,  0.0030,\n",
       "         -0.0002, -0.0102, -0.0695,  0.0440,  0.0558,  0.0444, -0.1042, -0.0795,\n",
       "          0.0712,  0.0774, -0.0921,  0.0426,  0.0452, -0.1158,  0.1225,  0.0131,\n",
       "          0.0744, -0.0434, -0.0665,  0.1068,  0.0046, -0.0303, -0.1030,  0.0489,\n",
       "         -0.0440,  0.0769,  0.0016, -0.0831, -0.0927, -0.1199,  0.0842, -0.0215],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0448, -0.0735,  0.0498, -0.0009, -0.1156, -0.0265, -0.0456,  0.0823,\n",
       "         -0.0566,  0.0172, -0.0548, -0.0099,  0.0813,  0.0814, -0.0064,  0.1025,\n",
       "         -0.0331, -0.0631,  0.0506, -0.0180, -0.0223,  0.0752, -0.1057, -0.0457,\n",
       "         -0.0909, -0.1117, -0.0918,  0.0315, -0.0546, -0.0446, -0.0889,  0.0532,\n",
       "         -0.0885, -0.0369,  0.0621, -0.1212,  0.0676,  0.0371, -0.0853,  0.0971,\n",
       "         -0.0657,  0.0313,  0.1250,  0.0157,  0.0314,  0.0673, -0.0211,  0.0305,\n",
       "         -0.1037, -0.0003, -0.1150,  0.0126,  0.0464, -0.0013, -0.0518, -0.0277,\n",
       "         -0.0417,  0.0671, -0.0126,  0.0566, -0.0424, -0.0244, -0.0350, -0.0445],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0249,  0.0215,  0.0531,  0.0017,  0.1241,  0.0487,  0.0765, -0.1026,\n",
       "         -0.1097, -0.0466,  0.1001,  0.1184,  0.1040,  0.1179, -0.0807,  0.1093,\n",
       "         -0.0626,  0.0040, -0.0266,  0.0895,  0.0124, -0.0828,  0.0515,  0.1002,\n",
       "         -0.0204, -0.0206, -0.0685,  0.0327,  0.1204,  0.0502,  0.0135, -0.0963,\n",
       "          0.0746, -0.0853,  0.0039,  0.0427, -0.0148,  0.0616, -0.0524,  0.0216,\n",
       "          0.1170,  0.0086, -0.0121,  0.0622, -0.0918, -0.0643,  0.0275, -0.1229,\n",
       "         -0.0867,  0.1030, -0.0344, -0.0837,  0.0705,  0.0058,  0.0684, -0.0406,\n",
       "         -0.0088, -0.0956, -0.0423, -0.0847,  0.1087, -0.0373,  0.0913,  0.0047],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1204, -0.0560,  0.1090, -0.0004, -0.0360,  0.0684,  0.0584, -0.1182,\n",
       "         -0.1201, -0.1135,  0.0002,  0.0602,  0.0148,  0.0547,  0.1106,  0.0674,\n",
       "          0.0548, -0.0573,  0.0095,  0.0649,  0.0170, -0.0870, -0.0376, -0.0055,\n",
       "         -0.0687,  0.0974, -0.0045,  0.0907,  0.0126,  0.0659,  0.0792, -0.0296,\n",
       "          0.0315,  0.0226,  0.0441, -0.0205, -0.0682, -0.1187, -0.0846,  0.0484,\n",
       "         -0.0680, -0.0138,  0.0064, -0.1195,  0.0909,  0.0538,  0.0560,  0.0896,\n",
       "         -0.0771, -0.0266, -0.1247,  0.1194,  0.0677, -0.0401, -0.0389, -0.0901,\n",
       "         -0.0364, -0.0674, -0.0181,  0.1176,  0.0624,  0.0283,  0.1160, -0.0362],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0248,  0.0402,  0.1176,  0.1172, -0.1076,  0.1171, -0.0228, -0.0564,\n",
       "          0.1196,  0.0758,  0.1190, -0.1229,  0.0879, -0.0910,  0.0377, -0.0702,\n",
       "          0.0051, -0.0992,  0.0116, -0.0502,  0.0004,  0.0773, -0.0541, -0.0079,\n",
       "          0.0282, -0.1180, -0.1109, -0.0631, -0.0901,  0.0119,  0.0715, -0.0318,\n",
       "          0.1010,  0.0248,  0.0980,  0.1028, -0.0833, -0.0435, -0.0484,  0.0845,\n",
       "         -0.0276, -0.0868, -0.0414,  0.0240,  0.0639, -0.1060, -0.0119, -0.1175,\n",
       "          0.0454,  0.0634,  0.0793,  0.0284,  0.0780,  0.0995, -0.1210,  0.0921,\n",
       "         -0.0924, -0.0224, -0.0484, -0.0120, -0.0593,  0.0660,  0.0689, -0.0619],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0415,  0.0855, -0.1206, -0.0694,  0.1031, -0.0333,  0.0354, -0.0891,\n",
       "         -0.0639,  0.0213,  0.0501,  0.0606,  0.0523,  0.0621,  0.0695, -0.1150,\n",
       "          0.1120,  0.0586,  0.0995,  0.0282, -0.0909, -0.0126, -0.0690,  0.0277,\n",
       "         -0.1195,  0.0808,  0.0784, -0.0328,  0.0839,  0.0088,  0.0120,  0.0086,\n",
       "         -0.0966,  0.1053, -0.1165, -0.0305, -0.1105, -0.0545,  0.0051,  0.0293,\n",
       "         -0.0369, -0.0550, -0.1041, -0.1220,  0.0630,  0.0087, -0.0296,  0.0834,\n",
       "          0.0250, -0.0622,  0.0076,  0.1141, -0.1146, -0.1011, -0.0575,  0.0871,\n",
       "          0.0592, -0.0677,  0.0316,  0.0868, -0.0912,  0.1051, -0.0834, -0.0794],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1208, -0.0347, -0.0470,  0.0846,  0.0908,  0.1214,  0.0668, -0.0437,\n",
       "          0.0191,  0.1012, -0.1181,  0.0596,  0.0325, -0.0139,  0.0349,  0.0700,\n",
       "         -0.0148,  0.0778,  0.0316,  0.0807,  0.0109,  0.0648, -0.0997, -0.0353,\n",
       "         -0.0597,  0.1115, -0.0472, -0.0431,  0.1172,  0.1118,  0.0008,  0.0236,\n",
       "         -0.1044, -0.0883, -0.0535, -0.0408,  0.1077,  0.0177,  0.0570, -0.0062,\n",
       "          0.1144, -0.0362,  0.1021,  0.1169,  0.1067,  0.0704, -0.0687, -0.0797,\n",
       "          0.0278,  0.0572,  0.0377,  0.0012, -0.1244, -0.1053, -0.0966,  0.0742,\n",
       "          0.1238, -0.1121,  0.1214,  0.0774,  0.0356,  0.0050,  0.0689, -0.1040],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0293, -0.0992,  0.0493, -0.0566,  0.0894,  0.0042, -0.0992,  0.0135,\n",
       "          0.0106, -0.0027, -0.0739, -0.0840,  0.0645, -0.0024,  0.1169,  0.1025,\n",
       "          0.0782, -0.0362,  0.0896, -0.0148,  0.0301, -0.0251,  0.0509,  0.0787,\n",
       "         -0.0744,  0.0822, -0.0821, -0.0946, -0.0782, -0.0727,  0.0480, -0.0813,\n",
       "          0.1103,  0.0892,  0.1151, -0.0795,  0.0048,  0.0082, -0.0386,  0.1233,\n",
       "          0.1015,  0.0478,  0.0917, -0.0990,  0.0660,  0.1040,  0.0652, -0.0158,\n",
       "         -0.0124,  0.0215, -0.0381,  0.1129,  0.0305, -0.0057, -0.1040, -0.1105,\n",
       "          0.0114, -0.1163,  0.0385,  0.0720,  0.0823, -0.0969,  0.1132,  0.0599],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0979,  0.0500, -0.0629,  0.0663,  0.0063,  0.0517, -0.0389,  0.1013,\n",
       "          0.0596, -0.0028,  0.0198, -0.0308, -0.0125, -0.0505, -0.1207, -0.0862,\n",
       "          0.0496,  0.0423,  0.0887,  0.0851, -0.0043, -0.1175, -0.0519,  0.0612,\n",
       "         -0.0771, -0.0499, -0.0589, -0.1217,  0.1249,  0.1075,  0.0244,  0.0358,\n",
       "          0.0738, -0.0197, -0.0755,  0.0744, -0.1076, -0.0174,  0.0034, -0.0350,\n",
       "          0.1069,  0.1097,  0.1228, -0.1140,  0.0769, -0.0354, -0.0909,  0.1191,\n",
       "         -0.1068,  0.0627, -0.0401, -0.1074, -0.0891,  0.0715,  0.0870,  0.0991,\n",
       "         -0.0980,  0.0173, -0.0991, -0.0165,  0.0185, -0.0852,  0.0943,  0.0609],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0391,  0.0911,  0.0016, -0.0019,  0.0078,  0.1145, -0.0660, -0.1077,\n",
       "         -0.0401,  0.0030,  0.1143, -0.0229, -0.1155, -0.0676, -0.0530, -0.0706,\n",
       "          0.0843,  0.0597,  0.0582, -0.0020,  0.0143, -0.1139,  0.0855,  0.0679,\n",
       "          0.0630, -0.0855,  0.0556,  0.0148, -0.0889, -0.0064, -0.0239,  0.0148,\n",
       "          0.0860, -0.0350,  0.0202, -0.1160,  0.0516,  0.0942,  0.1247, -0.0469,\n",
       "         -0.0684,  0.0093,  0.1078, -0.0450,  0.0480,  0.0339,  0.1229, -0.1249,\n",
       "          0.0897,  0.0155, -0.1231, -0.0693,  0.1127, -0.1010, -0.0160,  0.1046,\n",
       "          0.0374, -0.1116, -0.0859,  0.0592,  0.1012,  0.0920, -0.0498,  0.0636],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1157,  0.0568,  0.0494, -0.0700,  0.1032, -0.1085,  0.0007, -0.1155,\n",
       "          0.0366,  0.0885,  0.0406, -0.0723, -0.0470,  0.0494,  0.1070, -0.1010,\n",
       "          0.1026, -0.0158, -0.0031, -0.0389,  0.0430,  0.0940, -0.0133, -0.0446,\n",
       "          0.0604, -0.0340,  0.0968, -0.0573,  0.0284,  0.0317,  0.0401,  0.1041,\n",
       "          0.0842,  0.1028, -0.1096, -0.0705, -0.0960,  0.1002,  0.0905, -0.0663,\n",
       "          0.1218,  0.1031,  0.1126,  0.0720,  0.0447,  0.1066, -0.0393, -0.0569,\n",
       "         -0.0054, -0.0518,  0.0423, -0.0206, -0.0007, -0.0324, -0.0760, -0.0956,\n",
       "         -0.0029, -0.0971, -0.0555, -0.1085,  0.0501,  0.0279, -0.0552, -0.0078],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0283, -0.0584, -0.0003, -0.0897, -0.0346,  0.0017, -0.0390, -0.0583,\n",
       "         -0.0344,  0.0727, -0.0750,  0.0553, -0.0998,  0.0060, -0.0876,  0.0760,\n",
       "          0.0102,  0.0124,  0.0545, -0.1123,  0.0997,  0.0303, -0.1206,  0.1100,\n",
       "          0.0601, -0.1105, -0.0636, -0.0378,  0.0355, -0.0514, -0.0675,  0.0136,\n",
       "          0.0349, -0.0052, -0.0165,  0.0728,  0.1003, -0.0871, -0.0357, -0.0890,\n",
       "         -0.0941, -0.0706,  0.0213, -0.1162,  0.0899,  0.0701, -0.0205,  0.0290,\n",
       "         -0.0669,  0.1158, -0.0821,  0.0674,  0.0654, -0.0286, -0.0750, -0.0446,\n",
       "         -0.0985,  0.0095,  0.0417,  0.0485,  0.0540,  0.0646,  0.1104,  0.1143],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0130, -0.1043, -0.1142, -0.1233, -0.0932, -0.0933, -0.0818,  0.0301,\n",
       "          0.0490, -0.1136, -0.1012,  0.1232,  0.0388, -0.0676,  0.0769, -0.0433,\n",
       "          0.0295,  0.0384, -0.0706, -0.0997, -0.0148,  0.1078,  0.0453,  0.0408,\n",
       "          0.1237,  0.0880,  0.0444, -0.1089,  0.1200, -0.0322, -0.0766,  0.0971,\n",
       "          0.0816,  0.0221,  0.0191,  0.0502,  0.0794, -0.1168,  0.1046, -0.1204,\n",
       "          0.0046, -0.1139,  0.0056, -0.0751, -0.0108,  0.1191,  0.1013,  0.0666,\n",
       "          0.0960,  0.0229, -0.0545, -0.0510, -0.0114,  0.0718, -0.1003,  0.0234,\n",
       "          0.0760, -0.0441, -0.0972, -0.0810, -0.0309, -0.0983,  0.1000, -0.0983],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1112,  0.0831,  0.0616,  0.1036,  0.0630, -0.0339,  0.0311,  0.0591,\n",
       "          0.0472,  0.0923,  0.0080,  0.0473, -0.1015,  0.0698,  0.0907,  0.0369,\n",
       "         -0.0076,  0.0212,  0.0840,  0.1028, -0.0453,  0.0693, -0.0184, -0.1013,\n",
       "         -0.1015, -0.0368,  0.0997,  0.0271, -0.0581,  0.1054, -0.0984, -0.0841,\n",
       "          0.1081,  0.0089,  0.0746, -0.0895,  0.0910, -0.0133,  0.1133, -0.0920,\n",
       "          0.0771, -0.0042, -0.0130,  0.0575,  0.0598, -0.0730,  0.0834,  0.1207,\n",
       "          0.0474,  0.1025,  0.0411, -0.0871, -0.0745,  0.0698,  0.0658, -0.0652,\n",
       "         -0.0702,  0.1227, -0.0473, -0.0437, -0.0760,  0.0838,  0.0570,  0.1023],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0896, -0.0723,  0.0137, -0.1012, -0.1198,  0.0632,  0.0685,  0.0505,\n",
       "         -0.0907, -0.0745,  0.0666, -0.0612,  0.0613,  0.0247, -0.1231,  0.1021,\n",
       "          0.0807, -0.0560,  0.1096,  0.0350, -0.0944,  0.0197, -0.0130, -0.1187,\n",
       "          0.0026,  0.0613,  0.0789, -0.0761,  0.0354, -0.0400, -0.1205,  0.0893,\n",
       "         -0.0128,  0.0703,  0.0037, -0.0994,  0.0549, -0.0907,  0.1169,  0.0013,\n",
       "          0.0155, -0.0719, -0.0868,  0.1158, -0.1191,  0.0582, -0.0506,  0.1199,\n",
       "          0.0346,  0.0783, -0.1123,  0.0385,  0.0960,  0.0069, -0.0882, -0.0489,\n",
       "         -0.0397, -0.0718, -0.1098,  0.1020,  0.1063, -0.0724,  0.0880,  0.0335],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.1173, -0.0898,  0.0321,  0.0681,  0.1040,  0.0230,  0.0810,  0.0721,\n",
       "          0.0501,  0.0794, -0.0941, -0.0141, -0.0856, -0.0560, -0.0876,  0.0179,\n",
       "         -0.0005,  0.1135, -0.0631, -0.0527,  0.0508, -0.1017, -0.1246,  0.0613,\n",
       "          0.0661, -0.0103,  0.0785, -0.0820, -0.0444, -0.0546,  0.0575,  0.0265,\n",
       "          0.0725, -0.0333, -0.0281, -0.0392,  0.0958, -0.1189, -0.0261, -0.0900,\n",
       "          0.0748, -0.0881, -0.1040,  0.0888,  0.1119, -0.0776,  0.0858, -0.0305,\n",
       "          0.0303,  0.0123, -0.0722, -0.1014,  0.0949, -0.0157, -0.1077,  0.0909,\n",
       "          0.0259, -0.0986,  0.0184,  0.0624,  0.0677,  0.0609, -0.0739, -0.0775],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0804,  0.0007, -0.0697,  0.0812,  0.1212,  0.0136,  0.0469,  0.0819,\n",
       "          0.0536, -0.0204, -0.0473, -0.1208,  0.0398, -0.0400,  0.1098, -0.0386,\n",
       "          0.1035,  0.1182, -0.0943, -0.0994, -0.0616,  0.0897,  0.0594,  0.0977,\n",
       "         -0.0104,  0.1004,  0.0686, -0.1162, -0.0344,  0.0704, -0.0979, -0.0892,\n",
       "          0.0372,  0.1105,  0.1035,  0.0010, -0.1075,  0.0041, -0.0149,  0.0685,\n",
       "         -0.0033, -0.0024,  0.1233,  0.1250, -0.0601, -0.0620,  0.0651,  0.0023,\n",
       "          0.0972,  0.0719,  0.0415, -0.0911, -0.0971, -0.1065, -0.1218, -0.0407,\n",
       "          0.1185,  0.0042,  0.0359, -0.0612,  0.0293, -0.1003,  0.0255, -0.1205],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.1097,  0.0402, -0.0284, -0.1163, -0.0951,  0.0605, -0.0046,  0.0920,\n",
       "          0.0099,  0.0270,  0.0091,  0.0177,  0.0979,  0.0967,  0.0035, -0.0182,\n",
       "          0.0159, -0.0609,  0.0323,  0.0756, -0.0420,  0.1194,  0.0561, -0.0497,\n",
       "         -0.0976,  0.0700, -0.0334,  0.0682,  0.0078, -0.0149,  0.0995,  0.1066,\n",
       "         -0.0967, -0.0970, -0.0330,  0.0175, -0.0122,  0.0894,  0.0286, -0.0559,\n",
       "         -0.1011, -0.1209,  0.0872, -0.0957, -0.0336,  0.0217,  0.0041, -0.1248,\n",
       "          0.0695,  0.0219,  0.0657, -0.1139,  0.0328,  0.0144, -0.0453, -0.0331,\n",
       "          0.0026,  0.1006,  0.0873,  0.1190,  0.0576, -0.0601,  0.0295, -0.0524],\n",
       "        device='cuda:0'),\n",
       " tensor([ 0.0395,  0.0027,  0.0060,  ..., -0.0101, -0.0314,  0.0219],\n",
       "        device='cuda:0'),\n",
       " tensor([ 6.5835e-03,  1.3544e-03, -2.0369e-02,  4.7302e-03, -1.5733e-02,\n",
       "          1.8137e-02,  1.7040e-02, -2.5003e-04,  4.7464e-03, -1.2257e-03,\n",
       "         -9.7125e-03,  2.8025e-04,  2.3160e-04, -6.2758e-03, -1.4452e-02,\n",
       "         -1.6641e-02,  7.9885e-03,  1.0424e-02,  8.8848e-03, -1.7239e-02,\n",
       "         -1.1993e-02,  1.7662e-02,  1.0284e-02, -3.8651e-03,  7.7208e-03,\n",
       "          7.3141e-03, -2.3937e-03,  5.1046e-03, -4.7852e-03, -1.8859e-02,\n",
       "         -1.4030e-02,  1.6260e-02,  7.8263e-03,  1.2828e-02,  8.8271e-03,\n",
       "          8.2338e-03,  5.1727e-03,  2.0897e-02, -3.5140e-03, -1.3676e-02,\n",
       "          2.0248e-02,  2.1691e-02, -6.3050e-03, -8.1383e-03, -2.1125e-02,\n",
       "          3.5360e-03,  5.4608e-03,  4.1601e-03,  7.2669e-03, -2.1465e-02,\n",
       "          1.0805e-02, -1.5891e-02, -7.5267e-03, -4.6033e-03, -8.8763e-03,\n",
       "         -2.1385e-02,  1.0800e-03,  1.1495e-02,  9.2942e-04, -1.1116e-02,\n",
       "          2.0378e-03,  7.9557e-03, -1.3760e-02, -2.0621e-02,  3.6736e-03,\n",
       "          1.2749e-02, -1.4763e-02,  1.9845e-02,  1.3265e-02, -7.8343e-03,\n",
       "          2.7819e-04,  1.1420e-02, -1.2989e-02,  1.0188e-03,  1.1977e-02,\n",
       "          9.4198e-03,  1.6655e-02,  5.2596e-03,  1.6900e-02,  4.0626e-03,\n",
       "          1.7705e-02,  1.1862e-02,  1.3091e-02,  7.4692e-03,  1.8357e-02,\n",
       "         -8.2045e-03, -1.2312e-02, -1.8453e-02, -1.9637e-02, -1.5904e-02,\n",
       "          1.9601e-02, -2.7228e-04,  1.2633e-02,  5.6283e-03, -2.0059e-02,\n",
       "          1.6475e-02, -2.0804e-02, -5.2231e-03, -1.4626e-02, -2.1884e-02,\n",
       "         -5.1266e-03,  2.0467e-02,  1.9183e-02, -8.5534e-04, -1.9017e-02,\n",
       "          6.5986e-03,  1.0467e-02, -2.2370e-02,  8.4934e-03,  7.3280e-03,\n",
       "         -7.5155e-03, -1.5452e-02, -4.9912e-03,  2.0562e-02, -2.0715e-02,\n",
       "         -1.1937e-02, -4.2831e-03, -1.9836e-02,  1.2662e-03, -1.5926e-02,\n",
       "          1.2371e-02,  6.2613e-03, -1.7381e-03, -1.0528e-02, -1.9710e-03,\n",
       "         -1.0250e-03,  1.7687e-02, -5.3816e-03, -8.0303e-03,  1.1882e-02,\n",
       "          3.9566e-03,  5.5469e-03,  1.7171e-02, -1.9087e-02, -1.4396e-02,\n",
       "         -2.1047e-03,  1.6033e-02, -1.4193e-02, -7.6058e-04,  1.6734e-02,\n",
       "          1.1749e-02, -8.1620e-03,  1.1091e-02,  1.7925e-02,  1.8388e-02,\n",
       "         -1.4813e-02, -2.1862e-02, -3.5894e-03, -5.5478e-03,  2.1714e-02,\n",
       "          6.7850e-03, -4.7638e-03, -1.9641e-02,  7.9755e-03, -1.3494e-02,\n",
       "         -5.3330e-03,  7.4228e-03,  8.0287e-03, -1.9430e-04, -1.3771e-02,\n",
       "          3.6600e-03, -1.5747e-02, -5.4496e-05, -2.1556e-02, -8.0240e-03,\n",
       "         -2.0665e-02, -1.6102e-02,  1.4027e-02,  1.7834e-02, -1.1961e-02,\n",
       "          7.9827e-03,  1.6877e-02,  7.8304e-03,  1.0886e-02,  6.2053e-03,\n",
       "         -2.2090e-02,  1.5481e-02,  5.0800e-03,  1.4626e-02, -1.7899e-02,\n",
       "         -5.6832e-03, -1.7275e-03, -9.2037e-03,  6.0645e-04, -1.6639e-02,\n",
       "          3.6184e-03, -4.9941e-03, -5.7773e-03,  1.9368e-02,  1.1936e-02,\n",
       "         -1.0769e-03, -1.1354e-02, -1.7418e-02, -1.4531e-03,  1.4385e-02,\n",
       "          4.6569e-03,  9.5973e-03, -5.7599e-03,  1.3069e-03,  1.7451e-02,\n",
       "          5.3153e-03, -9.1324e-03,  1.3214e-02,  9.7949e-03,  1.8231e-04,\n",
       "         -1.2986e-02, -1.6888e-02, -5.3249e-03, -1.9851e-02, -2.9254e-03,\n",
       "         -1.0144e-02,  1.2973e-02,  2.0599e-03, -2.0333e-02, -1.0279e-02,\n",
       "          1.3719e-04,  2.5550e-03, -1.1501e-02,  1.7881e-02, -5.1073e-03,\n",
       "         -1.1150e-02, -1.1005e-02, -4.9730e-03, -1.5306e-02, -4.5956e-03,\n",
       "         -8.8584e-03, -3.5251e-04,  1.2053e-02, -1.7456e-02,  1.5114e-02,\n",
       "         -1.1012e-02,  1.6629e-02,  1.3739e-02, -1.5073e-02,  1.8722e-02,\n",
       "          1.7746e-02,  7.1186e-03,  1.5975e-02,  2.1946e-03,  1.0613e-02,\n",
       "          8.2053e-03, -1.0757e-02, -2.0139e-02,  2.1655e-02, -2.0415e-02,\n",
       "         -3.5530e-03,  8.9083e-03, -1.2145e-02, -1.6319e-02,  1.4723e-02,\n",
       "          9.0159e-03, -1.4155e-02, -4.9620e-04,  2.7061e-03, -1.9770e-02,\n",
       "          1.3071e-02,  1.5293e-02, -1.1299e-02,  1.2541e-02,  2.7008e-03,\n",
       "          1.7986e-02,  2.0367e-02,  1.8353e-02, -2.1642e-02,  2.2563e-03,\n",
       "         -1.8040e-02,  2.1350e-02, -1.5805e-02, -1.0359e-02, -2.0492e-02,\n",
       "          3.1332e-03,  2.2164e-03, -1.2633e-02, -1.4610e-02,  5.3174e-03,\n",
       "          6.2339e-05, -1.1748e-02, -1.7136e-02,  1.9868e-02,  2.1542e-02,\n",
       "         -1.2153e-02, -1.0598e-03, -1.2832e-02,  7.4788e-03,  1.3257e-02,\n",
       "         -1.1848e-02, -2.0135e-02, -7.6739e-03,  1.4890e-02, -1.0160e-02,\n",
       "         -2.1162e-02,  8.8288e-03, -1.5034e-02, -1.7573e-02, -1.2877e-02,\n",
       "          3.9570e-03, -2.6223e-03,  2.6494e-03,  1.9862e-02, -2.1931e-02,\n",
       "          1.4297e-03, -2.1204e-02, -1.0324e-03, -1.1557e-02, -2.1387e-02,\n",
       "          2.6241e-03,  8.1478e-03, -1.1053e-02, -2.0014e-02, -2.0692e-02,\n",
       "          1.9121e-02, -8.5055e-03, -2.0057e-02,  1.2922e-02, -1.8813e-02,\n",
       "          4.8404e-03,  1.0148e-03, -1.1095e-02, -2.1737e-02,  1.4827e-02,\n",
       "         -5.2013e-03,  1.5368e-02,  1.7003e-02,  8.4227e-03,  5.9609e-03,\n",
       "         -5.6402e-03,  1.3876e-02, -8.7779e-03, -2.1881e-02, -1.0632e-02,\n",
       "         -6.3084e-03,  7.9107e-03,  3.9581e-03,  1.6804e-02,  1.6302e-02,\n",
       "          1.3978e-02,  1.8189e-02,  1.0342e-02, -4.6070e-03,  2.1651e-02,\n",
       "          1.2541e-02,  1.7337e-02, -1.4811e-02,  9.3587e-03,  1.8998e-02,\n",
       "          1.5061e-03,  1.0117e-02,  6.0948e-03,  5.7253e-03, -1.3881e-03,\n",
       "         -1.7999e-02, -1.3901e-03, -1.9088e-02, -8.5560e-03, -8.6310e-03,\n",
       "          2.2056e-02, -1.3507e-02,  2.6837e-03, -1.2493e-02, -1.9980e-02,\n",
       "          1.5506e-02,  1.5377e-02,  1.3587e-02, -2.8252e-03, -4.7186e-03,\n",
       "         -1.3324e-02, -2.0997e-02,  2.1893e-03,  2.7751e-03, -3.2092e-03,\n",
       "         -1.2843e-02,  1.9225e-02,  5.8965e-04,  1.8998e-02, -8.4897e-03,\n",
       "          1.8272e-02,  2.1217e-02,  7.8734e-03, -8.0182e-03, -6.3658e-03,\n",
       "         -1.5024e-03,  3.2678e-03,  1.8839e-02,  1.6904e-02, -1.2166e-02,\n",
       "          1.8351e-02,  1.4796e-02,  1.6825e-02,  1.6071e-02, -1.8835e-03,\n",
       "          1.1009e-02,  1.0605e-02,  1.1641e-02,  9.5992e-03, -2.0272e-02,\n",
       "         -4.8552e-03,  3.8821e-03, -8.0003e-03,  1.5881e-02,  1.8002e-03,\n",
       "          1.0673e-02, -1.4394e-02,  1.6295e-02,  1.4407e-02,  7.2703e-03,\n",
       "         -4.2936e-03, -2.0966e-02, -3.6749e-03, -4.3631e-03, -1.2986e-02,\n",
       "          1.3554e-02,  1.5401e-02,  9.8456e-03,  1.3472e-02, -1.7389e-02,\n",
       "         -2.1240e-02, -4.3973e-03, -8.9934e-03,  1.1784e-02,  1.9777e-03,\n",
       "         -2.5702e-03,  2.0873e-02, -1.0718e-02, -1.9733e-02, -2.7758e-03,\n",
       "          8.4576e-03,  1.1298e-02, -2.1123e-03, -1.9264e-02,  2.1602e-02,\n",
       "          1.0007e-02,  1.3106e-02,  2.1023e-02,  5.1907e-03, -1.6706e-02,\n",
       "          8.1373e-03,  1.1946e-02, -4.8297e-03,  1.6158e-02,  9.5477e-03,\n",
       "          1.2923e-02, -8.8723e-03, -1.1800e-02,  4.2838e-03, -2.0248e-02,\n",
       "         -1.3125e-02,  1.5750e-02, -1.5607e-03,  1.6345e-02, -2.1620e-02,\n",
       "         -6.2927e-03,  1.8140e-02, -1.1781e-02,  2.0901e-02, -1.9230e-02,\n",
       "         -3.8129e-03,  3.1755e-03,  1.7564e-03,  2.0815e-02, -2.0831e-02,\n",
       "          1.5539e-02,  1.9039e-02, -1.5853e-02, -9.7394e-03, -2.3174e-03,\n",
       "         -2.0674e-02, -1.1496e-02,  3.8228e-03, -3.6362e-03, -2.2286e-02,\n",
       "          2.0021e-02, -8.4892e-04,  2.1406e-02, -1.8495e-03, -6.5926e-03,\n",
       "         -1.2454e-02,  1.9693e-03,  5.9246e-03, -3.2736e-03,  4.7293e-03,\n",
       "          6.4297e-03,  1.7367e-02, -1.7074e-02, -5.3991e-03,  5.2404e-03,\n",
       "         -1.9239e-02,  6.7577e-03,  1.1949e-02,  1.5364e-02,  2.0045e-02,\n",
       "          1.3420e-02,  1.5987e-02,  3.6114e-04,  1.7796e-03, -1.1838e-02,\n",
       "          2.0444e-02, -5.3271e-04,  1.6332e-03,  1.7211e-02,  6.9506e-03,\n",
       "         -1.8348e-02, -1.9192e-02, -1.7013e-02,  1.4452e-02,  1.8227e-02,\n",
       "          2.1068e-02,  1.2543e-02,  6.9859e-03,  1.5405e-02,  1.4824e-02,\n",
       "         -2.1617e-02, -7.4310e-04], device='cuda:0')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTS_LowRank(w, b , RANK, (1, 28, 28), n_patches=14, n_blocks=7, hidden_d=512, n_heads=8, out_d=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load decomposed layers\n",
    "load_sd_decomp(torch.load(BRANCH_LOC, map_location=device), model, DECOMPOSED_LAYERS)\n",
    "\n",
    "# Optimizers for both models\n",
    "learning_rate = 0.0004\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer_full = torch.optim.SGD(model_original.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using checkpoint, creation of model with only LC-checkpoint and another with LC-checkpoint + LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.6476528644561768\n",
      "LC Training Loss (Full): 1.6476528644561768\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.8125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.6175267696380615\n",
      "LC Training Loss (Full): 1.615043044090271\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.5801705121994019\n",
      "LC Training Loss (Full): 1.574953317642212\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.591447353363037\n",
      "LC Training Loss (Full): 1.584779977798462\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.5971896648406982\n",
      "LC Training Loss (Full): 1.5738531351089478\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.4670934677124023\n",
      "LC Training Loss (Full): 1.4636319875717163\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.881\n",
      "model accuracy: 0.891\n",
      "Full accuracy: 0.902, LC accuracy: 0.891, Decomposed-Full accuracy: 0.884, Decomposed-Restored accuracy: 0.881\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.5625988245010376\n",
      "LC Training Loss (Full): 1.5475776195526123\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.6310498714447021\n",
      "LC Training Loss (Full): 1.6086517572402954\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.6911908388137817\n",
      "LC Training Loss (Full): 1.6465522050857544\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.5175873041152954\n",
      "LC Training Loss (Full): 1.5111242532730103\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5849487781524658\n",
      "LC Training Loss (Full): 1.5786054134368896\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.90625\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.907\n",
      "Full accuracy: 0.906, LC accuracy: 0.907, Decomposed-Full accuracy: 0.884, Decomposed-Restored accuracy: 0.884\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.5823594331741333\n",
      "LC Training Loss (Full): 1.5519585609436035\n",
      "Epoch: 0, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.53700590133667\n",
      "LC Training Loss (Full): 1.524003028869629\n",
      "Epoch: 0, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.5637423992156982\n",
      "LC Training Loss (Full): 1.5556330680847168\n",
      "Epoch: 0, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.6024454832077026\n",
      "LC Training Loss (Full): 1.5741102695465088\n",
      "Epoch: 0, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.6382524967193604\n",
      "LC Training Loss (Full): 1.6289526224136353\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.906\n",
      "Full accuracy: 0.908, LC accuracy: 0.906, Decomposed-Full accuracy: 0.884, Decomposed-Restored accuracy: 0.884\n",
      "Epoch: 0, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.545155644416809\n",
      "LC Training Loss (Full): 1.5369577407836914\n",
      "Epoch: 0, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.5266690254211426\n",
      "LC Training Loss (Full): 1.5285980701446533\n",
      "Epoch: 0, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.6671552658081055\n",
      "LC Training Loss (Full): 1.633859395980835\n",
      "Epoch: 0, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.573921799659729\n",
      "LC Training Loss (Full): 1.5587471723556519\n",
      "Epoch: 0, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5384278297424316\n",
      "LC Training Loss (Full): 1.5049769878387451\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 0.96875\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.886\n",
      "model accuracy: 0.884\n",
      "model accuracy: 0.91\n",
      "Full accuracy: 0.91, LC accuracy: 0.91, Decomposed-Full accuracy: 0.886, Decomposed-Restored accuracy: 0.884\n",
      "Epoch: 0, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.61664879322052\n",
      "LC Training Loss (Full): 1.5637093782424927\n",
      "Epoch: 0, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.6189196109771729\n",
      "LC Training Loss (Full): 1.6164077520370483\n",
      "Epoch: 0, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.5841857194900513\n",
      "LC Training Loss (Full): 1.5343934297561646\n",
      "Epoch: 0, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.6690900325775146\n",
      "LC Training Loss (Full): 1.6226236820220947\n",
      "Epoch: 0, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.55624258518219\n",
      "LC Training Loss (Full): 1.5271016359329224\n",
      "model accuracy: 0.91\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.91\n",
      "Full accuracy: 0.91, LC accuracy: 0.91, Decomposed-Full accuracy: 0.887, Decomposed-Restored accuracy: 0.887\n",
      "Epoch: 0, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.5609402656555176\n",
      "LC Training Loss (Full): 1.5237621068954468\n",
      "Epoch: 0, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.5753103494644165\n",
      "LC Training Loss (Full): 1.5847833156585693\n",
      "Epoch: 0, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.4975953102111816\n",
      "LC Training Loss (Full): 1.494612216949463\n",
      "Epoch: 0, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.5035933256149292\n",
      "LC Training Loss (Full): 1.5023049116134644\n",
      "Epoch: 0, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_3\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_3/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5653390884399414\n",
      "LC Training Loss (Full): 1.5667401552200317\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.90625\n",
      "model accuracy: 0.908\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.909\n",
      "Full accuracy: 0.908, LC accuracy: 0.909, Decomposed-Full accuracy: 0.887, Decomposed-Restored accuracy: 0.887\n",
      "Epoch: 0, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 1.7273695468902588\n",
      "LC Training Loss (Full): 1.7218009233474731\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5886375904083252\n",
      "LC Training Loss (Full): 1.5630000829696655\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.5515947341918945\n",
      "LC Training Loss (Full): 1.5427451133728027\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.7323336601257324\n",
      "LC Training Loss (Full): 1.6409673690795898\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.4720157384872437\n",
      "LC Training Loss (Full): 1.4650022983551025\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.5606355667114258\n",
      "LC Training Loss (Full): 1.5626236200332642\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.6196638345718384\n",
      "LC Training Loss (Full): 1.5935685634613037\n",
      "model accuracy: 0.912\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.887\n",
      "model accuracy: 0.912\n",
      "Full accuracy: 0.912, LC accuracy: 0.912, Decomposed-Full accuracy: 0.887, Decomposed-Restored accuracy: 0.887\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.536361813545227\n",
      "LC Training Loss (Full): 1.5124694108963013\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.5890980958938599\n",
      "LC Training Loss (Full): 1.5653891563415527\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.6132522821426392\n",
      "LC Training Loss (Full): 1.6096806526184082\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.571102261543274\n",
      "LC Training Loss (Full): 1.5647156238555908\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5289002656936646\n",
      "LC Training Loss (Full): 1.5228798389434814\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 0.9375\n",
      "model accuracy: 0.915\n",
      "model accuracy: 0.889\n",
      "model accuracy: 0.888\n",
      "model accuracy: 0.912\n",
      "Full accuracy: 0.915, LC accuracy: 0.912, Decomposed-Full accuracy: 0.889, Decomposed-Restored accuracy: 0.888\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.5137214660644531\n",
      "LC Training Loss (Full): 1.5041683912277222\n",
      "Epoch: 1, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.6059207916259766\n",
      "LC Training Loss (Full): 1.5887773036956787\n",
      "Epoch: 1, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.6615427732467651\n",
      "LC Training Loss (Full): 1.627055287361145\n",
      "Epoch: 1, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.5351794958114624\n",
      "LC Training Loss (Full): 1.5031007528305054\n",
      "Epoch: 1, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.5989899635314941\n",
      "LC Training Loss (Full): 1.586742639541626\n",
      "model accuracy: 0.916\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.889\n",
      "model accuracy: 0.918\n",
      "Full accuracy: 0.916, LC accuracy: 0.918, Decomposed-Full accuracy: 0.89, Decomposed-Restored accuracy: 0.889\n",
      "Epoch: 1, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.4662226438522339\n",
      "LC Training Loss (Full): 1.4788089990615845\n",
      "Epoch: 1, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.5554335117340088\n",
      "LC Training Loss (Full): 1.5544763803482056\n",
      "Epoch: 1, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.6199153661727905\n",
      "LC Training Loss (Full): 1.5991697311401367\n",
      "Epoch: 1, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.5713282823562622\n",
      "LC Training Loss (Full): 1.536878228187561\n",
      "Epoch: 1, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5611467361450195\n",
      "LC Training Loss (Full): 1.5681501626968384\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.90625\n",
      "model accuracy: 0.918\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.917\n",
      "Full accuracy: 0.918, LC accuracy: 0.917, Decomposed-Full accuracy: 0.89, Decomposed-Restored accuracy: 0.89\n",
      "Epoch: 1, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.6480094194412231\n",
      "LC Training Loss (Full): 1.5909440517425537\n",
      "Epoch: 1, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.649728775024414\n",
      "LC Training Loss (Full): 1.630105972290039\n",
      "Epoch: 1, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.4937760829925537\n",
      "LC Training Loss (Full): 1.4753692150115967\n",
      "Epoch: 1, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.5475736856460571\n",
      "LC Training Loss (Full): 1.5211433172225952\n",
      "Epoch: 1, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.5985825061798096\n",
      "LC Training Loss (Full): 1.5584596395492554\n",
      "model accuracy: 0.92\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.919\n",
      "Full accuracy: 0.92, LC accuracy: 0.919, Decomposed-Full accuracy: 0.89, Decomposed-Restored accuracy: 0.89\n",
      "Epoch: 1, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.5730358362197876\n",
      "LC Training Loss (Full): 1.5345678329467773\n",
      "Epoch: 1, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.5381503105163574\n",
      "LC Training Loss (Full): 1.5479905605316162\n",
      "Epoch: 1, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.5951282978057861\n",
      "LC Training Loss (Full): 1.5619909763336182\n",
      "Epoch: 1, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.6306029558181763\n",
      "LC Training Loss (Full): 1.6052037477493286\n",
      "Epoch: 1, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_7\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_7/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5912460088729858\n",
      "LC Training Loss (Full): 1.524301290512085\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 1.0\n",
      "model accuracy: 0.923\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.89\n",
      "model accuracy: 0.923\n",
      "Full accuracy: 0.923, LC accuracy: 0.923, Decomposed-Full accuracy: 0.89, Decomposed-Restored accuracy: 0.89\n",
      "Epoch: 1, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 1.4698902368545532\n",
      "LC Training Loss (Full): 1.4697247743606567\n",
      "Epoch: 2, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.74422287940979\n",
      "LC Training Loss (Full): 1.6998990774154663\n",
      "Training Accuracy | Decomposed: 0.6875, Full : 0.78125\n",
      "Epoch: 2, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.6129746437072754\n",
      "LC Training Loss (Full): 1.5942740440368652\n",
      "Epoch: 2, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.5985863208770752\n",
      "LC Training Loss (Full): 1.5710270404815674\n",
      "Epoch: 2, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.498018503189087\n",
      "LC Training Loss (Full): 1.509284257888794\n",
      "Epoch: 2, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.6211881637573242\n",
      "LC Training Loss (Full): 1.6140822172164917\n",
      "Epoch: 2, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.547886848449707\n",
      "LC Training Loss (Full): 1.5149041414260864\n",
      "model accuracy: 0.922\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.891\n",
      "model accuracy: 0.922\n",
      "Full accuracy: 0.922, LC accuracy: 0.922, Decomposed-Full accuracy: 0.891, Decomposed-Restored accuracy: 0.891\n",
      "Epoch: 2, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.538408637046814\n",
      "LC Training Loss (Full): 1.5546962022781372\n",
      "Epoch: 2, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.6592695713043213\n",
      "LC Training Loss (Full): 1.64509916305542\n",
      "Epoch: 2, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.5654056072235107\n",
      "LC Training Loss (Full): 1.5426061153411865\n",
      "Epoch: 2, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.6773877143859863\n",
      "LC Training Loss (Full): 1.6356536149978638\n",
      "Epoch: 2, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.575333833694458\n",
      "LC Training Loss (Full): 1.5374219417572021\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.9375\n",
      "model accuracy: 0.925\n",
      "model accuracy: 0.892\n",
      "model accuracy: 0.892\n",
      "model accuracy: 0.924\n",
      "Full accuracy: 0.925, LC accuracy: 0.924, Decomposed-Full accuracy: 0.892, Decomposed-Restored accuracy: 0.892\n",
      "Epoch: 2, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.5295356512069702\n",
      "LC Training Loss (Full): 1.5251004695892334\n",
      "Epoch: 2, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.5838775634765625\n",
      "LC Training Loss (Full): 1.5439903736114502\n",
      "Epoch: 2, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.5615583658218384\n",
      "LC Training Loss (Full): 1.5304127931594849\n",
      "Epoch: 2, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.5556626319885254\n",
      "LC Training Loss (Full): 1.5341293811798096\n",
      "Epoch: 2, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.5413899421691895\n",
      "LC Training Loss (Full): 1.498176097869873\n",
      "model accuracy: 0.925\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.927\n",
      "Full accuracy: 0.925, LC accuracy: 0.927, Decomposed-Full accuracy: 0.893, Decomposed-Restored accuracy: 0.893\n",
      "Epoch: 2, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.558127522468567\n",
      "LC Training Loss (Full): 1.5294402837753296\n",
      "Epoch: 2, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.5383973121643066\n",
      "LC Training Loss (Full): 1.5071345567703247\n",
      "Epoch: 2, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.5659042596817017\n",
      "LC Training Loss (Full): 1.5132863521575928\n",
      "Epoch: 2, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.581773281097412\n",
      "LC Training Loss (Full): 1.570062518119812\n",
      "Epoch: 2, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5752092599868774\n",
      "LC Training Loss (Full): 1.5220757722854614\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.96875\n",
      "model accuracy: 0.922\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.893\n",
      "model accuracy: 0.923\n",
      "Full accuracy: 0.922, LC accuracy: 0.923, Decomposed-Full accuracy: 0.893, Decomposed-Restored accuracy: 0.893\n",
      "Epoch: 2, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.5002588033676147\n",
      "LC Training Loss (Full): 1.4973870515823364\n",
      "Epoch: 2, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.5837552547454834\n",
      "LC Training Loss (Full): 1.5315983295440674\n",
      "Epoch: 2, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.578742504119873\n",
      "LC Training Loss (Full): 1.5616450309753418\n",
      "Epoch: 2, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.6225776672363281\n",
      "LC Training Loss (Full): 1.593858242034912\n",
      "Epoch: 2, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.6110572814941406\n",
      "LC Training Loss (Full): 1.5737676620483398\n",
      "model accuracy: 0.928\n",
      "model accuracy: 0.895\n",
      "model accuracy: 0.894\n",
      "model accuracy: 0.924\n",
      "Full accuracy: 0.928, LC accuracy: 0.924, Decomposed-Full accuracy: 0.895, Decomposed-Restored accuracy: 0.894\n",
      "Epoch: 2, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.4745736122131348\n",
      "LC Training Loss (Full): 1.4739785194396973\n",
      "Epoch: 2, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.5520004034042358\n",
      "LC Training Loss (Full): 1.525937557220459\n",
      "Epoch: 2, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.600091814994812\n",
      "LC Training Loss (Full): 1.5500532388687134\n",
      "Epoch: 2, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.5256086587905884\n",
      "LC Training Loss (Full): 1.5234780311584473\n",
      "Epoch: 2, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_11\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_11/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5448367595672607\n",
      "LC Training Loss (Full): 1.5308194160461426\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 0.9375\n",
      "model accuracy: 0.933\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.934\n",
      "Full accuracy: 0.933, LC accuracy: 0.934, Decomposed-Full accuracy: 0.896, Decomposed-Restored accuracy: 0.896\n",
      "Epoch: 2, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 1.4761039018630981\n",
      "LC Training Loss (Full): 1.5167418718338013\n",
      "Epoch: 3, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5868594646453857\n",
      "LC Training Loss (Full): 1.5408495664596558\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.9375\n",
      "Epoch: 3, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.633999228477478\n",
      "LC Training Loss (Full): 1.558357834815979\n",
      "Epoch: 3, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.5940167903900146\n",
      "LC Training Loss (Full): 1.5722150802612305\n",
      "Epoch: 3, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.5557518005371094\n",
      "LC Training Loss (Full): 1.5461667776107788\n",
      "Epoch: 3, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.5373681783676147\n",
      "LC Training Loss (Full): 1.522204875946045\n",
      "Epoch: 3, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.5856415033340454\n",
      "LC Training Loss (Full): 1.560964822769165\n",
      "model accuracy: 0.934\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.931\n",
      "Full accuracy: 0.934, LC accuracy: 0.931, Decomposed-Full accuracy: 0.896, Decomposed-Restored accuracy: 0.896\n",
      "Epoch: 3, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.5368578433990479\n",
      "LC Training Loss (Full): 1.5273610353469849\n",
      "Epoch: 3, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.5191625356674194\n",
      "LC Training Loss (Full): 1.483471155166626\n",
      "Epoch: 3, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.6601965427398682\n",
      "LC Training Loss (Full): 1.6481088399887085\n",
      "Epoch: 3, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.5727524757385254\n",
      "LC Training Loss (Full): 1.5530949831008911\n",
      "Epoch: 3, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5141955614089966\n",
      "LC Training Loss (Full): 1.5219038724899292\n",
      "Training Accuracy | Decomposed: 0.96875, Full : 0.96875\n",
      "model accuracy: 0.934\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.935\n",
      "Full accuracy: 0.934, LC accuracy: 0.935, Decomposed-Full accuracy: 0.897, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 3, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.5992839336395264\n",
      "LC Training Loss (Full): 1.5283334255218506\n",
      "Epoch: 3, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.5512850284576416\n",
      "LC Training Loss (Full): 1.5258886814117432\n",
      "Epoch: 3, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.5134896039962769\n",
      "LC Training Loss (Full): 1.5105880498886108\n",
      "Epoch: 3, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.590035080909729\n",
      "LC Training Loss (Full): 1.5457383394241333\n",
      "Epoch: 3, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.5706251859664917\n",
      "LC Training Loss (Full): 1.540901780128479\n",
      "model accuracy: 0.94\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.934\n",
      "Full accuracy: 0.94, LC accuracy: 0.934, Decomposed-Full accuracy: 0.897, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 3, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.557931661605835\n",
      "LC Training Loss (Full): 1.5076302289962769\n",
      "Epoch: 3, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.648984432220459\n",
      "LC Training Loss (Full): 1.5915594100952148\n",
      "Epoch: 3, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.591077446937561\n",
      "LC Training Loss (Full): 1.5681453943252563\n",
      "Epoch: 3, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.586755394935608\n",
      "LC Training Loss (Full): 1.542894721031189\n",
      "Epoch: 3, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5616405010223389\n",
      "LC Training Loss (Full): 1.5361546277999878\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.96875\n",
      "model accuracy: 0.939\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.939\n",
      "Full accuracy: 0.939, LC accuracy: 0.939, Decomposed-Full accuracy: 0.897, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 3, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.5207619667053223\n",
      "LC Training Loss (Full): 1.484492301940918\n",
      "Epoch: 3, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.5423424243927002\n",
      "LC Training Loss (Full): 1.5421446561813354\n",
      "Epoch: 3, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.6975444555282593\n",
      "LC Training Loss (Full): 1.6407147645950317\n",
      "Epoch: 3, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.6060731410980225\n",
      "LC Training Loss (Full): 1.5298192501068115\n",
      "Epoch: 3, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.523832082748413\n",
      "LC Training Loss (Full): 1.5308773517608643\n",
      "model accuracy: 0.937\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.938\n",
      "Full accuracy: 0.937, LC accuracy: 0.938, Decomposed-Full accuracy: 0.897, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 3, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.5590887069702148\n",
      "LC Training Loss (Full): 1.5363118648529053\n",
      "Epoch: 3, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.536635160446167\n",
      "LC Training Loss (Full): 1.5443525314331055\n",
      "Epoch: 3, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.5860867500305176\n",
      "LC Training Loss (Full): 1.5378730297088623\n",
      "Epoch: 3, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.5384154319763184\n",
      "LC Training Loss (Full): 1.5187299251556396\n",
      "Epoch: 3, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_15\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_15/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5245230197906494\n",
      "LC Training Loss (Full): 1.5308727025985718\n",
      "Training Accuracy | Decomposed: 0.96875, Full : 0.96875\n",
      "model accuracy: 0.944\n",
      "model accuracy: 0.896\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.944\n",
      "Full accuracy: 0.944, LC accuracy: 0.944, Decomposed-Full accuracy: 0.896, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 3, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 1.6354691982269287\n",
      "LC Training Loss (Full): 1.6142325401306152\n",
      "Epoch: 4, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.527485728263855\n",
      "LC Training Loss (Full): 1.5106840133666992\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 0.96875\n",
      "Epoch: 4, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.4995121955871582\n",
      "LC Training Loss (Full): 1.4924993515014648\n",
      "Epoch: 4, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.6001408100128174\n",
      "LC Training Loss (Full): 1.5366520881652832\n",
      "Epoch: 4, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.7041946649551392\n",
      "LC Training Loss (Full): 1.6019481420516968\n",
      "Epoch: 4, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.5268038511276245\n",
      "LC Training Loss (Full): 1.5023590326309204\n",
      "Epoch: 4, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.493356466293335\n",
      "LC Training Loss (Full): 1.4882627725601196\n",
      "model accuracy: 0.94\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.942\n",
      "Full accuracy: 0.94, LC accuracy: 0.942, Decomposed-Full accuracy: 0.897, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 4, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.5615675449371338\n",
      "LC Training Loss (Full): 1.5378483533859253\n",
      "Epoch: 4, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.5979574918746948\n",
      "LC Training Loss (Full): 1.5615557432174683\n",
      "Epoch: 4, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.4982291460037231\n",
      "LC Training Loss (Full): 1.4754023551940918\n",
      "Epoch: 4, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.4745784997940063\n",
      "LC Training Loss (Full): 1.4683703184127808\n",
      "Epoch: 4, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5678389072418213\n",
      "LC Training Loss (Full): 1.5209612846374512\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.96875\n",
      "model accuracy: 0.934\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.933\n",
      "Full accuracy: 0.934, LC accuracy: 0.933, Decomposed-Full accuracy: 0.897, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 4, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.609379529953003\n",
      "LC Training Loss (Full): 1.5543158054351807\n",
      "Epoch: 4, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.580802083015442\n",
      "LC Training Loss (Full): 1.5789580345153809\n",
      "Epoch: 4, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.4825804233551025\n",
      "LC Training Loss (Full): 1.467682123184204\n",
      "Epoch: 4, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.5508122444152832\n",
      "LC Training Loss (Full): 1.5081565380096436\n",
      "Epoch: 4, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.5909457206726074\n",
      "LC Training Loss (Full): 1.5681408643722534\n",
      "model accuracy: 0.934\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.934\n",
      "Full accuracy: 0.934, LC accuracy: 0.934, Decomposed-Full accuracy: 0.897, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 4, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.600150227546692\n",
      "LC Training Loss (Full): 1.5337448120117188\n",
      "Epoch: 4, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.6847703456878662\n",
      "LC Training Loss (Full): 1.6307750940322876\n",
      "Epoch: 4, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.509748935699463\n",
      "LC Training Loss (Full): 1.5191296339035034\n",
      "Epoch: 4, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.6909711360931396\n",
      "LC Training Loss (Full): 1.6178555488586426\n",
      "Epoch: 4, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5254863500595093\n",
      "LC Training Loss (Full): 1.513476848602295\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 0.96875\n",
      "model accuracy: 0.942\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.897\n",
      "model accuracy: 0.941\n",
      "Full accuracy: 0.942, LC accuracy: 0.941, Decomposed-Full accuracy: 0.898, Decomposed-Restored accuracy: 0.897\n",
      "Epoch: 4, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.6396405696868896\n",
      "LC Training Loss (Full): 1.6184964179992676\n",
      "Epoch: 4, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.5648469924926758\n",
      "LC Training Loss (Full): 1.5318230390548706\n",
      "Epoch: 4, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.6335335969924927\n",
      "LC Training Loss (Full): 1.5883595943450928\n",
      "Epoch: 4, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.5805392265319824\n",
      "LC Training Loss (Full): 1.5781687498092651\n",
      "Epoch: 4, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.560820460319519\n",
      "LC Training Loss (Full): 1.5192049741744995\n",
      "model accuracy: 0.949\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.943\n",
      "Full accuracy: 0.949, LC accuracy: 0.943, Decomposed-Full accuracy: 0.898, Decomposed-Restored accuracy: 0.898\n",
      "Epoch: 4, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.5968235731124878\n",
      "LC Training Loss (Full): 1.5470678806304932\n",
      "Epoch: 4, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.534930944442749\n",
      "LC Training Loss (Full): 1.5390772819519043\n",
      "Epoch: 4, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.5637377500534058\n",
      "LC Training Loss (Full): 1.5210198163986206\n",
      "Epoch: 4, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 1.5788993835449219\n",
      "LC Training Loss (Full): 1.5473754405975342\n",
      "Epoch: 4, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_19\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_19/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.513381004333496\n",
      "LC Training Loss (Full): 1.4705350399017334\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 1.0\n",
      "model accuracy: 0.948\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.948\n",
      "Full accuracy: 0.948, LC accuracy: 0.948, Decomposed-Full accuracy: 0.898, Decomposed-Restored accuracy: 0.898\n",
      "Epoch: 4, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 1.5963666439056396\n",
      "LC Training Loss (Full): 1.5951628684997559\n",
      "Epoch: 5, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5016024112701416\n",
      "LC Training Loss (Full): 1.4865072965621948\n",
      "Training Accuracy | Decomposed: 0.96875, Full : 1.0\n",
      "Epoch: 5, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.5885604619979858\n",
      "LC Training Loss (Full): 1.5489593744277954\n",
      "Epoch: 5, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.559104084968567\n",
      "LC Training Loss (Full): 1.5096054077148438\n",
      "Epoch: 5, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.5847898721694946\n",
      "LC Training Loss (Full): 1.5644954442977905\n",
      "Epoch: 5, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.4738948345184326\n",
      "LC Training Loss (Full): 1.4793797731399536\n",
      "Epoch: 5, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.5356793403625488\n",
      "LC Training Loss (Full): 1.486566424369812\n",
      "model accuracy: 0.941\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.898\n",
      "model accuracy: 0.946\n",
      "Full accuracy: 0.941, LC accuracy: 0.946, Decomposed-Full accuracy: 0.898, Decomposed-Restored accuracy: 0.898\n",
      "Epoch: 5, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.537091612815857\n",
      "LC Training Loss (Full): 1.4983160495758057\n",
      "Epoch: 5, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.5454623699188232\n",
      "LC Training Loss (Full): 1.5075515508651733\n",
      "Epoch: 5, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.5702719688415527\n",
      "LC Training Loss (Full): 1.5103739500045776\n",
      "Epoch: 5, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.5242785215377808\n",
      "LC Training Loss (Full): 1.4824153184890747\n",
      "Epoch: 5, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.6300750970840454\n",
      "LC Training Loss (Full): 1.570858120918274\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.90625\n",
      "model accuracy: 0.947\n",
      "model accuracy: 0.9\n",
      "model accuracy: 0.899\n",
      "model accuracy: 0.945\n",
      "Full accuracy: 0.947, LC accuracy: 0.945, Decomposed-Full accuracy: 0.9, Decomposed-Restored accuracy: 0.899\n",
      "Epoch: 5, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.594760537147522\n",
      "LC Training Loss (Full): 1.5784049034118652\n",
      "Epoch: 5, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.6416999101638794\n",
      "LC Training Loss (Full): 1.5369099378585815\n",
      "Epoch: 5, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.6222504377365112\n",
      "LC Training Loss (Full): 1.6178736686706543\n",
      "Epoch: 5, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.5967541933059692\n",
      "LC Training Loss (Full): 1.522228479385376\n",
      "Epoch: 5, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.6651118993759155\n",
      "LC Training Loss (Full): 1.5630038976669312\n",
      "model accuracy: 0.954\n",
      "model accuracy: 0.901\n",
      "model accuracy: 0.9\n",
      "model accuracy: 0.95\n",
      "Full accuracy: 0.954, LC accuracy: 0.95, Decomposed-Full accuracy: 0.901, Decomposed-Restored accuracy: 0.9\n",
      "Epoch: 5, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.6103055477142334\n",
      "LC Training Loss (Full): 1.5999470949172974\n",
      "Epoch: 5, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.511080265045166\n",
      "LC Training Loss (Full): 1.4966546297073364\n",
      "Epoch: 5, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.6301425695419312\n",
      "LC Training Loss (Full): 1.5773098468780518\n",
      "Epoch: 5, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.5468299388885498\n",
      "LC Training Loss (Full): 1.5409313440322876\n",
      "Epoch: 5, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5164365768432617\n",
      "LC Training Loss (Full): 1.5286390781402588\n",
      "Training Accuracy | Decomposed: 0.96875, Full : 0.96875\n",
      "model accuracy: 0.954\n",
      "model accuracy: 0.901\n",
      "model accuracy: 0.901\n",
      "model accuracy: 0.954\n",
      "Full accuracy: 0.954, LC accuracy: 0.954, Decomposed-Full accuracy: 0.901, Decomposed-Restored accuracy: 0.901\n",
      "Epoch: 5, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.5665565729141235\n",
      "LC Training Loss (Full): 1.536664605140686\n",
      "Epoch: 5, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.5460954904556274\n",
      "LC Training Loss (Full): 1.5214753150939941\n",
      "Epoch: 5, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.655719518661499\n",
      "LC Training Loss (Full): 1.622631311416626\n",
      "Epoch: 5, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.5881845951080322\n",
      "LC Training Loss (Full): 1.5556368827819824\n",
      "Epoch: 5, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.512948751449585\n",
      "LC Training Loss (Full): 1.5025321245193481\n",
      "model accuracy: 0.955\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.955\n",
      "Full accuracy: 0.955, LC accuracy: 0.955, Decomposed-Full accuracy: 0.902, Decomposed-Restored accuracy: 0.902\n",
      "Epoch: 5, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.5137640237808228\n",
      "LC Training Loss (Full): 1.49192214012146\n",
      "Epoch: 5, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.5837377309799194\n",
      "LC Training Loss (Full): 1.5474907159805298\n",
      "Epoch: 5, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.5719540119171143\n",
      "LC Training Loss (Full): 1.5362776517868042\n",
      "Epoch: 5, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.5593230724334717\n",
      "LC Training Loss (Full): 1.5231590270996094\n",
      "Epoch: 5, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_23\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_23/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5308308601379395\n",
      "LC Training Loss (Full): 1.4914623498916626\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 1.0\n",
      "model accuracy: 0.95\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.949\n",
      "Full accuracy: 0.95, LC accuracy: 0.949, Decomposed-Full accuracy: 0.902, Decomposed-Restored accuracy: 0.902\n",
      "Epoch: 5, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 1.4759485721588135\n",
      "LC Training Loss (Full): 1.4912822246551514\n",
      "Epoch: 6, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5710636377334595\n",
      "LC Training Loss (Full): 1.5316369533538818\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.9375\n",
      "Epoch: 6, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.5615918636322021\n",
      "LC Training Loss (Full): 1.507041335105896\n",
      "Epoch: 6, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.7088383436203003\n",
      "LC Training Loss (Full): 1.6116806268692017\n",
      "Epoch: 6, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.5057440996170044\n",
      "LC Training Loss (Full): 1.478193998336792\n",
      "Epoch: 6, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.5532094240188599\n",
      "LC Training Loss (Full): 1.5486040115356445\n",
      "Epoch: 6, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.5500679016113281\n",
      "LC Training Loss (Full): 1.5129553079605103\n",
      "model accuracy: 0.948\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.947\n",
      "Full accuracy: 0.948, LC accuracy: 0.947, Decomposed-Full accuracy: 0.902, Decomposed-Restored accuracy: 0.902\n",
      "Epoch: 6, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.5468345880508423\n",
      "LC Training Loss (Full): 1.5148025751113892\n",
      "Epoch: 6, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.582158088684082\n",
      "LC Training Loss (Full): 1.4887516498565674\n",
      "Epoch: 6, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.5296529531478882\n",
      "LC Training Loss (Full): 1.5115761756896973\n",
      "Epoch: 6, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 1.574312686920166\n",
      "LC Training Loss (Full): 1.5257370471954346\n",
      "Epoch: 6, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.506668210029602\n",
      "LC Training Loss (Full): 1.4991788864135742\n",
      "Training Accuracy | Decomposed: 0.96875, Full : 0.96875\n",
      "model accuracy: 0.952\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.902\n",
      "model accuracy: 0.951\n",
      "Full accuracy: 0.952, LC accuracy: 0.951, Decomposed-Full accuracy: 0.902, Decomposed-Restored accuracy: 0.902\n",
      "Epoch: 6, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.5468151569366455\n",
      "LC Training Loss (Full): 1.4827852249145508\n",
      "Epoch: 6, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.5890247821807861\n",
      "LC Training Loss (Full): 1.5599919557571411\n",
      "Epoch: 6, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.6817042827606201\n",
      "LC Training Loss (Full): 1.5934734344482422\n",
      "Epoch: 6, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.6770915985107422\n",
      "LC Training Loss (Full): 1.584201455116272\n",
      "Epoch: 6, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.5185080766677856\n",
      "LC Training Loss (Full): 1.5093317031860352\n",
      "model accuracy: 0.957\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.953\n",
      "Full accuracy: 0.957, LC accuracy: 0.953, Decomposed-Full accuracy: 0.903, Decomposed-Restored accuracy: 0.903\n",
      "Epoch: 6, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.5355762243270874\n",
      "LC Training Loss (Full): 1.5337615013122559\n",
      "Epoch: 6, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.6261906623840332\n",
      "LC Training Loss (Full): 1.5584900379180908\n",
      "Epoch: 6, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.5347654819488525\n",
      "LC Training Loss (Full): 1.5200265645980835\n",
      "Epoch: 6, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.5357366800308228\n",
      "LC Training Loss (Full): 1.4961602687835693\n",
      "Epoch: 6, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.572300672531128\n",
      "LC Training Loss (Full): 1.4984431266784668\n",
      "Training Accuracy | Decomposed: 0.875, Full : 1.0\n",
      "model accuracy: 0.957\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.958\n",
      "Full accuracy: 0.957, LC accuracy: 0.958, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 6, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.587638020515442\n",
      "LC Training Loss (Full): 1.5476467609405518\n",
      "Epoch: 6, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.6322367191314697\n",
      "LC Training Loss (Full): 1.573580026626587\n",
      "Epoch: 6, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.5460630655288696\n",
      "LC Training Loss (Full): 1.5402063131332397\n",
      "Epoch: 6, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.5811902284622192\n",
      "LC Training Loss (Full): 1.5505019426345825\n",
      "Epoch: 6, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.5323855876922607\n",
      "LC Training Loss (Full): 1.5198254585266113\n",
      "model accuracy: 0.958\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.956\n",
      "Full accuracy: 0.958, LC accuracy: 0.956, Decomposed-Full accuracy: 0.903, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 6, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.5308475494384766\n",
      "LC Training Loss (Full): 1.501822590827942\n",
      "Epoch: 6, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.5395047664642334\n",
      "LC Training Loss (Full): 1.5154459476470947\n",
      "Epoch: 6, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.530767798423767\n",
      "LC Training Loss (Full): 1.521154761314392\n",
      "Epoch: 6, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 1.5868074893951416\n",
      "LC Training Loss (Full): 1.5480808019638062\n",
      "Epoch: 6, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_27\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_27/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.4955010414123535\n",
      "LC Training Loss (Full): 1.4971849918365479\n",
      "Training Accuracy | Decomposed: 0.96875, Full : 0.96875\n",
      "model accuracy: 0.955\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.903\n",
      "model accuracy: 0.955\n",
      "Full accuracy: 0.955, LC accuracy: 0.955, Decomposed-Full accuracy: 0.903, Decomposed-Restored accuracy: 0.903\n",
      "Epoch: 6, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 1.4634358882904053\n",
      "LC Training Loss (Full): 1.4837692975997925\n",
      "Epoch: 7, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5575145483016968\n",
      "LC Training Loss (Full): 1.5305063724517822\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.9375\n",
      "Epoch: 7, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.5644967555999756\n",
      "LC Training Loss (Full): 1.4918110370635986\n",
      "Epoch: 7, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.5991296768188477\n",
      "LC Training Loss (Full): 1.555518627166748\n",
      "Epoch: 7, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.59707772731781\n",
      "LC Training Loss (Full): 1.5663678646087646\n",
      "Epoch: 7, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.5573369264602661\n",
      "LC Training Loss (Full): 1.5111135244369507\n",
      "Epoch: 7, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.5658711194992065\n",
      "LC Training Loss (Full): 1.5256867408752441\n",
      "model accuracy: 0.952\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.952\n",
      "Full accuracy: 0.952, LC accuracy: 0.952, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 7, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.5017199516296387\n",
      "LC Training Loss (Full): 1.4821929931640625\n",
      "Epoch: 7, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.5574748516082764\n",
      "LC Training Loss (Full): 1.4897030591964722\n",
      "Epoch: 7, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.5663907527923584\n",
      "LC Training Loss (Full): 1.5516859292984009\n",
      "Epoch: 7, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 1.5489603281021118\n",
      "LC Training Loss (Full): 1.4948832988739014\n",
      "Epoch: 7, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.6003289222717285\n",
      "LC Training Loss (Full): 1.5675866603851318\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.90625\n",
      "model accuracy: 0.956\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.956\n",
      "Full accuracy: 0.956, LC accuracy: 0.956, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 7, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.5807898044586182\n",
      "LC Training Loss (Full): 1.53982675075531\n",
      "Epoch: 7, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.534212589263916\n",
      "LC Training Loss (Full): 1.534895658493042\n",
      "Epoch: 7, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.5842827558517456\n",
      "LC Training Loss (Full): 1.5501961708068848\n",
      "Epoch: 7, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.5538994073867798\n",
      "LC Training Loss (Full): 1.4769738912582397\n",
      "Epoch: 7, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.5654661655426025\n",
      "LC Training Loss (Full): 1.5124356746673584\n",
      "model accuracy: 0.955\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.956\n",
      "Full accuracy: 0.955, LC accuracy: 0.956, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 7, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.6294052600860596\n",
      "LC Training Loss (Full): 1.5735399723052979\n",
      "Epoch: 7, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.6539463996887207\n",
      "LC Training Loss (Full): 1.567247986793518\n",
      "Epoch: 7, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.5966439247131348\n",
      "LC Training Loss (Full): 1.550498366355896\n",
      "Epoch: 7, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 1.5772159099578857\n",
      "LC Training Loss (Full): 1.5153251886367798\n",
      "Epoch: 7, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5480133295059204\n",
      "LC Training Loss (Full): 1.5123993158340454\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.96875\n",
      "model accuracy: 0.964\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.962\n",
      "Full accuracy: 0.964, LC accuracy: 0.962, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 7, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.5251456499099731\n",
      "LC Training Loss (Full): 1.519926905632019\n",
      "Epoch: 7, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.5750068426132202\n",
      "LC Training Loss (Full): 1.4868230819702148\n",
      "Epoch: 7, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.5386608839035034\n",
      "LC Training Loss (Full): 1.5571786165237427\n",
      "Epoch: 7, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.583160400390625\n",
      "LC Training Loss (Full): 1.5121972560882568\n",
      "Epoch: 7, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.535767912864685\n",
      "LC Training Loss (Full): 1.4903125762939453\n",
      "model accuracy: 0.964\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.964\n",
      "Full accuracy: 0.964, LC accuracy: 0.964, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 7, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.5555808544158936\n",
      "LC Training Loss (Full): 1.4959099292755127\n",
      "Epoch: 7, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.5259661674499512\n",
      "LC Training Loss (Full): 1.4982140064239502\n",
      "Epoch: 7, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.5975803136825562\n",
      "LC Training Loss (Full): 1.549652099609375\n",
      "Epoch: 7, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.5772693157196045\n",
      "LC Training Loss (Full): 1.5617836713790894\n",
      "Epoch: 7, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_31\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_31/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.4711676836013794\n",
      "LC Training Loss (Full): 1.4699596166610718\n",
      "Training Accuracy | Decomposed: 1.0, Full : 1.0\n",
      "model accuracy: 0.963\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.904\n",
      "model accuracy: 0.963\n",
      "Full accuracy: 0.963, LC accuracy: 0.963, Decomposed-Full accuracy: 0.904, Decomposed-Restored accuracy: 0.904\n",
      "Epoch: 7, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 1.4644811153411865\n",
      "LC Training Loss (Full): 1.4636873006820679\n",
      "Epoch: 8, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5193734169006348\n",
      "LC Training Loss (Full): 1.5000849962234497\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 0.96875\n",
      "Epoch: 8, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.5130317211151123\n",
      "LC Training Loss (Full): 1.5029711723327637\n",
      "Epoch: 8, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.662226915359497\n",
      "LC Training Loss (Full): 1.516588568687439\n",
      "Epoch: 8, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.559303879737854\n",
      "LC Training Loss (Full): 1.5150409936904907\n",
      "Epoch: 8, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.56083083152771\n",
      "LC Training Loss (Full): 1.5206665992736816\n",
      "Epoch: 8, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.6116986274719238\n",
      "LC Training Loss (Full): 1.5374431610107422\n",
      "model accuracy: 0.963\n",
      "model accuracy: 0.905\n",
      "model accuracy: 0.905\n",
      "model accuracy: 0.963\n",
      "Full accuracy: 0.963, LC accuracy: 0.963, Decomposed-Full accuracy: 0.905, Decomposed-Restored accuracy: 0.905\n",
      "Epoch: 8, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.5872154235839844\n",
      "LC Training Loss (Full): 1.5203051567077637\n",
      "Epoch: 8, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.558007836341858\n",
      "LC Training Loss (Full): 1.509842038154602\n",
      "Epoch: 8, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.5091755390167236\n",
      "LC Training Loss (Full): 1.511091709136963\n",
      "Epoch: 8, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 1.6882182359695435\n",
      "LC Training Loss (Full): 1.5634666681289673\n",
      "Epoch: 8, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\\base_model.pt\n",
      "old_lc | saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_33/initial_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.5351306200027466\n",
      "LC Training Loss (Full): 1.5238730907440186\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 0.96875\n",
      "model accuracy: 0.963\n",
      "model accuracy: 0.905\n",
      "model accuracy: 0.905\n",
      "model accuracy: 0.963\n",
      "Full accuracy: 0.963, LC accuracy: 0.963, Decomposed-Full accuracy: 0.905, Decomposed-Restored accuracy: 0.905\n",
      "Epoch: 8, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 1.5628511905670166\n",
      "LC Training Loss (Full): 1.5470964908599854\n",
      "Epoch: 8, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 1.5625381469726562\n",
      "LC Training Loss (Full): 1.5395543575286865\n",
      "Epoch: 8, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 1.5305306911468506\n",
      "LC Training Loss (Full): 1.5173933506011963\n",
      "Epoch: 8, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 1.4753443002700806\n",
      "LC Training Loss (Full): 1.4723562002182007\n",
      "Epoch: 8, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 1.6161930561065674\n",
      "LC Training Loss (Full): 1.5426890850067139\n",
      "model accuracy: 0.96\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.906\n",
      "model accuracy: 0.962\n",
      "Full accuracy: 0.96, LC accuracy: 0.962, Decomposed-Full accuracy: 0.906, Decomposed-Restored accuracy: 0.906\n",
      "Epoch: 8, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 1.5769611597061157\n",
      "LC Training Loss (Full): 1.5447196960449219\n",
      "Epoch: 8, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/old-lc/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 1.6119354963302612\n",
      "LC Training Loss (Full): 1.5352253913879395\n",
      "Epoch: 8, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/vitS/lobranch/set_33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 116\u001b[0m\n\u001b[0;32m    114\u001b[0m cstate \u001b[38;5;241m=\u001b[39m model_original\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[0;32m    115\u001b[0m old_lc_delta, old_lc_bias \u001b[38;5;241m=\u001b[39m olc\u001b[38;5;241m.\u001b[39mgenerate_delta_gpu(prev_state, cstate, DECOMPOSED_LAYERS)\n\u001b[1;32m--> 116\u001b[0m olc_compressed_delta, update_prev \u001b[38;5;241m=\u001b[39m \u001b[43molc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_lc_delta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m olc\u001b[38;5;241m.\u001b[39msave_checkpoint(SAVE_LOC_OLC \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/set_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(current_set_old_lc), olc_compressed_delta, \n\u001b[0;32m    118\u001b[0m                     old_lc_bias, current_iter_old_lc)\n\u001b[0;32m    119\u001b[0m prev_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(prev_state, update_prev)\n",
      "File \u001b[1;32mc:\\Personal\\Singapour\\PFE\\code_of_shu-heng_with_models\\pfe_lc_lora\\old_lc\\main.py:744\u001b[0m, in \u001b[0;36mcompress_data\u001b[1;34m(δt, num_bits, threshhold)\u001b[0m\n\u001b[0;32m    741\u001b[0m     mp[(δt_exp[i], δt_sign[i])]\u001b[38;5;241m.\u001b[39mappend((i, δt[i]))\n\u001b[0;32m    742\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mp:\n\u001b[0;32m    743\u001b[0m     mp[k] \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39marray([x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mp[k]])), \n\u001b[1;32m--> 744\u001b[0m              [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mp[k]])\n\u001b[0;32m    745\u001b[0m mp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(mp\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# print(\"len(mp):\", len(mp))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Personal\\Singapour\\PFE\\code_of_shu-heng_with_models\\pfe_lc_lora\\old_lc\\main.py:744\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    741\u001b[0m     mp[(δt_exp[i], δt_sign[i])]\u001b[38;5;241m.\u001b[39mappend((i, δt[i]))\n\u001b[0;32m    742\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mp:\n\u001b[0;32m    743\u001b[0m     mp[k] \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39marray([x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mp[k]])), \n\u001b[1;32m--> 744\u001b[0m              [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mp[k]])\n\u001b[0;32m    745\u001b[0m mp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(mp\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# print(\"len(mp):\", len(mp))\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the maximum and minimum values of the delta and decomposed delta\n",
    "delta_normal_max = []\n",
    "delta_normal_min = []\n",
    "delta_decomposed_max = []\n",
    "delta_decomposed_min = []\n",
    "\n",
    "# Initialize lists to store the maximum and minimum values of the compressed delta and decomposed delta\n",
    "full_accuracy = []\n",
    "decomposed_full_accuracy = []\n",
    "restored_accuracy = []\n",
    "lc_accuracy = []\n",
    "\n",
    "# Initialize the current iteration and set to 0\n",
    "current_iter = 0\n",
    "current_set = 0\n",
    "\n",
    "# Initialize the current iteration and set to 0 for the old LC method\n",
    "current_iter_old_lc = 0\n",
    "current_set_old_lc = 0\n",
    "\n",
    "# Define a function to evaluate the accuracy of the model on the test set\n",
    "acc = lambda x, y : (torch.max(x, 1)[1] == y).sum().item() / y.size(0)\n",
    "\n",
    "# Train the model for 100 epochs\n",
    "for epch in range(20):\n",
    "    # Iterate over the training data\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        print(\"Epoch: {}, Iteration: {}\".format(epch, i))\n",
    "        \n",
    "        # Create a new set directory if it does not exist\n",
    "        set_path = \"/set_{}\".format(current_set)\n",
    "        if not os.path.exists(SAVE_LOC + set_path):\n",
    "            os.makedirs(SAVE_LOC + set_path)\n",
    "\n",
    "        # Check if it is the first iteration of the first epoch\n",
    "        if i == 0 and epch == 0: # first iteration, create baseline model\n",
    "            base, base_decomp = lc.extract_weights_gpu(model, SAVE_LOC + \n",
    "                                                       \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "        # Check if it is a full snapshot\n",
    "        else:\n",
    "            # Check if the iteration is a multiple of 10\n",
    "            if i % 10 == 0: \n",
    "                # full snapshot!\n",
    "\n",
    "                new_model = lazy_restore_gpu(base, base_decomp, bias, ViT((1, 28, 28), n_patches=14, n_blocks=7, hidden_d=512, n_heads=8, out_d=10), \n",
    "                                          original.state_dict(), DECOMPOSED_LAYERS, rank = RANK, scaling = SCALING)\n",
    "                # Changing previous \"original model\" used to restore the loRA model.\n",
    "                original = new_model \n",
    "                \n",
    "                current_set += 1\n",
    "                current_iter = 0\n",
    "\n",
    "                # Create a new set directory if it does not exist\n",
    "                set_path = \"/set_{}\".format(current_set)\n",
    "                if not os.path.exists(SAVE_LOC + set_path):\n",
    "                    os.makedirs(SAVE_LOC + set_path)\n",
    "                \n",
    "                # Rebuilding LoRA layers => reset model!\n",
    "\n",
    "                # Get the base model weights and biases\n",
    "                w, b = getBase(original)\n",
    "                # Create a new model with the base weights and specified rank\n",
    "                model = ViTS_LowRank(w, b , RANK, (1, 28, 28), n_patches=14, n_blocks=7, hidden_d=512, n_heads=8, out_d=10).to(device)\n",
    "                # Optimizer for the model's parameters with Stochastic Gradient Descent (SGD) and specified learning rate\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "                # Load state dictionary from full snapshot, including specified decomposed layers, and load it into the model\n",
    "                load_sd_decomp(original.state_dict(), model, DECOMPOSED_LAYERS)\n",
    "                # The base for all delta calculations\n",
    "                base, base_decomp = lc.extract_weights_gpu(model, SAVE_LOC + \n",
    "                                                       \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "\n",
    "            # If it is not a full snapshot, perform delta compression\n",
    "            else:\n",
    "                # Delta-compression : The delta for the weights of the normal and decomposed layers.\n",
    "                # Also returns the full dictionary, which holds the bias.\n",
    "                delta, decomp_delta, bias = lc.generate_delta_gpu(base, \n",
    "                                                                base_decomp, model.state_dict(), DECOMPOSED_LAYERS)\n",
    "                \n",
    "                # Compressing the delta and decomposed delta\n",
    "                compressed_delta, full_delta, compressed_dcomp_delta, full_dcomp_delta  = lc.compress_delta(delta, \n",
    "                                                                                                            decomp_delta)\n",
    "                \n",
    "                # Saving checkpoint\n",
    "                lc.save_checkpoint(compressed_delta, compressed_dcomp_delta, bias, current_iter, SAVE_LOC + \n",
    "                                \"/set_{}\".format(current_set))\n",
    "    \n",
    "                # Update base and base_decomp\n",
    "                base = np.add(base, full_delta) # Replace base with latest for delta to accumulate.\n",
    "                base_decomp = np.add(full_dcomp_delta, base_decomp)\n",
    "\n",
    "                # Update current iteration\n",
    "                current_iter += 1\n",
    "            \n",
    "        # # ==========================\n",
    "        # # Saving using LC-Checkpoint\n",
    "        # # ==========================\n",
    "                \n",
    "        if i == 0 and epch == 0:\n",
    "            cstate = model_original.state_dict()\n",
    "            set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "            if not os.path.exists(SAVE_LOC_OLC + set_path):\n",
    "                os.makedirs(SAVE_LOC_OLC + set_path)\n",
    "            prev_state = olc.extract_weights_gpu(cstate, SAVE_LOC_OLC + set_path,DECOMPOSED_LAYERS)\n",
    "        else:\n",
    "            if i % 10 == 0:\n",
    "                cstate = model_original.state_dict()\n",
    "                current_set_old_lc += 1\n",
    "                current_iter_old_lc = 0\n",
    "                set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                if not os.path.exists(SAVE_LOC_OLC + set_path):\n",
    "                    os.makedirs(SAVE_LOC_OLC + set_path)\n",
    "                prev_state = olc.extract_weights_gpu(cstate, SAVE_LOC_OLC + set_path, DECOMPOSED_LAYERS)\n",
    "            else:\n",
    "                cstate = model_original.state_dict()\n",
    "                old_lc_delta, old_lc_bias = olc.generate_delta_gpu(prev_state, cstate, DECOMPOSED_LAYERS)\n",
    "                olc_compressed_delta, update_prev = olc.compress_data(old_lc_delta, num_bits = 3)\n",
    "                olc.save_checkpoint(SAVE_LOC_OLC + \"/set_{}\".format(current_set_old_lc), olc_compressed_delta, \n",
    "                                    old_lc_bias, current_iter_old_lc)\n",
    "                prev_state = np.add(prev_state, update_prev)\n",
    "                current_iter_old_lc += 1\n",
    "        \n",
    "        # ==========================\n",
    "        # Training on Low-Rank Model\n",
    "        # ==========================\n",
    "\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs,labels)\n",
    "        print(\"LoRA+LC Training Loss (Decomposed): {}\".format(loss.item()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        # ======================\n",
    "        # Training on Full Model\n",
    "        # ======================\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer_full.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs_full = model_original(inputs)\n",
    "        loss_full = torch.nn.functional.cross_entropy(outputs_full,labels)\n",
    "        print(\"LC Training Loss (Full): {}\".format(loss_full.item()))\n",
    "        loss_full.backward()\n",
    "        optimizer_full.step()\n",
    "\n",
    "        # Print training accuracy every 20 iterations\n",
    "        if i % 10 == 0:\n",
    "            print(\"Training Accuracy | Decomposed: {}, Full : {}\".format(acc(outputs, labels), \n",
    "                                                                         acc(outputs_full, labels)))\n",
    "\n",
    "        # Evaluation every 5 iterations\n",
    "        if i != 0  and i % 5 == 0: # Evaluation on testing set\n",
    "\n",
    "            # Evaluate the accuracy of the model on the test set\n",
    "            full_accuracy.append(evaluate_accuracy_gpu(model_original, test_loader))\n",
    "\n",
    "            # Evaluate the accuracy of the model on the test set for decomposed model\n",
    "            decomposed_full_accuracy.append(evaluate_accuracy_gpu(model, test_loader))\n",
    "\n",
    "            # Restore the model from the full snapshot\n",
    "            restored_model = lazy_restore_gpu(base, base_decomp, bias, ViT((1, 28, 28), n_patches=14, n_blocks=7, hidden_d=512, n_heads=8, out_d=10), \n",
    "                                          original.state_dict(), DECOMPOSED_LAYERS, \n",
    "                                          rank = RANK, scaling = SCALING)\n",
    "\n",
    "            # Evaluate the accuracy of the restored model on the test set\n",
    "            restored_accuracy.append(evaluate_accuracy(restored_model, test_loader))\n",
    "\n",
    "            # Restore VGG16NoLite model from the old LC method\n",
    "            restored_lc_model = ViT((1, 28, 28), n_patches=14, n_blocks=7, hidden_d=512, n_heads=8, out_d=10).to(device)\n",
    "            restored_lc_model.load_state_dict(olc.restore_state_dict(prev_state, old_lc_bias, \n",
    "                                                                  restored_model.state_dict(), DECOMPOSED_LAYERS))\n",
    "            lc_accuracy.append(evaluate_accuracy_gpu(restored_lc_model, test_loader))\n",
    "            print(\"Full accuracy: {}, LC accuracy: {}, Decomposed-Full accuracy: {}, Decomposed-Restored accuracy: {}\".format(\n",
    "                full_accuracy[-1], lc_accuracy[-1], decomposed_full_accuracy[-1], restored_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For recovery and not restart from scratch : having the plots and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open a file to save the data (if it exists, otherwise ignore this cell)\n",
    "with open(HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vit/data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Update the data with the new values\n",
    "full_accuracy = data['full_acc']\n",
    "lc_accuracy = data[\"lc_restored_accuracy\"]\n",
    "restored_accuracy = data[\"decomposed_restored_accuracy\"]\n",
    "decomposed_full_accuracy = data[\"decomposed_full_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (30, 5))\n",
    "plt.title(\"Vision Transformer (ViT), Accuracy, Branched @ {} Accuracy\".format(BRANCH_ACC))\n",
    "plt.plot(full_accuracy, label = \"Default Vision Transformer (ViT)\")\n",
    "plt.plot(lc_accuracy, label = \"LC Vision Transformer (ViT)\")\n",
    "plt.plot(decomposed_full_accuracy, label = \"dLoRA Vision Transformer (ViT)\")\n",
    "plt.plot(restored_accuracy, label = \"dLoRA + LC Vision Transformer (ViT)\")\n",
    "plt.xticks([x for x in range(0, 120) if x % 6 == 0], [x for x in range(0, 20)])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the absolute accuracy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rangex = [x for x in range(0, 120) if x % 6 == 0]\n",
    "rangey = [x for x in range(0, 20)]\n",
    "plt.figure(figsize = (40, 10))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title(\"Vision Transformer (ViT) Absolute Accuracy Loss (Default VGG-16 vs LC + dLoRA VGG-16)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(restored_accuracy))), label = \"LC + dLoRA Vision Transformer (ViT)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC Vision Transformer (ViT)\")\n",
    "plt.legend()\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.ylim(0, 0.5)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.set_title(\"Vision Transformer (ViT) Absolute Restoration Accuracy Loss (LC + dLoRA Vision Transformer (ViT) & LC Vision Transformer (ViT))\")\n",
    "plt.plot(np.abs(np.subtract(np.array(restored_accuracy), \n",
    "                     np.array(decomposed_full_accuracy))), label = \"LC + dLoRA Vision Transformer (ViT)\")\n",
    "plt.plot(np.abs(np.subtract(np.array(full_accuracy), \n",
    "                     np.array(lc_accuracy))), label = \"LC Vision Transformer (ViT)\")\n",
    "plt.legend()\n",
    "plt.axhline(y = 0.05, color = 'r')\n",
    "plt.xticks(rangex, rangey)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.ylabel(\"Absolute Accuracy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function which compute the size of compressed and uncompressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def getsize(sl):\n",
    "    dir = [x for x in os.listdir(sl)]\n",
    "    csize, usize = 0, 0\n",
    "    for set in dir:\n",
    "        for f in os.listdir(sl + \"/\" + set):\n",
    "            fp = sl + \"/{}/{}\".format(set, f)\n",
    "            csize += os.path.getsize(fp)\n",
    "            usize += 24 * math.pow(2, 10) # torch checkpoint same size\n",
    "    return csize, usize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print compression ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC-Checkpoint + GZIP\n",
      "Compression Ratio: 244.15200000000002%, Space Savings: 59.041999999999994%\n",
      "LoRA + LC-Checkpoint + GZIP\n",
      "Compression Ratio: 223.928%, Space Savings: 55.342999999999996%\n"
     ]
    }
   ],
   "source": [
    "compressed_size, uncompressed_size = getsize(SAVE_LOC)\n",
    "a, b = evaluate_compression(uncompressed_size, compressed_size)\n",
    "compressed_size, uncompressed_size = getsize(SAVE_LOC_OLC)\n",
    "a1, b1 = evaluate_compression(uncompressed_size, compressed_size)\n",
    "\n",
    "print(\"LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a1, b1))\n",
    "print(\"LoRA + LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_comparison = ViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)\n",
    "\n",
    "# save model into \"comparison_model.pt\"\n",
    "torch.save(model_for_comparison.state_dict(), HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vit/baseline_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data in a dictionary and save it in a file data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"full_acc\" : full_accuracy,\n",
    "    \"decomposed_restored_accuracy\" : restored_accuracy,\n",
    "    \"decomposed_full_accuracy\" : decomposed_full_accuracy,\n",
    "    \"lc_restored_accuracy\" : lc_accuracy\n",
    "}\n",
    "with open(HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/vit/data.json\", 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
