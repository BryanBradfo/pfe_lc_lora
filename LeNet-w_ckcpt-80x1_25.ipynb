{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Efficient Checkpointing on LeNet** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these 3 approaches : \n",
    "1. **Initial accuracy measurement:** Train LeNet on MNIST and achieve a baseline accuracy of around 99.9% without considering poisoned models.\n",
    "2. **Incremental learning:** Implement incremental learning on the divided MNIST subsets and measure the accuracy drop due to this method.\n",
    "3. **LC-checkpoint and Delta LoRA:** Apply LC-checkpoint and Delta LoRA on top of incremental learning and observe the resulting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bradf\\anaconda3\\envs\\py310\\lib\\site-packages\\transformers\\utils\\generic.py:485: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy as spy\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import ssl\n",
    "import pickle, json\n",
    "import src.main as lc\n",
    "import old_lc.main as olc\n",
    "from src.models.LeNet import LeNet\n",
    "import src.compression.deltaCompress as lc_compress\n",
    "from src.models.LeNet_LowRank import getBase, LeNet_LowRank, load_sd_decomp\n",
    "from src.utils.utils import evaluate_accuracy, evaluate_accuracy_gpu, lazy_restore,lazy_restore_gpu, evaluate_compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Connexion to wandb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbryanchen1105\u001b[0m (\u001b[33mbryanbradfo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Bradf\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Connect to W&B\n",
    "wandb.login(key=\"beb938fdf67db528128a4298e19b9997afd83dfd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Variables and Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 1000\n",
    "num_work = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader():\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(0.1307, 0.3081)\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                          download=True, transform=transform)\n",
    "\n",
    "    trainset.data = trainset.data.clone()[:]\n",
    "    trainset.targets = trainset.targets.clone()[:]\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size = train_batch_size,\n",
    "                                              shuffle=True, num_workers=num_work)\n",
    "\n",
    "    testset = datasets.MNIST(root='./data', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "\n",
    "    testset.data = testset.data.clone()[:]\n",
    "    testset.targets = testset.targets.clone()[:]\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = test_batch_size,\n",
    "                                             shuffle=False, num_workers=num_work)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bypass using SSL unverified\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# MNIST dataset \n",
    "train_loader, test_loader = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bypass the matplotlib error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Verify if data loaded correctly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verify the 10 classes of training dataset and 10 classes of testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Going through the dataloader to extract an image per class\n",
    "def get_images_by_class(dataloader):\n",
    "    images_by_class = {i: None for i in range(10)}\n",
    "    for images, labels in dataloader:\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i].item()\n",
    "            if images_by_class[label] is None:\n",
    "                images_by_class[label] = images[i]\n",
    "            if all(v is not None for v in images_by_class.values()):\n",
    "                return images_by_class\n",
    "    return images_by_class\n",
    "\n",
    "def plot_images(images_by_class, title):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(15, 1.5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    for i in range(10):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images_by_class[i].squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_images = get_images_by_class(train_loader)\n",
    "test_images = get_images_by_class(test_loader)\n",
    "\n",
    "plot_images(train_images, \"Trainset Images by Class\")\n",
    "plot_images(test_images, \"Testset Images by Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verify that the 10 first images are visually different**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_first_images(dataloader, title, num_images=10):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 1.5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    images_shown = 0\n",
    "    for images, labels in dataloader:\n",
    "        for i in range(len(images)):\n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "            ax = axes[images_shown]\n",
    "            ax.imshow(images[i].squeeze(), cmap='gray')\n",
    "            ax.axis('off')\n",
    "            images_shown += 1\n",
    "        if images_shown >= num_images:\n",
    "            break\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_first_images(train_loader, \"First 10 Trainset Images\")\n",
    "plot_first_images(test_loader, \"First 10 Testset Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting the dataset into three subsets having each all classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train_loader1: 746\n",
      "Size of train_loader2: 749\n",
      "Size of train_loader3: 750\n",
      "Size of train_loader4: 751\n",
      "Size of train_loader5: 749\n",
      "Size of train_loader6: 749\n",
      "Size of train_loader7: 751\n",
      "Size of train_loader8: 751\n",
      "Size of train_loader9: 749\n",
      "Size of train_loader10: 750\n",
      "Size of train_loader11: 751\n",
      "Size of train_loader12: 749\n",
      "Size of train_loader13: 750\n",
      "Size of train_loader14: 749\n",
      "Size of train_loader15: 752\n",
      "Size of train_loader16: 750\n",
      "Size of train_loader17: 749\n",
      "Size of train_loader18: 749\n",
      "Size of train_loader19: 751\n",
      "Size of train_loader20: 750\n",
      "Size of train_loader21: 749\n",
      "Size of train_loader22: 751\n",
      "Size of train_loader23: 750\n",
      "Size of train_loader24: 750\n",
      "Size of train_loader25: 749\n",
      "Size of train_loader26: 751\n",
      "Size of train_loader27: 750\n",
      "Size of train_loader28: 750\n",
      "Size of train_loader29: 750\n",
      "Size of train_loader30: 751\n",
      "Size of train_loader31: 749\n",
      "Size of train_loader32: 751\n",
      "Size of train_loader33: 750\n",
      "Size of train_loader34: 749\n",
      "Size of train_loader35: 749\n",
      "Size of train_loader36: 751\n",
      "Size of train_loader37: 751\n",
      "Size of train_loader38: 749\n",
      "Size of train_loader39: 750\n",
      "Size of train_loader40: 752\n",
      "Size of train_loader41: 748\n",
      "Size of train_loader42: 750\n",
      "Size of train_loader43: 749\n",
      "Size of train_loader44: 751\n",
      "Size of train_loader45: 751\n",
      "Size of train_loader46: 749\n",
      "Size of train_loader47: 749\n",
      "Size of train_loader48: 750\n",
      "Size of train_loader49: 751\n",
      "Size of train_loader50: 749\n",
      "Size of train_loader51: 751\n",
      "Size of train_loader52: 750\n",
      "Size of train_loader53: 750\n",
      "Size of train_loader54: 750\n",
      "Size of train_loader55: 751\n",
      "Size of train_loader56: 749\n",
      "Size of train_loader57: 750\n",
      "Size of train_loader58: 750\n",
      "Size of train_loader59: 751\n",
      "Size of train_loader60: 749\n",
      "Size of train_loader61: 750\n",
      "Size of train_loader62: 751\n",
      "Size of train_loader63: 749\n",
      "Size of train_loader64: 749\n",
      "Size of train_loader65: 750\n",
      "Size of train_loader66: 752\n",
      "Size of train_loader67: 749\n",
      "Size of train_loader68: 750\n",
      "Size of train_loader69: 749\n",
      "Size of train_loader70: 751\n",
      "Size of train_loader71: 750\n",
      "Size of train_loader72: 749\n",
      "Size of train_loader73: 751\n",
      "Size of train_loader74: 751\n",
      "Size of train_loader75: 749\n",
      "Size of train_loader76: 749\n",
      "Size of train_loader77: 751\n",
      "Size of train_loader78: 750\n",
      "Size of train_loader79: 749\n",
      "Size of train_loader80: 746\n",
      "Size of train_loader: 59990\n",
      "Size of test_loader: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "def stratified_split(dataset, proportions):\n",
    "    class_indices = [np.where(np.array(dataset.targets) == i)[0] for i in range(80)]\n",
    "    \n",
    "    split_indices = []\n",
    "    for proportion in proportions:\n",
    "        class_split_indices = [np.split(indices, [int(proportion[0]*len(indices)),\n",
    "int((proportion[0]+proportion[1])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38])*len(indices)), \n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72]+proportion[73])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72]+proportion[73]+proportion[74])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72]+proportion[73]+proportion[74]+proportion[75])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72]+proportion[73]+proportion[74]+proportion[75]+proportion[76])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72]+proportion[73]+proportion[74]+proportion[75]+proportion[76]+proportion[77])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72]+proportion[73]+proportion[74]+proportion[75]+proportion[76]+proportion[77]+proportion[78])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72]+proportion[73]+proportion[74]+proportion[75]+proportion[76]+proportion[77]+proportion[78]+proportion[79])*len(indices)),\n",
    "int((proportion[0]+proportion[1]+proportion[2]+proportion[3]+proportion[4]+proportion[5]+proportion[6]+proportion[7]+proportion[8]+proportion[9]+proportion[10]+proportion[11]+proportion[12]+proportion[13]+proportion[14]+proportion[15]+proportion[16]+proportion[17]+proportion[18]+proportion[19]+proportion[20]\n",
    "     +proportion[21]+proportion[22]+proportion[23]+proportion[24]+proportion[25]+proportion[26]+proportion[27]+proportion[28]+proportion[29]+proportion[30]+proportion[31]+proportion[32]+proportion[33]+proportion[34]+proportion[35]+proportion[36]+proportion[37]+proportion[38]+proportion[39]+proportion[40]\n",
    "     +proportion[41]+proportion[42]+proportion[43]+proportion[44]+proportion[45]+proportion[46]+proportion[47]+proportion[48]+proportion[49]+proportion[50]+proportion[51]+proportion[52]+proportion[53]+proportion[54]+proportion[55]+proportion[56]+proportion[57]+proportion[58]+proportion[59]+proportion[60]\n",
    "     +proportion[61]+proportion[62]+proportion[63]+proportion[64]+proportion[65]+proportion[66]+proportion[67]+proportion[68]+proportion[69]+proportion[70]+proportion[71]+proportion[72]+proportion[73]+proportion[74]+proportion[75]+proportion[76]+proportion[77]+proportion[78]+proportion[79])*len(indices))\n",
    "]) for indices in class_indices]\n",
    "        split_indices.append([np.concatenate([split[i] for split in class_split_indices]) for i in range(80)])\n",
    "    \n",
    "    return split_indices\n",
    "\n",
    "def data_loader():\n",
    "     transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "     ])\n",
    "    \n",
    "     # Load the whole MNIST dataset\n",
    "     full_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    \n",
    "     # Proportions pour les splits\n",
    "     proportion = (0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
    "                  0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
    "                  0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
    "                  0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
    "                  0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
    "                  0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
    "                  0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125,\n",
    "                  0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125)\n",
    "     proportions = [proportion] * 10\n",
    "    \n",
    "     # Obtenir les indices pour chaque split\n",
    "     split_indices = stratified_split(full_trainset, proportions)\n",
    "    \n",
    "     # Créer des Subsets\n",
    "     trainset1 = Subset(full_trainset, split_indices[0][0])\n",
    "     trainset2 = Subset(full_trainset, split_indices[0][1])\n",
    "     trainset3 = Subset(full_trainset, split_indices[0][2])\n",
    "     trainset4 = Subset(full_trainset, split_indices[0][3])\n",
    "     trainset5 = Subset(full_trainset, split_indices[0][4])\n",
    "     trainset6 = Subset(full_trainset, split_indices[0][5])\n",
    "     trainset7 = Subset(full_trainset, split_indices[0][6])\n",
    "     trainset8 = Subset(full_trainset, split_indices[0][7])\n",
    "     trainset9 = Subset(full_trainset, split_indices[0][8])\n",
    "     trainset10 = Subset(full_trainset, split_indices[0][9])\n",
    "     trainset11 = Subset(full_trainset, split_indices[0][10])\n",
    "     trainset12 = Subset(full_trainset, split_indices[0][11])\n",
    "     trainset13 = Subset(full_trainset, split_indices[0][12])\n",
    "     trainset14 = Subset(full_trainset, split_indices[0][13])\n",
    "     trainset15 = Subset(full_trainset, split_indices[0][14])\n",
    "     trainset16 = Subset(full_trainset, split_indices[0][15])\n",
    "     trainset17 = Subset(full_trainset, split_indices[0][16])\n",
    "     trainset18 = Subset(full_trainset, split_indices[0][17])\n",
    "     trainset19 = Subset(full_trainset, split_indices[0][18])\n",
    "     trainset20 = Subset(full_trainset, split_indices[0][19])\n",
    "     trainset21 = Subset(full_trainset, split_indices[0][20])\n",
    "     trainset22 = Subset(full_trainset, split_indices[0][21])\n",
    "     trainset23 = Subset(full_trainset, split_indices[0][22])\n",
    "     trainset24 = Subset(full_trainset, split_indices[0][23])\n",
    "     trainset25 = Subset(full_trainset, split_indices[0][24])\n",
    "     trainset26 = Subset(full_trainset, split_indices[0][25])\n",
    "     trainset27 = Subset(full_trainset, split_indices[0][26])\n",
    "     trainset28 = Subset(full_trainset, split_indices[0][27])\n",
    "     trainset29 = Subset(full_trainset, split_indices[0][28])\n",
    "     trainset30 = Subset(full_trainset, split_indices[0][29])\n",
    "     trainset31 = Subset(full_trainset, split_indices[0][30])\n",
    "     trainset32 = Subset(full_trainset, split_indices[0][31])\n",
    "     trainset33 = Subset(full_trainset, split_indices[0][32])\n",
    "     trainset34 = Subset(full_trainset, split_indices[0][33])\n",
    "     trainset35 = Subset(full_trainset, split_indices[0][34])\n",
    "     trainset36 = Subset(full_trainset, split_indices[0][35])\n",
    "     trainset37 = Subset(full_trainset, split_indices[0][36])\n",
    "     trainset38 = Subset(full_trainset, split_indices[0][37])\n",
    "     trainset39 = Subset(full_trainset, split_indices[0][38])\n",
    "     trainset40 = Subset(full_trainset, split_indices[0][39])\n",
    "     trainset41 = Subset(full_trainset, split_indices[0][40])\n",
    "     trainset42 = Subset(full_trainset, split_indices[0][41])\n",
    "     trainset43 = Subset(full_trainset, split_indices[0][42])\n",
    "     trainset44 = Subset(full_trainset, split_indices[0][43])\n",
    "     trainset45 = Subset(full_trainset, split_indices[0][44])\n",
    "     trainset46 = Subset(full_trainset, split_indices[0][45])\n",
    "     trainset47 = Subset(full_trainset, split_indices[0][46])\n",
    "     trainset48 = Subset(full_trainset, split_indices[0][47])\n",
    "     trainset49 = Subset(full_trainset, split_indices[0][48])\n",
    "     trainset50 = Subset(full_trainset, split_indices[0][49])\n",
    "     trainset51 = Subset(full_trainset, split_indices[0][50])\n",
    "     trainset52 = Subset(full_trainset, split_indices[0][51])\n",
    "     trainset53 = Subset(full_trainset, split_indices[0][52])\n",
    "     trainset54 = Subset(full_trainset, split_indices[0][53])\n",
    "     trainset55 = Subset(full_trainset, split_indices[0][54])\n",
    "     trainset56 = Subset(full_trainset, split_indices[0][55])\n",
    "     trainset57 = Subset(full_trainset, split_indices[0][56])\n",
    "     trainset58 = Subset(full_trainset, split_indices[0][57])\n",
    "     trainset59 = Subset(full_trainset, split_indices[0][58])\n",
    "     trainset60 = Subset(full_trainset, split_indices[0][59])\n",
    "     trainset61 = Subset(full_trainset, split_indices[0][60])\n",
    "     trainset62 = Subset(full_trainset, split_indices[0][61])\n",
    "     trainset63 = Subset(full_trainset, split_indices[0][62])\n",
    "     trainset64 = Subset(full_trainset, split_indices[0][63])\n",
    "     trainset65 = Subset(full_trainset, split_indices[0][64])\n",
    "     trainset66 = Subset(full_trainset, split_indices[0][65])\n",
    "     trainset67 = Subset(full_trainset, split_indices[0][66])\n",
    "     trainset68 = Subset(full_trainset, split_indices[0][67])\n",
    "     trainset69 = Subset(full_trainset, split_indices[0][68])\n",
    "     trainset70 = Subset(full_trainset, split_indices[0][69])\n",
    "     trainset71 = Subset(full_trainset, split_indices[0][70])\n",
    "     trainset72 = Subset(full_trainset, split_indices[0][71])\n",
    "     trainset73 = Subset(full_trainset, split_indices[0][72])\n",
    "     trainset74 = Subset(full_trainset, split_indices[0][73])\n",
    "     trainset75 = Subset(full_trainset, split_indices[0][74])\n",
    "     trainset76 = Subset(full_trainset, split_indices[0][75])\n",
    "     trainset77 = Subset(full_trainset, split_indices[0][76])\n",
    "     trainset78 = Subset(full_trainset, split_indices[0][77])\n",
    "     trainset79 = Subset(full_trainset, split_indices[0][78])\n",
    "     trainset80 = Subset(full_trainset, split_indices[0][79])\n",
    "\n",
    "\n",
    "\n",
    "     # Créer des DataLoaders pour chacun des sous-ensembles\n",
    "     train_loader1 = DataLoader(trainset1, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader2 = DataLoader(trainset2, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader3 = DataLoader(trainset3, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader4 = DataLoader(trainset4, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader5 = DataLoader(trainset5, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader6 = DataLoader(trainset6, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader7 = DataLoader(trainset7, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader8 = DataLoader(trainset8, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader9 = DataLoader(trainset9, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader10 = DataLoader(trainset10, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader11 = DataLoader(trainset11, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader12 = DataLoader(trainset12, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader13 = DataLoader(trainset13, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader14 = DataLoader(trainset14, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader15 = DataLoader(trainset15, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader16 = DataLoader(trainset16, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader17 = DataLoader(trainset17, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader18 = DataLoader(trainset18, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader19 = DataLoader(trainset19, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader20 = DataLoader(trainset20, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader21 = DataLoader(trainset21, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader22 = DataLoader(trainset22, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader23 = DataLoader(trainset23, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader24 = DataLoader(trainset24, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader25 = DataLoader(trainset25, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader26 = DataLoader(trainset26, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader27 = DataLoader(trainset27, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader28 = DataLoader(trainset28, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader29 = DataLoader(trainset29, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader30 = DataLoader(trainset30, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader31 = DataLoader(trainset31, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader32 = DataLoader(trainset32, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader33 = DataLoader(trainset33, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader34 = DataLoader(trainset34, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader35 = DataLoader(trainset35, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader36 = DataLoader(trainset36, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader37 = DataLoader(trainset37, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader38 = DataLoader(trainset38, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader39 = DataLoader(trainset39, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader40 = DataLoader(trainset40, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader41 = DataLoader(trainset41, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader42 = DataLoader(trainset42, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader43 = DataLoader(trainset43, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader44 = DataLoader(trainset44, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader45 = DataLoader(trainset45, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader46 = DataLoader(trainset46, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader47 = DataLoader(trainset47, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader48 = DataLoader(trainset48, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader49 = DataLoader(trainset49, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader50 = DataLoader(trainset50, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader51 = DataLoader(trainset51, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader52 = DataLoader(trainset52, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader53 = DataLoader(trainset53, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader54 = DataLoader(trainset54, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader55 = DataLoader(trainset55, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader56 = DataLoader(trainset56, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader57 = DataLoader(trainset57, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader58 = DataLoader(trainset58, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader59 = DataLoader(trainset59, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader60 = DataLoader(trainset60, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader61 = DataLoader(trainset61, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader62 = DataLoader(trainset62, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader63 = DataLoader(trainset63, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader64 = DataLoader(trainset64, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader65 = DataLoader(trainset65, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader66 = DataLoader(trainset66, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader67 = DataLoader(trainset67, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader68 = DataLoader(trainset68, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader69 = DataLoader(trainset69, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader70 = DataLoader(trainset70, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader71 = DataLoader(trainset71, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader72 = DataLoader(trainset72, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader73 = DataLoader(trainset73, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader74 = DataLoader(trainset74, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader75 = DataLoader(trainset75, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader76 = DataLoader(trainset76, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader77 = DataLoader(trainset77, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader78 = DataLoader(trainset78, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader79 = DataLoader(trainset79, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     train_loader80 = DataLoader(trainset80, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "     # Charger le jeu de données de test complet\n",
    "     testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "     test_loader = DataLoader(testset, batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "     return train_loader1, train_loader2, train_loader3, train_loader4, train_loader5, train_loader6, train_loader7, train_loader8, train_loader9, train_loader10, train_loader11, train_loader12, train_loader13, train_loader14, train_loader15, train_loader16, train_loader17, train_loader18, train_loader19, train_loader20, train_loader21, train_loader22, train_loader23, train_loader24, train_loader25, train_loader26, train_loader27, train_loader28, train_loader29, train_loader30, train_loader31, train_loader32, train_loader33, train_loader34, train_loader35, train_loader36, train_loader37, train_loader38, train_loader39, train_loader40, train_loader41, train_loader42, train_loader43, train_loader44, train_loader45, train_loader46, train_loader47, train_loader48, train_loader49, train_loader50, train_loader51, train_loader52, train_loader53, train_loader54, train_loader55, train_loader56, train_loader57, train_loader58, train_loader59, train_loader60, train_loader61, train_loader62, train_loader63, train_loader64, train_loader65, train_loader66, train_loader67, train_loader68, train_loader69, train_loader70, train_loader71, train_loader72, train_loader73, train_loader74, train_loader75, train_loader76, train_loader77, train_loader78, train_loader79, train_loader80, test_loader\n",
    "# Load DataLoaders\n",
    "train_loader1, train_loader2, train_loader3, train_loader4, train_loader5, train_loader6, train_loader7, train_loader8, train_loader9, train_loader10, train_loader11, train_loader12, train_loader13, train_loader14, train_loader15, train_loader16, train_loader17, train_loader18, train_loader19, train_loader20, train_loader21, train_loader22, train_loader23, train_loader24, train_loader25, train_loader26, train_loader27, train_loader28, train_loader29, train_loader30, train_loader31, train_loader32, train_loader33, train_loader34, train_loader35, train_loader36, train_loader37, train_loader38, train_loader39, train_loader40, train_loader41, train_loader42, train_loader43, train_loader44, train_loader45, train_loader46, train_loader47, train_loader48, train_loader49, train_loader50, train_loader51, train_loader52, train_loader53, train_loader54, train_loader55, train_loader56, train_loader57, train_loader58, train_loader59, train_loader60, train_loader61, train_loader62, train_loader63, train_loader64, train_loader65, train_loader66, train_loader67, train_loader68, train_loader69, train_loader70, train_loader71, train_loader72, train_loader73, train_loader74, train_loader75, train_loader76, train_loader77, train_loader78, train_loader79, train_loader80, test_loader = data_loader()\n",
    "\n",
    "# Vérification des tailles des DataLoaders\n",
    "print(f'Size of train_loader1: {len(train_loader1.dataset)}')\n",
    "print(f'Size of train_loader2: {len(train_loader2.dataset)}')\n",
    "print(f'Size of train_loader3: {len(train_loader3.dataset)}')\n",
    "print(f'Size of train_loader4: {len(train_loader4.dataset)}')\n",
    "print(f'Size of train_loader5: {len(train_loader5.dataset)}')\n",
    "print(f'Size of train_loader6: {len(train_loader6.dataset)}')\n",
    "print(f'Size of train_loader7: {len(train_loader7.dataset)}')\n",
    "print(f'Size of train_loader8: {len(train_loader8.dataset)}')\n",
    "print(f'Size of train_loader9: {len(train_loader9.dataset)}')\n",
    "print(f'Size of train_loader10: {len(train_loader10.dataset)}')\n",
    "print(f'Size of train_loader11: {len(train_loader11.dataset)}')\n",
    "print(f'Size of train_loader12: {len(train_loader12.dataset)}')\n",
    "print(f'Size of train_loader13: {len(train_loader13.dataset)}')\n",
    "print(f'Size of train_loader14: {len(train_loader14.dataset)}')\n",
    "print(f'Size of train_loader15: {len(train_loader15.dataset)}')\n",
    "print(f'Size of train_loader16: {len(train_loader16.dataset)}')\n",
    "print(f'Size of train_loader17: {len(train_loader17.dataset)}')\n",
    "print(f'Size of train_loader18: {len(train_loader18.dataset)}')\n",
    "print(f'Size of train_loader19: {len(train_loader19.dataset)}')\n",
    "print(f'Size of train_loader20: {len(train_loader20.dataset)}')\n",
    "print(f'Size of train_loader21: {len(train_loader21.dataset)}')\n",
    "print(f'Size of train_loader22: {len(train_loader22.dataset)}')\n",
    "print(f'Size of train_loader23: {len(train_loader23.dataset)}')\n",
    "print(f'Size of train_loader24: {len(train_loader24.dataset)}')\n",
    "print(f'Size of train_loader25: {len(train_loader25.dataset)}')\n",
    "print(f'Size of train_loader26: {len(train_loader26.dataset)}')\n",
    "print(f'Size of train_loader27: {len(train_loader27.dataset)}')\n",
    "print(f'Size of train_loader28: {len(train_loader28.dataset)}')\n",
    "print(f'Size of train_loader29: {len(train_loader29.dataset)}')\n",
    "print(f'Size of train_loader30: {len(train_loader30.dataset)}')\n",
    "print(f'Size of train_loader31: {len(train_loader31.dataset)}')\n",
    "print(f'Size of train_loader32: {len(train_loader32.dataset)}')\n",
    "print(f'Size of train_loader33: {len(train_loader33.dataset)}')\n",
    "print(f'Size of train_loader34: {len(train_loader34.dataset)}')\n",
    "print(f'Size of train_loader35: {len(train_loader35.dataset)}')\n",
    "print(f'Size of train_loader36: {len(train_loader36.dataset)}')\n",
    "print(f'Size of train_loader37: {len(train_loader37.dataset)}')\n",
    "print(f'Size of train_loader38: {len(train_loader38.dataset)}')\n",
    "print(f'Size of train_loader39: {len(train_loader39.dataset)}')\n",
    "print(f'Size of train_loader40: {len(train_loader40.dataset)}')\n",
    "print(f'Size of train_loader41: {len(train_loader41.dataset)}')\n",
    "print(f'Size of train_loader42: {len(train_loader42.dataset)}')\n",
    "print(f'Size of train_loader43: {len(train_loader43.dataset)}')\n",
    "print(f'Size of train_loader44: {len(train_loader44.dataset)}')\n",
    "print(f'Size of train_loader45: {len(train_loader45.dataset)}')\n",
    "print(f'Size of train_loader46: {len(train_loader46.dataset)}')\n",
    "print(f'Size of train_loader47: {len(train_loader47.dataset)}')\n",
    "print(f'Size of train_loader48: {len(train_loader48.dataset)}')\n",
    "print(f'Size of train_loader49: {len(train_loader49.dataset)}')\n",
    "print(f'Size of train_loader50: {len(train_loader50.dataset)}')\n",
    "print(f'Size of train_loader51: {len(train_loader51.dataset)}')\n",
    "print(f'Size of train_loader52: {len(train_loader52.dataset)}')\n",
    "print(f'Size of train_loader53: {len(train_loader53.dataset)}')\n",
    "print(f'Size of train_loader54: {len(train_loader54.dataset)}')\n",
    "print(f'Size of train_loader55: {len(train_loader55.dataset)}')\n",
    "print(f'Size of train_loader56: {len(train_loader56.dataset)}')\n",
    "print(f'Size of train_loader57: {len(train_loader57.dataset)}')\n",
    "print(f'Size of train_loader58: {len(train_loader58.dataset)}')\n",
    "print(f'Size of train_loader59: {len(train_loader59.dataset)}')\n",
    "print(f'Size of train_loader60: {len(train_loader60.dataset)}')\n",
    "print(f'Size of train_loader61: {len(train_loader61.dataset)}')\n",
    "print(f'Size of train_loader62: {len(train_loader62.dataset)}')\n",
    "print(f'Size of train_loader63: {len(train_loader63.dataset)}')\n",
    "print(f'Size of train_loader64: {len(train_loader64.dataset)}')\n",
    "print(f'Size of train_loader65: {len(train_loader65.dataset)}')\n",
    "print(f'Size of train_loader66: {len(train_loader66.dataset)}')\n",
    "print(f'Size of train_loader67: {len(train_loader67.dataset)}')\n",
    "print(f'Size of train_loader68: {len(train_loader68.dataset)}')\n",
    "print(f'Size of train_loader69: {len(train_loader69.dataset)}')\n",
    "print(f'Size of train_loader70: {len(train_loader70.dataset)}')\n",
    "print(f'Size of train_loader71: {len(train_loader71.dataset)}')\n",
    "print(f'Size of train_loader72: {len(train_loader72.dataset)}')\n",
    "print(f'Size of train_loader73: {len(train_loader73.dataset)}')\n",
    "print(f'Size of train_loader74: {len(train_loader74.dataset)}')\n",
    "print(f'Size of train_loader75: {len(train_loader75.dataset)}')\n",
    "print(f'Size of train_loader76: {len(train_loader76.dataset)}')\n",
    "print(f'Size of train_loader77: {len(train_loader77.dataset)}')\n",
    "print(f'Size of train_loader78: {len(train_loader78.dataset)}')\n",
    "print(f'Size of train_loader79: {len(train_loader79.dataset)}')\n",
    "print(f'Size of train_loader80: {len(train_loader80.dataset)}')\n",
    "print(f'Size of train_loader: {len(train_loader1.dataset) + len(train_loader2.dataset) + len(train_loader3.dataset) + len(train_loader4.dataset) + len(train_loader5.dataset) + len(train_loader6.dataset) + len(train_loader7.dataset) + len(train_loader8.dataset) + len(train_loader9.dataset) + len(train_loader10.dataset) + len(train_loader11.dataset) + len(train_loader12.dataset) + len(train_loader13.dataset) + len(train_loader14.dataset) + len(train_loader15.dataset) + len(train_loader16.dataset) + len(train_loader17.dataset) + len(train_loader18.dataset) + len(train_loader19.dataset) + len(train_loader20.dataset) + len(train_loader21.dataset) + len(train_loader22.dataset) + len(train_loader23.dataset) + len(train_loader24.dataset) + len(train_loader25.dataset) + len(train_loader26.dataset) + len(train_loader27.dataset) + len(train_loader28.dataset) + len(train_loader29.dataset) + len(train_loader30.dataset) + len(train_loader31.dataset) + len(train_loader32.dataset) + len(train_loader33.dataset) + len(train_loader34.dataset) + len(train_loader35.dataset) + len(train_loader36.dataset) + len(train_loader37.dataset) + len(train_loader38.dataset) + len(train_loader39.dataset) + len(train_loader40.dataset) + len(train_loader41.dataset) + len(train_loader42.dataset) + len(train_loader43.dataset) + len(train_loader44.dataset) + len(train_loader45.dataset) + len(train_loader46.dataset) + len(train_loader47.dataset) + len(train_loader48.dataset) + len(train_loader49.dataset) + len(train_loader50.dataset) + len(train_loader51.dataset) + len(train_loader52.dataset) + len(train_loader53.dataset) + len(train_loader54.dataset) + len(train_loader55.dataset) + len(train_loader56.dataset) + len(train_loader57.dataset) + len(train_loader58.dataset) + len(train_loader59.dataset) + len(train_loader60.dataset) + len(train_loader61.dataset) + len(train_loader62.dataset) + len(train_loader63.dataset) + len(train_loader64.dataset) + len(train_loader65.dataset) + len(train_loader66.dataset) + len(train_loader67.dataset) + len(train_loader68.dataset) + len(train_loader69.dataset) + len(train_loader70.dataset) + len(train_loader71.dataset) + len(train_loader72.dataset) + len(train_loader73.dataset) + len(train_loader74.dataset) + len(train_loader75.dataset) + len(train_loader76.dataset) + len(train_loader77.dataset) + len(train_loader78.dataset) + len(train_loader79.dataset) + len(train_loader80.dataset)}')\n",
    "print(f'Size of test_loader: {len(test_loader.dataset)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Verify the content of train_loader subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verify the 10 classes of training dataset and 10 classes of testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Going through the dataloader to extract an image per class\n",
    "\n",
    "train_images1 = get_images_by_class(train_loader1)\n",
    "train_images2 = get_images_by_class(train_loader2)\n",
    "train_images3 = get_images_by_class(train_loader3)\n",
    "train_images4 = get_images_by_class(train_loader4)\n",
    "train_images5 = get_images_by_class(train_loader5)\n",
    "train_images6 = get_images_by_class(train_loader6)\n",
    "train_images7 = get_images_by_class(train_loader7)\n",
    "train_images8 = get_images_by_class(train_loader8)\n",
    "train_images9 = get_images_by_class(train_loader9)\n",
    "train_images10 = get_images_by_class(train_loader10)\n",
    "train_images11 = get_images_by_class(train_loader11)\n",
    "train_images12 = get_images_by_class(train_loader12)\n",
    "train_images13 = get_images_by_class(train_loader13)\n",
    "train_images14 = get_images_by_class(train_loader14)\n",
    "train_images15 = get_images_by_class(train_loader15)\n",
    "train_images16 = get_images_by_class(train_loader16)\n",
    "train_images17 = get_images_by_class(train_loader17)\n",
    "train_images18 = get_images_by_class(train_loader18)\n",
    "train_images19 = get_images_by_class(train_loader19)\n",
    "train_images20 = get_images_by_class(train_loader20)\n",
    "train_images21 = get_images_by_class(train_loader21)\n",
    "train_images22 = get_images_by_class(train_loader22)\n",
    "train_images23 = get_images_by_class(train_loader23)\n",
    "train_images24 = get_images_by_class(train_loader24)\n",
    "train_images25 = get_images_by_class(train_loader25)\n",
    "train_images26 = get_images_by_class(train_loader26)\n",
    "train_images27 = get_images_by_class(train_loader27)\n",
    "train_images28 = get_images_by_class(train_loader28)\n",
    "train_images29 = get_images_by_class(train_loader29)\n",
    "train_images30 = get_images_by_class(train_loader30)\n",
    "train_images31 = get_images_by_class(train_loader31)\n",
    "train_images32 = get_images_by_class(train_loader32)\n",
    "train_images33 = get_images_by_class(train_loader33)\n",
    "train_images34 = get_images_by_class(train_loader34)\n",
    "train_images35 = get_images_by_class(train_loader35)\n",
    "train_images36 = get_images_by_class(train_loader36)\n",
    "train_images37 = get_images_by_class(train_loader37)\n",
    "train_images38 = get_images_by_class(train_loader38)\n",
    "train_images39 = get_images_by_class(train_loader39)\n",
    "train_images40 = get_images_by_class(train_loader40)\n",
    "train_images41 = get_images_by_class(train_loader41)\n",
    "train_images42 = get_images_by_class(train_loader42)\n",
    "train_images43 = get_images_by_class(train_loader43)\n",
    "train_images44 = get_images_by_class(train_loader44)\n",
    "train_images45 = get_images_by_class(train_loader45)\n",
    "train_images46 = get_images_by_class(train_loader46)\n",
    "train_images47 = get_images_by_class(train_loader47)\n",
    "train_images48 = get_images_by_class(train_loader48)\n",
    "train_images49 = get_images_by_class(train_loader49)\n",
    "train_images50 = get_images_by_class(train_loader50)\n",
    "train_images51 = get_images_by_class(train_loader51)\n",
    "train_images52 = get_images_by_class(train_loader52)\n",
    "train_images53 = get_images_by_class(train_loader53)\n",
    "train_images54 = get_images_by_class(train_loader54)\n",
    "train_images55 = get_images_by_class(train_loader55)\n",
    "train_images56 = get_images_by_class(train_loader56)\n",
    "train_images57 = get_images_by_class(train_loader57)\n",
    "train_images58 = get_images_by_class(train_loader58)\n",
    "train_images59 = get_images_by_class(train_loader59)\n",
    "train_images60 = get_images_by_class(train_loader60)\n",
    "train_images61 = get_images_by_class(train_loader61)\n",
    "train_images62 = get_images_by_class(train_loader62)\n",
    "train_images63 = get_images_by_class(train_loader63)\n",
    "train_images64 = get_images_by_class(train_loader64)\n",
    "train_images65 = get_images_by_class(train_loader65)\n",
    "train_images66 = get_images_by_class(train_loader66)\n",
    "train_images67 = get_images_by_class(train_loader67)\n",
    "train_images68 = get_images_by_class(train_loader68)\n",
    "train_images69 = get_images_by_class(train_loader69)\n",
    "train_images70 = get_images_by_class(train_loader70)\n",
    "train_images71 = get_images_by_class(train_loader71)\n",
    "train_images72 = get_images_by_class(train_loader72)\n",
    "train_images73 = get_images_by_class(train_loader73)\n",
    "train_images74 = get_images_by_class(train_loader74)\n",
    "train_images75 = get_images_by_class(train_loader75)\n",
    "train_images76 = get_images_by_class(train_loader76)\n",
    "train_images77 = get_images_by_class(train_loader77)\n",
    "train_images78 = get_images_by_class(train_loader78)\n",
    "train_images79 = get_images_by_class(train_loader79)\n",
    "train_images80 = get_images_by_class(train_loader80)\n",
    "test_images = get_images_by_class(test_loader)\n",
    "\n",
    "plot_images(train_images1, \"Trainset Subset 1 Images by Class\")\n",
    "plot_images(train_images2, \"Trainset Subset 2 Images by Class\")\n",
    "plot_images(train_images3, \"Trainset Subset 3 Images by Class\")\n",
    "plot_images(train_images4, \"Trainset Subset 4 Images by Class\")\n",
    "plot_images(train_images5, \"Trainset Subset 5 Images by Class\")\n",
    "plot_images(train_images6, \"Trainset Subset 6 Images by Class\")\n",
    "plot_images(train_images7, \"Trainset Subset 7 Images by Class\")\n",
    "plot_images(train_images8, \"Trainset Subset 8 Images by Class\")\n",
    "plot_images(train_images9, \"Trainset Subset 9 Images by Class\")\n",
    "plot_images(train_images10, \"Trainset Subset 10 Images by Class\")\n",
    "plot_images(train_images11, \"Trainset Subset 11 Images by Class\")\n",
    "plot_images(train_images12, \"Trainset Subset 12 Images by Class\")\n",
    "plot_images(train_images13, \"Trainset Subset 13 Images by Class\")\n",
    "plot_images(train_images14, \"Trainset Subset 14 Images by Class\")\n",
    "plot_images(train_images15, \"Trainset Subset 15 Images by Class\")\n",
    "plot_images(train_images16, \"Trainset Subset 16 Images by Class\")\n",
    "plot_images(train_images17, \"Trainset Subset 17 Images by Class\")\n",
    "plot_images(train_images18, \"Trainset Subset 18 Images by Class\")\n",
    "plot_images(train_images19, \"Trainset Subset 19 Images by Class\")\n",
    "plot_images(train_images20, \"Trainset Subset 20 Images by Class\")\n",
    "plot_images(train_images21, \"Trainset Subset 21 Images by Class\")\n",
    "plot_images(train_images22, \"Trainset Subset 22 Images by Class\")\n",
    "plot_images(train_images23, \"Trainset Subset 23 Images by Class\")\n",
    "plot_images(train_images24, \"Trainset Subset 24 Images by Class\")\n",
    "plot_images(train_images25, \"Trainset Subset 25 Images by Class\")\n",
    "plot_images(train_images26, \"Trainset Subset 26 Images by Class\")\n",
    "plot_images(train_images27, \"Trainset Subset 27 Images by Class\")\n",
    "plot_images(train_images28, \"Trainset Subset 28 Images by Class\")\n",
    "plot_images(train_images29, \"Trainset Subset 29 Images by Class\")\n",
    "plot_images(train_images30, \"Trainset Subset 30 Images by Class\")\n",
    "plot_images(train_images31, \"Trainset Subset 31 Images by Class\")\n",
    "plot_images(train_images32, \"Trainset Subset 32 Images by Class\")\n",
    "plot_images(train_images33, \"Trainset Subset 33 Images by Class\")\n",
    "plot_images(train_images34, \"Trainset Subset 34 Images by Class\")\n",
    "plot_images(train_images35, \"Trainset Subset 35 Images by Class\")\n",
    "plot_images(train_images36, \"Trainset Subset 36 Images by Class\")\n",
    "plot_images(train_images37, \"Trainset Subset 37 Images by Class\")\n",
    "plot_images(train_images38, \"Trainset Subset 38 Images by Class\")\n",
    "plot_images(train_images39, \"Trainset Subset 39 Images by Class\")\n",
    "plot_images(train_images40, \"Trainset Subset 40 Images by Class\")\n",
    "plot_images(train_images41, \"Trainset Subset 41 Images by Class\")\n",
    "plot_images(train_images42, \"Trainset Subset 42 Images by Class\")\n",
    "plot_images(train_images43, \"Trainset Subset 43 Images by Class\")\n",
    "plot_images(train_images44, \"Trainset Subset 44 Images by Class\")\n",
    "plot_images(train_images45, \"Trainset Subset 45 Images by Class\")\n",
    "plot_images(train_images46, \"Trainset Subset 46 Images by Class\")\n",
    "plot_images(train_images47, \"Trainset Subset 47 Images by Class\")\n",
    "plot_images(train_images48, \"Trainset Subset 48 Images by Class\")\n",
    "plot_images(train_images49, \"Trainset Subset 49 Images by Class\")\n",
    "plot_images(train_images50, \"Trainset Subset 50 Images by Class\")\n",
    "plot_images(train_images51, \"Trainset Subset 51 Images by Class\")\n",
    "plot_images(train_images52, \"Trainset Subset 52 Images by Class\")\n",
    "plot_images(train_images53, \"Trainset Subset 53 Images by Class\")\n",
    "plot_images(train_images54, \"Trainset Subset 54 Images by Class\")\n",
    "plot_images(train_images55, \"Trainset Subset 55 Images by Class\")\n",
    "plot_images(train_images56, \"Trainset Subset 56 Images by Class\")\n",
    "plot_images(train_images57, \"Trainset Subset 57 Images by Class\")\n",
    "plot_images(train_images58, \"Trainset Subset 58 Images by Class\")\n",
    "plot_images(train_images59, \"Trainset Subset 59 Images by Class\")\n",
    "plot_images(train_images60, \"Trainset Subset 60 Images by Class\")\n",
    "plot_images(train_images61, \"Trainset Subset 61 Images by Class\")\n",
    "plot_images(train_images62, \"Trainset Subset 62 Images by Class\")\n",
    "plot_images(train_images63, \"Trainset Subset 63 Images by Class\")\n",
    "plot_images(train_images64, \"Trainset Subset 64 Images by Class\")\n",
    "plot_images(train_images65, \"Trainset Subset 65 Images by Class\")\n",
    "plot_images(train_images66, \"Trainset Subset 66 Images by Class\")\n",
    "plot_images(train_images67, \"Trainset Subset 67 Images by Class\")\n",
    "plot_images(train_images68, \"Trainset Subset 68 Images by Class\")\n",
    "plot_images(train_images69, \"Trainset Subset 69 Images by Class\")\n",
    "plot_images(train_images70, \"Trainset Subset 70 Images by Class\")\n",
    "plot_images(train_images71, \"Trainset Subset 71 Images by Class\")\n",
    "plot_images(train_images72, \"Trainset Subset 72 Images by Class\")\n",
    "plot_images(train_images73, \"Trainset Subset 73 Images by Class\")\n",
    "plot_images(train_images74, \"Trainset Subset 74 Images by Class\")\n",
    "plot_images(train_images75, \"Trainset Subset 75 Images by Class\")\n",
    "plot_images(train_images76, \"Trainset Subset 76 Images by Class\")\n",
    "plot_images(train_images77, \"Trainset Subset 77 Images by Class\")\n",
    "plot_images(train_images78, \"Trainset Subset 78 Images by Class\")\n",
    "plot_images(train_images79, \"Trainset Subset 79 Images by Class\")\n",
    "plot_images(train_images80, \"Trainset Subset 80 Images by Class\")\n",
    "plot_images(test_images, \"Testset Images by Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verify that the 10 first images are visually different**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_first_images(train_loader1, \"First 10 Trainset Subset 1 Images\")\n",
    "plot_first_images(train_loader2, \"First 10 Trainset Subset 2 Images\")\n",
    "plot_first_images(train_loader3, \"First 10 Trainset Subset 3 Images\")\n",
    "plot_first_images(train_loader4, \"First 10 Trainset Subset 4 Images\")\n",
    "plot_first_images(train_loader5, \"First 10 Trainset Subset 5 Images\")\n",
    "plot_first_images(train_loader6, \"First 10 Trainset Subset 6 Images\")\n",
    "plot_first_images(train_loader7, \"First 10 Trainset Subset 7 Images\")\n",
    "plot_first_images(train_loader8, \"First 10 Trainset Subset 8 Images\")\n",
    "plot_first_images(train_loader9, \"First 10 Trainset Subset 9 Images\")\n",
    "plot_first_images(train_loader10, \"First 10 Trainset Subset 10 Images\")\n",
    "plot_first_images(train_loader11, \"First 10 Trainset Subset 11 Images\")\n",
    "plot_first_images(train_loader12, \"First 10 Trainset Subset 12 Images\")\n",
    "plot_first_images(train_loader13, \"First 10 Trainset Subset 13 Images\")\n",
    "plot_first_images(train_loader14, \"First 10 Trainset Subset 14 Images\")\n",
    "plot_first_images(train_loader15, \"First 10 Trainset Subset 15 Images\")\n",
    "plot_first_images(train_loader16, \"First 10 Trainset Subset 16 Images\")\n",
    "plot_first_images(train_loader17, \"First 10 Trainset Subset 17 Images\")\n",
    "plot_first_images(train_loader18, \"First 10 Trainset Subset 18 Images\")\n",
    "plot_first_images(train_loader19, \"First 10 Trainset Subset 19 Images\")\n",
    "plot_first_images(train_loader20, \"First 10 Trainset Subset 20 Images\")\n",
    "plot_first_images(train_loader21, \"First 10 Trainset Subset 21 Images\")\n",
    "plot_first_images(train_loader22, \"First 10 Trainset Subset 22 Images\")\n",
    "plot_first_images(train_loader23, \"First 10 Trainset Subset 23 Images\")\n",
    "plot_first_images(train_loader24, \"First 10 Trainset Subset 24 Images\")\n",
    "plot_first_images(train_loader25, \"First 10 Trainset Subset 25 Images\")\n",
    "plot_first_images(train_loader26, \"First 10 Trainset Subset 26 Images\")\n",
    "plot_first_images(train_loader27, \"First 10 Trainset Subset 27 Images\")\n",
    "plot_first_images(train_loader28, \"First 10 Trainset Subset 28 Images\")\n",
    "plot_first_images(train_loader29, \"First 10 Trainset Subset 29 Images\")\n",
    "plot_first_images(train_loader30, \"First 10 Trainset Subset 30 Images\")\n",
    "plot_first_images(train_loader31, \"First 10 Trainset Subset 31 Images\")\n",
    "plot_first_images(train_loader32, \"First 10 Trainset Subset 32 Images\")\n",
    "plot_first_images(train_loader33, \"First 10 Trainset Subset 33 Images\")\n",
    "plot_first_images(train_loader34, \"First 10 Trainset Subset 34 Images\")\n",
    "plot_first_images(train_loader35, \"First 10 Trainset Subset 35 Images\")\n",
    "plot_first_images(train_loader36, \"First 10 Trainset Subset 36 Images\")\n",
    "plot_first_images(train_loader37, \"First 10 Trainset Subset 37 Images\")\n",
    "plot_first_images(train_loader38, \"First 10 Trainset Subset 38 Images\")\n",
    "plot_first_images(train_loader39, \"First 10 Trainset Subset 39 Images\")\n",
    "plot_first_images(train_loader40, \"First 10 Trainset Subset 40 Images\")\n",
    "plot_first_images(train_loader41, \"First 10 Trainset Subset 41 Images\")\n",
    "plot_first_images(train_loader42, \"First 10 Trainset Subset 42 Images\")\n",
    "plot_first_images(train_loader43, \"First 10 Trainset Subset 43 Images\")\n",
    "plot_first_images(train_loader44, \"First 10 Trainset Subset 44 Images\")\n",
    "plot_first_images(train_loader45, \"First 10 Trainset Subset 45 Images\")\n",
    "plot_first_images(train_loader46, \"First 10 Trainset Subset 46 Images\")\n",
    "plot_first_images(train_loader47, \"First 10 Trainset Subset 47 Images\")\n",
    "plot_first_images(train_loader48, \"First 10 Trainset Subset 48 Images\")\n",
    "plot_first_images(train_loader49, \"First 10 Trainset Subset 49 Images\")\n",
    "plot_first_images(train_loader50, \"First 10 Trainset Subset 50 Images\")\n",
    "plot_first_images(train_loader51, \"First 10 Trainset Subset 51 Images\")\n",
    "plot_first_images(train_loader52, \"First 10 Trainset Subset 52 Images\")\n",
    "plot_first_images(train_loader53, \"First 10 Trainset Subset 53 Images\")\n",
    "plot_first_images(train_loader54, \"First 10 Trainset Subset 54 Images\")\n",
    "plot_first_images(train_loader55, \"First 10 Trainset Subset 55 Images\")\n",
    "plot_first_images(train_loader56, \"First 10 Trainset Subset 56 Images\")\n",
    "plot_first_images(train_loader57, \"First 10 Trainset Subset 57 Images\")\n",
    "plot_first_images(train_loader58, \"First 10 Trainset Subset 58 Images\")\n",
    "plot_first_images(train_loader59, \"First 10 Trainset Subset 59 Images\")\n",
    "plot_first_images(train_loader60, \"First 10 Trainset Subset 60 Images\")\n",
    "plot_first_images(train_loader61, \"First 10 Trainset Subset 61 Images\")\n",
    "plot_first_images(train_loader62, \"First 10 Trainset Subset 62 Images\")\n",
    "plot_first_images(train_loader63, \"First 10 Trainset Subset 63 Images\")\n",
    "plot_first_images(train_loader64, \"First 10 Trainset Subset 64 Images\")\n",
    "plot_first_images(train_loader65, \"First 10 Trainset Subset 65 Images\")\n",
    "plot_first_images(train_loader66, \"First 10 Trainset Subset 66 Images\")\n",
    "plot_first_images(train_loader67, \"First 10 Trainset Subset 67 Images\")\n",
    "plot_first_images(train_loader68, \"First 10 Trainset Subset 68 Images\")\n",
    "plot_first_images(train_loader69, \"First 10 Trainset Subset 69 Images\")\n",
    "plot_first_images(train_loader70, \"First 10 Trainset Subset 70 Images\")\n",
    "plot_first_images(train_loader71, \"First 10 Trainset Subset 71 Images\")\n",
    "plot_first_images(train_loader72, \"First 10 Trainset Subset 72 Images\")\n",
    "plot_first_images(train_loader73, \"First 10 Trainset Subset 73 Images\")\n",
    "plot_first_images(train_loader74, \"First 10 Trainset Subset 74 Images\")\n",
    "plot_first_images(train_loader75, \"First 10 Trainset Subset 75 Images\")\n",
    "plot_first_images(train_loader76, \"First 10 Trainset Subset 76 Images\")\n",
    "plot_first_images(train_loader77, \"First 10 Trainset Subset 77 Images\")\n",
    "plot_first_images(train_loader78, \"First 10 Trainset Subset 78 Images\")\n",
    "plot_first_images(train_loader79, \"First 10 Trainset Subset 79 Images\")\n",
    "plot_first_images(train_loader80, \"First 10 Trainset Subset 80 Images\")\n",
    "plot_first_images(test_loader, \"First 10 Testset Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defining some variables and creating files & folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDFP = \"./volumes/Ultra Touch\" # Load HHD\n",
    "\n",
    "SAVE_LOC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch\"\n",
    "if not os.path.exists(SAVE_LOC):\n",
    "    os.makedirs(SAVE_LOC)\n",
    "\n",
    "SAVE_LOC_OLC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc\"\n",
    "if not os.path.exists(SAVE_LOC_OLC):\n",
    "    os.makedirs(SAVE_LOC_OLC)\n",
    "\n",
    "SAVE_BRANCH_PRETRAINING = HDFP + \"/lobranch-snapshot/branchpoints/lenet/pretraining\"\n",
    "if not os.path.exists(SAVE_BRANCH_PRETRAINING):\n",
    "    os.makedirs(SAVE_BRANCH_PRETRAINING)\n",
    "\n",
    "SAVE_BRANCH = HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch\"\n",
    "if not os.path.exists(SAVE_BRANCH):\n",
    "    os.makedirs(SAVE_BRANCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pretraining the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Personal\\Singapour\\PFE\\code_of_shu-heng_with_models\\pfe_lc_lora\\wandb\\run-20240716_145235-qh7kbknh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace' target=\"_blank\">LeNet-Pretraining-Without-Incremental-Learning</a></strong> to <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of model training...\n",
      "Epoch: [0/49], Training Loss: 1.891492, Validation Loss: 1.149016, Training Accuracy: 0.558367, Validation Accuracy: 0.745900\n",
      "End of model training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fd4f2601174255831e67b3ff03c978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.55837</td></tr><tr><td>train_loss</td><td>1.89149</td></tr><tr><td>valid_accuracy</td><td>0.7459</td></tr><tr><td>valid_loss</td><td>1.14902</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-Pretraining-Without-Incremental-Learning</strong> at: <a href='https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240716_145235-qh7kbknh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_for_checkpoint = LeNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_for_checkpoint = nn.DataParallel(model_for_checkpoint)\n",
    "    model_for_checkpoint.to(device)\n",
    "else:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU!\")\n",
    "    model_for_checkpoint.to(device)\n",
    "\n",
    "# Training code\n",
    "NUM_EPOCHES = 50\n",
    "learning_rate = 0.005\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-Pretraining-Without-Incremental-Learning\", \n",
    "           tags=[\"LeNet\", \"Pretraining\", \"Without-Incremental-Learning\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"train dataset\": \"MNIST train dataset[:]\",\n",
    "                    \"test dataset\": \"MNIST test dataset[:]\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"optimizer\": \"SGD\",\n",
    "                }\n",
    "           )\n",
    "\n",
    "print(\"Start of model training...\")\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_for_checkpoint.train()\n",
    "        for iter, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_for_checkpoint(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_for_checkpoint.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_for_checkpoint(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    if valid_accuracy > 0.70:\n",
    "        torch.save(model_for_checkpoint.state_dict(), SAVE_BRANCH_PRETRAINING + \"/branch_{:.3f}.pt\".format(valid_accuracy))\n",
    "        print(\"Model saved with accuracy: {:.3f} in the file: branch_{:.3f}.pt\".format(valid_accuracy, valid_accuracy))\n",
    "        # Comment the line below if you want to train on the whole dataset\n",
    "        isLoop = False\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training...\")\n",
    "\n",
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First version : LeNet without Incremental Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_for_checkpoint = LeNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_for_checkpoint = nn.DataParallel(model_for_checkpoint)\n",
    "    model_for_checkpoint.to(device)\n",
    "else:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU!\")\n",
    "    model_for_checkpoint.to(device)\n",
    "\n",
    "# Training code\n",
    "NUM_EPOCHES = 50\n",
    "learning_rate = 0.02\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-Without-Incremental-Learning\", \n",
    "           tags=[\"LeNet\", \"Without-Incremental-Learning\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"train dataset\": \"MNIST train dataset[:]\",\n",
    "                    \"test dataset\": \"MNIST test dataset[:]\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"optimizer\": \"SGD\",\n",
    "                }\n",
    "           )\n",
    "\n",
    "print(\"Start of model training...\")\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_for_checkpoint.train()\n",
    "        for iter, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_for_checkpoint(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_for_checkpoint.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_for_checkpoint(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training...\")\n",
    "\n",
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Second version : LeNet with Incremental Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training on trainloader1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_with_incremental_learning = LeNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_with_incremental_learning = nn.DataParallel(model_with_incremental_learning)\n",
    "    model_with_incremental_learning.to(device)\n",
    "else:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU!\")\n",
    "    model_with_incremental_learning.to(device)\n",
    "\n",
    "# Training code\n",
    "NUM_EPOCHES = 45\n",
    "learning_rate = 0.01\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_with_incremental_learning.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-With-Incremental-Learning\", \n",
    "           tags=[\"LeNet\", \"With-Incremental-Learning\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"train dataset\": \"CIFAR10 train dataloader1\",\n",
    "                    \"test dataset\": \"CIFAR10 test dataset[:]\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"optimizer\": \"SGD\",\n",
    "                }\n",
    "           )\n",
    "\n",
    "\n",
    "\n",
    "print(\"Start of model training on dataloader1...\")\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_with_incremental_learning.train()\n",
    "        for iter, data in enumerate(train_loader1):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_with_incremental_learning(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_with_incremental_learning.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_with_incremental_learning(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader1.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training on dataloader1...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training on trainloader2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "# Training code on dataloader2\n",
    "print(\"Start of model training on dataloader2...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_with_incremental_learning.train()\n",
    "        for iter, data in enumerate(train_loader2):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_with_incremental_learning(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_with_incremental_learning.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_with_incremental_learning(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader2.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training on dataloader2...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training on trainloader3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "# Training code on dataloader2\n",
    "print(\"Start of model training on dataloader3...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_with_incremental_learning.train()\n",
    "        for iter, data in enumerate(train_loader3):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_with_incremental_learning(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_with_incremental_learning.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_with_incremental_learning(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader3.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training on dataloader3...\")\n",
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Third version : LeNet with Incremental Learning, LC-checkpoint, and Delta-LoRA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Personal\\Singapour\\PFE\\code_of_shu-heng_with_models\\pfe_lc_lora\\wandb\\run-20240705_131328-uwimhxwh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bryanbradfo/LeNet/runs/uwimhxwh/workspace' target=\"_blank\">LeNet-With-Incremental-Learning_LC_DLORA-Without-Restore_25_25_25_25</a></strong> to <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bryanbradfo/LeNet/runs/uwimhxwh/workspace' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet/runs/uwimhxwh/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of model training on dataloader1...\n",
      "Epoch: [0/29], Training Loss: 2.263898, Validation Loss: 2.211693, Training Accuracy: 0.247016, Validation Accuracy: 0.452200\n",
      "Epoch: [1/29], Training Loss: 2.111947, Validation Loss: 1.965460, Training Accuracy: 0.541380, Validation Accuracy: 0.571200\n",
      "Epoch: [2/29], Training Loss: 1.775779, Validation Loss: 1.560456, Training Accuracy: 0.561387, Validation Accuracy: 0.603400\n",
      "Model saved at accuracy: 0.7024\n",
      "End of model training on dataloader1...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_with_incremental_learning_lc_dlora = LeNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_with_incremental_learning_lc_dlora = nn.DataParallel(model_with_incremental_learning_lc_dlora)\n",
    "    model_with_incremental_learning_lc_dlora.to(device)\n",
    "else:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU!\")\n",
    "    model_with_incremental_learning_lc_dlora.to(device)\n",
    "\n",
    "# Training code\n",
    "NUM_EPOCHES = 30\n",
    "learning_rate = 0.1\n",
    "learning_rate_dloralc = 0.1\n",
    "learning_rate1 = 0.005\n",
    "# super_step = len(train_loader2)\n",
    "# super_step = 20\n",
    "isLoop = True\n",
    "\n",
    "optimizer = torch.optim.SGD(model_with_incremental_learning_lc_dlora.parameters(), lr=learning_rate1)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-With-Incremental-Learning_LC_DLORA-Without-Restore_25_25_25_25\", \n",
    "           tags=[\"LeNet\", \"With-Incremental-Learning_LC_DLORA\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"splitting\": \"25-25-25-25\",\n",
    "                    \"train dataset 1\": \"MNIST train dataloader1\",\n",
    "                    \"test dataset\": \"MNIST test dataset[:]\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate_nothing\": learning_rate,\n",
    "                    \"learning_rate_dloralc\": learning_rate_dloralc,\n",
    "                    \"optimizer\": \"SGD\"\n",
    "                }\n",
    "           )\n",
    "\n",
    "print(\"Start of model training on dataloader1...\")\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_with_incremental_learning_lc_dlora.train()\n",
    "        for iter, data in enumerate(train_loader1):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_with_incremental_learning_lc_dlora(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_with_incremental_learning_lc_dlora.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_with_incremental_learning_lc_dlora(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader1.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    if valid_accuracy > 0.7:\n",
    "        rounded_valid_acc = round(valid_accuracy, 4)\n",
    "        # torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/vit/branch_{}.pt\".format(rounded_valid_acc))\n",
    "        torch.save(model_with_incremental_learning_lc_dlora.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch_{}.pt\".format(rounded_valid_acc))\n",
    "        print(\"Model saved at accuracy: {:.4f}\".format(rounded_valid_acc))\n",
    "        isLoop = False\n",
    "        break\n",
    "    # if valid_accuracy > 0.90:\n",
    "    #     isLoop = False\n",
    "    #     break\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss_dloralc\": train_loss,\n",
    "        \"valid_loss_dloralc\": valid_loss,\n",
    "        \"train_accuracy_dloralc\": train_accuarcy,\n",
    "        \"valid_accuracy_dloralc\": valid_accuracy,\n",
    "        \"train_loss_lc\": train_loss,\n",
    "        \"valid_loss_lc\": valid_loss,\n",
    "        \"train_accuracy_lc\": train_accuarcy,\n",
    "        \"valid_accuracy_lc\": valid_accuracy, \n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "        \"epoch\": epoch,\n",
    "    })\n",
    "    # wandb.log({\n",
    "    #     \"train_loss_dloralc\": train_loss,\n",
    "    #     \"valid_loss_dloralc\": valid_loss,\n",
    "    #     \"train_accuracy_dloralc\": train_accuarcy,\n",
    "    #     \"valid_accuracy_dloralc\": valid_accuracy,\n",
    "    #     \"train_loss_lc\": train_loss,\n",
    "    #     \"valid_loss_lc\": valid_loss,\n",
    "    #     \"train_accuracy_lc\": train_accuarcy,\n",
    "    #     \"valid_accuracy_lc\": valid_accuracy, \n",
    "    #     \"train_loss\": train_loss,\n",
    "    #     \"valid_loss\": valid_loss,\n",
    "    #     \"train_accuracy\": train_accuarcy,\n",
    "    #     \"valid_accuracy\": valid_accuracy,\n",
    "    #     \"valid_loss_dloralc_restored\": valid_loss,\n",
    "    #     \"valid_accuracy_dloralc_restored\": valid_accuracy,\n",
    "    #     \"epoch\": epoch,\n",
    "    # })\n",
    "\n",
    "print(\"End of model training on dataloader1...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Working on training with delta-LoRA and LC-checkpoint** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECOMPOSED_LAYERS = [\"classifier.1.weight\", \"classifier.3.weight\"]\n",
    "RANK = -1\n",
    "SCALING = -1\n",
    "BRANCH_ACC = \"0.746\"\n",
    "learning_rate = 0.02\n",
    "learning_rate_dloralc = 0.4\n",
    "NUM_EPOCHES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "original = LeNet().to(device)\n",
    "model_original = LeNet().to(device)\n",
    "model_no_touch = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BRANCH_LOC = HDFP + \"/lobranch-snapshot/branchpoints/lenet/pretraining/branch_{}.pt\".format(BRANCH_ACC)\n",
    "original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "model_original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "model_no_touch.load_state_dict(torch.load(BRANCH_LOC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = getBase(original)\n",
    "model = LeNet_LowRank(w, b, rank = RANK).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['feature.0.weight', 'feature.0.bias', 'feature.3.weight', 'feature.3.bias', 'classifier.1.alpha', 'classifier.1.beta', 'classifier.1.bias', 'classifier.3.alpha', 'classifier.3.beta', 'classifier.3.bias', 'classifier.5.weight', 'classifier.5.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sd_decomp(torch.load(BRANCH_LOC, map_location=device), model, DECOMPOSED_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate_dloralc)\n",
    "optimizer_lc_only = torch.optim.SGD(model_original.parameters(), lr=learning_rate)\n",
    "optimizer_no_touch = torch.optim.SGD(model_no_touch.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_accuracy = []\n",
    "decomposed_full_accuracy = []\n",
    "restored_accuracy = []\n",
    "lc_accuracy = []\n",
    "\n",
    "# Initialize the current iteration and set to 0\n",
    "current_iter = 0\n",
    "current_set = 0\n",
    "\n",
    "# Initialize the current iteration and set to 0 for the old LC method\n",
    "current_iter_old_lc = 0\n",
    "current_set_old_lc = 0\n",
    "\n",
    "acc = lambda x, y : (torch.max(x, 1)[1] == y).sum().item() / y.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1985b4566c53499199cf53d55b7508bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Personal\\Singapour\\PFE\\code_of_shu-heng_with_models\\pfe_lc_lora\\wandb\\run-20240716_230346-3r3zdh3w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bryanbradfo/LeNet/runs/3r3zdh3w/workspace' target=\"_blank\">LeNet-With-Incremental-Learning</a></strong> to <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bryanbradfo/LeNet/runs/3r3zdh3w/workspace' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet/runs/3r3zdh3w/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Beginning of model training on train_loader1...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.132196068763733\n",
      "LC Training Loss (Full): 1.132196068763733\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.765625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.1750646829605103\n",
      "LC Training Loss (Full): 1.2217124700546265\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.0505313873291016\n",
      "LC Training Loss (Full): 1.1303263902664185\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9321801066398621\n",
      "LC Training Loss (Full): 1.0528396368026733\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.0028455257415771\n",
      "LC Training Loss (Full): 1.1414722204208374\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9400675892829895\n",
      "LC Training Loss (Full): 1.1062839031219482\n",
      "Full accuracy (w/o dLoRA+LC): 0.7482, LC accuracy: 0.7465, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7483, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7423\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9677613973617554\n",
      "LC Training Loss (Full): 1.1492669582366943\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.0538743734359741\n",
      "LC Training Loss (Full): 1.2361928224563599\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9045249819755554\n",
      "LC Training Loss (Full): 1.1223082542419434\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8495904803276062\n",
      "LC Training Loss (Full): 1.0889618396759033\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.875304102897644\n",
      "LC Training Loss (Full): 1.0627411603927612\n",
      "Full accuracy (w/o dLoRA+LC): 0.7483, LC accuracy: 0.7498, Decomposed-Full (w/dLoRA+LC) accuracy: 0.755, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7556\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.0654492378234863\n",
      "LC Training Loss (Full): 1.2402616739273071\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9538878798484802\n",
      "LC Training Loss (Full): 1.117891550064087\n",
      "Training Accuracy | Decomposed: 0.65625, Full : 0.6875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.0907546281814575\n",
      "LC Training Loss (Full): 1.2347517013549805\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.880025327205658\n",
      "LC Training Loss (Full): 1.0615088939666748\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8502299785614014\n",
      "LC Training Loss (Full): 1.0185699462890625\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9394927024841309\n",
      "LC Training Loss (Full): 1.1042888164520264\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9120162725448608\n",
      "LC Training Loss (Full): 1.072969913482666\n",
      "Full accuracy (w/o dLoRA+LC): 0.7547, LC accuracy: 0.7535, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7584, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7566\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7846642732620239\n",
      "LC Training Loss (Full): 0.9558681845664978\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8843151330947876\n",
      "LC Training Loss (Full): 1.0441073179244995\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.041604995727539\n",
      "LC Training Loss (Full): 1.1956483125686646\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8705912828445435\n",
      "LC Training Loss (Full): 1.0079251527786255\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9529467821121216\n",
      "LC Training Loss (Full): 1.0875505208969116\n",
      "Full accuracy (w/o dLoRA+LC): 0.7573, LC accuracy: 0.7571, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7582, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7578\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8363207578659058\n",
      "LC Training Loss (Full): 0.9727915525436401\n",
      "End of model training on train_loader1...\n",
      "Model saved at accuracy: 0.7582\n",
      "--------------------------\n",
      "Beginning of model training on train_loader2...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0043264627456665\n",
      "LC Training Loss (Full): 1.1287161111831665\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.75\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.1698440313339233\n",
      "LC Training Loss (Full): 1.2697426080703735\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.0031909942626953\n",
      "LC Training Loss (Full): 1.1486784219741821\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8914380073547363\n",
      "LC Training Loss (Full): 1.0159716606140137\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9901882410049438\n",
      "LC Training Loss (Full): 1.1999543905258179\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.985164225101471\n",
      "LC Training Loss (Full): 1.2227442264556885\n",
      "Full accuracy (w/o dLoRA+LC): 0.7632, LC accuracy: 0.758, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7995, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7778\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8283225297927856\n",
      "LC Training Loss (Full): 1.0611469745635986\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9080686569213867\n",
      "LC Training Loss (Full): 1.0839961767196655\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7782757878303528\n",
      "LC Training Loss (Full): 1.0267667770385742\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8615102171897888\n",
      "LC Training Loss (Full): 1.1237143278121948\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8099654316902161\n",
      "LC Training Loss (Full): 0.9927535653114319\n",
      "Full accuracy (w/o dLoRA+LC): 0.76, LC accuracy: 0.7602, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7703, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7708\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.9063206315040588\n",
      "LC Training Loss (Full): 1.0586873292922974\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9063701629638672\n",
      "LC Training Loss (Full): 1.0861190557479858\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.828125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8228579163551331\n",
      "LC Training Loss (Full): 0.9946314096450806\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9401962757110596\n",
      "LC Training Loss (Full): 1.0651891231536865\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.0183862447738647\n",
      "LC Training Loss (Full): 1.1547726392745972\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.0283957719802856\n",
      "LC Training Loss (Full): 1.1282747983932495\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8563461303710938\n",
      "LC Training Loss (Full): 1.0167882442474365\n",
      "Full accuracy (w/o dLoRA+LC): 0.7594, LC accuracy: 0.7583, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7725, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7725\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7921042442321777\n",
      "LC Training Loss (Full): 0.9266650676727295\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.0369060039520264\n",
      "LC Training Loss (Full): 1.1937053203582764\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8867171406745911\n",
      "LC Training Loss (Full): 1.0647186040878296\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9639599919319153\n",
      "LC Training Loss (Full): 1.1180630922317505\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8097732067108154\n",
      "LC Training Loss (Full): 0.9482595920562744\n",
      "Full accuracy (w/o dLoRA+LC): 0.7644, LC accuracy: 0.7646, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7734, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7735\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.9089452028274536\n",
      "LC Training Loss (Full): 1.0233131647109985\n",
      "End of model training on train_loader2...\n",
      "Model saved at accuracy: 0.7734\n",
      "--------------------------\n",
      "Beginning of model training on train_loader3...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8361262083053589\n",
      "LC Training Loss (Full): 0.9908942580223083\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.734375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6369919180870056\n",
      "LC Training Loss (Full): 0.8249568939208984\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7408263683319092\n",
      "LC Training Loss (Full): 0.8764690160751343\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7247676849365234\n",
      "LC Training Loss (Full): 0.916129469871521\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8118710517883301\n",
      "LC Training Loss (Full): 0.9972308874130249\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5859572887420654\n",
      "LC Training Loss (Full): 0.8378713726997375\n",
      "Full accuracy (w/o dLoRA+LC): 0.773, LC accuracy: 0.7641, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7978, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7864\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5554191470146179\n",
      "LC Training Loss (Full): 0.8126475214958191\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6512433290481567\n",
      "LC Training Loss (Full): 0.9405109882354736\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6230889558792114\n",
      "LC Training Loss (Full): 0.8456932902336121\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.515425443649292\n",
      "LC Training Loss (Full): 0.7859159111976624\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6544414162635803\n",
      "LC Training Loss (Full): 0.8633630871772766\n",
      "Full accuracy (w/o dLoRA+LC): 0.7772, LC accuracy: 0.7775, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7841, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7842\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6420739889144897\n",
      "LC Training Loss (Full): 0.816450297832489\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7129814028739929\n",
      "LC Training Loss (Full): 0.9028481841087341\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.75\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5099743008613586\n",
      "LC Training Loss (Full): 0.6998505592346191\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5715315937995911\n",
      "LC Training Loss (Full): 0.7788025736808777\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5964410305023193\n",
      "LC Training Loss (Full): 0.7678736448287964\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7871914505958557\n",
      "LC Training Loss (Full): 0.9339502453804016\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6888379454612732\n",
      "LC Training Loss (Full): 0.8898749351501465\n",
      "Full accuracy (w/o dLoRA+LC): 0.7816, LC accuracy: 0.7771, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7863, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7853\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7882323265075684\n",
      "LC Training Loss (Full): 0.9501696825027466\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6813600659370422\n",
      "LC Training Loss (Full): 0.832737922668457\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5283953547477722\n",
      "LC Training Loss (Full): 0.6901471018791199\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7369465827941895\n",
      "LC Training Loss (Full): 0.9062320590019226\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6791178584098816\n",
      "LC Training Loss (Full): 0.810426652431488\n",
      "Full accuracy (w/o dLoRA+LC): 0.788, LC accuracy: 0.7877, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7883, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7873\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6439260840415955\n",
      "LC Training Loss (Full): 0.7825612425804138\n",
      "End of model training on train_loader3...\n",
      "Model saved at accuracy: 0.7883\n",
      "--------------------------\n",
      "Beginning of model training on train_loader4...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6306472420692444\n",
      "LC Training Loss (Full): 0.7825186252593994\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.84375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7765547633171082\n",
      "LC Training Loss (Full): 0.8735151886940002\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5727586150169373\n",
      "LC Training Loss (Full): 0.7570512890815735\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8065552115440369\n",
      "LC Training Loss (Full): 0.9313575029373169\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7275240421295166\n",
      "LC Training Loss (Full): 0.8808709383010864\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5855490565299988\n",
      "LC Training Loss (Full): 0.7918946146965027\n",
      "Full accuracy (w/o dLoRA+LC): 0.7886, LC accuracy: 0.7862, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7707, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7827\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7596829533576965\n",
      "LC Training Loss (Full): 0.9317694902420044\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7238091826438904\n",
      "LC Training Loss (Full): 0.8964484333992004\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5790735483169556\n",
      "LC Training Loss (Full): 0.8103249073028564\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6184016466140747\n",
      "LC Training Loss (Full): 0.8547624349594116\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7240654826164246\n",
      "LC Training Loss (Full): 0.8469310998916626\n",
      "Full accuracy (w/o dLoRA+LC): 0.7966, LC accuracy: 0.7961, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7982, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7975\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6801372766494751\n",
      "LC Training Loss (Full): 0.8496973514556885\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8233453035354614\n",
      "LC Training Loss (Full): 0.9477524757385254\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.75\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.773223340511322\n",
      "LC Training Loss (Full): 0.907765805721283\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5783827304840088\n",
      "LC Training Loss (Full): 0.7205595374107361\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7561396956443787\n",
      "LC Training Loss (Full): 0.8821773529052734\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6194343566894531\n",
      "LC Training Loss (Full): 0.7609922289848328\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6157565712928772\n",
      "LC Training Loss (Full): 0.7475072741508484\n",
      "Full accuracy (w/o dLoRA+LC): 0.7979, LC accuracy: 0.7969, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8007, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7981\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7817463874816895\n",
      "LC Training Loss (Full): 0.9099588990211487\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5778657793998718\n",
      "LC Training Loss (Full): 0.7245373129844666\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6783846616744995\n",
      "LC Training Loss (Full): 0.7963117957115173\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6803446412086487\n",
      "LC Training Loss (Full): 0.8301241993904114\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6014580726623535\n",
      "LC Training Loss (Full): 0.7182981967926025\n",
      "Full accuracy (w/o dLoRA+LC): 0.8006, LC accuracy: 0.8021, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7992, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7986\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7020615339279175\n",
      "LC Training Loss (Full): 0.8013453483581543\n",
      "End of model training on train_loader4...\n",
      "Model saved at accuracy: 0.7992\n",
      "--------------------------\n",
      "Beginning of model training on train_loader5...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5569173693656921\n",
      "LC Training Loss (Full): 0.6695101857185364\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.828125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6677106618881226\n",
      "LC Training Loss (Full): 0.7733583450317383\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6319248676300049\n",
      "LC Training Loss (Full): 0.7946850657463074\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7367841005325317\n",
      "LC Training Loss (Full): 0.8627785444259644\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5399661660194397\n",
      "LC Training Loss (Full): 0.6613342761993408\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5979048609733582\n",
      "LC Training Loss (Full): 0.7782324552536011\n",
      "Full accuracy (w/o dLoRA+LC): 0.8068, LC accuracy: 0.8023, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8011, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8013\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.585096001625061\n",
      "LC Training Loss (Full): 0.7422814965248108\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5337917804718018\n",
      "LC Training Loss (Full): 0.7557613253593445\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5631448030471802\n",
      "LC Training Loss (Full): 0.7346470355987549\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5656055212020874\n",
      "LC Training Loss (Full): 0.7572299838066101\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7896115183830261\n",
      "LC Training Loss (Full): 0.8477674126625061\n",
      "Full accuracy (w/o dLoRA+LC): 0.809, LC accuracy: 0.8089, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8018, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7997\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7592984437942505\n",
      "LC Training Loss (Full): 0.824633777141571\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6285324692726135\n",
      "LC Training Loss (Full): 0.7295681238174438\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.828125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7225180864334106\n",
      "LC Training Loss (Full): 0.8399443626403809\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6396543383598328\n",
      "LC Training Loss (Full): 0.7423955798149109\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5327887535095215\n",
      "LC Training Loss (Full): 0.6335541605949402\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5381540656089783\n",
      "LC Training Loss (Full): 0.639951229095459\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7047512531280518\n",
      "LC Training Loss (Full): 0.7855415344238281\n",
      "Full accuracy (w/o dLoRA+LC): 0.8131, LC accuracy: 0.8091, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8036, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8008\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6821075677871704\n",
      "LC Training Loss (Full): 0.7752513885498047\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6058766841888428\n",
      "LC Training Loss (Full): 0.6888489723205566\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6810600161552429\n",
      "LC Training Loss (Full): 0.7629369497299194\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6347216963768005\n",
      "LC Training Loss (Full): 0.7591450214385986\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6638269424438477\n",
      "LC Training Loss (Full): 0.7295578122138977\n",
      "Full accuracy (w/o dLoRA+LC): 0.8145, LC accuracy: 0.814, Decomposed-Full (w/dLoRA+LC) accuracy: 0.803, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8017\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader5/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader5/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5047239661216736\n",
      "LC Training Loss (Full): 0.5951603651046753\n",
      "End of model training on train_loader5...\n",
      "Model saved at accuracy: 0.8030\n",
      "--------------------------\n",
      "Beginning of model training on train_loader6...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7830090522766113\n",
      "LC Training Loss (Full): 0.8485650420188904\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.8125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8115508556365967\n",
      "LC Training Loss (Full): 0.8454617261886597\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8506906032562256\n",
      "LC Training Loss (Full): 0.867795467376709\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5383604168891907\n",
      "LC Training Loss (Full): 0.6391676664352417\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.63689786195755\n",
      "LC Training Loss (Full): 0.7638899087905884\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.49734970927238464\n",
      "LC Training Loss (Full): 0.6426048278808594\n",
      "Full accuracy (w/o dLoRA+LC): 0.8187, LC accuracy: 0.8137, Decomposed-Full (w/dLoRA+LC) accuracy: 0.821, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8082\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5040987133979797\n",
      "LC Training Loss (Full): 0.6766337752342224\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6173592805862427\n",
      "LC Training Loss (Full): 0.7987969517707825\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5756807327270508\n",
      "LC Training Loss (Full): 0.6894804835319519\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6743444204330444\n",
      "LC Training Loss (Full): 0.766271710395813\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7278496026992798\n",
      "LC Training Loss (Full): 0.7939438819885254\n",
      "Full accuracy (w/o dLoRA+LC): 0.8222, LC accuracy: 0.8208, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8091, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8102\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5521207451820374\n",
      "LC Training Loss (Full): 0.6756957769393921\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7094482779502869\n",
      "LC Training Loss (Full): 0.7709300518035889\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.765625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6513683795928955\n",
      "LC Training Loss (Full): 0.7390080690383911\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.808137834072113\n",
      "LC Training Loss (Full): 0.8586168885231018\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6230529546737671\n",
      "LC Training Loss (Full): 0.7045242190361023\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6878870129585266\n",
      "LC Training Loss (Full): 0.7495967745780945\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6285314559936523\n",
      "LC Training Loss (Full): 0.7190343141555786\n",
      "Full accuracy (w/o dLoRA+LC): 0.8276, LC accuracy: 0.8219, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8132, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8099\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7897891998291016\n",
      "LC Training Loss (Full): 0.842654287815094\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4982845187187195\n",
      "LC Training Loss (Full): 0.5948782563209534\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5998451113700867\n",
      "LC Training Loss (Full): 0.6589358448982239\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6298134922981262\n",
      "LC Training Loss (Full): 0.7216447591781616\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5825913548469543\n",
      "LC Training Loss (Full): 0.6668151021003723\n",
      "Full accuracy (w/o dLoRA+LC): 0.8284, LC accuracy: 0.8278, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8111, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8109\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader6/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader6/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4566330909729004\n",
      "LC Training Loss (Full): 0.5688916444778442\n",
      "End of model training on train_loader6...\n",
      "Model saved at accuracy: 0.8111\n",
      "--------------------------\n",
      "Beginning of model training on train_loader7...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7170685529708862\n",
      "LC Training Loss (Full): 0.8047072887420654\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.765625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7701138257980347\n",
      "LC Training Loss (Full): 0.8118035197257996\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6808323860168457\n",
      "LC Training Loss (Full): 0.7398326992988586\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7568467855453491\n",
      "LC Training Loss (Full): 0.7843098044395447\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.670792818069458\n",
      "LC Training Loss (Full): 0.7460636496543884\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5749092698097229\n",
      "LC Training Loss (Full): 0.6488794088363647\n",
      "Full accuracy (w/o dLoRA+LC): 0.8288, LC accuracy: 0.8284, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8115, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8046\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7085455060005188\n",
      "LC Training Loss (Full): 0.7732120752334595\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.696411669254303\n",
      "LC Training Loss (Full): 0.7500086426734924\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.722732424736023\n",
      "LC Training Loss (Full): 0.7298405766487122\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5999603867530823\n",
      "LC Training Loss (Full): 0.705466628074646\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6767447590827942\n",
      "LC Training Loss (Full): 0.7295960783958435\n",
      "Full accuracy (w/o dLoRA+LC): 0.8337, LC accuracy: 0.8327, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8142, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8133\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6967524886131287\n",
      "LC Training Loss (Full): 0.7633889317512512\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8105612397193909\n",
      "LC Training Loss (Full): 0.8501110672950745\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.796875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7075451016426086\n",
      "LC Training Loss (Full): 0.7449759840965271\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6033887267112732\n",
      "LC Training Loss (Full): 0.6759194731712341\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5871424078941345\n",
      "LC Training Loss (Full): 0.658959150314331\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7491430640220642\n",
      "LC Training Loss (Full): 0.7841121554374695\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6325681805610657\n",
      "LC Training Loss (Full): 0.6784138679504395\n",
      "Full accuracy (w/o dLoRA+LC): 0.8361, LC accuracy: 0.8337, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8169, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8149\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7412444353103638\n",
      "LC Training Loss (Full): 0.7853020429611206\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6511394381523132\n",
      "LC Training Loss (Full): 0.692140519618988\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6685656905174255\n",
      "LC Training Loss (Full): 0.7183765769004822\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6858179569244385\n",
      "LC Training Loss (Full): 0.7378494739532471\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7057611346244812\n",
      "LC Training Loss (Full): 0.7104079723358154\n",
      "Full accuracy (w/o dLoRA+LC): 0.8372, LC accuracy: 0.8371, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8158, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8147\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader7/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader7/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5269107222557068\n",
      "LC Training Loss (Full): 0.593553364276886\n",
      "End of model training on train_loader7...\n",
      "Model saved at accuracy: 0.8158\n",
      "--------------------------\n",
      "Beginning of model training on train_loader8...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6602730751037598\n",
      "LC Training Loss (Full): 0.6769264936447144\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.8125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6168621182441711\n",
      "LC Training Loss (Full): 0.6548460721969604\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5798729062080383\n",
      "LC Training Loss (Full): 0.6346713900566101\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6037421226501465\n",
      "LC Training Loss (Full): 0.6509338021278381\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6205194592475891\n",
      "LC Training Loss (Full): 0.6665715575218201\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7153735756874084\n",
      "LC Training Loss (Full): 0.6982024908065796\n",
      "Full accuracy (w/o dLoRA+LC): 0.8381, LC accuracy: 0.8386, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7993, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8165\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5248410701751709\n",
      "LC Training Loss (Full): 0.5753385424613953\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.49992164969444275\n",
      "LC Training Loss (Full): 0.624274730682373\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5566486716270447\n",
      "LC Training Loss (Full): 0.6633449792861938\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.47671976685523987\n",
      "LC Training Loss (Full): 0.6278311014175415\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6122540831565857\n",
      "LC Training Loss (Full): 0.6239861845970154\n",
      "Full accuracy (w/o dLoRA+LC): 0.838, LC accuracy: 0.8387, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8143, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8153\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.666790246963501\n",
      "LC Training Loss (Full): 0.6408515572547913\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.547130823135376\n",
      "LC Training Loss (Full): 0.5771108865737915\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7939474582672119\n",
      "LC Training Loss (Full): 0.8005316257476807\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5621927976608276\n",
      "LC Training Loss (Full): 0.5920277833938599\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4482470154762268\n",
      "LC Training Loss (Full): 0.4846201539039612\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6220715045928955\n",
      "LC Training Loss (Full): 0.604250431060791\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5565953254699707\n",
      "LC Training Loss (Full): 0.5938879251480103\n",
      "Full accuracy (w/o dLoRA+LC): 0.8385, LC accuracy: 0.8374, Decomposed-Full (w/dLoRA+LC) accuracy: 0.818, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8144\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8210153579711914\n",
      "LC Training Loss (Full): 0.7986449599266052\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.639106273651123\n",
      "LC Training Loss (Full): 0.6524648070335388\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4603298604488373\n",
      "LC Training Loss (Full): 0.5161018967628479\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5317411422729492\n",
      "LC Training Loss (Full): 0.5732318758964539\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.506977915763855\n",
      "LC Training Loss (Full): 0.5554750561714172\n",
      "Full accuracy (w/o dLoRA+LC): 0.8409, LC accuracy: 0.8402, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8163, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8146\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader8/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader8/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6398612260818481\n",
      "LC Training Loss (Full): 0.6097210645675659\n",
      "End of model training on train_loader8...\n",
      "Model saved at accuracy: 0.8163\n",
      "--------------------------\n",
      "Beginning of model training on train_loader9...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6070670485496521\n",
      "LC Training Loss (Full): 0.6464963555335999\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4383476972579956\n",
      "LC Training Loss (Full): 0.5050461292266846\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.49306222796440125\n",
      "LC Training Loss (Full): 0.5632926225662231\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6453846096992493\n",
      "LC Training Loss (Full): 0.6569136381149292\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.401996374130249\n",
      "LC Training Loss (Full): 0.47804829478263855\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4891667068004608\n",
      "LC Training Loss (Full): 0.5272166132926941\n",
      "Full accuracy (w/o dLoRA+LC): 0.843, LC accuracy: 0.8407, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8211, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8157\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5538867115974426\n",
      "LC Training Loss (Full): 0.6350583434104919\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6857225298881531\n",
      "LC Training Loss (Full): 0.7484599947929382\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45260924100875854\n",
      "LC Training Loss (Full): 0.5765306949615479\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5102806687355042\n",
      "LC Training Loss (Full): 0.6400537490844727\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6283975839614868\n",
      "LC Training Loss (Full): 0.6184583902359009\n",
      "Full accuracy (w/o dLoRA+LC): 0.8435, LC accuracy: 0.8445, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8217, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8215\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6038437485694885\n",
      "LC Training Loss (Full): 0.6531434655189514\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6920760869979858\n",
      "LC Training Loss (Full): 0.6889646053314209\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.828125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.43114161491394043\n",
      "LC Training Loss (Full): 0.4848457872867584\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6116700172424316\n",
      "LC Training Loss (Full): 0.6166133284568787\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5166395902633667\n",
      "LC Training Loss (Full): 0.5418006181716919\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6551893353462219\n",
      "LC Training Loss (Full): 0.6895509958267212\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4946962296962738\n",
      "LC Training Loss (Full): 0.5154604315757751\n",
      "Full accuracy (w/o dLoRA+LC): 0.8444, LC accuracy: 0.8451, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8257, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8217\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6378746628761292\n",
      "LC Training Loss (Full): 0.6593100428581238\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.515264630317688\n",
      "LC Training Loss (Full): 0.5451857447624207\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5696743726730347\n",
      "LC Training Loss (Full): 0.6296537518501282\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6327418088912964\n",
      "LC Training Loss (Full): 0.6376972198486328\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.44416892528533936\n",
      "LC Training Loss (Full): 0.454535573720932\n",
      "Full accuracy (w/o dLoRA+LC): 0.8486, LC accuracy: 0.849, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8225, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8213\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader9/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader9/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.32758188247680664\n",
      "LC Training Loss (Full): 0.4109858274459839\n",
      "End of model training on train_loader9...\n",
      "Model saved at accuracy: 0.8225\n",
      "--------------------------\n",
      "Beginning of model training on train_loader10...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6416733264923096\n",
      "LC Training Loss (Full): 0.6319920420646667\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.78125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6439607739448547\n",
      "LC Training Loss (Full): 0.5984804630279541\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.60045325756073\n",
      "LC Training Loss (Full): 0.5811039805412292\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6126973032951355\n",
      "LC Training Loss (Full): 0.5688440799713135\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5495321154594421\n",
      "LC Training Loss (Full): 0.5329098701477051\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7270724177360535\n",
      "LC Training Loss (Full): 0.7219408750534058\n",
      "Full accuracy (w/o dLoRA+LC): 0.8513, LC accuracy: 0.8478, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8278, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8265\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7781246304512024\n",
      "LC Training Loss (Full): 0.790343701839447\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4440879821777344\n",
      "LC Training Loss (Full): 0.5512428879737854\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7061846256256104\n",
      "LC Training Loss (Full): 0.7218244075775146\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5925903916358948\n",
      "LC Training Loss (Full): 0.6492856740951538\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4886256456375122\n",
      "LC Training Loss (Full): 0.5651913285255432\n",
      "Full accuracy (w/o dLoRA+LC): 0.8542, LC accuracy: 0.8544, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8284, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8278\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6265558004379272\n",
      "LC Training Loss (Full): 0.6222835183143616\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5557799935340881\n",
      "LC Training Loss (Full): 0.5421195030212402\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5470410585403442\n",
      "LC Training Loss (Full): 0.5600417256355286\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5946348905563354\n",
      "LC Training Loss (Full): 0.6020743250846863\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5232445597648621\n",
      "LC Training Loss (Full): 0.5493472814559937\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8317766785621643\n",
      "LC Training Loss (Full): 0.7385867834091187\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49860328435897827\n",
      "LC Training Loss (Full): 0.49594637751579285\n",
      "Full accuracy (w/o dLoRA+LC): 0.8543, LC accuracy: 0.8531, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8281, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8273\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6498508453369141\n",
      "LC Training Loss (Full): 0.6182907819747925\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7389211654663086\n",
      "LC Training Loss (Full): 0.6829724907875061\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.636447012424469\n",
      "LC Training Loss (Full): 0.6618098616600037\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5857256054878235\n",
      "LC Training Loss (Full): 0.592124342918396\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.644534170627594\n",
      "LC Training Loss (Full): 0.631079375743866\n",
      "Full accuracy (w/o dLoRA+LC): 0.8555, LC accuracy: 0.8551, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8271, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8276\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader10/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader10/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6344854831695557\n",
      "LC Training Loss (Full): 0.578829824924469\n",
      "End of model training on train_loader10...\n",
      "Model saved at accuracy: 0.8271\n",
      "--------------------------\n",
      "Beginning of model training on train_loader11...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5042481422424316\n",
      "LC Training Loss (Full): 0.5315842628479004\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.859375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7324656844139099\n",
      "LC Training Loss (Full): 0.7016265392303467\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7878154516220093\n",
      "LC Training Loss (Full): 0.7515981197357178\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6474002003669739\n",
      "LC Training Loss (Full): 0.6732401847839355\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5725060701370239\n",
      "LC Training Loss (Full): 0.5149005651473999\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6205796003341675\n",
      "LC Training Loss (Full): 0.6692647933959961\n",
      "Full accuracy (w/o dLoRA+LC): 0.8568, LC accuracy: 0.8555, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8172, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8265\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.600971519947052\n",
      "LC Training Loss (Full): 0.6456719040870667\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5858312249183655\n",
      "LC Training Loss (Full): 0.6600343585014343\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5960143804550171\n",
      "LC Training Loss (Full): 0.6603999733924866\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.40589988231658936\n",
      "LC Training Loss (Full): 0.49984878301620483\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6211385130882263\n",
      "LC Training Loss (Full): 0.5837745070457458\n",
      "Full accuracy (w/o dLoRA+LC): 0.8572, LC accuracy: 0.8562, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8293, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8294\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7951314449310303\n",
      "LC Training Loss (Full): 0.7390900254249573\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5478588342666626\n",
      "LC Training Loss (Full): 0.5447446703910828\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5999331474304199\n",
      "LC Training Loss (Full): 0.586611270904541\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6216455698013306\n",
      "LC Training Loss (Full): 0.5784161686897278\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.846770703792572\n",
      "LC Training Loss (Full): 0.802492082118988\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6575295329093933\n",
      "LC Training Loss (Full): 0.6482235789299011\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.619756817817688\n",
      "LC Training Loss (Full): 0.6328427791595459\n",
      "Full accuracy (w/o dLoRA+LC): 0.8565, LC accuracy: 0.8565, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8306, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8298\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5154016017913818\n",
      "LC Training Loss (Full): 0.5025006532669067\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.845919132232666\n",
      "LC Training Loss (Full): 0.7944375276565552\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4589596688747406\n",
      "LC Training Loss (Full): 0.48094436526298523\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.65204256772995\n",
      "LC Training Loss (Full): 0.5902637839317322\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5242977738380432\n",
      "LC Training Loss (Full): 0.5156012177467346\n",
      "Full accuracy (w/o dLoRA+LC): 0.8592, LC accuracy: 0.859, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8295, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8295\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader11/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader11/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5254425406455994\n",
      "LC Training Loss (Full): 0.5378698110580444\n",
      "End of model training on train_loader11...\n",
      "Model saved at accuracy: 0.8295\n",
      "--------------------------\n",
      "Beginning of model training on train_loader12...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6534534096717834\n",
      "LC Training Loss (Full): 0.6017432808876038\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.859375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7916336059570312\n",
      "LC Training Loss (Full): 0.6691514849662781\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5786593556404114\n",
      "LC Training Loss (Full): 0.5726872086524963\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5179871320724487\n",
      "LC Training Loss (Full): 0.5481858253479004\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8440443873405457\n",
      "LC Training Loss (Full): 0.7417131066322327\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5588487982749939\n",
      "LC Training Loss (Full): 0.5487174987792969\n",
      "Full accuracy (w/o dLoRA+LC): 0.8625, LC accuracy: 0.8593, Decomposed-Full (w/dLoRA+LC) accuracy: 0.792, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8182\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8730404376983643\n",
      "LC Training Loss (Full): 0.6865108013153076\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8619418740272522\n",
      "LC Training Loss (Full): 0.6859463453292847\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8035275340080261\n",
      "LC Training Loss (Full): 0.6176500916481018\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6625902056694031\n",
      "LC Training Loss (Full): 0.542328953742981\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.754697322845459\n",
      "LC Training Loss (Full): 0.6802631616592407\n",
      "Full accuracy (w/o dLoRA+LC): 0.8608, LC accuracy: 0.8621, Decomposed-Full (w/dLoRA+LC) accuracy: 0.829, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8279\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.806300938129425\n",
      "LC Training Loss (Full): 0.7465794086456299\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6840718984603882\n",
      "LC Training Loss (Full): 0.552804708480835\n",
      "Training Accuracy | Decomposed: 0.703125, Full : 0.875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9501471519470215\n",
      "LC Training Loss (Full): 0.8528145551681519\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6991841793060303\n",
      "LC Training Loss (Full): 0.6343303322792053\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6649995446205139\n",
      "LC Training Loss (Full): 0.6302489042282104\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4910084009170532\n",
      "LC Training Loss (Full): 0.4800506830215454\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8984636068344116\n",
      "LC Training Loss (Full): 0.7718877196311951\n",
      "Full accuracy (w/o dLoRA+LC): 0.8606, LC accuracy: 0.8628, Decomposed-Full (w/dLoRA+LC) accuracy: 0.83, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8293\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.682316243648529\n",
      "LC Training Loss (Full): 0.5986413955688477\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4796300530433655\n",
      "LC Training Loss (Full): 0.46449947357177734\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5645621418952942\n",
      "LC Training Loss (Full): 0.5630516409873962\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7398712635040283\n",
      "LC Training Loss (Full): 0.725053071975708\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.637252688407898\n",
      "LC Training Loss (Full): 0.5870035290718079\n",
      "Full accuracy (w/o dLoRA+LC): 0.8647, LC accuracy: 0.8633, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8297, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8296\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader12/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader12/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.47775328159332275\n",
      "LC Training Loss (Full): 0.43288734555244446\n",
      "End of model training on train_loader12...\n",
      "Model saved at accuracy: 0.8297\n",
      "--------------------------\n",
      "Beginning of model training on train_loader13...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3383043706417084\n",
      "LC Training Loss (Full): 0.3429139256477356\n",
      "Training Accuracy | Decomposed: 0.953125, Full : 0.96875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6187531352043152\n",
      "LC Training Loss (Full): 0.5785256624221802\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6324087381362915\n",
      "LC Training Loss (Full): 0.5973401665687561\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5565788745880127\n",
      "LC Training Loss (Full): 0.4933663308620453\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4985490143299103\n",
      "LC Training Loss (Full): 0.5030044913291931\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6717111468315125\n",
      "LC Training Loss (Full): 0.6193563342094421\n",
      "Full accuracy (w/o dLoRA+LC): 0.8635, LC accuracy: 0.8639, Decomposed-Full (w/dLoRA+LC) accuracy: 0.826, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8295\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5319085121154785\n",
      "LC Training Loss (Full): 0.5151634812355042\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.565899133682251\n",
      "LC Training Loss (Full): 0.5615746378898621\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4664556384086609\n",
      "LC Training Loss (Full): 0.42560097575187683\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7860869765281677\n",
      "LC Training Loss (Full): 0.752485454082489\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4905078113079071\n",
      "LC Training Loss (Full): 0.4852018654346466\n",
      "Full accuracy (w/o dLoRA+LC): 0.8625, LC accuracy: 0.8628, Decomposed-Full (w/dLoRA+LC) accuracy: 0.834, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8332\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5965814590454102\n",
      "LC Training Loss (Full): 0.5317593812942505\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5165500640869141\n",
      "LC Training Loss (Full): 0.4969094395637512\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41017261147499084\n",
      "LC Training Loss (Full): 0.39730560779571533\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5238692760467529\n",
      "LC Training Loss (Full): 0.47767266631126404\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6908124089241028\n",
      "LC Training Loss (Full): 0.602109432220459\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7581342458724976\n",
      "LC Training Loss (Full): 0.6888454556465149\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5145410895347595\n",
      "LC Training Loss (Full): 0.5003278851509094\n",
      "Full accuracy (w/o dLoRA+LC): 0.8606, LC accuracy: 0.863, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8347, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8347\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5695325136184692\n",
      "LC Training Loss (Full): 0.5456259250640869\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.552463710308075\n",
      "LC Training Loss (Full): 0.5302940607070923\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49786385893821716\n",
      "LC Training Loss (Full): 0.45636773109436035\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.43428662419319153\n",
      "LC Training Loss (Full): 0.39359527826309204\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6757863759994507\n",
      "LC Training Loss (Full): 0.6101992130279541\n",
      "Full accuracy (w/o dLoRA+LC): 0.8634, LC accuracy: 0.8638, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8345, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8345\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader13/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader13/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4950924217700958\n",
      "LC Training Loss (Full): 0.46467792987823486\n",
      "End of model training on train_loader13...\n",
      "Model saved at accuracy: 0.8345\n",
      "--------------------------\n",
      "Beginning of model training on train_loader14...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5914354920387268\n",
      "LC Training Loss (Full): 0.5215395092964172\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.84375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5126396417617798\n",
      "LC Training Loss (Full): 0.4477809965610504\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5236284136772156\n",
      "LC Training Loss (Full): 0.41425102949142456\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5346906781196594\n",
      "LC Training Loss (Full): 0.49289894104003906\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.417466402053833\n",
      "LC Training Loss (Full): 0.4163527190685272\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5528069734573364\n",
      "LC Training Loss (Full): 0.5106671452522278\n",
      "Full accuracy (w/o dLoRA+LC): 0.8649, LC accuracy: 0.864, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8393, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.833\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.490124374628067\n",
      "LC Training Loss (Full): 0.44346627593040466\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4985305964946747\n",
      "LC Training Loss (Full): 0.4538431465625763\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6923745274543762\n",
      "LC Training Loss (Full): 0.6206549406051636\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45578548312187195\n",
      "LC Training Loss (Full): 0.4402987062931061\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5269519090652466\n",
      "LC Training Loss (Full): 0.46415531635284424\n",
      "Full accuracy (w/o dLoRA+LC): 0.8676, LC accuracy: 0.8673, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8352, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8348\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.67372065782547\n",
      "LC Training Loss (Full): 0.545963704586029\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5704141855239868\n",
      "LC Training Loss (Full): 0.4836091995239258\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4677719473838806\n",
      "LC Training Loss (Full): 0.42052367329597473\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6442111134529114\n",
      "LC Training Loss (Full): 0.5655219554901123\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6383946537971497\n",
      "LC Training Loss (Full): 0.488798052072525\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3856605589389801\n",
      "LC Training Loss (Full): 0.34442853927612305\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5133491158485413\n",
      "LC Training Loss (Full): 0.4588729441165924\n",
      "Full accuracy (w/o dLoRA+LC): 0.8699, LC accuracy: 0.8666, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8372, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8353\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6646336913108826\n",
      "LC Training Loss (Full): 0.5538271069526672\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3684145212173462\n",
      "LC Training Loss (Full): 0.37634891271591187\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4106178283691406\n",
      "LC Training Loss (Full): 0.3916058838367462\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5605107545852661\n",
      "LC Training Loss (Full): 0.48932942748069763\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5310415625572205\n",
      "LC Training Loss (Full): 0.4830983877182007\n",
      "Full accuracy (w/o dLoRA+LC): 0.8688, LC accuracy: 0.867, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8348, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.836\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader14/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader14/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5681503415107727\n",
      "LC Training Loss (Full): 0.4840928316116333\n",
      "End of model training on train_loader14...\n",
      "Model saved at accuracy: 0.8348\n",
      "--------------------------\n",
      "Beginning of model training on train_loader15...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5966692566871643\n",
      "LC Training Loss (Full): 0.5230779051780701\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.84375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5431373715400696\n",
      "LC Training Loss (Full): 0.4699689745903015\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5159510970115662\n",
      "LC Training Loss (Full): 0.4178325831890106\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.28982096910476685\n",
      "LC Training Loss (Full): 0.2545277178287506\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5694546699523926\n",
      "LC Training Loss (Full): 0.519305944442749\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6229864358901978\n",
      "LC Training Loss (Full): 0.5355817675590515\n",
      "Full accuracy (w/o dLoRA+LC): 0.8674, LC accuracy: 0.868, Decomposed-Full (w/dLoRA+LC) accuracy: 0.796, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8264\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5854418277740479\n",
      "LC Training Loss (Full): 0.5248170495033264\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5208761096000671\n",
      "LC Training Loss (Full): 0.462434321641922\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5507628917694092\n",
      "LC Training Loss (Full): 0.47133946418762207\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.39843159914016724\n",
      "LC Training Loss (Full): 0.41637831926345825\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5830936431884766\n",
      "LC Training Loss (Full): 0.47017568349838257\n",
      "Full accuracy (w/o dLoRA+LC): 0.8698, LC accuracy: 0.8693, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8329, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8314\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5761059522628784\n",
      "LC Training Loss (Full): 0.47405993938446045\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5056400895118713\n",
      "LC Training Loss (Full): 0.43975383043289185\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4877333641052246\n",
      "LC Training Loss (Full): 0.474099725484848\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4058881103992462\n",
      "LC Training Loss (Full): 0.356561541557312\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6693694591522217\n",
      "LC Training Loss (Full): 0.5378690361976624\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5891270637512207\n",
      "LC Training Loss (Full): 0.4721373915672302\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5605732202529907\n",
      "LC Training Loss (Full): 0.5139139890670776\n",
      "Full accuracy (w/o dLoRA+LC): 0.8681, LC accuracy: 0.8701, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8319, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8323\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4955781400203705\n",
      "LC Training Loss (Full): 0.4137880206108093\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4417140781879425\n",
      "LC Training Loss (Full): 0.3766103684902191\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39243417978286743\n",
      "LC Training Loss (Full): 0.38091841340065\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4137730002403259\n",
      "LC Training Loss (Full): 0.37651970982551575\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6096368432044983\n",
      "LC Training Loss (Full): 0.5286675095558167\n",
      "Full accuracy (w/o dLoRA+LC): 0.8705, LC accuracy: 0.8695, Decomposed-Full (w/dLoRA+LC) accuracy: 0.833, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8323\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader15/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader15/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5725407600402832\n",
      "LC Training Loss (Full): 0.4654095470905304\n",
      "End of model training on train_loader15...\n",
      "Model saved at accuracy: 0.8330\n",
      "--------------------------\n",
      "Beginning of model training on train_loader16...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5896725654602051\n",
      "LC Training Loss (Full): 0.48510387539863586\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5606847405433655\n",
      "LC Training Loss (Full): 0.4536679685115814\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5269173383712769\n",
      "LC Training Loss (Full): 0.45842838287353516\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5245158672332764\n",
      "LC Training Loss (Full): 0.4710679352283478\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7911080718040466\n",
      "LC Training Loss (Full): 0.7687780261039734\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5871562361717224\n",
      "LC Training Loss (Full): 0.4944431185722351\n",
      "Full accuracy (w/o dLoRA+LC): 0.8726, LC accuracy: 0.8712, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8307, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.831\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.584606945514679\n",
      "LC Training Loss (Full): 0.540458083152771\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7829549312591553\n",
      "LC Training Loss (Full): 0.7277746200561523\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6757456660270691\n",
      "LC Training Loss (Full): 0.5615077614784241\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5660657286643982\n",
      "LC Training Loss (Full): 0.559956967830658\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.43662288784980774\n",
      "LC Training Loss (Full): 0.3644392192363739\n",
      "Full accuracy (w/o dLoRA+LC): 0.8752, LC accuracy: 0.876, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8342, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8349\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4937000274658203\n",
      "LC Training Loss (Full): 0.46475911140441895\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5692760348320007\n",
      "LC Training Loss (Full): 0.49153727293014526\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5990743637084961\n",
      "LC Training Loss (Full): 0.5118187069892883\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8225231766700745\n",
      "LC Training Loss (Full): 0.6753383278846741\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.536804735660553\n",
      "LC Training Loss (Full): 0.49810847640037537\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5616268515586853\n",
      "LC Training Loss (Full): 0.43834254145622253\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.559665858745575\n",
      "LC Training Loss (Full): 0.5200929045677185\n",
      "Full accuracy (w/o dLoRA+LC): 0.874, LC accuracy: 0.875, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8353, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8339\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5893305540084839\n",
      "LC Training Loss (Full): 0.5098583102226257\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6620901226997375\n",
      "LC Training Loss (Full): 0.5510067343711853\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5198651552200317\n",
      "LC Training Loss (Full): 0.4624462425708771\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4795648753643036\n",
      "LC Training Loss (Full): 0.3647400438785553\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5693498849868774\n",
      "LC Training Loss (Full): 0.502424955368042\n",
      "Full accuracy (w/o dLoRA+LC): 0.8751, LC accuracy: 0.8749, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8337, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8335\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader16/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader16/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6070417761802673\n",
      "LC Training Loss (Full): 0.5990573763847351\n",
      "End of model training on train_loader16...\n",
      "Model saved at accuracy: 0.8337\n",
      "--------------------------\n",
      "Beginning of model training on train_loader17...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.49251773953437805\n",
      "LC Training Loss (Full): 0.43806010484695435\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.84375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5536508560180664\n",
      "LC Training Loss (Full): 0.41008460521698\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6907151937484741\n",
      "LC Training Loss (Full): 0.5676456689834595\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5549908876419067\n",
      "LC Training Loss (Full): 0.5342932939529419\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9265583753585815\n",
      "LC Training Loss (Full): 0.7814417481422424\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5981866121292114\n",
      "LC Training Loss (Full): 0.5217320919036865\n",
      "Full accuracy (w/o dLoRA+LC): 0.8757, LC accuracy: 0.8758, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8155, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8318\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6138746738433838\n",
      "LC Training Loss (Full): 0.567084789276123\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8882995247840881\n",
      "LC Training Loss (Full): 0.7600427269935608\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7187250852584839\n",
      "LC Training Loss (Full): 0.6139362454414368\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6352470517158508\n",
      "LC Training Loss (Full): 0.6314714550971985\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4056926965713501\n",
      "LC Training Loss (Full): 0.33557257056236267\n",
      "Full accuracy (w/o dLoRA+LC): 0.8784, LC accuracy: 0.8771, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8383, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8387\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4025770425796509\n",
      "LC Training Loss (Full): 0.3894828259944916\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6297405362129211\n",
      "LC Training Loss (Full): 0.5794174671173096\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.859375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5242607593536377\n",
      "LC Training Loss (Full): 0.4630518853664398\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5008848905563354\n",
      "LC Training Loss (Full): 0.3963952958583832\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4484381675720215\n",
      "LC Training Loss (Full): 0.4157525300979614\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8460308313369751\n",
      "LC Training Loss (Full): 0.7118982672691345\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6608555316925049\n",
      "LC Training Loss (Full): 0.5579398274421692\n",
      "Full accuracy (w/o dLoRA+LC): 0.8778, LC accuracy: 0.8785, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8394, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8379\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.576183021068573\n",
      "LC Training Loss (Full): 0.48134636878967285\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5817564129829407\n",
      "LC Training Loss (Full): 0.5013066530227661\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6645917296409607\n",
      "LC Training Loss (Full): 0.5559506416320801\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5520051121711731\n",
      "LC Training Loss (Full): 0.46991410851478577\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8638274073600769\n",
      "LC Training Loss (Full): 0.7296303510665894\n",
      "Full accuracy (w/o dLoRA+LC): 0.8789, LC accuracy: 0.8793, Decomposed-Full (w/dLoRA+LC) accuracy: 0.838, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.838\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader17/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader17/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.48778483271598816\n",
      "LC Training Loss (Full): 0.43777939677238464\n",
      "End of model training on train_loader17...\n",
      "Model saved at accuracy: 0.8380\n",
      "--------------------------\n",
      "Beginning of model training on train_loader18...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48044198751449585\n",
      "LC Training Loss (Full): 0.35018742084503174\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6818558573722839\n",
      "LC Training Loss (Full): 0.49682897329330444\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.678984522819519\n",
      "LC Training Loss (Full): 0.3851989805698395\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.833147406578064\n",
      "LC Training Loss (Full): 0.6464643478393555\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8366684913635254\n",
      "LC Training Loss (Full): 0.6636595129966736\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5894016623497009\n",
      "LC Training Loss (Full): 0.44870713353157043\n",
      "Full accuracy (w/o dLoRA+LC): 0.8803, LC accuracy: 0.8797, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8497, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8412\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5464159846305847\n",
      "LC Training Loss (Full): 0.4407201111316681\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5810483694076538\n",
      "LC Training Loss (Full): 0.5269668102264404\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7780916690826416\n",
      "LC Training Loss (Full): 0.5667051076889038\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5027040839195251\n",
      "LC Training Loss (Full): 0.4830019176006317\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4562295377254486\n",
      "LC Training Loss (Full): 0.3834450840950012\n",
      "Full accuracy (w/o dLoRA+LC): 0.8801, LC accuracy: 0.8798, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8342, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8331\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.8369562029838562\n",
      "LC Training Loss (Full): 0.6580140590667725\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7300037145614624\n",
      "LC Training Loss (Full): 0.5816119313240051\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.8125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6157825589179993\n",
      "LC Training Loss (Full): 0.47744637727737427\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41008082032203674\n",
      "LC Training Loss (Full): 0.29547399282455444\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5330525040626526\n",
      "LC Training Loss (Full): 0.43643927574157715\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8186070919036865\n",
      "LC Training Loss (Full): 0.6372299194335938\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5878828167915344\n",
      "LC Training Loss (Full): 0.4633772075176239\n",
      "Full accuracy (w/o dLoRA+LC): 0.881, LC accuracy: 0.8802, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8354, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8335\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4166698157787323\n",
      "LC Training Loss (Full): 0.3276365399360657\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8448305726051331\n",
      "LC Training Loss (Full): 0.6686429381370544\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7304771542549133\n",
      "LC Training Loss (Full): 0.5894085168838501\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5399414300918579\n",
      "LC Training Loss (Full): 0.4209008812904358\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.566129744052887\n",
      "LC Training Loss (Full): 0.4651683270931244\n",
      "Full accuracy (w/o dLoRA+LC): 0.8833, LC accuracy: 0.8833, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8366, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8351\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader18/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader18/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5165776610374451\n",
      "LC Training Loss (Full): 0.43119940161705017\n",
      "End of model training on train_loader18...\n",
      "Model saved at accuracy: 0.8366\n",
      "--------------------------\n",
      "Beginning of model training on train_loader19...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48138558864593506\n",
      "LC Training Loss (Full): 0.41367107629776\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5469123125076294\n",
      "LC Training Loss (Full): 0.4492352604866028\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4853896200656891\n",
      "LC Training Loss (Full): 0.352019727230072\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6257870197296143\n",
      "LC Training Loss (Full): 0.5372118353843689\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5452107191085815\n",
      "LC Training Loss (Full): 0.4575527310371399\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.532961368560791\n",
      "LC Training Loss (Full): 0.4715772271156311\n",
      "Full accuracy (w/o dLoRA+LC): 0.8814, LC accuracy: 0.881, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8436, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8399\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5693517327308655\n",
      "LC Training Loss (Full): 0.496545672416687\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5852447152137756\n",
      "LC Training Loss (Full): 0.5424102544784546\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6109684109687805\n",
      "LC Training Loss (Full): 0.508470356464386\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6114205718040466\n",
      "LC Training Loss (Full): 0.5544146299362183\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.673804521560669\n",
      "LC Training Loss (Full): 0.5569003820419312\n",
      "Full accuracy (w/o dLoRA+LC): 0.8824, LC accuracy: 0.8816, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8373, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8349\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.38859859108924866\n",
      "LC Training Loss (Full): 0.2809891104698181\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.502583384513855\n",
      "LC Training Loss (Full): 0.4157736599445343\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4300628900527954\n",
      "LC Training Loss (Full): 0.3165203630924225\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5916587710380554\n",
      "LC Training Loss (Full): 0.5262554287910461\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5325915217399597\n",
      "LC Training Loss (Full): 0.45427075028419495\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7284318804740906\n",
      "LC Training Loss (Full): 0.572353184223175\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41923561692237854\n",
      "LC Training Loss (Full): 0.3604569435119629\n",
      "Full accuracy (w/o dLoRA+LC): 0.8847, LC accuracy: 0.8828, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8422, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8383\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6706544160842896\n",
      "LC Training Loss (Full): 0.5819866061210632\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5997769832611084\n",
      "LC Training Loss (Full): 0.52939772605896\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5714269876480103\n",
      "LC Training Loss (Full): 0.5071691870689392\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.38609203696250916\n",
      "LC Training Loss (Full): 0.32449081540107727\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5371592044830322\n",
      "LC Training Loss (Full): 0.45539408922195435\n",
      "Full accuracy (w/o dLoRA+LC): 0.8819, LC accuracy: 0.8821, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8394, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8387\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader19/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader19/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.47624385356903076\n",
      "LC Training Loss (Full): 0.39465487003326416\n",
      "End of model training on train_loader19...\n",
      "Model saved at accuracy: 0.8394\n",
      "--------------------------\n",
      "Beginning of model training on train_loader20...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5876691937446594\n",
      "LC Training Loss (Full): 0.4380761384963989\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5000876784324646\n",
      "LC Training Loss (Full): 0.43214091658592224\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7508839964866638\n",
      "LC Training Loss (Full): 0.6121968626976013\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8304441571235657\n",
      "LC Training Loss (Full): 0.5836115479469299\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7761969566345215\n",
      "LC Training Loss (Full): 0.5562288165092468\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6798975467681885\n",
      "LC Training Loss (Full): 0.5348259210586548\n",
      "Full accuracy (w/o dLoRA+LC): 0.884, LC accuracy: 0.8828, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8473, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8386\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.34806546568870544\n",
      "LC Training Loss (Full): 0.26812732219696045\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6094365119934082\n",
      "LC Training Loss (Full): 0.5314421057701111\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5976052284240723\n",
      "LC Training Loss (Full): 0.5167878866195679\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4491240978240967\n",
      "LC Training Loss (Full): 0.44977888464927673\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6972251534461975\n",
      "LC Training Loss (Full): 0.5047282576560974\n",
      "Full accuracy (w/o dLoRA+LC): 0.8865, LC accuracy: 0.8861, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8464, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8467\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5884373784065247\n",
      "LC Training Loss (Full): 0.5086075067520142\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5707935690879822\n",
      "LC Training Loss (Full): 0.43904703855514526\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.859375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5586055517196655\n",
      "LC Training Loss (Full): 0.43784624338150024\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5376365780830383\n",
      "LC Training Loss (Full): 0.41985365748405457\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7561278343200684\n",
      "LC Training Loss (Full): 0.5969119668006897\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5550018548965454\n",
      "LC Training Loss (Full): 0.44915375113487244\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5631892681121826\n",
      "LC Training Loss (Full): 0.43289825320243835\n",
      "Full accuracy (w/o dLoRA+LC): 0.8873, LC accuracy: 0.8862, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8459, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8471\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.408988893032074\n",
      "LC Training Loss (Full): 0.3267045021057129\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.520359218120575\n",
      "LC Training Loss (Full): 0.370045006275177\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7334893941879272\n",
      "LC Training Loss (Full): 0.5930085778236389\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5193573832511902\n",
      "LC Training Loss (Full): 0.45880600810050964\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7691749334335327\n",
      "LC Training Loss (Full): 0.5613210201263428\n",
      "Full accuracy (w/o dLoRA+LC): 0.886, LC accuracy: 0.8871, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8473, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8473\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader20/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader20/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6500431895256042\n",
      "LC Training Loss (Full): 0.55903559923172\n",
      "End of model training on train_loader20...\n",
      "Model saved at accuracy: 0.8473\n",
      "--------------------------\n",
      "Beginning of model training on train_loader21...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5769757628440857\n",
      "LC Training Loss (Full): 0.48412707448005676\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6752312183380127\n",
      "LC Training Loss (Full): 0.5853187441825867\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.44790908694267273\n",
      "LC Training Loss (Full): 0.40146079659461975\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7252025008201599\n",
      "LC Training Loss (Full): 0.5425411462783813\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5640009045600891\n",
      "LC Training Loss (Full): 0.4049627482891083\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4798712134361267\n",
      "LC Training Loss (Full): 0.3736761510372162\n",
      "Full accuracy (w/o dLoRA+LC): 0.8864, LC accuracy: 0.8863, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8415, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8473\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.40824881196022034\n",
      "LC Training Loss (Full): 0.3389755189418793\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.31245335936546326\n",
      "LC Training Loss (Full): 0.2752273380756378\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7598058581352234\n",
      "LC Training Loss (Full): 0.6122987270355225\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5323187112808228\n",
      "LC Training Loss (Full): 0.39427557587623596\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.601081907749176\n",
      "LC Training Loss (Full): 0.4894293248653412\n",
      "Full accuracy (w/o dLoRA+LC): 0.8883, LC accuracy: 0.8875, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8418, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8414\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4388996660709381\n",
      "LC Training Loss (Full): 0.332124799489975\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4408396780490875\n",
      "LC Training Loss (Full): 0.36243465542793274\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.46793633699417114\n",
      "LC Training Loss (Full): 0.41368111968040466\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7405352592468262\n",
      "LC Training Loss (Full): 0.5451128482818604\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47260960936546326\n",
      "LC Training Loss (Full): 0.37106192111968994\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4661734998226166\n",
      "LC Training Loss (Full): 0.39494162797927856\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4395109713077545\n",
      "LC Training Loss (Full): 0.3741936683654785\n",
      "Full accuracy (w/o dLoRA+LC): 0.8897, LC accuracy: 0.8864, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8457, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8427\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4905429780483246\n",
      "LC Training Loss (Full): 0.3842179477214813\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5091732740402222\n",
      "LC Training Loss (Full): 0.4924717843532562\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.73820960521698\n",
      "LC Training Loss (Full): 0.5158095955848694\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6381319165229797\n",
      "LC Training Loss (Full): 0.49383363127708435\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4624461531639099\n",
      "LC Training Loss (Full): 0.34955617785453796\n",
      "Full accuracy (w/o dLoRA+LC): 0.8873, LC accuracy: 0.8896, Decomposed-Full (w/dLoRA+LC) accuracy: 0.844, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8426\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader21/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader21/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.46754685044288635\n",
      "LC Training Loss (Full): 0.329190731048584\n",
      "End of model training on train_loader21...\n",
      "Model saved at accuracy: 0.8440\n",
      "--------------------------\n",
      "Beginning of model training on train_loader22...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7217375040054321\n",
      "LC Training Loss (Full): 0.5680074691772461\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.84375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6813310980796814\n",
      "LC Training Loss (Full): 0.5084366202354431\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6109680533409119\n",
      "LC Training Loss (Full): 0.4345461130142212\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6226713061332703\n",
      "LC Training Loss (Full): 0.40812423825263977\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4645887315273285\n",
      "LC Training Loss (Full): 0.42721623182296753\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5748143196105957\n",
      "LC Training Loss (Full): 0.4892135560512543\n",
      "Full accuracy (w/o dLoRA+LC): 0.893, LC accuracy: 0.8874, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7844, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8387\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48568782210350037\n",
      "LC Training Loss (Full): 0.35557079315185547\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.43683335185050964\n",
      "LC Training Loss (Full): 0.3214664161205292\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4667419195175171\n",
      "LC Training Loss (Full): 0.3719102442264557\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5907056331634521\n",
      "LC Training Loss (Full): 0.48042434453964233\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5376678109169006\n",
      "LC Training Loss (Full): 0.43737488985061646\n",
      "Full accuracy (w/o dLoRA+LC): 0.8914, LC accuracy: 0.8909, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8426, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8419\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4613496959209442\n",
      "LC Training Loss (Full): 0.3516565263271332\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7011840343475342\n",
      "LC Training Loss (Full): 0.5169506072998047\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.796875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6047587990760803\n",
      "LC Training Loss (Full): 0.428016722202301\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5303455591201782\n",
      "LC Training Loss (Full): 0.4696471691131592\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7368490099906921\n",
      "LC Training Loss (Full): 0.5780482292175293\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7393642067909241\n",
      "LC Training Loss (Full): 0.5437570214271545\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3218075931072235\n",
      "LC Training Loss (Full): 0.2561974823474884\n",
      "Full accuracy (w/o dLoRA+LC): 0.891, LC accuracy: 0.8905, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8447, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.843\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4874497056007385\n",
      "LC Training Loss (Full): 0.3733868896961212\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4872584939002991\n",
      "LC Training Loss (Full): 0.38244765996932983\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45976847410202026\n",
      "LC Training Loss (Full): 0.34316545724868774\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5434364676475525\n",
      "LC Training Loss (Full): 0.4334060549736023\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5166443586349487\n",
      "LC Training Loss (Full): 0.33838725090026855\n",
      "Full accuracy (w/o dLoRA+LC): 0.8909, LC accuracy: 0.8912, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8437, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8433\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader22/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader22/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3750375509262085\n",
      "LC Training Loss (Full): 0.2605147957801819\n",
      "End of model training on train_loader22...\n",
      "Model saved at accuracy: 0.8437\n",
      "--------------------------\n",
      "Beginning of model training on train_loader23...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7150691747665405\n",
      "LC Training Loss (Full): 0.524438738822937\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7264246344566345\n",
      "LC Training Loss (Full): 0.5352452397346497\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6346167922019958\n",
      "LC Training Loss (Full): 0.5034787058830261\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48800423741340637\n",
      "LC Training Loss (Full): 0.4188593626022339\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.865039050579071\n",
      "LC Training Loss (Full): 0.6870157122612\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4755134582519531\n",
      "LC Training Loss (Full): 0.4415065348148346\n",
      "Full accuracy (w/o dLoRA+LC): 0.8928, LC accuracy: 0.8899, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8411, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8447\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5897651314735413\n",
      "LC Training Loss (Full): 0.4532434940338135\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4686102271080017\n",
      "LC Training Loss (Full): 0.2820902168750763\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6934743523597717\n",
      "LC Training Loss (Full): 0.5562891960144043\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5417520999908447\n",
      "LC Training Loss (Full): 0.3796974718570709\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4865148067474365\n",
      "LC Training Loss (Full): 0.37438714504241943\n",
      "Full accuracy (w/o dLoRA+LC): 0.8926, LC accuracy: 0.893, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8455, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8459\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.41213035583496094\n",
      "LC Training Loss (Full): 0.3433976471424103\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6121707558631897\n",
      "LC Training Loss (Full): 0.473457932472229\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4576333463191986\n",
      "LC Training Loss (Full): 0.35080936551094055\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6733762621879578\n",
      "LC Training Loss (Full): 0.505145788192749\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4815738797187805\n",
      "LC Training Loss (Full): 0.3159671425819397\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5399960875511169\n",
      "LC Training Loss (Full): 0.3624742925167084\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.48594745993614197\n",
      "LC Training Loss (Full): 0.34370267391204834\n",
      "Full accuracy (w/o dLoRA+LC): 0.8947, LC accuracy: 0.8931, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8493, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.846\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8093467950820923\n",
      "LC Training Loss (Full): 0.6856016516685486\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6568430066108704\n",
      "LC Training Loss (Full): 0.501855194568634\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5414063930511475\n",
      "LC Training Loss (Full): 0.38608986139297485\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6916600465774536\n",
      "LC Training Loss (Full): 0.5596893429756165\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.41840317845344543\n",
      "LC Training Loss (Full): 0.2666865885257721\n",
      "Full accuracy (w/o dLoRA+LC): 0.8947, LC accuracy: 0.895, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8468, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8465\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader23/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader23/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7525736093521118\n",
      "LC Training Loss (Full): 0.6198458671569824\n",
      "End of model training on train_loader23...\n",
      "Model saved at accuracy: 0.8468\n",
      "--------------------------\n",
      "Beginning of model training on train_loader24...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.421949565410614\n",
      "LC Training Loss (Full): 0.3635399043560028\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5414648056030273\n",
      "LC Training Loss (Full): 0.368554025888443\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5593935251235962\n",
      "LC Training Loss (Full): 0.4130856394767761\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5634284615516663\n",
      "LC Training Loss (Full): 0.32166609168052673\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5626216530799866\n",
      "LC Training Loss (Full): 0.3390646278858185\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5125770568847656\n",
      "LC Training Loss (Full): 0.4373506009578705\n",
      "Full accuracy (w/o dLoRA+LC): 0.8918, LC accuracy: 0.8912, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8205, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8357\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.756034255027771\n",
      "LC Training Loss (Full): 0.5182850956916809\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3467324674129486\n",
      "LC Training Loss (Full): 0.26606571674346924\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.38263505697250366\n",
      "LC Training Loss (Full): 0.3250396251678467\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4838460087776184\n",
      "LC Training Loss (Full): 0.4181268513202667\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.500721275806427\n",
      "LC Training Loss (Full): 0.38162961602211\n",
      "Full accuracy (w/o dLoRA+LC): 0.8922, LC accuracy: 0.8932, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8462, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8469\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5597649216651917\n",
      "LC Training Loss (Full): 0.4594089388847351\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.493852823972702\n",
      "LC Training Loss (Full): 0.36228668689727783\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5437152981758118\n",
      "LC Training Loss (Full): 0.3910874128341675\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5794343948364258\n",
      "LC Training Loss (Full): 0.4947788119316101\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47720572352409363\n",
      "LC Training Loss (Full): 0.3675699234008789\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6375425457954407\n",
      "LC Training Loss (Full): 0.5325733423233032\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.34354349970817566\n",
      "LC Training Loss (Full): 0.2530063986778259\n",
      "Full accuracy (w/o dLoRA+LC): 0.8897, LC accuracy: 0.89, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8479, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.846\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39339062571525574\n",
      "LC Training Loss (Full): 0.31868910789489746\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.43982449173927307\n",
      "LC Training Loss (Full): 0.3078545928001404\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4116666615009308\n",
      "LC Training Loss (Full): 0.3035774528980255\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4388052523136139\n",
      "LC Training Loss (Full): 0.36715376377105713\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4349740743637085\n",
      "LC Training Loss (Full): 0.35253995656967163\n",
      "Full accuracy (w/o dLoRA+LC): 0.8889, LC accuracy: 0.8893, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8454, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8461\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader24/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader24/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.47546157240867615\n",
      "LC Training Loss (Full): 0.3586665391921997\n",
      "End of model training on train_loader24...\n",
      "Model saved at accuracy: 0.8454\n",
      "--------------------------\n",
      "Beginning of model training on train_loader25...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4163249731063843\n",
      "LC Training Loss (Full): 0.31336283683776855\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.96875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5661907196044922\n",
      "LC Training Loss (Full): 0.35689467191696167\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4768233299255371\n",
      "LC Training Loss (Full): 0.2873969078063965\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6288018822669983\n",
      "LC Training Loss (Full): 0.4023085832595825\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5379751920700073\n",
      "LC Training Loss (Full): 0.43922531604766846\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7365531921386719\n",
      "LC Training Loss (Full): 0.5708156228065491\n",
      "Full accuracy (w/o dLoRA+LC): 0.8906, LC accuracy: 0.889, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8314, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8432\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.614779531955719\n",
      "LC Training Loss (Full): 0.5393908619880676\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.416980504989624\n",
      "LC Training Loss (Full): 0.355824738740921\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6657177805900574\n",
      "LC Training Loss (Full): 0.4523320496082306\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5339249968528748\n",
      "LC Training Loss (Full): 0.30041658878326416\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.47333741188049316\n",
      "LC Training Loss (Full): 0.36397236585617065\n",
      "Full accuracy (w/o dLoRA+LC): 0.8921, LC accuracy: 0.8918, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8451, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8436\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4510277211666107\n",
      "LC Training Loss (Full): 0.3324067294597626\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5044438242912292\n",
      "LC Training Loss (Full): 0.381634384393692\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3940730690956116\n",
      "LC Training Loss (Full): 0.3312777280807495\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5447368621826172\n",
      "LC Training Loss (Full): 0.36200401186943054\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.30567848682403564\n",
      "LC Training Loss (Full): 0.21670852601528168\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6499011516571045\n",
      "LC Training Loss (Full): 0.48303142189979553\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6308516263961792\n",
      "LC Training Loss (Full): 0.46674734354019165\n",
      "Full accuracy (w/o dLoRA+LC): 0.8924, LC accuracy: 0.892, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8466, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.845\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6122356653213501\n",
      "LC Training Loss (Full): 0.4921300709247589\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5237924456596375\n",
      "LC Training Loss (Full): 0.3578539788722992\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4249880909919739\n",
      "LC Training Loss (Full): 0.3402906656265259\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4654584228992462\n",
      "LC Training Loss (Full): 0.3008049428462982\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5979136228561401\n",
      "LC Training Loss (Full): 0.48463279008865356\n",
      "Full accuracy (w/o dLoRA+LC): 0.8935, LC accuracy: 0.894, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8468, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8454\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader25/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader25/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.42361509799957275\n",
      "LC Training Loss (Full): 0.3130798637866974\n",
      "End of model training on train_loader25...\n",
      "Model saved at accuracy: 0.8468\n",
      "--------------------------\n",
      "Beginning of model training on train_loader26...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.43128880858421326\n",
      "LC Training Loss (Full): 0.28284069895744324\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.34955888986587524\n",
      "LC Training Loss (Full): 0.19247634708881378\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.35409024357795715\n",
      "LC Training Loss (Full): 0.24402187764644623\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3157385587692261\n",
      "LC Training Loss (Full): 0.20310893654823303\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.41075336933135986\n",
      "LC Training Loss (Full): 0.3301188051700592\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5315840244293213\n",
      "LC Training Loss (Full): 0.39575669169425964\n",
      "Full accuracy (w/o dLoRA+LC): 0.8946, LC accuracy: 0.8932, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7924, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8476\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8322339057922363\n",
      "LC Training Loss (Full): 0.5648521184921265\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.1692240238189697\n",
      "LC Training Loss (Full): 0.46157127618789673\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9773339629173279\n",
      "LC Training Loss (Full): 0.35408174991607666\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4199603796005249\n",
      "LC Training Loss (Full): 0.3143216371536255\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5470832586288452\n",
      "LC Training Loss (Full): 0.36484193801879883\n",
      "Full accuracy (w/o dLoRA+LC): 0.8945, LC accuracy: 0.8943, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8435, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8442\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.48249760270118713\n",
      "LC Training Loss (Full): 0.31783831119537354\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.45458313822746277\n",
      "LC Training Loss (Full): 0.30243465304374695\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5170397162437439\n",
      "LC Training Loss (Full): 0.3116692006587982\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5134228467941284\n",
      "LC Training Loss (Full): 0.366111695766449\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.595053493976593\n",
      "LC Training Loss (Full): 0.40303391218185425\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4209767282009125\n",
      "LC Training Loss (Full): 0.33481565117836\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47312262654304504\n",
      "LC Training Loss (Full): 0.3298974633216858\n",
      "Full accuracy (w/o dLoRA+LC): 0.8961, LC accuracy: 0.8958, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8461, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8445\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.36977431178092957\n",
      "LC Training Loss (Full): 0.26172906160354614\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.40883392095565796\n",
      "LC Training Loss (Full): 0.2886987328529358\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4012203514575958\n",
      "LC Training Loss (Full): 0.27173569798469543\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5269232392311096\n",
      "LC Training Loss (Full): 0.44546929001808167\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.350761741399765\n",
      "LC Training Loss (Full): 0.24436131119728088\n",
      "Full accuracy (w/o dLoRA+LC): 0.8959, LC accuracy: 0.8965, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8455, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8455\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader26/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader26/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5204124450683594\n",
      "LC Training Loss (Full): 0.29252684116363525\n",
      "End of model training on train_loader26...\n",
      "Model saved at accuracy: 0.8455\n",
      "--------------------------\n",
      "Beginning of model training on train_loader27...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.36880388855934143\n",
      "LC Training Loss (Full): 0.23474475741386414\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.96875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5787498950958252\n",
      "LC Training Loss (Full): 0.5006031394004822\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6617642045021057\n",
      "LC Training Loss (Full): 0.3967755138874054\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.41790419816970825\n",
      "LC Training Loss (Full): 0.33326393365859985\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3928769528865814\n",
      "LC Training Loss (Full): 0.2935573160648346\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3100489675998688\n",
      "LC Training Loss (Full): 0.21793991327285767\n",
      "Full accuracy (w/o dLoRA+LC): 0.8966, LC accuracy: 0.8961, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8504, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8508\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.46013393998146057\n",
      "LC Training Loss (Full): 0.3508160710334778\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45003005862236023\n",
      "LC Training Loss (Full): 0.39396876096725464\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4580925703048706\n",
      "LC Training Loss (Full): 0.3231029808521271\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5078186988830566\n",
      "LC Training Loss (Full): 0.4418359100818634\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.30265116691589355\n",
      "LC Training Loss (Full): 0.18472349643707275\n",
      "Full accuracy (w/o dLoRA+LC): 0.8985, LC accuracy: 0.8984, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8491, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8497\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.787844181060791\n",
      "LC Training Loss (Full): 0.6183620691299438\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4082443416118622\n",
      "LC Training Loss (Full): 0.2945655584335327\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.632826030254364\n",
      "LC Training Loss (Full): 0.47567859292030334\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5220956206321716\n",
      "LC Training Loss (Full): 0.45133325457572937\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47666341066360474\n",
      "LC Training Loss (Full): 0.41117626428604126\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3968384861946106\n",
      "LC Training Loss (Full): 0.24160099029541016\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4694855809211731\n",
      "LC Training Loss (Full): 0.32714977860450745\n",
      "Full accuracy (w/o dLoRA+LC): 0.8974, LC accuracy: 0.8983, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8508, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8495\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5266640782356262\n",
      "LC Training Loss (Full): 0.40381455421447754\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.29678216576576233\n",
      "LC Training Loss (Full): 0.21317900717258453\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.33423441648483276\n",
      "LC Training Loss (Full): 0.26691365242004395\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4537675976753235\n",
      "LC Training Loss (Full): 0.32819777727127075\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3790535628795624\n",
      "LC Training Loss (Full): 0.2616778016090393\n",
      "Full accuracy (w/o dLoRA+LC): 0.8987, LC accuracy: 0.8993, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8507, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8505\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader27/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader27/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.49243849515914917\n",
      "LC Training Loss (Full): 0.3397051692008972\n",
      "End of model training on train_loader27...\n",
      "Model saved at accuracy: 0.8507\n",
      "--------------------------\n",
      "Beginning of model training on train_loader28...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.45373499393463135\n",
      "LC Training Loss (Full): 0.2987666428089142\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.96875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4987902343273163\n",
      "LC Training Loss (Full): 0.4175602197647095\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5183886289596558\n",
      "LC Training Loss (Full): 0.32277148962020874\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6750993728637695\n",
      "LC Training Loss (Full): 0.38275134563446045\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5019940733909607\n",
      "LC Training Loss (Full): 0.31445685029029846\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6127365827560425\n",
      "LC Training Loss (Full): 0.46829983592033386\n",
      "Full accuracy (w/o dLoRA+LC): 0.8996, LC accuracy: 0.8983, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8004, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.841\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5145576000213623\n",
      "LC Training Loss (Full): 0.307087779045105\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6426417231559753\n",
      "LC Training Loss (Full): 0.4833017587661743\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.693966269493103\n",
      "LC Training Loss (Full): 0.5621996521949768\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.511759340763092\n",
      "LC Training Loss (Full): 0.42910683155059814\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4667665362358093\n",
      "LC Training Loss (Full): 0.3151325583457947\n",
      "Full accuracy (w/o dLoRA+LC): 0.8992, LC accuracy: 0.8985, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8481, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8467\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.40130454301834106\n",
      "LC Training Loss (Full): 0.27685680985450745\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5418190360069275\n",
      "LC Training Loss (Full): 0.3362753093242645\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.9375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5493198037147522\n",
      "LC Training Loss (Full): 0.36197787523269653\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.40098583698272705\n",
      "LC Training Loss (Full): 0.26072829961776733\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5881244540214539\n",
      "LC Training Loss (Full): 0.42430758476257324\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49272358417510986\n",
      "LC Training Loss (Full): 0.34258073568344116\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4615742266178131\n",
      "LC Training Loss (Full): 0.3294070065021515\n",
      "Full accuracy (w/o dLoRA+LC): 0.8978, LC accuracy: 0.8998, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8508, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8488\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4621700942516327\n",
      "LC Training Loss (Full): 0.2970499098300934\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.621753454208374\n",
      "LC Training Loss (Full): 0.48152488470077515\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5177083611488342\n",
      "LC Training Loss (Full): 0.32990550994873047\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6105713844299316\n",
      "LC Training Loss (Full): 0.3831251263618469\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.42076796293258667\n",
      "LC Training Loss (Full): 0.3528299331665039\n",
      "Full accuracy (w/o dLoRA+LC): 0.8997, LC accuracy: 0.8995, Decomposed-Full (w/dLoRA+LC) accuracy: 0.851, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8506\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader28/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader28/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7423920035362244\n",
      "LC Training Loss (Full): 0.5756776928901672\n",
      "End of model training on train_loader28...\n",
      "Model saved at accuracy: 0.8510\n",
      "--------------------------\n",
      "Beginning of model training on train_loader29...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5431421995162964\n",
      "LC Training Loss (Full): 0.40167221426963806\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7733664512634277\n",
      "LC Training Loss (Full): 0.5768024921417236\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.40124279260635376\n",
      "LC Training Loss (Full): 0.2818410098552704\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48537787795066833\n",
      "LC Training Loss (Full): 0.3000740110874176\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7151257991790771\n",
      "LC Training Loss (Full): 0.4661697745323181\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5570186376571655\n",
      "LC Training Loss (Full): 0.3867860436439514\n",
      "Full accuracy (w/o dLoRA+LC): 0.8994, LC accuracy: 0.9001, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8353, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8444\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3825962245464325\n",
      "LC Training Loss (Full): 0.28716403245925903\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3258552551269531\n",
      "LC Training Loss (Full): 0.2433323860168457\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4351700246334076\n",
      "LC Training Loss (Full): 0.3248133063316345\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3505794405937195\n",
      "LC Training Loss (Full): 0.234129399061203\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.46314316987991333\n",
      "LC Training Loss (Full): 0.3395863473415375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9004, LC accuracy: 0.8998, Decomposed-Full (w/dLoRA+LC) accuracy: 0.854, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8537\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5634998083114624\n",
      "LC Training Loss (Full): 0.41982778906822205\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.2708524763584137\n",
      "LC Training Loss (Full): 0.1893731653690338\n",
      "Training Accuracy | Decomposed: 0.953125, Full : 0.96875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4559134244918823\n",
      "LC Training Loss (Full): 0.38995203375816345\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8433620929718018\n",
      "LC Training Loss (Full): 0.6113813519477844\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3986300826072693\n",
      "LC Training Loss (Full): 0.2731586694717407\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4843364655971527\n",
      "LC Training Loss (Full): 0.33521342277526855\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.37312185764312744\n",
      "LC Training Loss (Full): 0.23805567622184753\n",
      "Full accuracy (w/o dLoRA+LC): 0.9002, LC accuracy: 0.9005, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8546, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8533\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.505659818649292\n",
      "LC Training Loss (Full): 0.31691664457321167\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5108053088188171\n",
      "LC Training Loss (Full): 0.391468346118927\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5165168642997742\n",
      "LC Training Loss (Full): 0.35716038942337036\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5176783800125122\n",
      "LC Training Loss (Full): 0.32937902212142944\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5588996410369873\n",
      "LC Training Loss (Full): 0.3788439929485321\n",
      "Full accuracy (w/o dLoRA+LC): 0.9007, LC accuracy: 0.9007, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8543, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8535\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader29/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader29/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3675914406776428\n",
      "LC Training Loss (Full): 0.2119232714176178\n",
      "End of model training on train_loader29...\n",
      "Model saved at accuracy: 0.8543\n",
      "--------------------------\n",
      "Beginning of model training on train_loader30...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.46825286746025085\n",
      "LC Training Loss (Full): 0.3686830699443817\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8346706628799438\n",
      "LC Training Loss (Full): 0.3022059500217438\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8840585947036743\n",
      "LC Training Loss (Full): 0.4225013554096222\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5005818009376526\n",
      "LC Training Loss (Full): 0.36756786704063416\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4390057623386383\n",
      "LC Training Loss (Full): 0.3031165599822998\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5671285390853882\n",
      "LC Training Loss (Full): 0.40406858921051025\n",
      "Full accuracy (w/o dLoRA+LC): 0.8996, LC accuracy: 0.9004, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8589, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8548\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3364219069480896\n",
      "LC Training Loss (Full): 0.23535257577896118\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5034812688827515\n",
      "LC Training Loss (Full): 0.4715675413608551\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4158928394317627\n",
      "LC Training Loss (Full): 0.3465418517589569\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.347247451543808\n",
      "LC Training Loss (Full): 0.27348795533180237\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6767107248306274\n",
      "LC Training Loss (Full): 0.43842995166778564\n",
      "Full accuracy (w/o dLoRA+LC): 0.9027, LC accuracy: 0.9011, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8581, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.856\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.35488757491111755\n",
      "LC Training Loss (Full): 0.2654334008693695\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5336040258407593\n",
      "LC Training Loss (Full): 0.30699002742767334\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.42410433292388916\n",
      "LC Training Loss (Full): 0.31844043731689453\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6180339455604553\n",
      "LC Training Loss (Full): 0.46948423981666565\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45629554986953735\n",
      "LC Training Loss (Full): 0.35696858167648315\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.409425288438797\n",
      "LC Training Loss (Full): 0.25756558775901794\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.44167113304138184\n",
      "LC Training Loss (Full): 0.283785343170166\n",
      "Full accuracy (w/o dLoRA+LC): 0.9024, LC accuracy: 0.903, Decomposed-Full (w/dLoRA+LC) accuracy: 0.86, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8578\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45387962460517883\n",
      "LC Training Loss (Full): 0.3089153468608856\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.618269145488739\n",
      "LC Training Loss (Full): 0.4785343408584595\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5141264796257019\n",
      "LC Training Loss (Full): 0.3869929313659668\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3853810727596283\n",
      "LC Training Loss (Full): 0.3181649148464203\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4365195631980896\n",
      "LC Training Loss (Full): 0.31214439868927\n",
      "Full accuracy (w/o dLoRA+LC): 0.9046, LC accuracy: 0.9033, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8587, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8586\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader30/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader30/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3493556082248688\n",
      "LC Training Loss (Full): 0.2074902355670929\n",
      "End of model training on train_loader30...\n",
      "Model saved at accuracy: 0.8587\n",
      "--------------------------\n",
      "Beginning of model training on train_loader31...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.44866982102394104\n",
      "LC Training Loss (Full): 0.3645102381706238\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8009524941444397\n",
      "LC Training Loss (Full): 0.5268393754959106\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.43423622846603394\n",
      "LC Training Loss (Full): 0.3491078317165375\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6238009333610535\n",
      "LC Training Loss (Full): 0.49825337529182434\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.25915780663490295\n",
      "LC Training Loss (Full): 0.1717400848865509\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45320990681648254\n",
      "LC Training Loss (Full): 0.36385437846183777\n",
      "Full accuracy (w/o dLoRA+LC): 0.9043, LC accuracy: 0.9039, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8348, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8482\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4370558559894562\n",
      "LC Training Loss (Full): 0.3617055118083954\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.719502329826355\n",
      "LC Training Loss (Full): 0.44264301657676697\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4955824017524719\n",
      "LC Training Loss (Full): 0.3378274440765381\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5530802011489868\n",
      "LC Training Loss (Full): 0.2834528088569641\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4329061210155487\n",
      "LC Training Loss (Full): 0.4035758972167969\n",
      "Full accuracy (w/o dLoRA+LC): 0.9039, LC accuracy: 0.9034, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8586, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8595\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5831334590911865\n",
      "LC Training Loss (Full): 0.5045253038406372\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.40879687666893005\n",
      "LC Training Loss (Full): 0.335978627204895\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45258215069770813\n",
      "LC Training Loss (Full): 0.32190805673599243\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4228668510913849\n",
      "LC Training Loss (Full): 0.31650516390800476\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5887539982795715\n",
      "LC Training Loss (Full): 0.410060316324234\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.569872260093689\n",
      "LC Training Loss (Full): 0.3845161199569702\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5089578628540039\n",
      "LC Training Loss (Full): 0.33039745688438416\n",
      "Full accuracy (w/o dLoRA+LC): 0.9022, LC accuracy: 0.903, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8605, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.859\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5980806350708008\n",
      "LC Training Loss (Full): 0.4517054259777069\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5773234963417053\n",
      "LC Training Loss (Full): 0.4399060606956482\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3879653811454773\n",
      "LC Training Loss (Full): 0.2627405524253845\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3712468445301056\n",
      "LC Training Loss (Full): 0.32843536138534546\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48979148268699646\n",
      "LC Training Loss (Full): 0.3838794231414795\n",
      "Full accuracy (w/o dLoRA+LC): 0.9031, LC accuracy: 0.9028, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8585, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.858\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader31/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader31/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.533747673034668\n",
      "LC Training Loss (Full): 0.39292654395103455\n",
      "End of model training on train_loader31...\n",
      "Model saved at accuracy: 0.8585\n",
      "--------------------------\n",
      "Beginning of model training on train_loader32...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4046322703361511\n",
      "LC Training Loss (Full): 0.26326456665992737\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3844243288040161\n",
      "LC Training Loss (Full): 0.321071982383728\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4942462146282196\n",
      "LC Training Loss (Full): 0.40362706780433655\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5756235122680664\n",
      "LC Training Loss (Full): 0.4161317050457001\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5359194278717041\n",
      "LC Training Loss (Full): 0.3176618814468384\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5304068922996521\n",
      "LC Training Loss (Full): 0.36411166191101074\n",
      "Full accuracy (w/o dLoRA+LC): 0.9046, LC accuracy: 0.9019, Decomposed-Full (w/dLoRA+LC) accuracy: 0.812, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8485\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3827352225780487\n",
      "LC Training Loss (Full): 0.25409001111984253\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.32720518112182617\n",
      "LC Training Loss (Full): 0.23832419514656067\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4758571982383728\n",
      "LC Training Loss (Full): 0.3095545172691345\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3119763135910034\n",
      "LC Training Loss (Full): 0.27834850549697876\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4676474630832672\n",
      "LC Training Loss (Full): 0.3768679201602936\n",
      "Full accuracy (w/o dLoRA+LC): 0.9056, LC accuracy: 0.9059, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8548, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8542\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3511298596858978\n",
      "LC Training Loss (Full): 0.25054940581321716\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.43002963066101074\n",
      "LC Training Loss (Full): 0.292054682970047\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2939567565917969\n",
      "LC Training Loss (Full): 0.2556893527507782\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.457343727350235\n",
      "LC Training Loss (Full): 0.3127736449241638\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5266433954238892\n",
      "LC Training Loss (Full): 0.3896145224571228\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39613398909568787\n",
      "LC Training Loss (Full): 0.23950858414173126\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3319866359233856\n",
      "LC Training Loss (Full): 0.22114236652851105\n",
      "Full accuracy (w/o dLoRA+LC): 0.9054, LC accuracy: 0.9061, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8558, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8541\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.44324055314064026\n",
      "LC Training Loss (Full): 0.31483444571495056\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4648278057575226\n",
      "LC Training Loss (Full): 0.34555235505104065\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5910654067993164\n",
      "LC Training Loss (Full): 0.4118924140930176\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39427831768989563\n",
      "LC Training Loss (Full): 0.24584010243415833\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4158463180065155\n",
      "LC Training Loss (Full): 0.3312194347381592\n",
      "Full accuracy (w/o dLoRA+LC): 0.9084, LC accuracy: 0.9083, Decomposed-Full (w/dLoRA+LC) accuracy: 0.856, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8562\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader32/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader32/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4009932577610016\n",
      "LC Training Loss (Full): 0.24271449446678162\n",
      "End of model training on train_loader32...\n",
      "Model saved at accuracy: 0.8560\n",
      "--------------------------\n",
      "Beginning of model training on train_loader33...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7048054933547974\n",
      "LC Training Loss (Full): 0.4568774104118347\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6596026420593262\n",
      "LC Training Loss (Full): 0.45645302534103394\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5359459519386292\n",
      "LC Training Loss (Full): 0.2733723521232605\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6207613945007324\n",
      "LC Training Loss (Full): 0.3873883783817291\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5906921029090881\n",
      "LC Training Loss (Full): 0.4511336386203766\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5405216813087463\n",
      "LC Training Loss (Full): 0.37238773703575134\n",
      "Full accuracy (w/o dLoRA+LC): 0.9082, LC accuracy: 0.9082, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8566, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8586\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5537669062614441\n",
      "LC Training Loss (Full): 0.39877405762672424\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6040963530540466\n",
      "LC Training Loss (Full): 0.341941773891449\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6258923411369324\n",
      "LC Training Loss (Full): 0.4157087504863739\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6066750288009644\n",
      "LC Training Loss (Full): 0.368206262588501\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.47544050216674805\n",
      "LC Training Loss (Full): 0.3585292100906372\n",
      "Full accuracy (w/o dLoRA+LC): 0.9099, LC accuracy: 0.9091, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8608, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8594\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4488593339920044\n",
      "LC Training Loss (Full): 0.30289292335510254\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6076322197914124\n",
      "LC Training Loss (Full): 0.39584803581237793\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.84375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4205823838710785\n",
      "LC Training Loss (Full): 0.37278738617897034\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4689323902130127\n",
      "LC Training Loss (Full): 0.31218719482421875\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5788986086845398\n",
      "LC Training Loss (Full): 0.4503704905509949\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.59416663646698\n",
      "LC Training Loss (Full): 0.4284866750240326\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4176965653896332\n",
      "LC Training Loss (Full): 0.27332136034965515\n",
      "Full accuracy (w/o dLoRA+LC): 0.9085, LC accuracy: 0.9093, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8608, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8599\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.44215667247772217\n",
      "LC Training Loss (Full): 0.2748647630214691\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49390047788619995\n",
      "LC Training Loss (Full): 0.3253322243690491\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5040844082832336\n",
      "LC Training Loss (Full): 0.29929614067077637\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.729827880859375\n",
      "LC Training Loss (Full): 0.5669080018997192\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7339015007019043\n",
      "LC Training Loss (Full): 0.5066704750061035\n",
      "Full accuracy (w/o dLoRA+LC): 0.9098, LC accuracy: 0.9073, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8607, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.86\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader33/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader33/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.35842809081077576\n",
      "LC Training Loss (Full): 0.1796794980764389\n",
      "End of model training on train_loader33...\n",
      "Model saved at accuracy: 0.8607\n",
      "--------------------------\n",
      "Beginning of model training on train_loader34...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.49160048365592957\n",
      "LC Training Loss (Full): 0.32763969898223877\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6269585490226746\n",
      "LC Training Loss (Full): 0.3734430968761444\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6191359758377075\n",
      "LC Training Loss (Full): 0.366298645734787\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6484929323196411\n",
      "LC Training Loss (Full): 0.38571491837501526\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4642999768257141\n",
      "LC Training Loss (Full): 0.23210231959819794\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5421097874641418\n",
      "LC Training Loss (Full): 0.36048436164855957\n",
      "Full accuracy (w/o dLoRA+LC): 0.9083, LC accuracy: 0.9097, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8661, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8613\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4687856137752533\n",
      "LC Training Loss (Full): 0.4156664311885834\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4905462861061096\n",
      "LC Training Loss (Full): 0.35019993782043457\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6131204962730408\n",
      "LC Training Loss (Full): 0.3629246652126312\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.703414261341095\n",
      "LC Training Loss (Full): 0.5900975465774536\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.67836594581604\n",
      "LC Training Loss (Full): 0.46490490436553955\n",
      "Full accuracy (w/o dLoRA+LC): 0.9087, LC accuracy: 0.9102, Decomposed-Full (w/dLoRA+LC) accuracy: 0.859, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8595\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7026681303977966\n",
      "LC Training Loss (Full): 0.47598227858543396\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5985721349716187\n",
      "LC Training Loss (Full): 0.448518842458725\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.859375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7015438079833984\n",
      "LC Training Loss (Full): 0.5049936771392822\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6052810549736023\n",
      "LC Training Loss (Full): 0.35769134759902954\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6960036754608154\n",
      "LC Training Loss (Full): 0.5416721105575562\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3365132510662079\n",
      "LC Training Loss (Full): 0.23198065161705017\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41713055968284607\n",
      "LC Training Loss (Full): 0.2848343551158905\n",
      "Full accuracy (w/o dLoRA+LC): 0.9096, LC accuracy: 0.9076, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8614, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8598\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7023317813873291\n",
      "LC Training Loss (Full): 0.4957648515701294\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39150065183639526\n",
      "LC Training Loss (Full): 0.26288551092147827\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45443227887153625\n",
      "LC Training Loss (Full): 0.3531208336353302\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5839231014251709\n",
      "LC Training Loss (Full): 0.38822269439697266\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.49909356236457825\n",
      "LC Training Loss (Full): 0.35314616560935974\n",
      "Full accuracy (w/o dLoRA+LC): 0.9089, LC accuracy: 0.9097, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8618, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8603\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader34/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader34/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4954794943332672\n",
      "LC Training Loss (Full): 0.31562528014183044\n",
      "End of model training on train_loader34...\n",
      "Model saved at accuracy: 0.8618\n",
      "--------------------------\n",
      "Beginning of model training on train_loader35...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3860724866390228\n",
      "LC Training Loss (Full): 0.3414507508277893\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4705994725227356\n",
      "LC Training Loss (Full): 0.33972305059432983\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5673239827156067\n",
      "LC Training Loss (Full): 0.2923627495765686\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5835421681404114\n",
      "LC Training Loss (Full): 0.2956375777721405\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45409253239631653\n",
      "LC Training Loss (Full): 0.3420748710632324\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4541144073009491\n",
      "LC Training Loss (Full): 0.31882792711257935\n",
      "Full accuracy (w/o dLoRA+LC): 0.91, LC accuracy: 0.9086, Decomposed-Full (w/dLoRA+LC) accuracy: 0.861, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8605\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.46021169424057007\n",
      "LC Training Loss (Full): 0.30358636379241943\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3561024069786072\n",
      "LC Training Loss (Full): 0.2838963568210602\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45679834485054016\n",
      "LC Training Loss (Full): 0.43105578422546387\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45655956864356995\n",
      "LC Training Loss (Full): 0.3215404748916626\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4633529782295227\n",
      "LC Training Loss (Full): 0.29842159152030945\n",
      "Full accuracy (w/o dLoRA+LC): 0.9106, LC accuracy: 0.9108, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8491, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8457\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3843046724796295\n",
      "LC Training Loss (Full): 0.2551984488964081\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4618891775608063\n",
      "LC Training Loss (Full): 0.37096643447875977\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4008171856403351\n",
      "LC Training Loss (Full): 0.27391374111175537\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.33290180563926697\n",
      "LC Training Loss (Full): 0.21052084863185883\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5304336547851562\n",
      "LC Training Loss (Full): 0.36512312293052673\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.34780678153038025\n",
      "LC Training Loss (Full): 0.26948443055152893\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3976716995239258\n",
      "LC Training Loss (Full): 0.2934248149394989\n",
      "Full accuracy (w/o dLoRA+LC): 0.9105, LC accuracy: 0.9114, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8556, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8511\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.48518893122673035\n",
      "LC Training Loss (Full): 0.34199389815330505\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.36627626419067383\n",
      "LC Training Loss (Full): 0.22361375391483307\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41379302740097046\n",
      "LC Training Loss (Full): 0.28188368678092957\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41106322407722473\n",
      "LC Training Loss (Full): 0.30843549966812134\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6466495394706726\n",
      "LC Training Loss (Full): 0.4793216586112976\n",
      "Full accuracy (w/o dLoRA+LC): 0.9109, LC accuracy: 0.9113, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8556, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8513\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader35/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader35/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3627050518989563\n",
      "LC Training Loss (Full): 0.2775270640850067\n",
      "End of model training on train_loader35...\n",
      "Model saved at accuracy: 0.8556\n",
      "--------------------------\n",
      "Beginning of model training on train_loader36...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5361290574073792\n",
      "LC Training Loss (Full): 0.4121907651424408\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7319760918617249\n",
      "LC Training Loss (Full): 0.4296663701534271\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4797460734844208\n",
      "LC Training Loss (Full): 0.291392982006073\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6313185095787048\n",
      "LC Training Loss (Full): 0.48202183842658997\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.38389331102371216\n",
      "LC Training Loss (Full): 0.22571325302124023\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6822292804718018\n",
      "LC Training Loss (Full): 0.4401369094848633\n",
      "Full accuracy (w/o dLoRA+LC): 0.9116, LC accuracy: 0.9114, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8364, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8637\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.500041127204895\n",
      "LC Training Loss (Full): 0.2894917130470276\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5832344889640808\n",
      "LC Training Loss (Full): 0.41279420256614685\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5274533033370972\n",
      "LC Training Loss (Full): 0.3692460060119629\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.557526171207428\n",
      "LC Training Loss (Full): 0.4257242977619171\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6299317479133606\n",
      "LC Training Loss (Full): 0.4492287039756775\n",
      "Full accuracy (w/o dLoRA+LC): 0.9114, LC accuracy: 0.911, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8626, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8623\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7369997501373291\n",
      "LC Training Loss (Full): 0.5931617021560669\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5377199649810791\n",
      "LC Training Loss (Full): 0.4365074932575226\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.859375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41757115721702576\n",
      "LC Training Loss (Full): 0.2769451439380646\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5662833452224731\n",
      "LC Training Loss (Full): 0.4319995641708374\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.42055538296699524\n",
      "LC Training Loss (Full): 0.26663869619369507\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6416962742805481\n",
      "LC Training Loss (Full): 0.4552331268787384\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9440781474113464\n",
      "LC Training Loss (Full): 0.6175656318664551\n",
      "Full accuracy (w/o dLoRA+LC): 0.9106, LC accuracy: 0.9107, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8632, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8622\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5879249572753906\n",
      "LC Training Loss (Full): 0.3597371280193329\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.537911593914032\n",
      "LC Training Loss (Full): 0.4667481482028961\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5300673842430115\n",
      "LC Training Loss (Full): 0.3062901496887207\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.43120908737182617\n",
      "LC Training Loss (Full): 0.3156191110610962\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.45026910305023193\n",
      "LC Training Loss (Full): 0.2619744837284088\n",
      "Full accuracy (w/o dLoRA+LC): 0.9102, LC accuracy: 0.91, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8631, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8622\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader36/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader36/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5400819778442383\n",
      "LC Training Loss (Full): 0.3480755090713501\n",
      "End of model training on train_loader36...\n",
      "Model saved at accuracy: 0.8631\n",
      "--------------------------\n",
      "Beginning of model training on train_loader37...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.43047547340393066\n",
      "LC Training Loss (Full): 0.2532307207584381\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5439668893814087\n",
      "LC Training Loss (Full): 0.41111519932746887\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5822811126708984\n",
      "LC Training Loss (Full): 0.43071606755256653\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5401283502578735\n",
      "LC Training Loss (Full): 0.27971184253692627\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5092840790748596\n",
      "LC Training Loss (Full): 0.273936003446579\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.41645577549934387\n",
      "LC Training Loss (Full): 0.3131006062030792\n",
      "Full accuracy (w/o dLoRA+LC): 0.9127, LC accuracy: 0.9107, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8434, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8564\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.33407875895500183\n",
      "LC Training Loss (Full): 0.2798457145690918\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4049454629421234\n",
      "LC Training Loss (Full): 0.2639108896255493\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5634124279022217\n",
      "LC Training Loss (Full): 0.4001055657863617\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.598496675491333\n",
      "LC Training Loss (Full): 0.4524056613445282\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.34350496530532837\n",
      "LC Training Loss (Full): 0.29411980509757996\n",
      "Full accuracy (w/o dLoRA+LC): 0.9127, LC accuracy: 0.9128, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8604, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8607\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3183917701244354\n",
      "LC Training Loss (Full): 0.1806601732969284\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5235823392868042\n",
      "LC Training Loss (Full): 0.2971975803375244\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.953125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3052274286746979\n",
      "LC Training Loss (Full): 0.21032702922821045\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4485093057155609\n",
      "LC Training Loss (Full): 0.2902590334415436\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45820435881614685\n",
      "LC Training Loss (Full): 0.27495741844177246\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.523617148399353\n",
      "LC Training Loss (Full): 0.35749027132987976\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.44437140226364136\n",
      "LC Training Loss (Full): 0.33745384216308594\n",
      "Full accuracy (w/o dLoRA+LC): 0.9137, LC accuracy: 0.9124, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8621, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8608\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3328787088394165\n",
      "LC Training Loss (Full): 0.23629440367221832\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.553127110004425\n",
      "LC Training Loss (Full): 0.4150632619857788\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.24271172285079956\n",
      "LC Training Loss (Full): 0.1273636817932129\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6381317377090454\n",
      "LC Training Loss (Full): 0.461266428232193\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5777043104171753\n",
      "LC Training Loss (Full): 0.3937702178955078\n",
      "Full accuracy (w/o dLoRA+LC): 0.9135, LC accuracy: 0.9132, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8602, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8605\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader37/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader37/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.48625561594963074\n",
      "LC Training Loss (Full): 0.31479424238204956\n",
      "End of model training on train_loader37...\n",
      "Model saved at accuracy: 0.8602\n",
      "--------------------------\n",
      "Beginning of model training on train_loader38...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.36228814721107483\n",
      "LC Training Loss (Full): 0.2235192209482193\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.49712443351745605\n",
      "LC Training Loss (Full): 0.27176591753959656\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4243418276309967\n",
      "LC Training Loss (Full): 0.21002164483070374\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48616907000541687\n",
      "LC Training Loss (Full): 0.3591662645339966\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3925058841705322\n",
      "LC Training Loss (Full): 0.24899372458457947\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.32436591386795044\n",
      "LC Training Loss (Full): 0.20266573131084442\n",
      "Full accuracy (w/o dLoRA+LC): 0.9136, LC accuracy: 0.9131, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8461, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8563\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5027283430099487\n",
      "LC Training Loss (Full): 0.3414362668991089\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4413715600967407\n",
      "LC Training Loss (Full): 0.32913342118263245\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6178914308547974\n",
      "LC Training Loss (Full): 0.36735180020332336\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.383354514837265\n",
      "LC Training Loss (Full): 0.29223084449768066\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3891472816467285\n",
      "LC Training Loss (Full): 0.22916963696479797\n",
      "Full accuracy (w/o dLoRA+LC): 0.9143, LC accuracy: 0.9137, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8612, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.861\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.44699129462242126\n",
      "LC Training Loss (Full): 0.310966819524765\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6670826077461243\n",
      "LC Training Loss (Full): 0.36897024512290955\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5460289120674133\n",
      "LC Training Loss (Full): 0.4101261496543884\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.36990025639533997\n",
      "LC Training Loss (Full): 0.2506031095981598\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49344345927238464\n",
      "LC Training Loss (Full): 0.3140479326248169\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.31336653232574463\n",
      "LC Training Loss (Full): 0.18054470419883728\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3178015649318695\n",
      "LC Training Loss (Full): 0.22975492477416992\n",
      "Full accuracy (w/o dLoRA+LC): 0.9146, LC accuracy: 0.9151, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8634, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8615\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39444875717163086\n",
      "LC Training Loss (Full): 0.25918591022491455\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3711780607700348\n",
      "LC Training Loss (Full): 0.26921191811561584\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.38921239972114563\n",
      "LC Training Loss (Full): 0.22073113918304443\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49466630816459656\n",
      "LC Training Loss (Full): 0.3528871536254883\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3587858974933624\n",
      "LC Training Loss (Full): 0.19271644949913025\n",
      "Full accuracy (w/o dLoRA+LC): 0.9144, LC accuracy: 0.9149, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8625, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8616\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader38/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader38/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.2741844952106476\n",
      "LC Training Loss (Full): 0.12195272743701935\n",
      "End of model training on train_loader38...\n",
      "Model saved at accuracy: 0.8625\n",
      "--------------------------\n",
      "Beginning of model training on train_loader39...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3331858217716217\n",
      "LC Training Loss (Full): 0.23761919140815735\n",
      "Training Accuracy | Decomposed: 0.9375, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.720779299736023\n",
      "LC Training Loss (Full): 0.4780760109424591\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.0414788722991943\n",
      "LC Training Loss (Full): 0.2692495882511139\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.2943907976150513\n",
      "LC Training Loss (Full): 0.2867029309272766\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5230181217193604\n",
      "LC Training Loss (Full): 0.2870367169380188\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6947062015533447\n",
      "LC Training Loss (Full): 0.46394017338752747\n",
      "Full accuracy (w/o dLoRA+LC): 0.9153, LC accuracy: 0.9152, Decomposed-Full (w/dLoRA+LC) accuracy: 0.841, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8577\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4316330552101135\n",
      "LC Training Loss (Full): 0.21286147832870483\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6999654769897461\n",
      "LC Training Loss (Full): 0.48946690559387207\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2840312123298645\n",
      "LC Training Loss (Full): 0.25062844157218933\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5187141299247742\n",
      "LC Training Loss (Full): 0.3844577372074127\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4508642554283142\n",
      "LC Training Loss (Full): 0.31239908933639526\n",
      "Full accuracy (w/o dLoRA+LC): 0.9151, LC accuracy: 0.9146, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8604, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8591\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3412047326564789\n",
      "LC Training Loss (Full): 0.21854168176651\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5304469466209412\n",
      "LC Training Loss (Full): 0.3304520547389984\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5804605484008789\n",
      "LC Training Loss (Full): 0.4420558512210846\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.46701228618621826\n",
      "LC Training Loss (Full): 0.3526178002357483\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.23767037689685822\n",
      "LC Training Loss (Full): 0.1152067705988884\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4290870428085327\n",
      "LC Training Loss (Full): 0.27547889947891235\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5087756514549255\n",
      "LC Training Loss (Full): 0.4073167145252228\n",
      "Full accuracy (w/o dLoRA+LC): 0.9163, LC accuracy: 0.9162, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8618, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8595\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.38248175382614136\n",
      "LC Training Loss (Full): 0.2435455620288849\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4074595272541046\n",
      "LC Training Loss (Full): 0.25101029872894287\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3738248646259308\n",
      "LC Training Loss (Full): 0.3184451758861542\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7162823677062988\n",
      "LC Training Loss (Full): 0.4492449462413788\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4324164092540741\n",
      "LC Training Loss (Full): 0.2122538685798645\n",
      "Full accuracy (w/o dLoRA+LC): 0.9155, LC accuracy: 0.9154, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8612, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8596\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader39/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader39/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5073245763778687\n",
      "LC Training Loss (Full): 0.311530202627182\n",
      "End of model training on train_loader39...\n",
      "Model saved at accuracy: 0.8612\n",
      "--------------------------\n",
      "Beginning of model training on train_loader40...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.373102068901062\n",
      "LC Training Loss (Full): 0.21742406487464905\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5471201539039612\n",
      "LC Training Loss (Full): 0.3799492418766022\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.34630945324897766\n",
      "LC Training Loss (Full): 0.19815516471862793\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.705695629119873\n",
      "LC Training Loss (Full): 0.5729520320892334\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8703911304473877\n",
      "LC Training Loss (Full): 0.6224468350410461\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6344237923622131\n",
      "LC Training Loss (Full): 0.29975366592407227\n",
      "Full accuracy (w/o dLoRA+LC): 0.9163, LC accuracy: 0.9154, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8549, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8612\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4635196030139923\n",
      "LC Training Loss (Full): 0.28082454204559326\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6123814582824707\n",
      "LC Training Loss (Full): 0.32727593183517456\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5825154185295105\n",
      "LC Training Loss (Full): 0.3065408766269684\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.638252854347229\n",
      "LC Training Loss (Full): 0.40696409344673157\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6779348254203796\n",
      "LC Training Loss (Full): 0.3517797887325287\n",
      "Full accuracy (w/o dLoRA+LC): 0.9165, LC accuracy: 0.9163, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8585, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8584\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4930131733417511\n",
      "LC Training Loss (Full): 0.35668691992759705\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5470020174980164\n",
      "LC Training Loss (Full): 0.30768951773643494\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3421128988265991\n",
      "LC Training Loss (Full): 0.25525006651878357\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4971262216567993\n",
      "LC Training Loss (Full): 0.2990137040615082\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.377634733915329\n",
      "LC Training Loss (Full): 0.20713229477405548\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5856984257698059\n",
      "LC Training Loss (Full): 0.397993803024292\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49956315755844116\n",
      "LC Training Loss (Full): 0.36331337690353394\n",
      "Full accuracy (w/o dLoRA+LC): 0.9156, LC accuracy: 0.9173, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8611, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8585\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4434729516506195\n",
      "LC Training Loss (Full): 0.282563179731369\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.606347382068634\n",
      "LC Training Loss (Full): 0.32801979780197144\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9655545949935913\n",
      "LC Training Loss (Full): 0.6712496280670166\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4713905453681946\n",
      "LC Training Loss (Full): 0.3085584342479706\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6209006309509277\n",
      "LC Training Loss (Full): 0.4351922869682312\n",
      "Full accuracy (w/o dLoRA+LC): 0.9177, LC accuracy: 0.9169, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8612, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8607\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader40/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader40/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4944715201854706\n",
      "LC Training Loss (Full): 0.2854480445384979\n",
      "End of model training on train_loader40...\n",
      "Model saved at accuracy: 0.8612\n",
      "--------------------------\n",
      "Beginning of model training on train_loader41...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6326883435249329\n",
      "LC Training Loss (Full): 0.31460481882095337\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7715333104133606\n",
      "LC Training Loss (Full): 0.44261497259140015\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9021915793418884\n",
      "LC Training Loss (Full): 0.6673162579536438\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5590938925743103\n",
      "LC Training Loss (Full): 0.36900627613067627\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4466094374656677\n",
      "LC Training Loss (Full): 0.2832094132900238\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4770187735557556\n",
      "LC Training Loss (Full): 0.25574567914009094\n",
      "Full accuracy (w/o dLoRA+LC): 0.9174, LC accuracy: 0.9187, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8597, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8619\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5178232192993164\n",
      "LC Training Loss (Full): 0.2709513008594513\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45510920882225037\n",
      "LC Training Loss (Full): 0.21774277091026306\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7040419578552246\n",
      "LC Training Loss (Full): 0.41384828090667725\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7496988773345947\n",
      "LC Training Loss (Full): 0.31769105792045593\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6219929456710815\n",
      "LC Training Loss (Full): 0.4273700714111328\n",
      "Full accuracy (w/o dLoRA+LC): 0.9171, LC accuracy: 0.9176, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8577, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8597\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7344508767127991\n",
      "LC Training Loss (Full): 0.48272934556007385\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.504010021686554\n",
      "LC Training Loss (Full): 0.3466320037841797\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.84375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.822772741317749\n",
      "LC Training Loss (Full): 0.5092980265617371\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5022965669631958\n",
      "LC Training Loss (Full): 0.31825169920921326\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6871883273124695\n",
      "LC Training Loss (Full): 0.4660307765007019\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.537375807762146\n",
      "LC Training Loss (Full): 0.3356848955154419\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.640323281288147\n",
      "LC Training Loss (Full): 0.3499162197113037\n",
      "Full accuracy (w/o dLoRA+LC): 0.9168, LC accuracy: 0.9171, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8619, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8583\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47825247049331665\n",
      "LC Training Loss (Full): 0.2969585061073303\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6353901624679565\n",
      "LC Training Loss (Full): 0.4413664937019348\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4595264792442322\n",
      "LC Training Loss (Full): 0.24995073676109314\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5000883936882019\n",
      "LC Training Loss (Full): 0.21791036427021027\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5970925092697144\n",
      "LC Training Loss (Full): 0.3666035532951355\n",
      "Full accuracy (w/o dLoRA+LC): 0.9161, LC accuracy: 0.9165, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8602, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8594\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader41/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader41/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4148993492126465\n",
      "LC Training Loss (Full): 0.28804537653923035\n",
      "End of model training on train_loader41...\n",
      "Model saved at accuracy: 0.8602\n",
      "--------------------------\n",
      "Beginning of model training on train_loader42...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.673474133014679\n",
      "LC Training Loss (Full): 0.5357338786125183\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.70262211561203\n",
      "LC Training Loss (Full): 0.40190038084983826\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.641029417514801\n",
      "LC Training Loss (Full): 0.3627220392227173\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7354305386543274\n",
      "LC Training Loss (Full): 0.4357827305793762\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6642706990242004\n",
      "LC Training Loss (Full): 0.3800022602081299\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4953858256340027\n",
      "LC Training Loss (Full): 0.29170680046081543\n",
      "Full accuracy (w/o dLoRA+LC): 0.9171, LC accuracy: 0.9162, Decomposed-Full (w/dLoRA+LC) accuracy: 0.864, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8609\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5346794128417969\n",
      "LC Training Loss (Full): 0.32011574506759644\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7472633719444275\n",
      "LC Training Loss (Full): 0.5386950969696045\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8838096261024475\n",
      "LC Training Loss (Full): 0.5291429162025452\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.38352078199386597\n",
      "LC Training Loss (Full): 0.17268218100070953\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5735434889793396\n",
      "LC Training Loss (Full): 0.37498044967651367\n",
      "Full accuracy (w/o dLoRA+LC): 0.9184, LC accuracy: 0.918, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8585, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8584\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3513684868812561\n",
      "LC Training Loss (Full): 0.2558172345161438\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5572829842567444\n",
      "LC Training Loss (Full): 0.3773060739040375\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5757007598876953\n",
      "LC Training Loss (Full): 0.40384772419929504\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5918214917182922\n",
      "LC Training Loss (Full): 0.4394637942314148\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5962862968444824\n",
      "LC Training Loss (Full): 0.34806185960769653\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6706732511520386\n",
      "LC Training Loss (Full): 0.4770403802394867\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6097743511199951\n",
      "LC Training Loss (Full): 0.44032225012779236\n",
      "Full accuracy (w/o dLoRA+LC): 0.9178, LC accuracy: 0.9183, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8606, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8591\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6765952110290527\n",
      "LC Training Loss (Full): 0.4354449510574341\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4671300947666168\n",
      "LC Training Loss (Full): 0.26731956005096436\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4188797175884247\n",
      "LC Training Loss (Full): 0.2049759477376938\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.468483030796051\n",
      "LC Training Loss (Full): 0.31399741768836975\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6630086898803711\n",
      "LC Training Loss (Full): 0.4175725281238556\n",
      "Full accuracy (w/o dLoRA+LC): 0.9187, LC accuracy: 0.9183, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8609, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8597\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader42/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader42/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5335321426391602\n",
      "LC Training Loss (Full): 0.2857174575328827\n",
      "End of model training on train_loader42...\n",
      "Model saved at accuracy: 0.8609\n",
      "--------------------------\n",
      "Beginning of model training on train_loader43...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4953504800796509\n",
      "LC Training Loss (Full): 0.3265592157840729\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4881490170955658\n",
      "LC Training Loss (Full): 0.18339605629444122\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.764647901058197\n",
      "LC Training Loss (Full): 0.5095031261444092\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5686833262443542\n",
      "LC Training Loss (Full): 0.3565921485424042\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3948291540145874\n",
      "LC Training Loss (Full): 0.22765925526618958\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6379824280738831\n",
      "LC Training Loss (Full): 0.44028180837631226\n",
      "Full accuracy (w/o dLoRA+LC): 0.9184, LC accuracy: 0.9185, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8659, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8594\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4432632327079773\n",
      "LC Training Loss (Full): 0.3913709223270416\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6211336255073547\n",
      "LC Training Loss (Full): 0.3595048785209656\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7071748971939087\n",
      "LC Training Loss (Full): 0.360108882188797\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8443488478660583\n",
      "LC Training Loss (Full): 0.48098045587539673\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6314465999603271\n",
      "LC Training Loss (Full): 0.38691818714141846\n",
      "Full accuracy (w/o dLoRA+LC): 0.9185, LC accuracy: 0.9191, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8497, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8475\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6957115530967712\n",
      "LC Training Loss (Full): 0.4610045254230499\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48710915446281433\n",
      "LC Training Loss (Full): 0.3447795808315277\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5494950413703918\n",
      "LC Training Loss (Full): 0.38711825013160706\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6002152562141418\n",
      "LC Training Loss (Full): 0.42958033084869385\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7115539908409119\n",
      "LC Training Loss (Full): 0.47072285413742065\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3754193186759949\n",
      "LC Training Loss (Full): 0.20583303272724152\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7889993190765381\n",
      "LC Training Loss (Full): 0.5384714603424072\n",
      "Full accuracy (w/o dLoRA+LC): 0.919, LC accuracy: 0.9188, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8557, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8501\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5340770483016968\n",
      "LC Training Loss (Full): 0.2913348376750946\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5629900097846985\n",
      "LC Training Loss (Full): 0.3061850965023041\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5557896494865417\n",
      "LC Training Loss (Full): 0.3628358840942383\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.544900119304657\n",
      "LC Training Loss (Full): 0.2518458366394043\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6316964030265808\n",
      "LC Training Loss (Full): 0.3618713915348053\n",
      "Full accuracy (w/o dLoRA+LC): 0.9181, LC accuracy: 0.9174, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8555, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8517\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader43/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader43/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5252083539962769\n",
      "LC Training Loss (Full): 0.29074642062187195\n",
      "End of model training on train_loader43...\n",
      "Model saved at accuracy: 0.8555\n",
      "--------------------------\n",
      "Beginning of model training on train_loader44...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4036841094493866\n",
      "LC Training Loss (Full): 0.26498523354530334\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4569719433784485\n",
      "LC Training Loss (Full): 0.2777063548564911\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6904231309890747\n",
      "LC Training Loss (Full): 0.3912216126918793\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6809543371200562\n",
      "LC Training Loss (Full): 0.3864574730396271\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6603049635887146\n",
      "LC Training Loss (Full): 0.3983602821826935\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7246326208114624\n",
      "LC Training Loss (Full): 0.46168407797813416\n",
      "Full accuracy (w/o dLoRA+LC): 0.9179, LC accuracy: 0.9183, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8077, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8576\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5022832751274109\n",
      "LC Training Loss (Full): 0.21251694858074188\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6207881569862366\n",
      "LC Training Loss (Full): 0.3434705138206482\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48293906450271606\n",
      "LC Training Loss (Full): 0.2945941388607025\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4184982180595398\n",
      "LC Training Loss (Full): 0.27676230669021606\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.42704886198043823\n",
      "LC Training Loss (Full): 0.2874831557273865\n",
      "Full accuracy (w/o dLoRA+LC): 0.9191, LC accuracy: 0.9188, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8608, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8596\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4983330965042114\n",
      "LC Training Loss (Full): 0.17257219552993774\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.43730175495147705\n",
      "LC Training Loss (Full): 0.2330835610628128\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.953125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5890150666236877\n",
      "LC Training Loss (Full): 0.3530791699886322\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.794866144657135\n",
      "LC Training Loss (Full): 0.49113747477531433\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.46046072244644165\n",
      "LC Training Loss (Full): 0.3047259449958801\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4407098591327667\n",
      "LC Training Loss (Full): 0.2541923522949219\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5065270662307739\n",
      "LC Training Loss (Full): 0.30992573499679565\n",
      "Full accuracy (w/o dLoRA+LC): 0.9164, LC accuracy: 0.9178, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8616, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8612\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.46912333369255066\n",
      "LC Training Loss (Full): 0.2688431739807129\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2299267202615738\n",
      "LC Training Loss (Full): 0.15746037662029266\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45362359285354614\n",
      "LC Training Loss (Full): 0.2845346927642822\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.397630900144577\n",
      "LC Training Loss (Full): 0.29622140526771545\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.44091981649398804\n",
      "LC Training Loss (Full): 0.31124749779701233\n",
      "Full accuracy (w/o dLoRA+LC): 0.9179, LC accuracy: 0.9177, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8618, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8618\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader44/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader44/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.45148614048957825\n",
      "LC Training Loss (Full): 0.332137793302536\n",
      "End of model training on train_loader44...\n",
      "Model saved at accuracy: 0.8618\n",
      "--------------------------\n",
      "Beginning of model training on train_loader45...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7176571488380432\n",
      "LC Training Loss (Full): 0.45246759057044983\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.43484100699424744\n",
      "LC Training Loss (Full): 0.19645056128501892\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4861510992050171\n",
      "LC Training Loss (Full): 0.2937347888946533\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4475101828575134\n",
      "LC Training Loss (Full): 0.26011210680007935\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4371614456176758\n",
      "LC Training Loss (Full): 0.23231016099452972\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4710862934589386\n",
      "LC Training Loss (Full): 0.23497332632541656\n",
      "Full accuracy (w/o dLoRA+LC): 0.9185, LC accuracy: 0.9182, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8665, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8638\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4557074010372162\n",
      "LC Training Loss (Full): 0.24441352486610413\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.369754821062088\n",
      "LC Training Loss (Full): 0.17232763767242432\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.30013516545295715\n",
      "LC Training Loss (Full): 0.19592487812042236\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4330282509326935\n",
      "LC Training Loss (Full): 0.29260554909706116\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48153284192085266\n",
      "LC Training Loss (Full): 0.28287220001220703\n",
      "Full accuracy (w/o dLoRA+LC): 0.9186, LC accuracy: 0.9186, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8657, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8647\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.32193806767463684\n",
      "LC Training Loss (Full): 0.13257257640361786\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5435950756072998\n",
      "LC Training Loss (Full): 0.28720802068710327\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4798351228237152\n",
      "LC Training Loss (Full): 0.25510504841804504\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.34541231393814087\n",
      "LC Training Loss (Full): 0.18122059106826782\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.37921619415283203\n",
      "LC Training Loss (Full): 0.13371878862380981\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35227543115615845\n",
      "LC Training Loss (Full): 0.18522486090660095\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4442860186100006\n",
      "LC Training Loss (Full): 0.2730615735054016\n",
      "Full accuracy (w/o dLoRA+LC): 0.9179, LC accuracy: 0.9176, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8674, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8653\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3997563123703003\n",
      "LC Training Loss (Full): 0.1875418722629547\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5521711111068726\n",
      "LC Training Loss (Full): 0.35129284858703613\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4378923773765564\n",
      "LC Training Loss (Full): 0.29326698184013367\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2733880579471588\n",
      "LC Training Loss (Full): 0.15090949833393097\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.41258007287979126\n",
      "LC Training Loss (Full): 0.1801382601261139\n",
      "Full accuracy (w/o dLoRA+LC): 0.9192, LC accuracy: 0.9193, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8655, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.865\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader45/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader45/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.717781662940979\n",
      "LC Training Loss (Full): 0.45602327585220337\n",
      "End of model training on train_loader45...\n",
      "Model saved at accuracy: 0.8655\n",
      "--------------------------\n",
      "Beginning of model training on train_loader46...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3829479217529297\n",
      "LC Training Loss (Full): 0.23598000407218933\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37009939551353455\n",
      "LC Training Loss (Full): 0.25825604796409607\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.485870897769928\n",
      "LC Training Loss (Full): 0.2464374154806137\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5056234002113342\n",
      "LC Training Loss (Full): 0.26449868083000183\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5305631756782532\n",
      "LC Training Loss (Full): 0.32093682885169983\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2433919608592987\n",
      "LC Training Loss (Full): 0.17209433019161224\n",
      "Full accuracy (w/o dLoRA+LC): 0.9197, LC accuracy: 0.9194, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8684, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8639\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.444732666015625\n",
      "LC Training Loss (Full): 0.39047566056251526\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7532837390899658\n",
      "LC Training Loss (Full): 0.4556505084037781\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.47749677300453186\n",
      "LC Training Loss (Full): 0.26887696981430054\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.31588014960289\n",
      "LC Training Loss (Full): 0.21432964503765106\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.31897813081741333\n",
      "LC Training Loss (Full): 0.23883157968521118\n",
      "Full accuracy (w/o dLoRA+LC): 0.9208, LC accuracy: 0.9206, Decomposed-Full (w/dLoRA+LC) accuracy: 0.866, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8653\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.2630080282688141\n",
      "LC Training Loss (Full): 0.1308761090040207\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3051982522010803\n",
      "LC Training Loss (Full): 0.15258465707302094\n",
      "Training Accuracy | Decomposed: 0.953125, Full : 0.984375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3701469898223877\n",
      "LC Training Loss (Full): 0.2704966962337494\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5004873275756836\n",
      "LC Training Loss (Full): 0.3656606078147888\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45055505633354187\n",
      "LC Training Loss (Full): 0.36846351623535156\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5365402698516846\n",
      "LC Training Loss (Full): 0.29567277431488037\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.44806885719299316\n",
      "LC Training Loss (Full): 0.25872987508773804\n",
      "Full accuracy (w/o dLoRA+LC): 0.9207, LC accuracy: 0.9209, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8673, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8661\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.30315229296684265\n",
      "LC Training Loss (Full): 0.14042876660823822\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3859758973121643\n",
      "LC Training Loss (Full): 0.30383360385894775\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4470069110393524\n",
      "LC Training Loss (Full): 0.27748844027519226\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.30890145897865295\n",
      "LC Training Loss (Full): 0.21518078446388245\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3931971490383148\n",
      "LC Training Loss (Full): 0.2761342227458954\n",
      "Full accuracy (w/o dLoRA+LC): 0.9221, LC accuracy: 0.9212, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8659, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8659\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader46/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader46/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.24450626969337463\n",
      "LC Training Loss (Full): 0.12851272523403168\n",
      "End of model training on train_loader46...\n",
      "Model saved at accuracy: 0.8659\n",
      "--------------------------\n",
      "Beginning of model training on train_loader47...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.47484904527664185\n",
      "LC Training Loss (Full): 0.2679137885570526\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5765052437782288\n",
      "LC Training Loss (Full): 0.2245619297027588\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.43219801783561707\n",
      "LC Training Loss (Full): 0.2680441439151764\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5900014042854309\n",
      "LC Training Loss (Full): 0.46477195620536804\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.518738865852356\n",
      "LC Training Loss (Full): 0.26272791624069214\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.34472212195396423\n",
      "LC Training Loss (Full): 0.2671230137348175\n",
      "Full accuracy (w/o dLoRA+LC): 0.9211, LC accuracy: 0.9222, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8682, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8661\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5222731828689575\n",
      "LC Training Loss (Full): 0.427949994802475\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3344959020614624\n",
      "LC Training Loss (Full): 0.16858796775341034\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6118233799934387\n",
      "LC Training Loss (Full): 0.36647123098373413\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5030166506767273\n",
      "LC Training Loss (Full): 0.40976184606552124\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5017910003662109\n",
      "LC Training Loss (Full): 0.2632438540458679\n",
      "Full accuracy (w/o dLoRA+LC): 0.9205, LC accuracy: 0.921, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8621, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8631\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.2002638876438141\n",
      "LC Training Loss (Full): 0.09288130700588226\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4870627224445343\n",
      "LC Training Loss (Full): 0.344774067401886\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.9375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47656795382499695\n",
      "LC Training Loss (Full): 0.3020501434803009\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.37808987498283386\n",
      "LC Training Loss (Full): 0.20573818683624268\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6387069225311279\n",
      "LC Training Loss (Full): 0.416762113571167\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.37637045979499817\n",
      "LC Training Loss (Full): 0.2347121238708496\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4789521098136902\n",
      "LC Training Loss (Full): 0.3125998377799988\n",
      "Full accuracy (w/o dLoRA+LC): 0.9205, LC accuracy: 0.9207, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8615, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.862\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4473458528518677\n",
      "LC Training Loss (Full): 0.28679612278938293\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5597915649414062\n",
      "LC Training Loss (Full): 0.2793169915676117\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.42683881521224976\n",
      "LC Training Loss (Full): 0.29163774847984314\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4617690145969391\n",
      "LC Training Loss (Full): 0.2732449471950531\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.41532373428344727\n",
      "LC Training Loss (Full): 0.18507683277130127\n",
      "Full accuracy (w/o dLoRA+LC): 0.921, LC accuracy: 0.9208, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8625, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8626\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader47/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader47/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4056437313556671\n",
      "LC Training Loss (Full): 0.2550782561302185\n",
      "End of model training on train_loader47...\n",
      "Model saved at accuracy: 0.8625\n",
      "--------------------------\n",
      "Beginning of model training on train_loader48...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.32617655396461487\n",
      "LC Training Loss (Full): 0.20422378182411194\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.43525901436805725\n",
      "LC Training Loss (Full): 0.2497125267982483\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37622857093811035\n",
      "LC Training Loss (Full): 0.2269466370344162\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.28073224425315857\n",
      "LC Training Loss (Full): 0.13889315724372864\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3788158595561981\n",
      "LC Training Loss (Full): 0.3048187494277954\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5767673254013062\n",
      "LC Training Loss (Full): 0.3797346353530884\n",
      "Full accuracy (w/o dLoRA+LC): 0.9215, LC accuracy: 0.9224, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8358, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8613\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3928427994251251\n",
      "LC Training Loss (Full): 0.16597291827201843\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.632878303527832\n",
      "LC Training Loss (Full): 0.402165949344635\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.47349974513053894\n",
      "LC Training Loss (Full): 0.24401351809501648\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.35950496792793274\n",
      "LC Training Loss (Full): 0.20880521833896637\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.31001850962638855\n",
      "LC Training Loss (Full): 0.15795783698558807\n",
      "Full accuracy (w/o dLoRA+LC): 0.9207, LC accuracy: 0.9217, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8641, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8639\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.39839741587638855\n",
      "LC Training Loss (Full): 0.24435961246490479\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3471650183200836\n",
      "LC Training Loss (Full): 0.16151343286037445\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.9375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3304956555366516\n",
      "LC Training Loss (Full): 0.21733781695365906\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4185595214366913\n",
      "LC Training Loss (Full): 0.26590558886528015\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4277324080467224\n",
      "LC Training Loss (Full): 0.28384777903556824\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2798432409763336\n",
      "LC Training Loss (Full): 0.20336271822452545\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5596843957901001\n",
      "LC Training Loss (Full): 0.4349817633628845\n",
      "Full accuracy (w/o dLoRA+LC): 0.9213, LC accuracy: 0.9209, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8659, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8639\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4325423836708069\n",
      "LC Training Loss (Full): 0.2813815474510193\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3168709874153137\n",
      "LC Training Loss (Full): 0.151376873254776\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4905073344707489\n",
      "LC Training Loss (Full): 0.25186821818351746\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.30267998576164246\n",
      "LC Training Loss (Full): 0.16704900562763214\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.44319456815719604\n",
      "LC Training Loss (Full): 0.22287128865718842\n",
      "Full accuracy (w/o dLoRA+LC): 0.921, LC accuracy: 0.9217, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8638, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8642\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader48/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader48/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3575267493724823\n",
      "LC Training Loss (Full): 0.1525590866804123\n",
      "End of model training on train_loader48...\n",
      "Model saved at accuracy: 0.8638\n",
      "--------------------------\n",
      "Beginning of model training on train_loader49...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3872576057910919\n",
      "LC Training Loss (Full): 0.24066266417503357\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.35523146390914917\n",
      "LC Training Loss (Full): 0.19779972732067108\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45619702339172363\n",
      "LC Training Loss (Full): 0.15955843031406403\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5873668193817139\n",
      "LC Training Loss (Full): 0.2018827497959137\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7430954575538635\n",
      "LC Training Loss (Full): 0.29140564799308777\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8142170906066895\n",
      "LC Training Loss (Full): 0.35975855588912964\n",
      "Full accuracy (w/o dLoRA+LC): 0.922, LC accuracy: 0.9213, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7792, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8499\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5078845024108887\n",
      "LC Training Loss (Full): 0.14025937020778656\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5643330216407776\n",
      "LC Training Loss (Full): 0.35365644097328186\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.42637020349502563\n",
      "LC Training Loss (Full): 0.28851398825645447\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.35118499398231506\n",
      "LC Training Loss (Full): 0.20219795405864716\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5494424104690552\n",
      "LC Training Loss (Full): 0.3372000753879547\n",
      "Full accuracy (w/o dLoRA+LC): 0.9213, LC accuracy: 0.9223, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8586, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8569\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.40493518114089966\n",
      "LC Training Loss (Full): 0.3142668604850769\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5151678323745728\n",
      "LC Training Loss (Full): 0.244611918926239\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.9375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.36213621497154236\n",
      "LC Training Loss (Full): 0.1782914102077484\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.237777978181839\n",
      "LC Training Loss (Full): 0.12110500782728195\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4507361948490143\n",
      "LC Training Loss (Full): 0.3019995093345642\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35124167799949646\n",
      "LC Training Loss (Full): 0.1572902798652649\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.538603663444519\n",
      "LC Training Loss (Full): 0.33489155769348145\n",
      "Full accuracy (w/o dLoRA+LC): 0.9201, LC accuracy: 0.9209, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8647, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.86\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3961631655693054\n",
      "LC Training Loss (Full): 0.2369537204504013\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4280061423778534\n",
      "LC Training Loss (Full): 0.24052870273590088\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45208799839019775\n",
      "LC Training Loss (Full): 0.2849113643169403\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4391288757324219\n",
      "LC Training Loss (Full): 0.2688886225223541\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4084813594818115\n",
      "LC Training Loss (Full): 0.24092838168144226\n",
      "Full accuracy (w/o dLoRA+LC): 0.9203, LC accuracy: 0.9191, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8624, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8611\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader49/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader49/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5455082058906555\n",
      "LC Training Loss (Full): 0.3024548292160034\n",
      "End of model training on train_loader49...\n",
      "Model saved at accuracy: 0.8624\n",
      "--------------------------\n",
      "Beginning of model training on train_loader50...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7063416242599487\n",
      "LC Training Loss (Full): 0.48028647899627686\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.828125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5638605356216431\n",
      "LC Training Loss (Full): 0.32045474648475647\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7003520131111145\n",
      "LC Training Loss (Full): 0.33869922161102295\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5192762613296509\n",
      "LC Training Loss (Full): 0.40752682089805603\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.42604178190231323\n",
      "LC Training Loss (Full): 0.28713589906692505\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7225297689437866\n",
      "LC Training Loss (Full): 0.4944700598716736\n",
      "Full accuracy (w/o dLoRA+LC): 0.922, LC accuracy: 0.919, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8366, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8627\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5023155212402344\n",
      "LC Training Loss (Full): 0.32719656825065613\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.40916314721107483\n",
      "LC Training Loss (Full): 0.32773515582084656\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.511427104473114\n",
      "LC Training Loss (Full): 0.4547775387763977\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5384868383407593\n",
      "LC Training Loss (Full): 0.4432339072227478\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7575363516807556\n",
      "LC Training Loss (Full): 0.4951896667480469\n",
      "Full accuracy (w/o dLoRA+LC): 0.9227, LC accuracy: 0.9223, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8684, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8659\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5840888619422913\n",
      "LC Training Loss (Full): 0.35944414138793945\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5234543681144714\n",
      "LC Training Loss (Full): 0.37156978249549866\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45362791419029236\n",
      "LC Training Loss (Full): 0.30304765701293945\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6743679046630859\n",
      "LC Training Loss (Full): 0.4961360692977905\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47556570172309875\n",
      "LC Training Loss (Full): 0.29929468035697937\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49355995655059814\n",
      "LC Training Loss (Full): 0.2890213429927826\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6401596069335938\n",
      "LC Training Loss (Full): 0.41213393211364746\n",
      "Full accuracy (w/o dLoRA+LC): 0.9222, LC accuracy: 0.9222, Decomposed-Full (w/dLoRA+LC) accuracy: 0.87, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8666\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3716631531715393\n",
      "LC Training Loss (Full): 0.20070452988147736\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7581115365028381\n",
      "LC Training Loss (Full): 0.5093631744384766\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.53232741355896\n",
      "LC Training Loss (Full): 0.39042431116104126\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41902491450309753\n",
      "LC Training Loss (Full): 0.2620183229446411\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6662038564682007\n",
      "LC Training Loss (Full): 0.3507530093193054\n",
      "Full accuracy (w/o dLoRA+LC): 0.9212, LC accuracy: 0.9212, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8675, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8667\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader50/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader50/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6185315251350403\n",
      "LC Training Loss (Full): 0.43831485509872437\n",
      "End of model training on train_loader50...\n",
      "Model saved at accuracy: 0.8675\n",
      "--------------------------\n",
      "Beginning of model training on train_loader51...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5326875448226929\n",
      "LC Training Loss (Full): 0.3517696261405945\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4993288218975067\n",
      "LC Training Loss (Full): 0.2632954716682434\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6078173518180847\n",
      "LC Training Loss (Full): 0.26590895652770996\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.593460738658905\n",
      "LC Training Loss (Full): 0.25180894136428833\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7513453364372253\n",
      "LC Training Loss (Full): 0.3097197413444519\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5556662082672119\n",
      "LC Training Loss (Full): 0.33378836512565613\n",
      "Full accuracy (w/o dLoRA+LC): 0.9242, LC accuracy: 0.9235, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8344, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8628\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.567838728427887\n",
      "LC Training Loss (Full): 0.2653692364692688\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6149900555610657\n",
      "LC Training Loss (Full): 0.33293089270591736\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5319726467132568\n",
      "LC Training Loss (Full): 0.4074309170246124\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3160581886768341\n",
      "LC Training Loss (Full): 0.21486979722976685\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4332069754600525\n",
      "LC Training Loss (Full): 0.24677439033985138\n",
      "Full accuracy (w/o dLoRA+LC): 0.9238, LC accuracy: 0.9235, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8704, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.868\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5684190392494202\n",
      "LC Training Loss (Full): 0.2818078398704529\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4587576985359192\n",
      "LC Training Loss (Full): 0.30003252625465393\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6133918762207031\n",
      "LC Training Loss (Full): 0.2787243723869324\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39767006039619446\n",
      "LC Training Loss (Full): 0.2263580858707428\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47267651557922363\n",
      "LC Training Loss (Full): 0.3500092029571533\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4625488817691803\n",
      "LC Training Loss (Full): 0.2569800317287445\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5205592513084412\n",
      "LC Training Loss (Full): 0.3051755130290985\n",
      "Full accuracy (w/o dLoRA+LC): 0.9239, LC accuracy: 0.9238, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8716, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8705\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5381001830101013\n",
      "LC Training Loss (Full): 0.32551851868629456\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41473162174224854\n",
      "LC Training Loss (Full): 0.26604658365249634\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4989829659461975\n",
      "LC Training Loss (Full): 0.3515338897705078\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39954692125320435\n",
      "LC Training Loss (Full): 0.21279019117355347\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3803718686103821\n",
      "LC Training Loss (Full): 0.21696420013904572\n",
      "Full accuracy (w/o dLoRA+LC): 0.9245, LC accuracy: 0.9243, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8706, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8704\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader51/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader51/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.35697275400161743\n",
      "LC Training Loss (Full): 0.2501120865345001\n",
      "End of model training on train_loader51...\n",
      "Model saved at accuracy: 0.8706\n",
      "--------------------------\n",
      "Beginning of model training on train_loader52...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4223891496658325\n",
      "LC Training Loss (Full): 0.2488037347793579\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.29109126329421997\n",
      "LC Training Loss (Full): 0.16986675560474396\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7239077687263489\n",
      "LC Training Loss (Full): 0.4320753812789917\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8408441543579102\n",
      "LC Training Loss (Full): 0.3110836148262024\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8240647912025452\n",
      "LC Training Loss (Full): 0.19116950035095215\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6740800142288208\n",
      "LC Training Loss (Full): 0.23503535985946655\n",
      "Full accuracy (w/o dLoRA+LC): 0.9248, LC accuracy: 0.925, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8296, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8624\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.46221503615379333\n",
      "LC Training Loss (Full): 0.2386302649974823\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37536194920539856\n",
      "LC Training Loss (Full): 0.19343212246894836\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45719513297080994\n",
      "LC Training Loss (Full): 0.26052042841911316\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3179788291454315\n",
      "LC Training Loss (Full): 0.19449619948863983\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.38636770844459534\n",
      "LC Training Loss (Full): 0.21823114156723022\n",
      "Full accuracy (w/o dLoRA+LC): 0.9251, LC accuracy: 0.9248, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8689, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8684\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.30798274278640747\n",
      "LC Training Loss (Full): 0.20594172179698944\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5936630368232727\n",
      "LC Training Loss (Full): 0.3647880554199219\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4343962073326111\n",
      "LC Training Loss (Full): 0.22661323845386505\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3295765221118927\n",
      "LC Training Loss (Full): 0.2038804143667221\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4545307159423828\n",
      "LC Training Loss (Full): 0.28790283203125\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35991185903549194\n",
      "LC Training Loss (Full): 0.18761490285396576\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.24166785180568695\n",
      "LC Training Loss (Full): 0.14221826195716858\n",
      "Full accuracy (w/o dLoRA+LC): 0.9257, LC accuracy: 0.9242, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8715, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8692\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4066450893878937\n",
      "LC Training Loss (Full): 0.23058666288852692\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3322508931159973\n",
      "LC Training Loss (Full): 0.18939894437789917\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.373617023229599\n",
      "LC Training Loss (Full): 0.23978763818740845\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5107542872428894\n",
      "LC Training Loss (Full): 0.3026871383190155\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3869157135486603\n",
      "LC Training Loss (Full): 0.24397778511047363\n",
      "Full accuracy (w/o dLoRA+LC): 0.9253, LC accuracy: 0.9253, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8693, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8692\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader52/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader52/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3933831453323364\n",
      "LC Training Loss (Full): 0.14960868656635284\n",
      "End of model training on train_loader52...\n",
      "Model saved at accuracy: 0.8693\n",
      "--------------------------\n",
      "Beginning of model training on train_loader53...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6269842386245728\n",
      "LC Training Loss (Full): 0.4317527413368225\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.84375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7414080500602722\n",
      "LC Training Loss (Full): 0.3520808219909668\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6398329734802246\n",
      "LC Training Loss (Full): 0.17543703317642212\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6445049047470093\n",
      "LC Training Loss (Full): 0.4610339105129242\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4012725353240967\n",
      "LC Training Loss (Full): 0.29972830414772034\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6060076355934143\n",
      "LC Training Loss (Full): 0.2481328547000885\n",
      "Full accuracy (w/o dLoRA+LC): 0.9254, LC accuracy: 0.9254, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8434, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8693\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6014178395271301\n",
      "LC Training Loss (Full): 0.3562602400779724\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4961937963962555\n",
      "LC Training Loss (Full): 0.2481984943151474\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4208965599536896\n",
      "LC Training Loss (Full): 0.24408794939517975\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6433057188987732\n",
      "LC Training Loss (Full): 0.5710329413414001\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4909975826740265\n",
      "LC Training Loss (Full): 0.26868849992752075\n",
      "Full accuracy (w/o dLoRA+LC): 0.9253, LC accuracy: 0.9251, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8636, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8623\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.45892277359962463\n",
      "LC Training Loss (Full): 0.19985045492649078\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5573346018791199\n",
      "LC Training Loss (Full): 0.34307488799095154\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.360794335603714\n",
      "LC Training Loss (Full): 0.24040934443473816\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.30825161933898926\n",
      "LC Training Loss (Full): 0.09998217970132828\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49728646874427795\n",
      "LC Training Loss (Full): 0.29417577385902405\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7779677510261536\n",
      "LC Training Loss (Full): 0.47848957777023315\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35060858726501465\n",
      "LC Training Loss (Full): 0.18364675343036652\n",
      "Full accuracy (w/o dLoRA+LC): 0.9245, LC accuracy: 0.9259, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8696, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8656\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6189448833465576\n",
      "LC Training Loss (Full): 0.4161968529224396\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.43549105525016785\n",
      "LC Training Loss (Full): 0.3384478688240051\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3850760757923126\n",
      "LC Training Loss (Full): 0.2603115737438202\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.48123112320899963\n",
      "LC Training Loss (Full): 0.27087491750717163\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4899175465106964\n",
      "LC Training Loss (Full): 0.2988854646682739\n",
      "Full accuracy (w/o dLoRA+LC): 0.9244, LC accuracy: 0.9249, Decomposed-Full (w/dLoRA+LC) accuracy: 0.866, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8651\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader53/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader53/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6364773511886597\n",
      "LC Training Loss (Full): 0.40632927417755127\n",
      "End of model training on train_loader53...\n",
      "Model saved at accuracy: 0.8660\n",
      "--------------------------\n",
      "Beginning of model training on train_loader54...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4480779767036438\n",
      "LC Training Loss (Full): 0.24436430633068085\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6623312830924988\n",
      "LC Training Loss (Full): 0.3369073271751404\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.637657880783081\n",
      "LC Training Loss (Full): 0.32306408882141113\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6499646902084351\n",
      "LC Training Loss (Full): 0.32602450251579285\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5070115923881531\n",
      "LC Training Loss (Full): 0.290296345949173\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4490993320941925\n",
      "LC Training Loss (Full): 0.2874405086040497\n",
      "Full accuracy (w/o dLoRA+LC): 0.9262, LC accuracy: 0.9241, Decomposed-Full (w/dLoRA+LC) accuracy: 0.862, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8669\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.31659671664237976\n",
      "LC Training Loss (Full): 0.16767968237400055\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3592061996459961\n",
      "LC Training Loss (Full): 0.2059812992811203\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6074233651161194\n",
      "LC Training Loss (Full): 0.3980598449707031\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37300899624824524\n",
      "LC Training Loss (Full): 0.22496451437473297\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4318021535873413\n",
      "LC Training Loss (Full): 0.20420680940151215\n",
      "Full accuracy (w/o dLoRA+LC): 0.9266, LC accuracy: 0.9262, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8691, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8671\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3619983196258545\n",
      "LC Training Loss (Full): 0.26468613743782043\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5239189267158508\n",
      "LC Training Loss (Full): 0.22719261050224304\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.953125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5366606116294861\n",
      "LC Training Loss (Full): 0.2959793210029602\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4823477566242218\n",
      "LC Training Loss (Full): 0.28750988841056824\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47393256425857544\n",
      "LC Training Loss (Full): 0.31939050555229187\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41178008913993835\n",
      "LC Training Loss (Full): 0.20348739624023438\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47762247920036316\n",
      "LC Training Loss (Full): 0.3070742189884186\n",
      "Full accuracy (w/o dLoRA+LC): 0.9278, LC accuracy: 0.9269, Decomposed-Full (w/dLoRA+LC) accuracy: 0.871, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.868\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.510877251625061\n",
      "LC Training Loss (Full): 0.3127732276916504\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45471200346946716\n",
      "LC Training Loss (Full): 0.2963252365589142\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.43039509654045105\n",
      "LC Training Loss (Full): 0.21729008853435516\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.43863576650619507\n",
      "LC Training Loss (Full): 0.27735665440559387\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3568030595779419\n",
      "LC Training Loss (Full): 0.13706010580062866\n",
      "Full accuracy (w/o dLoRA+LC): 0.9279, LC accuracy: 0.9268, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8692, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8687\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader54/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader54/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3400903344154358\n",
      "LC Training Loss (Full): 0.18820752203464508\n",
      "End of model training on train_loader54...\n",
      "Model saved at accuracy: 0.8692\n",
      "--------------------------\n",
      "Beginning of model training on train_loader55...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.34434255957603455\n",
      "LC Training Loss (Full): 0.12641972303390503\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.96875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6876583695411682\n",
      "LC Training Loss (Full): 0.4503333866596222\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4365592896938324\n",
      "LC Training Loss (Full): 0.163360595703125\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37992149591445923\n",
      "LC Training Loss (Full): 0.19911839067935944\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3628512918949127\n",
      "LC Training Loss (Full): 0.198727548122406\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4264582097530365\n",
      "LC Training Loss (Full): 0.27641773223876953\n",
      "Full accuracy (w/o dLoRA+LC): 0.9277, LC accuracy: 0.9268, Decomposed-Full (w/dLoRA+LC) accuracy: 0.81, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8505\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2803460955619812\n",
      "LC Training Loss (Full): 0.10861468315124512\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6302054524421692\n",
      "LC Training Loss (Full): 0.18054065108299255\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7644103169441223\n",
      "LC Training Loss (Full): 0.2968759536743164\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4230610728263855\n",
      "LC Training Loss (Full): 0.2622569799423218\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.553817093372345\n",
      "LC Training Loss (Full): 0.35168156027793884\n",
      "Full accuracy (w/o dLoRA+LC): 0.9273, LC accuracy: 0.9272, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8699, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8704\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5736711621284485\n",
      "LC Training Loss (Full): 0.31301242113113403\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.22429686784744263\n",
      "LC Training Loss (Full): 0.10568758845329285\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.984375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45327678322792053\n",
      "LC Training Loss (Full): 0.17803768813610077\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39527931809425354\n",
      "LC Training Loss (Full): 0.20785994827747345\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4886564016342163\n",
      "LC Training Loss (Full): 0.2358052134513855\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.30565017461776733\n",
      "LC Training Loss (Full): 0.1530592143535614\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5412412285804749\n",
      "LC Training Loss (Full): 0.28637808561325073\n",
      "Full accuracy (w/o dLoRA+LC): 0.9273, LC accuracy: 0.9281, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8735, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8706\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.482244074344635\n",
      "LC Training Loss (Full): 0.3380000591278076\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4283650815486908\n",
      "LC Training Loss (Full): 0.2514558434486389\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35081636905670166\n",
      "LC Training Loss (Full): 0.21439719200134277\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4157935380935669\n",
      "LC Training Loss (Full): 0.1887330263853073\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.537723958492279\n",
      "LC Training Loss (Full): 0.33900973200798035\n",
      "Full accuracy (w/o dLoRA+LC): 0.9274, LC accuracy: 0.9277, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8718, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8703\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader55/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader55/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4544788599014282\n",
      "LC Training Loss (Full): 0.24509698152542114\n",
      "End of model training on train_loader55...\n",
      "Model saved at accuracy: 0.8718\n",
      "--------------------------\n",
      "Beginning of model training on train_loader56...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5573917031288147\n",
      "LC Training Loss (Full): 0.38156449794769287\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4675537049770355\n",
      "LC Training Loss (Full): 0.3009324073791504\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5939843058586121\n",
      "LC Training Loss (Full): 0.392742395401001\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4840620160102844\n",
      "LC Training Loss (Full): 0.3207261264324188\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4706830680370331\n",
      "LC Training Loss (Full): 0.19002938270568848\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6147317886352539\n",
      "LC Training Loss (Full): 0.40408557653427124\n",
      "Full accuracy (w/o dLoRA+LC): 0.9266, LC accuracy: 0.9273, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8128, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8637\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5916834473609924\n",
      "LC Training Loss (Full): 0.3361402451992035\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6278102993965149\n",
      "LC Training Loss (Full): 0.2581072449684143\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.41821178793907166\n",
      "LC Training Loss (Full): 0.2171325981616974\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.365831196308136\n",
      "LC Training Loss (Full): 0.19801366329193115\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.49067115783691406\n",
      "LC Training Loss (Full): 0.3081948757171631\n",
      "Full accuracy (w/o dLoRA+LC): 0.9268, LC accuracy: 0.9254, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8685, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8684\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.35762783885002136\n",
      "LC Training Loss (Full): 0.1998346745967865\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.574398398399353\n",
      "LC Training Loss (Full): 0.2558569610118866\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5283809304237366\n",
      "LC Training Loss (Full): 0.29390978813171387\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5708429217338562\n",
      "LC Training Loss (Full): 0.37648990750312805\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4884656071662903\n",
      "LC Training Loss (Full): 0.4141806960105896\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.357525110244751\n",
      "LC Training Loss (Full): 0.1881783902645111\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4101608991622925\n",
      "LC Training Loss (Full): 0.2170182317495346\n",
      "Full accuracy (w/o dLoRA+LC): 0.9251, LC accuracy: 0.9265, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8697, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8676\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5496151447296143\n",
      "LC Training Loss (Full): 0.2773987054824829\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4817185401916504\n",
      "LC Training Loss (Full): 0.27885016798973083\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5528287291526794\n",
      "LC Training Loss (Full): 0.31091028451919556\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.431512713432312\n",
      "LC Training Loss (Full): 0.27202874422073364\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3209127187728882\n",
      "LC Training Loss (Full): 0.1987150013446808\n",
      "Full accuracy (w/o dLoRA+LC): 0.9251, LC accuracy: 0.9251, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8683, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.868\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader56/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader56/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.48794353008270264\n",
      "LC Training Loss (Full): 0.33264946937561035\n",
      "End of model training on train_loader56...\n",
      "Model saved at accuracy: 0.8683\n",
      "--------------------------\n",
      "Beginning of model training on train_loader57...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.754979133605957\n",
      "LC Training Loss (Full): 0.5454040765762329\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.859375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5960658192634583\n",
      "LC Training Loss (Full): 0.33256009221076965\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6610698103904724\n",
      "LC Training Loss (Full): 0.37716880440711975\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6191359758377075\n",
      "LC Training Loss (Full): 0.31155288219451904\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.520475447177887\n",
      "LC Training Loss (Full): 0.30439549684524536\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5311463475227356\n",
      "LC Training Loss (Full): 0.3050927221775055\n",
      "Full accuracy (w/o dLoRA+LC): 0.9266, LC accuracy: 0.9242, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8486, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8724\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.647295355796814\n",
      "LC Training Loss (Full): 0.4366362690925598\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6286194920539856\n",
      "LC Training Loss (Full): 0.3767131268978119\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6085836291313171\n",
      "LC Training Loss (Full): 0.2751710116863251\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6448745727539062\n",
      "LC Training Loss (Full): 0.4698920249938965\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6021442413330078\n",
      "LC Training Loss (Full): 0.38065946102142334\n",
      "Full accuracy (w/o dLoRA+LC): 0.9272, LC accuracy: 0.9266, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8725, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.87\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6222578287124634\n",
      "LC Training Loss (Full): 0.3516922891139984\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5964634418487549\n",
      "LC Training Loss (Full): 0.3911801874637604\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.48315751552581787\n",
      "LC Training Loss (Full): 0.2634198069572449\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49787411093711853\n",
      "LC Training Loss (Full): 0.31004658341407776\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4832678735256195\n",
      "LC Training Loss (Full): 0.31845125555992126\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5193202495574951\n",
      "LC Training Loss (Full): 0.3677656352519989\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3894418776035309\n",
      "LC Training Loss (Full): 0.1710987538099289\n",
      "Full accuracy (w/o dLoRA+LC): 0.927, LC accuracy: 0.9271, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8741, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8714\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39580726623535156\n",
      "LC Training Loss (Full): 0.1835026890039444\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7211252450942993\n",
      "LC Training Loss (Full): 0.41493380069732666\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6306362152099609\n",
      "LC Training Loss (Full): 0.442427396774292\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5460333228111267\n",
      "LC Training Loss (Full): 0.32311365008354187\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7232754230499268\n",
      "LC Training Loss (Full): 0.5186613202095032\n",
      "Full accuracy (w/o dLoRA+LC): 0.9273, LC accuracy: 0.9274, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8731, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8722\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader57/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader57/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7808958888053894\n",
      "LC Training Loss (Full): 0.45874401926994324\n",
      "End of model training on train_loader57...\n",
      "Model saved at accuracy: 0.8731\n",
      "--------------------------\n",
      "Beginning of model training on train_loader58...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.504939615726471\n",
      "LC Training Loss (Full): 0.31937792897224426\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.501642644405365\n",
      "LC Training Loss (Full): 0.1648755967617035\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5273329019546509\n",
      "LC Training Loss (Full): 0.3203083872795105\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.46768543124198914\n",
      "LC Training Loss (Full): 0.2807985246181488\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5352325439453125\n",
      "LC Training Loss (Full): 0.3357681930065155\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.24059264361858368\n",
      "LC Training Loss (Full): 0.10860489308834076\n",
      "Full accuracy (w/o dLoRA+LC): 0.9269, LC accuracy: 0.9278, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8157, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.863\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4628751575946808\n",
      "LC Training Loss (Full): 0.18084551393985748\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4820720851421356\n",
      "LC Training Loss (Full): 0.22866219282150269\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5976019501686096\n",
      "LC Training Loss (Full): 0.4542768597602844\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4871304929256439\n",
      "LC Training Loss (Full): 0.3418348729610443\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3082008361816406\n",
      "LC Training Loss (Full): 0.13197742402553558\n",
      "Full accuracy (w/o dLoRA+LC): 0.9293, LC accuracy: 0.9295, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8709, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8698\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4137270152568817\n",
      "LC Training Loss (Full): 0.1871238350868225\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.41026532649993896\n",
      "LC Training Loss (Full): 0.26275232434272766\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3486268222332001\n",
      "LC Training Loss (Full): 0.24989666044712067\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.43910738825798035\n",
      "LC Training Loss (Full): 0.20546478033065796\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3216037452220917\n",
      "LC Training Loss (Full): 0.11230482161045074\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.42340582609176636\n",
      "LC Training Loss (Full): 0.21752290427684784\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4549446403980255\n",
      "LC Training Loss (Full): 0.22010000050067902\n",
      "Full accuracy (w/o dLoRA+LC): 0.929, LC accuracy: 0.9295, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8737, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8706\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6574751734733582\n",
      "LC Training Loss (Full): 0.4498671889305115\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.423576682806015\n",
      "LC Training Loss (Full): 0.19140729308128357\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3366974890232086\n",
      "LC Training Loss (Full): 0.19809940457344055\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.51018226146698\n",
      "LC Training Loss (Full): 0.33087822794914246\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5388872027397156\n",
      "LC Training Loss (Full): 0.2668972313404083\n",
      "Full accuracy (w/o dLoRA+LC): 0.9287, LC accuracy: 0.9298, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8712, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8697\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader58/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader58/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.36665078997612\n",
      "LC Training Loss (Full): 0.19936785101890564\n",
      "End of model training on train_loader58...\n",
      "Model saved at accuracy: 0.8712\n",
      "--------------------------\n",
      "Beginning of model training on train_loader59...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.35479339957237244\n",
      "LC Training Loss (Full): 0.18217331171035767\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5352290272712708\n",
      "LC Training Loss (Full): 0.30083686113357544\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4852803945541382\n",
      "LC Training Loss (Full): 0.2633748948574066\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5497475266456604\n",
      "LC Training Loss (Full): 0.37065598368644714\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2457040548324585\n",
      "LC Training Loss (Full): 0.14274701476097107\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6445338129997253\n",
      "LC Training Loss (Full): 0.3708839416503906\n",
      "Full accuracy (w/o dLoRA+LC): 0.9309, LC accuracy: 0.9277, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8334, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8681\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3304603397846222\n",
      "LC Training Loss (Full): 0.1708129197359085\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6721285581588745\n",
      "LC Training Loss (Full): 0.3045891523361206\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5055209398269653\n",
      "LC Training Loss (Full): 0.30113768577575684\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.36589956283569336\n",
      "LC Training Loss (Full): 0.20386813580989838\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3688930571079254\n",
      "LC Training Loss (Full): 0.13651910424232483\n",
      "Full accuracy (w/o dLoRA+LC): 0.93, LC accuracy: 0.9304, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8696, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8693\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.2506926357746124\n",
      "LC Training Loss (Full): 0.1390981525182724\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4001213014125824\n",
      "LC Training Loss (Full): 0.2357184886932373\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.33386555314064026\n",
      "LC Training Loss (Full): 0.21141374111175537\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4218875467777252\n",
      "LC Training Loss (Full): 0.2433437556028366\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5657516121864319\n",
      "LC Training Loss (Full): 0.32734790444374084\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.26766154170036316\n",
      "LC Training Loss (Full): 0.13262046873569489\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4965691566467285\n",
      "LC Training Loss (Full): 0.294082373380661\n",
      "Full accuracy (w/o dLoRA+LC): 0.9291, LC accuracy: 0.9297, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8711, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8691\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41136258840560913\n",
      "LC Training Loss (Full): 0.23061949014663696\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3630175292491913\n",
      "LC Training Loss (Full): 0.2036505788564682\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3110656142234802\n",
      "LC Training Loss (Full): 0.16260722279548645\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.44216814637184143\n",
      "LC Training Loss (Full): 0.29014402627944946\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3885868191719055\n",
      "LC Training Loss (Full): 0.1567312330007553\n",
      "Full accuracy (w/o dLoRA+LC): 0.9303, LC accuracy: 0.9296, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8692, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8685\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader59/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader59/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5551084876060486\n",
      "LC Training Loss (Full): 0.30636194348335266\n",
      "End of model training on train_loader59...\n",
      "Model saved at accuracy: 0.8692\n",
      "--------------------------\n",
      "Beginning of model training on train_loader60...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5199271440505981\n",
      "LC Training Loss (Full): 0.31803885102272034\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4568079113960266\n",
      "LC Training Loss (Full): 0.16288715600967407\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.43001413345336914\n",
      "LC Training Loss (Full): 0.23458419740200043\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6180564761161804\n",
      "LC Training Loss (Full): 0.32721424102783203\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7629398107528687\n",
      "LC Training Loss (Full): 0.4473574161529541\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4464794397354126\n",
      "LC Training Loss (Full): 0.18359413743019104\n",
      "Full accuracy (w/o dLoRA+LC): 0.9315, LC accuracy: 0.9298, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8757, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8724\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3331376910209656\n",
      "LC Training Loss (Full): 0.24970662593841553\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4529972970485687\n",
      "LC Training Loss (Full): 0.3289809226989746\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6006097793579102\n",
      "LC Training Loss (Full): 0.31472542881965637\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.699841320514679\n",
      "LC Training Loss (Full): 0.39847415685653687\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.29669296741485596\n",
      "LC Training Loss (Full): 0.12154023349285126\n",
      "Full accuracy (w/o dLoRA+LC): 0.9309, LC accuracy: 0.9305, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8729, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8727\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5240090489387512\n",
      "LC Training Loss (Full): 0.29429563879966736\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5696331858634949\n",
      "LC Training Loss (Full): 0.3420945405960083\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.40018901228904724\n",
      "LC Training Loss (Full): 0.22152307629585266\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.33242490887641907\n",
      "LC Training Loss (Full): 0.18983341753482819\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5605711936950684\n",
      "LC Training Loss (Full): 0.3848210275173187\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3671784996986389\n",
      "LC Training Loss (Full): 0.2388959378004074\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4794365167617798\n",
      "LC Training Loss (Full): 0.22562295198440552\n",
      "Full accuracy (w/o dLoRA+LC): 0.9314, LC accuracy: 0.9312, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8753, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8725\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3919295370578766\n",
      "LC Training Loss (Full): 0.23378919064998627\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4665660560131073\n",
      "LC Training Loss (Full): 0.2579973340034485\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3794132173061371\n",
      "LC Training Loss (Full): 0.22553081810474396\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.40409108996391296\n",
      "LC Training Loss (Full): 0.20673638582229614\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4913032352924347\n",
      "LC Training Loss (Full): 0.32888662815093994\n",
      "Full accuracy (w/o dLoRA+LC): 0.9309, LC accuracy: 0.9309, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8731, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8729\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader60/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader60/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5267139673233032\n",
      "LC Training Loss (Full): 0.347112774848938\n",
      "End of model training on train_loader60...\n",
      "Model saved at accuracy: 0.8731\n",
      "--------------------------\n",
      "Beginning of model training on train_loader61...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.42994046211242676\n",
      "LC Training Loss (Full): 0.27038317918777466\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.1276382207870483\n",
      "LC Training Loss (Full): 0.24413111805915833\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9394097924232483\n",
      "LC Training Loss (Full): 0.19622966647148132\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.1579052209854126\n",
      "LC Training Loss (Full): 0.38523873686790466\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6871092915534973\n",
      "LC Training Loss (Full): 0.25831514596939087\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.29679280519485474\n",
      "LC Training Loss (Full): 0.14702121913433075\n",
      "Full accuracy (w/o dLoRA+LC): 0.9307, LC accuracy: 0.9297, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8631, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.857\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.34548434615135193\n",
      "LC Training Loss (Full): 0.1665835976600647\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3373602032661438\n",
      "LC Training Loss (Full): 0.19021272659301758\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6527292132377625\n",
      "LC Training Loss (Full): 0.381449818611145\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3141290247440338\n",
      "LC Training Loss (Full): 0.20371557772159576\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.46502625942230225\n",
      "LC Training Loss (Full): 0.2979944050312042\n",
      "Full accuracy (w/o dLoRA+LC): 0.9307, LC accuracy: 0.9311, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8728, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8723\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3814646303653717\n",
      "LC Training Loss (Full): 0.22672440111637115\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.437416672706604\n",
      "LC Training Loss (Full): 0.25738880038261414\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3722699284553528\n",
      "LC Training Loss (Full): 0.19283808767795563\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3663659393787384\n",
      "LC Training Loss (Full): 0.18152236938476562\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3599773347377777\n",
      "LC Training Loss (Full): 0.22420327365398407\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.46093401312828064\n",
      "LC Training Loss (Full): 0.25346770882606506\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.48248517513275146\n",
      "LC Training Loss (Full): 0.32056617736816406\n",
      "Full accuracy (w/o dLoRA+LC): 0.9299, LC accuracy: 0.9297, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8769, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8731\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3885006606578827\n",
      "LC Training Loss (Full): 0.28425097465515137\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.46533432602882385\n",
      "LC Training Loss (Full): 0.22852212190628052\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.38711118698120117\n",
      "LC Training Loss (Full): 0.2742694914340973\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.38050881028175354\n",
      "LC Training Loss (Full): 0.20979218184947968\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3329550325870514\n",
      "LC Training Loss (Full): 0.17320215702056885\n",
      "Full accuracy (w/o dLoRA+LC): 0.9295, LC accuracy: 0.9293, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8731, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.873\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader61/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader61/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3638823926448822\n",
      "LC Training Loss (Full): 0.21980169415473938\n",
      "End of model training on train_loader61...\n",
      "Model saved at accuracy: 0.8731\n",
      "--------------------------\n",
      "Beginning of model training on train_loader62...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6680851578712463\n",
      "LC Training Loss (Full): 0.37289488315582275\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6375264525413513\n",
      "LC Training Loss (Full): 0.3243890702724457\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.43410518765449524\n",
      "LC Training Loss (Full): 0.16660279035568237\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.33557984232902527\n",
      "LC Training Loss (Full): 0.15409407019615173\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.564764678478241\n",
      "LC Training Loss (Full): 0.34712567925453186\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.38547924160957336\n",
      "LC Training Loss (Full): 0.2358805239200592\n",
      "Full accuracy (w/o dLoRA+LC): 0.9301, LC accuracy: 0.9286, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8646, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8724\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4781409800052643\n",
      "LC Training Loss (Full): 0.2608111500740051\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5177357196807861\n",
      "LC Training Loss (Full): 0.3103393316268921\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4223243296146393\n",
      "LC Training Loss (Full): 0.23665598034858704\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.49235180020332336\n",
      "LC Training Loss (Full): 0.31374919414520264\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3838476240634918\n",
      "LC Training Loss (Full): 0.19037871062755585\n",
      "Full accuracy (w/o dLoRA+LC): 0.9319, LC accuracy: 0.9321, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8667, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.865\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.34088224172592163\n",
      "LC Training Loss (Full): 0.1929134875535965\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.45638081431388855\n",
      "LC Training Loss (Full): 0.19891135394573212\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.96875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7563697695732117\n",
      "LC Training Loss (Full): 0.42996272444725037\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5190997123718262\n",
      "LC Training Loss (Full): 0.35611140727996826\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5368698239326477\n",
      "LC Training Loss (Full): 0.3998745083808899\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39889124035835266\n",
      "LC Training Loss (Full): 0.1699492484331131\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.26927658915519714\n",
      "LC Training Loss (Full): 0.16885577142238617\n",
      "Full accuracy (w/o dLoRA+LC): 0.9321, LC accuracy: 0.9311, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8735, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.867\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4248897135257721\n",
      "LC Training Loss (Full): 0.23643392324447632\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3315197825431824\n",
      "LC Training Loss (Full): 0.1690993756055832\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3736512362957001\n",
      "LC Training Loss (Full): 0.1898634433746338\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.285809189081192\n",
      "LC Training Loss (Full): 0.16651317477226257\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4884912967681885\n",
      "LC Training Loss (Full): 0.24375678598880768\n",
      "Full accuracy (w/o dLoRA+LC): 0.931, LC accuracy: 0.9318, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8699, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8683\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader62/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader62/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.405444860458374\n",
      "LC Training Loss (Full): 0.2530938684940338\n",
      "End of model training on train_loader62...\n",
      "Model saved at accuracy: 0.8699\n",
      "--------------------------\n",
      "Beginning of model training on train_loader63...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.45904719829559326\n",
      "LC Training Loss (Full): 0.34617096185684204\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4508640766143799\n",
      "LC Training Loss (Full): 0.25724512338638306\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3518967628479004\n",
      "LC Training Loss (Full): 0.24628199636936188\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.30650749802589417\n",
      "LC Training Loss (Full): 0.11251240223646164\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.395573228597641\n",
      "LC Training Loss (Full): 0.22436685860157013\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3614158630371094\n",
      "LC Training Loss (Full): 0.2268742471933365\n",
      "Full accuracy (w/o dLoRA+LC): 0.933, LC accuracy: 0.9322, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8412, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8766\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3520474135875702\n",
      "LC Training Loss (Full): 0.11756496131420135\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37956318259239197\n",
      "LC Training Loss (Full): 0.20365461707115173\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5293946266174316\n",
      "LC Training Loss (Full): 0.2854175269603729\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48885855078697205\n",
      "LC Training Loss (Full): 0.35514384508132935\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48041489720344543\n",
      "LC Training Loss (Full): 0.2920299470424652\n",
      "Full accuracy (w/o dLoRA+LC): 0.9323, LC accuracy: 0.9328, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8697, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8693\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5238394141197205\n",
      "LC Training Loss (Full): 0.2683280408382416\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3602089583873749\n",
      "LC Training Loss (Full): 0.2512500286102295\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4472728967666626\n",
      "LC Training Loss (Full): 0.2526370584964752\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5069781541824341\n",
      "LC Training Loss (Full): 0.25274214148521423\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3190418481826782\n",
      "LC Training Loss (Full): 0.14570993185043335\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4118502736091614\n",
      "LC Training Loss (Full): 0.230352982878685\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5017109513282776\n",
      "LC Training Loss (Full): 0.31900516152381897\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.932, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8761, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8715\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4873214364051819\n",
      "LC Training Loss (Full): 0.26101991534233093\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3690805733203888\n",
      "LC Training Loss (Full): 0.22072933614253998\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4100690484046936\n",
      "LC Training Loss (Full): 0.23587197065353394\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35475093126296997\n",
      "LC Training Loss (Full): 0.22671747207641602\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.35834258794784546\n",
      "LC Training Loss (Full): 0.17302080988883972\n",
      "Full accuracy (w/o dLoRA+LC): 0.9328, LC accuracy: 0.9329, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8717, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8719\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader63/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader63/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.28597739338874817\n",
      "LC Training Loss (Full): 0.14973999559879303\n",
      "End of model training on train_loader63...\n",
      "Model saved at accuracy: 0.8717\n",
      "--------------------------\n",
      "Beginning of model training on train_loader64...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.43822380900382996\n",
      "LC Training Loss (Full): 0.2284640073776245\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5284742116928101\n",
      "LC Training Loss (Full): 0.28196093440055847\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.71596759557724\n",
      "LC Training Loss (Full): 0.34667158126831055\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7410379648208618\n",
      "LC Training Loss (Full): 0.3989063799381256\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5628892779350281\n",
      "LC Training Loss (Full): 0.3338233530521393\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4778519868850708\n",
      "LC Training Loss (Full): 0.296597421169281\n",
      "Full accuracy (w/o dLoRA+LC): 0.9333, LC accuracy: 0.9329, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8727, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8761\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.33500853180885315\n",
      "LC Training Loss (Full): 0.20151013135910034\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.35557612776756287\n",
      "LC Training Loss (Full): 0.2217211276292801\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3859077990055084\n",
      "LC Training Loss (Full): 0.18035179376602173\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5726941823959351\n",
      "LC Training Loss (Full): 0.32444560527801514\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3988877534866333\n",
      "LC Training Loss (Full): 0.16693460941314697\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.9334, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8753, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8746\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.42861536145210266\n",
      "LC Training Loss (Full): 0.17891448736190796\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5368334650993347\n",
      "LC Training Loss (Full): 0.35791829228401184\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4237753450870514\n",
      "LC Training Loss (Full): 0.22793033719062805\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.32248979806900024\n",
      "LC Training Loss (Full): 0.12128998339176178\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4250730872154236\n",
      "LC Training Loss (Full): 0.2268751710653305\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.689415454864502\n",
      "LC Training Loss (Full): 0.3277019262313843\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4139900207519531\n",
      "LC Training Loss (Full): 0.2249128818511963\n",
      "Full accuracy (w/o dLoRA+LC): 0.9329, LC accuracy: 0.9332, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8781, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8753\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4616210162639618\n",
      "LC Training Loss (Full): 0.3053573668003082\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47763845324516296\n",
      "LC Training Loss (Full): 0.17112132906913757\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4447137117385864\n",
      "LC Training Loss (Full): 0.2240089774131775\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4897465109825134\n",
      "LC Training Loss (Full): 0.23133397102355957\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5820373892784119\n",
      "LC Training Loss (Full): 0.33052775263786316\n",
      "Full accuracy (w/o dLoRA+LC): 0.9332, LC accuracy: 0.9327, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8785, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8762\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader64/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader64/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.2949196696281433\n",
      "LC Training Loss (Full): 0.135410875082016\n",
      "End of model training on train_loader64...\n",
      "Model saved at accuracy: 0.8785\n",
      "--------------------------\n",
      "Beginning of model training on train_loader65...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5595194697380066\n",
      "LC Training Loss (Full): 0.3310762345790863\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45107513666152954\n",
      "LC Training Loss (Full): 0.2136879861354828\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3325611650943756\n",
      "LC Training Loss (Full): 0.18085749447345734\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4094099998474121\n",
      "LC Training Loss (Full): 0.13670538365840912\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.39960888028144836\n",
      "LC Training Loss (Full): 0.16983364522457123\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3096533715724945\n",
      "LC Training Loss (Full): 0.13945886492729187\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.9327, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8084, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8761\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.22165626287460327\n",
      "LC Training Loss (Full): 0.07875727862119675\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4175717234611511\n",
      "LC Training Loss (Full): 0.26648399233818054\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3910117447376251\n",
      "LC Training Loss (Full): 0.1877041608095169\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3629622459411621\n",
      "LC Training Loss (Full): 0.28829094767570496\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.44190308451652527\n",
      "LC Training Loss (Full): 0.26566407084465027\n",
      "Full accuracy (w/o dLoRA+LC): 0.9338, LC accuracy: 0.9336, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8791, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8792\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3770569860935211\n",
      "LC Training Loss (Full): 0.12519554793834686\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.2737055718898773\n",
      "LC Training Loss (Full): 0.14909134805202484\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.953125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.381204754114151\n",
      "LC Training Loss (Full): 0.17683301866054535\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3654462695121765\n",
      "LC Training Loss (Full): 0.17782528698444366\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3825628459453583\n",
      "LC Training Loss (Full): 0.24840588867664337\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2289716899394989\n",
      "LC Training Loss (Full): 0.10262423753738403\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.34887945652008057\n",
      "LC Training Loss (Full): 0.2282952219247818\n",
      "Full accuracy (w/o dLoRA+LC): 0.9327, LC accuracy: 0.9327, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8797, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.879\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.42177170515060425\n",
      "LC Training Loss (Full): 0.22850754857063293\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.41359904408454895\n",
      "LC Training Loss (Full): 0.25895369052886963\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.37136387825012207\n",
      "LC Training Loss (Full): 0.20278827846050262\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.28752607107162476\n",
      "LC Training Loss (Full): 0.13042719662189484\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.33118242025375366\n",
      "LC Training Loss (Full): 0.16004396975040436\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.9329, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8791, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8785\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader65/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader65/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5033835172653198\n",
      "LC Training Loss (Full): 0.2846086621284485\n",
      "End of model training on train_loader65...\n",
      "Model saved at accuracy: 0.8791\n",
      "--------------------------\n",
      "Beginning of model training on train_loader66...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.39016586542129517\n",
      "LC Training Loss (Full): 0.24276745319366455\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6554980874061584\n",
      "LC Training Loss (Full): 0.3863542675971985\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6562517285346985\n",
      "LC Training Loss (Full): 0.25516247749328613\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6971012353897095\n",
      "LC Training Loss (Full): 0.4436017572879791\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.47105374932289124\n",
      "LC Training Loss (Full): 0.3419859707355499\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6046283841133118\n",
      "LC Training Loss (Full): 0.25443950295448303\n",
      "Full accuracy (w/o dLoRA+LC): 0.9318, LC accuracy: 0.9324, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7766, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8572\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6727411150932312\n",
      "LC Training Loss (Full): 0.23001787066459656\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48958635330200195\n",
      "LC Training Loss (Full): 0.3171156346797943\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5363888144493103\n",
      "LC Training Loss (Full): 0.29723024368286133\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5238128900527954\n",
      "LC Training Loss (Full): 0.27611684799194336\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6293644905090332\n",
      "LC Training Loss (Full): 0.4242502748966217\n",
      "Full accuracy (w/o dLoRA+LC): 0.9326, LC accuracy: 0.932, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8767, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8775\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.36943313479423523\n",
      "LC Training Loss (Full): 0.1553288847208023\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5019378662109375\n",
      "LC Training Loss (Full): 0.34001708030700684\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4509740173816681\n",
      "LC Training Loss (Full): 0.2803778052330017\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4868588149547577\n",
      "LC Training Loss (Full): 0.2657025456428528\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6474935412406921\n",
      "LC Training Loss (Full): 0.3289583623409271\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4702950716018677\n",
      "LC Training Loss (Full): 0.20892834663391113\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6366631984710693\n",
      "LC Training Loss (Full): 0.3484349846839905\n",
      "Full accuracy (w/o dLoRA+LC): 0.932, LC accuracy: 0.9326, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8798, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8777\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.34606608748435974\n",
      "LC Training Loss (Full): 0.1406865417957306\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.570892870426178\n",
      "LC Training Loss (Full): 0.2987276017665863\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.531930685043335\n",
      "LC Training Loss (Full): 0.3481454849243164\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4525161683559418\n",
      "LC Training Loss (Full): 0.23940379917621613\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5388414263725281\n",
      "LC Training Loss (Full): 0.29927772283554077\n",
      "Full accuracy (w/o dLoRA+LC): 0.9326, LC accuracy: 0.932, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8784, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8786\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader66/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader66/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4681360721588135\n",
      "LC Training Loss (Full): 0.2852599322795868\n",
      "End of model training on train_loader66...\n",
      "Model saved at accuracy: 0.8784\n",
      "--------------------------\n",
      "Beginning of model training on train_loader67...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5673774480819702\n",
      "LC Training Loss (Full): 0.3612675666809082\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4277265965938568\n",
      "LC Training Loss (Full): 0.23060722649097443\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7013258934020996\n",
      "LC Training Loss (Full): 0.46320709586143494\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5852066874504089\n",
      "LC Training Loss (Full): 0.18870049715042114\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7605287432670593\n",
      "LC Training Loss (Full): 0.5066739320755005\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.49557411670684814\n",
      "LC Training Loss (Full): 0.15387344360351562\n",
      "Full accuracy (w/o dLoRA+LC): 0.9332, LC accuracy: 0.9325, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8383, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8765\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3447120487689972\n",
      "LC Training Loss (Full): 0.08725351095199585\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4505768418312073\n",
      "LC Training Loss (Full): 0.3388236165046692\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3152000904083252\n",
      "LC Training Loss (Full): 0.11803695559501648\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6308691501617432\n",
      "LC Training Loss (Full): 0.3367164433002472\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6775237321853638\n",
      "LC Training Loss (Full): 0.3822389841079712\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.9331, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8806, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8788\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5391051769256592\n",
      "LC Training Loss (Full): 0.2756061553955078\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.39765968918800354\n",
      "LC Training Loss (Full): 0.322102427482605\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.45284804701805115\n",
      "LC Training Loss (Full): 0.27692949771881104\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5962621569633484\n",
      "LC Training Loss (Full): 0.3060643970966339\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35805845260620117\n",
      "LC Training Loss (Full): 0.16329260170459747\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3871404826641083\n",
      "LC Training Loss (Full): 0.20818795263767242\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.34086474776268005\n",
      "LC Training Loss (Full): 0.17416244745254517\n",
      "Full accuracy (w/o dLoRA+LC): 0.9321, LC accuracy: 0.9324, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8805, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8809\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.42372748255729675\n",
      "LC Training Loss (Full): 0.2931694984436035\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4659290015697479\n",
      "LC Training Loss (Full): 0.2221035212278366\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.562234103679657\n",
      "LC Training Loss (Full): 0.356429785490036\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.32774969935417175\n",
      "LC Training Loss (Full): 0.20342329144477844\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5269157290458679\n",
      "LC Training Loss (Full): 0.3014126121997833\n",
      "Full accuracy (w/o dLoRA+LC): 0.9332, LC accuracy: 0.9334, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8806, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8802\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader67/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader67/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6496039032936096\n",
      "LC Training Loss (Full): 0.4215114116668701\n",
      "End of model training on train_loader67...\n",
      "Model saved at accuracy: 0.8806\n",
      "--------------------------\n",
      "Beginning of model training on train_loader68...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4193393886089325\n",
      "LC Training Loss (Full): 0.3023633360862732\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3242596685886383\n",
      "LC Training Loss (Full): 0.1850665807723999\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.309331476688385\n",
      "LC Training Loss (Full): 0.14814393222332\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.26426467299461365\n",
      "LC Training Loss (Full): 0.14951267838478088\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7550472021102905\n",
      "LC Training Loss (Full): 0.5300112962722778\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6447368860244751\n",
      "LC Training Loss (Full): 0.4101191759109497\n",
      "Full accuracy (w/o dLoRA+LC): 0.9335, LC accuracy: 0.9328, Decomposed-Full (w/dLoRA+LC) accuracy: 0.873, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8771\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4731482267379761\n",
      "LC Training Loss (Full): 0.2883051931858063\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4386729300022125\n",
      "LC Training Loss (Full): 0.20711660385131836\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3524321913719177\n",
      "LC Training Loss (Full): 0.1493154913187027\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.34740710258483887\n",
      "LC Training Loss (Full): 0.13577938079833984\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.390943706035614\n",
      "LC Training Loss (Full): 0.14841976761817932\n",
      "Full accuracy (w/o dLoRA+LC): 0.9333, LC accuracy: 0.9335, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8784, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8769\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6988662481307983\n",
      "LC Training Loss (Full): 0.39126065373420715\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4200640618801117\n",
      "LC Training Loss (Full): 0.25531134009361267\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3213014602661133\n",
      "LC Training Loss (Full): 0.1612367182970047\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3647747039794922\n",
      "LC Training Loss (Full): 0.12051338702440262\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.46442630887031555\n",
      "LC Training Loss (Full): 0.2600158751010895\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.31691136956214905\n",
      "LC Training Loss (Full): 0.1663179248571396\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4843454957008362\n",
      "LC Training Loss (Full): 0.2740257680416107\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.9344, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8769, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8772\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3875669538974762\n",
      "LC Training Loss (Full): 0.23790580034255981\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2990835905075073\n",
      "LC Training Loss (Full): 0.15355943143367767\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4544900059700012\n",
      "LC Training Loss (Full): 0.28989070653915405\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49547475576400757\n",
      "LC Training Loss (Full): 0.2862035632133484\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5259785652160645\n",
      "LC Training Loss (Full): 0.3000967800617218\n",
      "Full accuracy (w/o dLoRA+LC): 0.9347, LC accuracy: 0.9351, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8778, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.877\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader68/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader68/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6267764568328857\n",
      "LC Training Loss (Full): 0.360978901386261\n",
      "End of model training on train_loader68...\n",
      "Model saved at accuracy: 0.8778\n",
      "--------------------------\n",
      "Beginning of model training on train_loader69...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3604177236557007\n",
      "LC Training Loss (Full): 0.17731766402721405\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.33722636103630066\n",
      "LC Training Loss (Full): 0.16011406481266022\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48732078075408936\n",
      "LC Training Loss (Full): 0.28397345542907715\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3660285770893097\n",
      "LC Training Loss (Full): 0.16330063343048096\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.20334503054618835\n",
      "LC Training Loss (Full): 0.13854195177555084\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4699901342391968\n",
      "LC Training Loss (Full): 0.21927955746650696\n",
      "Full accuracy (w/o dLoRA+LC): 0.9349, LC accuracy: 0.9356, Decomposed-Full (w/dLoRA+LC) accuracy: 0.862, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8768\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5774446129798889\n",
      "LC Training Loss (Full): 0.3623906672000885\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48734575510025024\n",
      "LC Training Loss (Full): 0.23491935431957245\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.27326321601867676\n",
      "LC Training Loss (Full): 0.20249848067760468\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.22072429955005646\n",
      "LC Training Loss (Full): 0.0832514688372612\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5167528390884399\n",
      "LC Training Loss (Full): 0.20634056627750397\n",
      "Full accuracy (w/o dLoRA+LC): 0.9357, LC accuracy: 0.9356, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8802, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.879\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4640372395515442\n",
      "LC Training Loss (Full): 0.2916961908340454\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3337794542312622\n",
      "LC Training Loss (Full): 0.12116385251283646\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.984375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4246280789375305\n",
      "LC Training Loss (Full): 0.2747611105442047\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.29177162051200867\n",
      "LC Training Loss (Full): 0.13094168901443481\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3152104318141937\n",
      "LC Training Loss (Full): 0.13398689031600952\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5126773118972778\n",
      "LC Training Loss (Full): 0.24824194610118866\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.26122668385505676\n",
      "LC Training Loss (Full): 0.0805172473192215\n",
      "Full accuracy (w/o dLoRA+LC): 0.9357, LC accuracy: 0.9357, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8805, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8801\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5653122663497925\n",
      "LC Training Loss (Full): 0.26230373978614807\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3471989035606384\n",
      "LC Training Loss (Full): 0.1509634256362915\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.31514251232147217\n",
      "LC Training Loss (Full): 0.19358691573143005\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5341558456420898\n",
      "LC Training Loss (Full): 0.3635590374469757\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4729452431201935\n",
      "LC Training Loss (Full): 0.22124387323856354\n",
      "Full accuracy (w/o dLoRA+LC): 0.9349, LC accuracy: 0.9354, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8804, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8801\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader69/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader69/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3054829239845276\n",
      "LC Training Loss (Full): 0.13536638021469116\n",
      "End of model training on train_loader69...\n",
      "Model saved at accuracy: 0.8804\n",
      "--------------------------\n",
      "Beginning of model training on train_loader70...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5653904676437378\n",
      "LC Training Loss (Full): 0.32108569145202637\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5524775385856628\n",
      "LC Training Loss (Full): 0.22570465505123138\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4342236816883087\n",
      "LC Training Loss (Full): 0.09112968295812607\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37291207909584045\n",
      "LC Training Loss (Full): 0.14866934716701508\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5372743606567383\n",
      "LC Training Loss (Full): 0.32166585326194763\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.36884763836860657\n",
      "LC Training Loss (Full): 0.2645992338657379\n",
      "Full accuracy (w/o dLoRA+LC): 0.937, LC accuracy: 0.9355, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8619, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8707\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5917649269104004\n",
      "LC Training Loss (Full): 0.20905646681785583\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3573150336742401\n",
      "LC Training Loss (Full): 0.1941203773021698\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5510334372520447\n",
      "LC Training Loss (Full): 0.34965717792510986\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.477377325296402\n",
      "LC Training Loss (Full): 0.22558096051216125\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6230831146240234\n",
      "LC Training Loss (Full): 0.37842848896980286\n",
      "Full accuracy (w/o dLoRA+LC): 0.9365, LC accuracy: 0.9364, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8792, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8777\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.41331133246421814\n",
      "LC Training Loss (Full): 0.15189428627490997\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.36559292674064636\n",
      "LC Training Loss (Full): 0.14410029351711273\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49997612833976746\n",
      "LC Training Loss (Full): 0.28332605957984924\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.36429351568222046\n",
      "LC Training Loss (Full): 0.17626997828483582\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5526355504989624\n",
      "LC Training Loss (Full): 0.23870526254177094\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2792964279651642\n",
      "LC Training Loss (Full): 0.18121162056922913\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8005251288414001\n",
      "LC Training Loss (Full): 0.48124071955680847\n",
      "Full accuracy (w/o dLoRA+LC): 0.9355, LC accuracy: 0.9358, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8823, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8801\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4845920205116272\n",
      "LC Training Loss (Full): 0.16111847758293152\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.22136837244033813\n",
      "LC Training Loss (Full): 0.09769507497549057\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49631500244140625\n",
      "LC Training Loss (Full): 0.19020164012908936\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4007641077041626\n",
      "LC Training Loss (Full): 0.19725798070430756\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4636148512363434\n",
      "LC Training Loss (Full): 0.301298588514328\n",
      "Full accuracy (w/o dLoRA+LC): 0.9347, LC accuracy: 0.9351, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8801, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8808\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader70/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader70/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.36248332262039185\n",
      "LC Training Loss (Full): 0.2455524504184723\n",
      "End of model training on train_loader70...\n",
      "Model saved at accuracy: 0.8801\n",
      "--------------------------\n",
      "Beginning of model training on train_loader71...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4212779104709625\n",
      "LC Training Loss (Full): 0.27910903096199036\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5053442120552063\n",
      "LC Training Loss (Full): 0.232888862490654\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4065608084201813\n",
      "LC Training Loss (Full): 0.2458886057138443\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5708969831466675\n",
      "LC Training Loss (Full): 0.2914809286594391\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6720600724220276\n",
      "LC Training Loss (Full): 0.28352001309394836\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.554827094078064\n",
      "LC Training Loss (Full): 0.22557877004146576\n",
      "Full accuracy (w/o dLoRA+LC): 0.9353, LC accuracy: 0.9338, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8665, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8782\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.40621045231819153\n",
      "LC Training Loss (Full): 0.24060900509357452\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.35396379232406616\n",
      "LC Training Loss (Full): 0.21704867482185364\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5011351704597473\n",
      "LC Training Loss (Full): 0.21952585875988007\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5352993011474609\n",
      "LC Training Loss (Full): 0.33826377987861633\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5303764343261719\n",
      "LC Training Loss (Full): 0.27971789240837097\n",
      "Full accuracy (w/o dLoRA+LC): 0.936, LC accuracy: 0.9358, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8818, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8803\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.606049656867981\n",
      "LC Training Loss (Full): 0.39902573823928833\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.46600285172462463\n",
      "LC Training Loss (Full): 0.26527315378189087\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4157681465148926\n",
      "LC Training Loss (Full): 0.26265615224838257\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4910534918308258\n",
      "LC Training Loss (Full): 0.270816445350647\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.458752304315567\n",
      "LC Training Loss (Full): 0.20072419941425323\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.610387921333313\n",
      "LC Training Loss (Full): 0.29287049174308777\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4483400583267212\n",
      "LC Training Loss (Full): 0.1980886459350586\n",
      "Full accuracy (w/o dLoRA+LC): 0.9349, LC accuracy: 0.935, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8819, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8802\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4329022169113159\n",
      "LC Training Loss (Full): 0.28702422976493835\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2906572222709656\n",
      "LC Training Loss (Full): 0.11469043046236038\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.610756516456604\n",
      "LC Training Loss (Full): 0.3925502598285675\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.33469048142433167\n",
      "LC Training Loss (Full): 0.20186738669872284\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5551604628562927\n",
      "LC Training Loss (Full): 0.3562755882740021\n",
      "Full accuracy (w/o dLoRA+LC): 0.9352, LC accuracy: 0.935, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8805, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8812\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader71/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader71/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3659633994102478\n",
      "LC Training Loss (Full): 0.16805139183998108\n",
      "End of model training on train_loader71...\n",
      "Model saved at accuracy: 0.8805\n",
      "--------------------------\n",
      "Beginning of model training on train_loader72...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.42346876859664917\n",
      "LC Training Loss (Full): 0.19896389544010162\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4119700789451599\n",
      "LC Training Loss (Full): 0.28436577320098877\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4398539960384369\n",
      "LC Training Loss (Full): 0.15361416339874268\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5198118686676025\n",
      "LC Training Loss (Full): 0.30642059445381165\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4428485333919525\n",
      "LC Training Loss (Full): 0.18786998093128204\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5471105575561523\n",
      "LC Training Loss (Full): 0.2759351432323456\n",
      "Full accuracy (w/o dLoRA+LC): 0.9362, LC accuracy: 0.9351, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8194, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8741\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45883709192276\n",
      "LC Training Loss (Full): 0.3435101807117462\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7137430906295776\n",
      "LC Training Loss (Full): 0.4394236207008362\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.28478020429611206\n",
      "LC Training Loss (Full): 0.21046824753284454\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.49441590905189514\n",
      "LC Training Loss (Full): 0.379180371761322\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5694928169250488\n",
      "LC Training Loss (Full): 0.3322658836841583\n",
      "Full accuracy (w/o dLoRA+LC): 0.9362, LC accuracy: 0.9368, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8753, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8736\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.3084760010242462\n",
      "LC Training Loss (Full): 0.17181581258773804\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5997546315193176\n",
      "LC Training Loss (Full): 0.3125626742839813\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.859375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3760499358177185\n",
      "LC Training Loss (Full): 0.1538006067276001\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4122066795825958\n",
      "LC Training Loss (Full): 0.2583349943161011\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.21429359912872314\n",
      "LC Training Loss (Full): 0.14745408296585083\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4056221842765808\n",
      "LC Training Loss (Full): 0.25351035594940186\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.32697898149490356\n",
      "LC Training Loss (Full): 0.16170945763587952\n",
      "Full accuracy (w/o dLoRA+LC): 0.9368, LC accuracy: 0.9364, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8774, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8776\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3575124144554138\n",
      "LC Training Loss (Full): 0.20242013037204742\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.579465389251709\n",
      "LC Training Loss (Full): 0.47875943779945374\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5973824262619019\n",
      "LC Training Loss (Full): 0.5106661319732666\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.34746623039245605\n",
      "LC Training Loss (Full): 0.1507118195295334\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5402780771255493\n",
      "LC Training Loss (Full): 0.2612188160419464\n",
      "Full accuracy (w/o dLoRA+LC): 0.9359, LC accuracy: 0.9359, Decomposed-Full (w/dLoRA+LC) accuracy: 0.878, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8785\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader72/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader72/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.35733696818351746\n",
      "LC Training Loss (Full): 0.16980300843715668\n",
      "End of model training on train_loader72...\n",
      "Model saved at accuracy: 0.8780\n",
      "--------------------------\n",
      "Beginning of model training on train_loader73...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.38092637062072754\n",
      "LC Training Loss (Full): 0.22601181268692017\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.90625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37718817591667175\n",
      "LC Training Loss (Full): 0.1587401181459427\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6032976508140564\n",
      "LC Training Loss (Full): 0.11572969704866409\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.4108126163482666\n",
      "LC Training Loss (Full): 0.3302607536315918\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7397464513778687\n",
      "LC Training Loss (Full): 0.15094757080078125\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6619886159896851\n",
      "LC Training Loss (Full): 0.19322499632835388\n",
      "Full accuracy (w/o dLoRA+LC): 0.9376, LC accuracy: 0.9366, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8138, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8639\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5049572587013245\n",
      "LC Training Loss (Full): 0.2228083312511444\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.43410855531692505\n",
      "LC Training Loss (Full): 0.130487322807312\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5402409434318542\n",
      "LC Training Loss (Full): 0.24605944752693176\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3140464425086975\n",
      "LC Training Loss (Full): 0.09892410784959793\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3249955475330353\n",
      "LC Training Loss (Full): 0.11328786611557007\n",
      "Full accuracy (w/o dLoRA+LC): 0.9367, LC accuracy: 0.9367, Decomposed-Full (w/dLoRA+LC) accuracy: 0.88, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8794\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.24927930533885956\n",
      "LC Training Loss (Full): 0.12150955200195312\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.368561714887619\n",
      "LC Training Loss (Full): 0.16514229774475098\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.953125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.469618022441864\n",
      "LC Training Loss (Full): 0.22710451483726501\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2618199288845062\n",
      "LC Training Loss (Full): 0.11616583913564682\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3630777597427368\n",
      "LC Training Loss (Full): 0.19048550724983215\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5021803975105286\n",
      "LC Training Loss (Full): 0.2767222225666046\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.48825064301490784\n",
      "LC Training Loss (Full): 0.21849747002124786\n",
      "Full accuracy (w/o dLoRA+LC): 0.9363, LC accuracy: 0.9369, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8826, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8808\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.24055038392543793\n",
      "LC Training Loss (Full): 0.09113174676895142\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.24900278449058533\n",
      "LC Training Loss (Full): 0.1270693987607956\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3152617812156677\n",
      "LC Training Loss (Full): 0.13711661100387573\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3164411187171936\n",
      "LC Training Loss (Full): 0.09514915943145752\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.2593778371810913\n",
      "LC Training Loss (Full): 0.10556671023368835\n",
      "Full accuracy (w/o dLoRA+LC): 0.9364, LC accuracy: 0.9362, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8808, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8806\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader73/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader73/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.43247848749160767\n",
      "LC Training Loss (Full): 0.23652538657188416\n",
      "End of model training on train_loader73...\n",
      "Model saved at accuracy: 0.8808\n",
      "--------------------------\n",
      "Beginning of model training on train_loader74...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.541430652141571\n",
      "LC Training Loss (Full): 0.3136582374572754\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3146205246448517\n",
      "LC Training Loss (Full): 0.10626742243766785\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2461012601852417\n",
      "LC Training Loss (Full): 0.11983247101306915\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5542897582054138\n",
      "LC Training Loss (Full): 0.3184634745121002\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4684063792228699\n",
      "LC Training Loss (Full): 0.19990409910678864\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3715273141860962\n",
      "LC Training Loss (Full): 0.11512434482574463\n",
      "Full accuracy (w/o dLoRA+LC): 0.9381, LC accuracy: 0.9363, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8641, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8812\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4863654375076294\n",
      "LC Training Loss (Full): 0.26215991377830505\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4065324664115906\n",
      "LC Training Loss (Full): 0.2595760226249695\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5067020058631897\n",
      "LC Training Loss (Full): 0.25600412487983704\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.560384213924408\n",
      "LC Training Loss (Full): 0.27334102988243103\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.28633952140808105\n",
      "LC Training Loss (Full): 0.14877596497535706\n",
      "Full accuracy (w/o dLoRA+LC): 0.9374, LC accuracy: 0.9374, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8808, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8809\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5811628103256226\n",
      "LC Training Loss (Full): 0.3771905303001404\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5392414331436157\n",
      "LC Training Loss (Full): 0.31901124119758606\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.921875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.31675681471824646\n",
      "LC Training Loss (Full): 0.17775511741638184\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3400338888168335\n",
      "LC Training Loss (Full): 0.20817501842975616\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3146878778934479\n",
      "LC Training Loss (Full): 0.20393089950084686\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6960231065750122\n",
      "LC Training Loss (Full): 0.39620181918144226\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.37075695395469666\n",
      "LC Training Loss (Full): 0.18562553822994232\n",
      "Full accuracy (w/o dLoRA+LC): 0.9368, LC accuracy: 0.9378, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8814, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8805\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3630973994731903\n",
      "LC Training Loss (Full): 0.20015957951545715\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35393571853637695\n",
      "LC Training Loss (Full): 0.1662006974220276\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.27308884263038635\n",
      "LC Training Loss (Full): 0.1100623682141304\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2755918502807617\n",
      "LC Training Loss (Full): 0.0995953306555748\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5141172409057617\n",
      "LC Training Loss (Full): 0.2951752841472626\n",
      "Full accuracy (w/o dLoRA+LC): 0.9357, LC accuracy: 0.9363, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8805, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8815\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader74/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader74/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.2770361006259918\n",
      "LC Training Loss (Full): 0.13527892529964447\n",
      "End of model training on train_loader74...\n",
      "Model saved at accuracy: 0.8805\n",
      "--------------------------\n",
      "Beginning of model training on train_loader75...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.41789430379867554\n",
      "LC Training Loss (Full): 0.2248610109090805\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2862338721752167\n",
      "LC Training Loss (Full): 0.14337138831615448\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3301483392715454\n",
      "LC Training Loss (Full): 0.19835889339447021\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.23754042387008667\n",
      "LC Training Loss (Full): 0.14470697939395905\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.47198745608329773\n",
      "LC Training Loss (Full): 0.2802368700504303\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.40288376808166504\n",
      "LC Training Loss (Full): 0.2035612314939499\n",
      "Full accuracy (w/o dLoRA+LC): 0.9372, LC accuracy: 0.9357, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8641, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8802\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3993167579174042\n",
      "LC Training Loss (Full): 0.1855126917362213\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3390226662158966\n",
      "LC Training Loss (Full): 0.15238481760025024\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.27814337611198425\n",
      "LC Training Loss (Full): 0.08683925122022629\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2560076117515564\n",
      "LC Training Loss (Full): 0.1864922046661377\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.36308130621910095\n",
      "LC Training Loss (Full): 0.237433522939682\n",
      "Full accuracy (w/o dLoRA+LC): 0.9373, LC accuracy: 0.9374, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8811, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.881\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.2858419120311737\n",
      "LC Training Loss (Full): 0.0830317810177803\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3139718770980835\n",
      "LC Training Loss (Full): 0.1176726296544075\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.984375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3750222623348236\n",
      "LC Training Loss (Full): 0.22298793494701385\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.17754627764225006\n",
      "LC Training Loss (Full): 0.05355425179004669\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3386559784412384\n",
      "LC Training Loss (Full): 0.23697331547737122\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.23062291741371155\n",
      "LC Training Loss (Full): 0.062150947749614716\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3562508821487427\n",
      "LC Training Loss (Full): 0.23395763337612152\n",
      "Full accuracy (w/o dLoRA+LC): 0.9372, LC accuracy: 0.9374, Decomposed-Full (w/dLoRA+LC) accuracy: 0.882, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8811\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5501179695129395\n",
      "LC Training Loss (Full): 0.3323265314102173\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.257606565952301\n",
      "LC Training Loss (Full): 0.12559498846530914\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3301660716533661\n",
      "LC Training Loss (Full): 0.2120690494775772\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.36515891551971436\n",
      "LC Training Loss (Full): 0.1558913141489029\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.2656666040420532\n",
      "LC Training Loss (Full): 0.12881627678871155\n",
      "Full accuracy (w/o dLoRA+LC): 0.9369, LC accuracy: 0.9367, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8822, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8814\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader75/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader75/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.37829673290252686\n",
      "LC Training Loss (Full): 0.12475181370973587\n",
      "End of model training on train_loader75...\n",
      "Model saved at accuracy: 0.8822\n",
      "--------------------------\n",
      "Beginning of model training on train_loader76...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.34606286883354187\n",
      "LC Training Loss (Full): 0.15226371586322784\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3539855182170868\n",
      "LC Training Loss (Full): 0.21030165255069733\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.48805418610572815\n",
      "LC Training Loss (Full): 0.2469632923603058\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.647975504398346\n",
      "LC Training Loss (Full): 0.29806452989578247\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5770962834358215\n",
      "LC Training Loss (Full): 0.15089401602745056\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5953865051269531\n",
      "LC Training Loss (Full): 0.2606406807899475\n",
      "Full accuracy (w/o dLoRA+LC): 0.9387, LC accuracy: 0.9375, Decomposed-Full (w/dLoRA+LC) accuracy: 0.871, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8794\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3432294726371765\n",
      "LC Training Loss (Full): 0.15656019747257233\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5216714143753052\n",
      "LC Training Loss (Full): 0.24704194068908691\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.477441668510437\n",
      "LC Training Loss (Full): 0.20573101937770844\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.40868523716926575\n",
      "LC Training Loss (Full): 0.15775926411151886\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.43353426456451416\n",
      "LC Training Loss (Full): 0.26000362634658813\n",
      "Full accuracy (w/o dLoRA+LC): 0.9383, LC accuracy: 0.9388, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8811, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8801\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.24232913553714752\n",
      "LC Training Loss (Full): 0.1138262078166008\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5718000531196594\n",
      "LC Training Loss (Full): 0.3187340497970581\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.90625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.39954158663749695\n",
      "LC Training Loss (Full): 0.18988554179668427\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5538632273674011\n",
      "LC Training Loss (Full): 0.33779099583625793\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.22783638536930084\n",
      "LC Training Loss (Full): 0.0837073102593422\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2838183045387268\n",
      "LC Training Loss (Full): 0.1673792600631714\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.3463289439678192\n",
      "LC Training Loss (Full): 0.15171512961387634\n",
      "Full accuracy (w/o dLoRA+LC): 0.9382, LC accuracy: 0.9379, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8818, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8806\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.434510737657547\n",
      "LC Training Loss (Full): 0.22175908088684082\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2992076575756073\n",
      "LC Training Loss (Full): 0.13286271691322327\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.33639881014823914\n",
      "LC Training Loss (Full): 0.16474971175193787\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.32086890935897827\n",
      "LC Training Loss (Full): 0.1675252765417099\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.38536494970321655\n",
      "LC Training Loss (Full): 0.1940334588289261\n",
      "Full accuracy (w/o dLoRA+LC): 0.9368, LC accuracy: 0.9364, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8807, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8818\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader76/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader76/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.40919384360313416\n",
      "LC Training Loss (Full): 0.18707028031349182\n",
      "End of model training on train_loader76...\n",
      "Model saved at accuracy: 0.8807\n",
      "--------------------------\n",
      "Beginning of model training on train_loader77...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4094453752040863\n",
      "LC Training Loss (Full): 0.22168724238872528\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.921875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4520852863788605\n",
      "LC Training Loss (Full): 0.20887337625026703\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5371648073196411\n",
      "LC Training Loss (Full): 0.19772198796272278\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.37508276104927063\n",
      "LC Training Loss (Full): 0.06907078623771667\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.29025211930274963\n",
      "LC Training Loss (Full): 0.1299450844526291\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.39444565773010254\n",
      "LC Training Loss (Full): 0.16522124409675598\n",
      "Full accuracy (w/o dLoRA+LC): 0.9373, LC accuracy: 0.9373, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8804, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8843\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3130311369895935\n",
      "LC Training Loss (Full): 0.14266584813594818\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5133564472198486\n",
      "LC Training Loss (Full): 0.2439189851284027\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4264046251773834\n",
      "LC Training Loss (Full): 0.23989331722259521\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.4493234157562256\n",
      "LC Training Loss (Full): 0.35457438230514526\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3388999402523041\n",
      "LC Training Loss (Full): 0.18013466894626617\n",
      "Full accuracy (w/o dLoRA+LC): 0.9376, LC accuracy: 0.9379, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8834, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8833\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.28864985704421997\n",
      "LC Training Loss (Full): 0.10017776489257812\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4168616831302643\n",
      "LC Training Loss (Full): 0.24474090337753296\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.890625\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4752344787120819\n",
      "LC Training Loss (Full): 0.28599607944488525\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.40979474782943726\n",
      "LC Training Loss (Full): 0.17188364267349243\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2634279131889343\n",
      "LC Training Loss (Full): 0.09879227727651596\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2736029624938965\n",
      "LC Training Loss (Full): 0.10690882802009583\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4107844829559326\n",
      "LC Training Loss (Full): 0.16506512463092804\n",
      "Full accuracy (w/o dLoRA+LC): 0.937, LC accuracy: 0.9375, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8854, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8836\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2919478118419647\n",
      "LC Training Loss (Full): 0.09997797012329102\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.30984506011009216\n",
      "LC Training Loss (Full): 0.1305312216281891\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.42811137437820435\n",
      "LC Training Loss (Full): 0.19011251628398895\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2348889708518982\n",
      "LC Training Loss (Full): 0.08719936013221741\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4114629328250885\n",
      "LC Training Loss (Full): 0.2591037452220917\n",
      "Full accuracy (w/o dLoRA+LC): 0.9373, LC accuracy: 0.9376, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8837, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8839\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader77/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader77/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.47764164209365845\n",
      "LC Training Loss (Full): 0.2994254529476166\n",
      "End of model training on train_loader77...\n",
      "Model saved at accuracy: 0.8837\n",
      "--------------------------\n",
      "Beginning of model training on train_loader78...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.2755117118358612\n",
      "LC Training Loss (Full): 0.12558303773403168\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.33952954411506653\n",
      "LC Training Loss (Full): 0.11416353285312653\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.23228809237480164\n",
      "LC Training Loss (Full): 0.0802791640162468\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2374442219734192\n",
      "LC Training Loss (Full): 0.07539036870002747\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.46083006262779236\n",
      "LC Training Loss (Full): 0.16360178589820862\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.17780087888240814\n",
      "LC Training Loss (Full): 0.04342678189277649\n",
      "Full accuracy (w/o dLoRA+LC): 0.9375, LC accuracy: 0.9375, Decomposed-Full (w/dLoRA+LC) accuracy: 0.885, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8824\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.18460190296173096\n",
      "LC Training Loss (Full): 0.14131811261177063\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3061728775501251\n",
      "LC Training Loss (Full): 0.15963663160800934\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.273293673992157\n",
      "LC Training Loss (Full): 0.12643957138061523\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.46174606680870056\n",
      "LC Training Loss (Full): 0.17896202206611633\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3686322569847107\n",
      "LC Training Loss (Full): 0.15163955092430115\n",
      "Full accuracy (w/o dLoRA+LC): 0.937, LC accuracy: 0.938, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8803, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8803\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5196076035499573\n",
      "LC Training Loss (Full): 0.22701479494571686\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.21775197982788086\n",
      "LC Training Loss (Full): 0.08276678621768951\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.984375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4222372770309448\n",
      "LC Training Loss (Full): 0.16769498586654663\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2017524093389511\n",
      "LC Training Loss (Full): 0.07379458099603653\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.33948856592178345\n",
      "LC Training Loss (Full): 0.17013174295425415\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.22045831382274628\n",
      "LC Training Loss (Full): 0.0712018832564354\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2803249955177307\n",
      "LC Training Loss (Full): 0.10213294625282288\n",
      "Full accuracy (w/o dLoRA+LC): 0.935, LC accuracy: 0.9369, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8833, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8831\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.25626838207244873\n",
      "LC Training Loss (Full): 0.09245128184556961\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.23121480643749237\n",
      "LC Training Loss (Full): 0.12462341040372849\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.34467872977256775\n",
      "LC Training Loss (Full): 0.1576234996318817\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2460019439458847\n",
      "LC Training Loss (Full): 0.0969306081533432\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.35489901900291443\n",
      "LC Training Loss (Full): 0.151805579662323\n",
      "Full accuracy (w/o dLoRA+LC): 0.9359, LC accuracy: 0.9357, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8833, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8829\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader78/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader78/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.3799402415752411\n",
      "LC Training Loss (Full): 0.1501752883195877\n",
      "End of model training on train_loader78...\n",
      "Model saved at accuracy: 0.8833\n",
      "--------------------------\n",
      "Beginning of model training on train_loader79...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3050385117530823\n",
      "LC Training Loss (Full): 0.1548667699098587\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.984375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.30492347478866577\n",
      "LC Training Loss (Full): 0.1137031689286232\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.31664714217185974\n",
      "LC Training Loss (Full): 0.11635471135377884\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.15194565057754517\n",
      "LC Training Loss (Full): 0.03719048947095871\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.23706063628196716\n",
      "LC Training Loss (Full): 0.15072835981845856\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.2718529999256134\n",
      "LC Training Loss (Full): 0.16249334812164307\n",
      "Full accuracy (w/o dLoRA+LC): 0.9379, LC accuracy: 0.9357, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8729, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8799\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.18473601341247559\n",
      "LC Training Loss (Full): 0.07507989555597305\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.12365259975194931\n",
      "LC Training Loss (Full): 0.04059456288814545\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.18476083874702454\n",
      "LC Training Loss (Full): 0.0903424471616745\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.10082394629716873\n",
      "LC Training Loss (Full): 0.03834841027855873\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.20664870738983154\n",
      "LC Training Loss (Full): 0.10459496825933456\n",
      "Full accuracy (w/o dLoRA+LC): 0.9383, LC accuracy: 0.9384, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8838, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.884\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.2388494312763214\n",
      "LC Training Loss (Full): 0.07362031191587448\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3195052742958069\n",
      "LC Training Loss (Full): 0.12606675922870636\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.96875\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.22676458954811096\n",
      "LC Training Loss (Full): 0.06150044873356819\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2030935138463974\n",
      "LC Training Loss (Full): 0.07088809460401535\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.23002664744853973\n",
      "LC Training Loss (Full): 0.07569252699613571\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.28956523537635803\n",
      "LC Training Loss (Full): 0.12657740712165833\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.1588074415922165\n",
      "LC Training Loss (Full): 0.055155642330646515\n",
      "Full accuracy (w/o dLoRA+LC): 0.9384, LC accuracy: 0.9386, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8839, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8839\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.26996591687202454\n",
      "LC Training Loss (Full): 0.1552036702632904\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.19173814356327057\n",
      "LC Training Loss (Full): 0.056855976581573486\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.19774138927459717\n",
      "LC Training Loss (Full): 0.08197394013404846\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.19969144463539124\n",
      "LC Training Loss (Full): 0.1405225545167923\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.16457971930503845\n",
      "LC Training Loss (Full): 0.04844599589705467\n",
      "Full accuracy (w/o dLoRA+LC): 0.9384, LC accuracy: 0.9384, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8842, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8836\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader79/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader79/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.19473712146282196\n",
      "LC Training Loss (Full): 0.04956866800785065\n",
      "End of model training on train_loader79...\n",
      "Model saved at accuracy: 0.8842\n",
      "--------------------------\n",
      "Beginning of model training on train_loader80...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.35808244347572327\n",
      "LC Training Loss (Full): 0.16666539013385773\n",
      "Training Accuracy | Decomposed: 0.890625, Full : 0.953125\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.35356560349464417\n",
      "LC Training Loss (Full): 0.2105705291032791\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.289700984954834\n",
      "LC Training Loss (Full): 0.19568613171577454\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.45510241389274597\n",
      "LC Training Loss (Full): 0.2262607216835022\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5419924259185791\n",
      "LC Training Loss (Full): 0.3087981343269348\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.38407015800476074\n",
      "LC Training Loss (Full): 0.14721356332302094\n",
      "Full accuracy (w/o dLoRA+LC): 0.9391, LC accuracy: 0.9379, Decomposed-Full (w/dLoRA+LC) accuracy: 0.816, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8694\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5527611374855042\n",
      "LC Training Loss (Full): 0.31976836919784546\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.32567140460014343\n",
      "LC Training Loss (Full): 0.23773261904716492\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3782970607280731\n",
      "LC Training Loss (Full): 0.23217448592185974\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.3864993155002594\n",
      "LC Training Loss (Full): 0.32448285818099976\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.2309902161359787\n",
      "LC Training Loss (Full): 0.14729361236095428\n",
      "Full accuracy (w/o dLoRA+LC): 0.9396, LC accuracy: 0.9393, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8814, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8813\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.18842455744743347\n",
      "LC Training Loss (Full): 0.08576072752475739\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.27913543581962585\n",
      "LC Training Loss (Full): 0.12570196390151978\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.953125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2884918451309204\n",
      "LC Training Loss (Full): 0.20797018706798553\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.323665976524353\n",
      "LC Training Loss (Full): 0.23448671400547028\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2613685727119446\n",
      "LC Training Loss (Full): 0.1841443032026291\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.47682327032089233\n",
      "LC Training Loss (Full): 0.2483816295862198\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.2003132402896881\n",
      "LC Training Loss (Full): 0.1055578887462616\n",
      "Full accuracy (w/o dLoRA+LC): 0.9396, LC accuracy: 0.9397, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8797, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8808\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.26407673954963684\n",
      "LC Training Loss (Full): 0.15246407687664032\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4226381480693817\n",
      "LC Training Loss (Full): 0.25126320123672485\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.49541541934013367\n",
      "LC Training Loss (Full): 0.34599608182907104\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.35429292917251587\n",
      "LC Training Loss (Full): 0.14398899674415588\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.3202851116657257\n",
      "LC Training Loss (Full): 0.1862545907497406\n",
      "Full accuracy (w/o dLoRA+LC): 0.9391, LC accuracy: 0.9385, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8801, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8807\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader80/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader80/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.4045768976211548\n",
      "LC Training Loss (Full): 0.18662989139556885\n",
      "End of model training on train_loader80...\n",
      "Model saved at accuracy: 0.8801\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-With-Incremental-Learning\", \n",
    "           tags=[\"LeNet\", \"With-Incremental-Learning\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"train dataset\": \"MNIST train dataset[:]\",\n",
    "                    \"test dataset\": \"MNIST test dataset[:]\",\n",
    "                    \"splitting\": \"80x1_25\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"learning_rate_dloralc\": learning_rate_dloralc,\n",
    "                    \"optimizer\": \"SGD\",\n",
    "                }\n",
    "           )\n",
    "\n",
    "train_loader_list = [train_loader1, train_loader2, train_loader3, train_loader4, train_loader5, train_loader6, train_loader7, train_loader8, train_loader9, train_loader10, train_loader11, train_loader12, train_loader13, train_loader14, train_loader15, train_loader16, train_loader17, train_loader18, train_loader19, train_loader20,\n",
    "                    train_loader21, train_loader22, train_loader23, train_loader24, train_loader25, train_loader26, train_loader27, train_loader28, train_loader29, train_loader30, train_loader31, train_loader32, train_loader33, train_loader34, train_loader35, train_loader36, train_loader37, train_loader38, train_loader39, train_loader40,\n",
    "                    train_loader41, train_loader42, train_loader43, train_loader44, train_loader45, train_loader46, train_loader47, train_loader48, train_loader49, train_loader50, train_loader51, train_loader52, train_loader53, train_loader54, train_loader55, train_loader56, train_loader57, train_loader58, train_loader59, train_loader60,\n",
    "                    train_loader61, train_loader62, train_loader63, train_loader64, train_loader65, train_loader66, train_loader67, train_loader68, train_loader69, train_loader70, train_loader71, train_loader72, train_loader73, train_loader74, train_loader75, train_loader76, train_loader77, train_loader78, train_loader79, train_loader80]\n",
    "\n",
    "for j in range(len(train_loader_list)):\n",
    "    train_loader_txt = \"train_loader{}\".format(j+1)\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Beginning of model training on {}...\".format(train_loader_txt))\n",
    "\n",
    "    full_accuracy_dloralc = 0\n",
    "    decomposed_full_accuracy_dloralc = 0\n",
    "    restored_accuracy_dloralc = 0\n",
    "    lc_accuracy_dloralc = 0\n",
    "\n",
    "    for epch in range(NUM_EPOCHES):\n",
    "        for i, data in enumerate(train_loader_list[j], 0):\n",
    "\n",
    "            SAVE_LOC_j = SAVE_LOC + \"/\"+train_loader_txt\n",
    "            if not os.path.exists(SAVE_LOC_j):\n",
    "                os.makedirs(SAVE_LOC_j)\n",
    "                \n",
    "            SAVE_LOC_OLC_j = SAVE_LOC_OLC + \"/\"+train_loader_txt\n",
    "            if not os.path.exists(SAVE_LOC_OLC_j):\n",
    "                os.makedirs(SAVE_LOC_OLC_j)\n",
    "            print(\"Epoch: {}, Iteration: {}\".format(epch, i))\n",
    "            \n",
    "            set_path = \"/set_{}\".format(current_set)\n",
    "            if not os.path.exists(SAVE_LOC_j + set_path):\n",
    "                os.makedirs(SAVE_LOC_j + set_path)\n",
    "\n",
    "            if i == 0 and epch == 0: # first iteration, create baseline model\n",
    "                base, base_decomp = lc.extract_weights_gpu(model, SAVE_LOC_j + \n",
    "                                                        \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "            else:\n",
    "                if i % 10 == 0: \n",
    "                    # full snapshot!\n",
    "                    new_model = lazy_restore_gpu(base, base_decomp, bias, LeNet(), \n",
    "                                            original.state_dict(), DECOMPOSED_LAYERS, rank = RANK, scaling = SCALING)\n",
    "                    original = new_model # Changing previous \"original model\" used to restore the loRA model.\n",
    "                    \n",
    "                    current_set += 1\n",
    "                    current_iter = 0\n",
    "\n",
    "                    set_path = \"/set_{}\".format(current_set)\n",
    "                    if not os.path.exists(SAVE_LOC_j + set_path):\n",
    "                        os.makedirs(SAVE_LOC_j + set_path)\n",
    "                    \n",
    "                    # Rebuilding LoRA layers => reset model!\n",
    "                    w, b = getBase(original)\n",
    "                    model = LeNet_LowRank(w, b, rank = RANK).to(device)\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "                    load_sd_decomp(original.state_dict(), model, DECOMPOSED_LAYERS)\n",
    "                    base, base_decomp = lc.extract_weights_gpu(model, SAVE_LOC_j + \n",
    "                                                        \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "\n",
    "                else:\n",
    "                    # Delta-compression\n",
    "                    delta, decomp_delta, bias = lc.generate_delta_gpu(base, \n",
    "                                                                    base_decomp, model.state_dict(), DECOMPOSED_LAYERS)\n",
    "                    compressed_delta, full_delta, compressed_dcomp_delta, full_dcomp_delta  = lc.compress_delta(delta, \n",
    "                                                                                                                decomp_delta)\n",
    "                    \n",
    "                    # Saving checkpoint\n",
    "                    lc.save_checkpoint(compressed_delta, compressed_dcomp_delta, bias, current_iter, SAVE_LOC_j + \n",
    "                                    \"/set_{}\".format(current_set))\n",
    "        \n",
    "                    base = np.add(base, full_delta) # Replace base with latest for delta to accumulate.\n",
    "                    base_decomp = np.add(full_dcomp_delta, base_decomp)\n",
    "\n",
    "                    current_iter += 1\n",
    "                \n",
    "            # ==========================\n",
    "            # Saving using LC-Checkpoint\n",
    "            # ==========================\n",
    "                    \n",
    "            if i == 0 and epch == 0:\n",
    "                cstate = model_original.state_dict()\n",
    "                set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                if not os.path.exists(SAVE_LOC_OLC_j + set_path):\n",
    "                    os.makedirs(SAVE_LOC_OLC_j + set_path)\n",
    "                torch.save(cstate, SAVE_LOC_OLC_j + set_path + \"/initial_model.pt\")\n",
    "                prev_state = olc.extract_weights_gpu(cstate, SAVE_LOC_OLC_j + set_path, DECOMPOSED_LAYERS)\n",
    "            else:\n",
    "                if i % 10 == 0:\n",
    "                    cstate = model_original.state_dict()\n",
    "                    current_set_old_lc += 1\n",
    "                    current_iter_old_lc = 0\n",
    "                    set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                    if not os.path.exists(SAVE_LOC_OLC_j + set_path):\n",
    "                        os.makedirs(SAVE_LOC_OLC_j + set_path)\n",
    "                    torch.save(cstate, SAVE_LOC_OLC_j + set_path + \"/initial_model.pt\")\n",
    "                    prev_state = olc.extract_weights_gpu(cstate, SAVE_LOC_OLC_j + set_path, DECOMPOSED_LAYERS)\n",
    "                else:\n",
    "                    cstate = model_original.state_dict()\n",
    "                    old_lc_delta, old_lc_bias = olc.generate_delta_gpu(prev_state, cstate, DECOMPOSED_LAYERS)\n",
    "                    olc_compressed_delta, update_prev = olc.compress_data(old_lc_delta, num_bits = 3)\n",
    "                    olc.save_checkpoint(SAVE_LOC_OLC_j + \"/set_{}\".format(current_set_old_lc), olc_compressed_delta, \n",
    "                                        old_lc_bias, current_iter_old_lc)\n",
    "                    prev_state = np.add(prev_state, update_prev)\n",
    "                    current_iter_old_lc += 1\n",
    "            \n",
    "            # ==========================\n",
    "            # Training on Low-Rank Model\n",
    "            # ==========================\n",
    "\n",
    "            # Get the inputs and labels\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs,labels)\n",
    "            loss.backward()\n",
    "            print(\"LoRA+LC Training Loss (Decomposed): {}\".format(loss.item()))\n",
    "            optimizer.step()\n",
    "                \n",
    "            # ======================\n",
    "            # Training on Full Model\n",
    "            # ======================\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer_lc_only.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs_full = model_original(inputs)\n",
    "            loss_full = torch.nn.functional.cross_entropy(outputs_full,labels)\n",
    "            loss_full.backward()\n",
    "            print(\"LC Training Loss (Full): {}\".format(loss_full.item()))\n",
    "            optimizer_lc_only.step()\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print(\"Training Accuracy | Decomposed: {}, Full : {}\".format(acc(outputs, labels), \n",
    "                                                                            acc(outputs_full, labels)))\n",
    "\n",
    "            if i != 0  and i % 5 == 0: # Evaluation on testing set\n",
    "                full_accuracy_dloralc = evaluate_accuracy_gpu(model_original, test_loader, device)\n",
    "                full_accuracy.append(full_accuracy_dloralc)\n",
    "\n",
    "                decomposed_full_accuracy_dloralc = evaluate_accuracy_gpu(model, test_loader, device)\n",
    "                decomposed_full_accuracy.append(decomposed_full_accuracy_dloralc)\n",
    "                \n",
    "                restored_model = lazy_restore_gpu(base, base_decomp, bias, LeNet(), \n",
    "                                            original.state_dict(), DECOMPOSED_LAYERS, \n",
    "                                            rank = RANK, scaling = SCALING)\n",
    "                restored_accuracy_dloralc_restored = evaluate_accuracy(restored_model, test_loader)\n",
    "                restored_accuracy.append(restored_accuracy_dloralc_restored)\n",
    "\n",
    "                restored_lc_model = LeNet().to(device)\n",
    "                restored_lc_model.load_state_dict(olc.restore_state_dict(prev_state, old_lc_bias, \n",
    "                                                                    restored_model.state_dict(), DECOMPOSED_LAYERS))\n",
    "                lc_accuracy_lc = evaluate_accuracy_gpu(restored_lc_model, test_loader, device)\n",
    "                lc_accuracy.append(lc_accuracy_lc)\n",
    "                print(\"Full accuracy (w/o dLoRA+LC): {}, LC accuracy: {}, Decomposed-Full (w/dLoRA+LC) accuracy: {}, Decomposed-Restored (w/dLoRA+LC restored) accuracy: {}\".format(\n",
    "                    full_accuracy[-1], lc_accuracy[-1], decomposed_full_accuracy[-1], restored_accuracy[-1]))\n",
    "                \n",
    "                wandb.log({\n",
    "                    \"accuracy w/o dLoRALC\": full_accuracy[-1],\n",
    "                    \"accuracy w/ LC\": lc_accuracy[-1],\n",
    "                    \"accuracy w/ dLoRALC\": decomposed_full_accuracy[-1],\n",
    "                    \"accuracy w/ dLoRALC after restoration\": restored_accuracy[-1]\n",
    "                })\n",
    "                \n",
    "\n",
    "    print(\"End of model training on {}...\".format(train_loader_txt))\n",
    "\n",
    "    rounded_valid_acc = decomposed_full_accuracy_dloralc\n",
    "    torch.save(model.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch/branch_{}.pt\".format(rounded_valid_acc))\n",
    "    print(\"Model saved at accuracy: {:.4f}\".format(rounded_valid_acc))\n",
    "\n",
    "    w, b = getBase(original)\n",
    "    model = LeNet_LowRank(w, b, rank = RANK).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch/branch_{}.pt\".format(rounded_valid_acc)))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate_dloralc)\n",
    "\n",
    "    # Initialize the current iteration and set to 0\n",
    "    current_iter = 0\n",
    "    current_set = 0\n",
    "\n",
    "    # Initialize the current iteration and set to 0 for the old LC method\n",
    "    current_iter_old_lc = 0\n",
    "    current_set_old_lc = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7af2d3d16d4200853c0a07712a2494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy w/ LC</td><td>▁▂▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>accuracy w/ dLoRALC</td><td>▁▃▃▄▅▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>accuracy w/ dLoRALC after restoration</td><td>▁▃▃▄▅▅▅▅▅▅▆▆▆▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>accuracy w/o dLoRALC</td><td>▁▂▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy w/ LC</td><td>0.9385</td></tr><tr><td>accuracy w/ dLoRALC</td><td>0.8801</td></tr><tr><td>accuracy w/ dLoRALC after restoration</td><td>0.8807</td></tr><tr><td>accuracy w/o dLoRALC</td><td>0.9391</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-With-Incremental-Learning</strong> at: <a href='https://wandb.ai/bryanbradfo/LeNet/runs/3r3zdh3w/workspace' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet/runs/3r3zdh3w/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240716_230346-3r3zdh3w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model_original.state_dict(), './model_original.pt')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC-Checkpoint + GZIP\n",
      "Compression Ratio: 565.071%, Space Savings: 82.303%\n",
      "LoRA + LC-Checkpoint + GZIP\n",
      "Compression Ratio: 2016.665%, Space Savings: 95.041%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def getsize(sl):\n",
    "    dir = [x for x in os.listdir(sl)]\n",
    "    csize, usize = 0, 0\n",
    "    for dataloader in dir:\n",
    "        for set in os.listdir(sl + \"/\" + dataloader):\n",
    "            # print(set)\n",
    "            for f in os.listdir(sl + \"/\" + dataloader + \"/\" + set):\n",
    "                # print(f)\n",
    "                fp = sl + \"/\" + dataloader + \"/{}/{}\".format(set, f)\n",
    "                csize += os.path.getsize(fp)\n",
    "                usize += 244.0 * math.pow(2, 10) # torch checkpoint same size\n",
    "    return csize, usize\n",
    "\n",
    "compressed_size, uncompressed_size = getsize(SAVE_LOC)\n",
    "a, b = evaluate_compression(uncompressed_size, compressed_size)\n",
    "compressed_size, uncompressed_size = getsize(SAVE_LOC_OLC)\n",
    "a1, b1 = evaluate_compression(uncompressed_size, compressed_size)\n",
    "\n",
    "print(\"LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a1, b1))\n",
    "print(\"LoRA + LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a, b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
