{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.main as lc\n",
    "import torch, os\n",
    "\n",
    "# Filepaths\n",
    "HHD = \"/volumes/Ultra Touch\"\n",
    "MLP_LOC = HHD + \"/MLP/LC_test\"\n",
    "COMPRESSED_SAVELOC = HHD + \"/MLP/Compressed\"\n",
    "DECOMPRESSED_SAVELOC = HHD + \"/MLP/Decompressed_test\"\n",
    "\n",
    "# Base dictionary (for decompressor to understand structure of the model)\n",
    "BASE_DICT = torch.load(MLP_LOC + \"/frame0.tar\", map_location = torch.device('cpu'))[\"network_fn_state_dict\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compression of MLP model set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /volumes/Ultra Touch/MLP/LC_test/frame0.tar\n",
      "Delta Compression on: frame1.tar\n",
      "Loading: /volumes/Ultra Touch/MLP/LC_test/frame1.tar\n",
      "Delta Compression on: frame2.tar\n",
      "Loading: /volumes/Ultra Touch/MLP/LC_test/frame2.tar\n",
      "Delta Compression on: frame3.tar\n",
      "Loading: /volumes/Ultra Touch/MLP/LC_test/frame3.tar\n",
      "Delta Compression on: frame4.tar\n",
      "Loading: /volumes/Ultra Touch/MLP/LC_test/frame4.tar\n",
      "Saving Compressed Format: frame0.tar\n",
      "Saving Compressed Format: frame1.tar\n",
      "Saving Compressed Format: frame2.tar\n",
      "Saving Compressed Format: frame3.tar\n",
      "Saving Compressed Format: frame4.tar\n"
     ]
    }
   ],
   "source": [
    "lc.compress_set(MLP_LOC, COMPRESSED_SAVELOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decompression from Compressed Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decompressing for: compressed_frame0.pt\n",
      "Decompressing for: compressed_frame1.pt\n",
      "Decompressing for: compressed_frame2.pt\n",
      "Decompressing for: compressed_frame3.pt\n",
      "Decompressing for: compressed_frame4.pt\n",
      "Saving Decompressed Model at: decompressed_frame0.pt\n",
      "Saving Decompressed Model at: decompressed_frame1.pt\n",
      "Saving Decompressed Model at: decompressed_frame2.pt\n",
      "Saving Decompressed Model at: decompressed_frame3.pt\n",
      "Saving Decompressed Model at: decompressed_frame4.pt\n"
     ]
    }
   ],
   "source": [
    "lc.load_compressed_set(COMPRESSED_SAVELOC, DECOMPRESSED_SAVELOC, BASE_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Testing Random Weights in decompressed MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_no = 3\n",
    "original = torch.load(MLP_LOC + \"/frame{}.tar\".format(frame_no), map_location = torch.device('cpu'))[\"network_fn_state_dict\"]\n",
    "compressed = lc.read_decompressed_state_dict(DECOMPRESSED_SAVELOC + \"/decompressed_frame{}.pt\".format(frame_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1628, -0.0399,  0.0876, -0.0959,  0.2464, -0.0933, -0.0802,  0.0091,\n",
       "         0.1737, -0.0667])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original['pts_linears.1.weight'][2][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1436, -0.0426,  0.0437, -0.0939,  0.2938, -0.0950, -0.0698,  0.0255,\n",
       "         0.1078, -0.0235])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed['pts_linears.1.weight'][2][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0092,  0.0341, -0.3084, -0.0638,  0.0502,  0.1596, -0.0123,  0.0431,\n",
       "        -0.0161,  0.1263])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original['pts_linears.2.weight'][4][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0399,  0.0949, -0.3225, -0.1085,  0.0502,  0.1478, -0.0327,  0.0424,\n",
       "        -0.0353,  0.1362])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed['pts_linears.2.weight'][4][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_no = 1\n",
    "original = torch.load(MLP_LOC + \"/frame{}.tar\".format(frame_no), \n",
    "                      map_location = torch.device('cpu'))[\"network_fn_state_dict\"]\n",
    "compressed = lc.read_decompressed_state_dict(DECOMPRESSED_SAVELOC + \"/decompressed_frame{}.pt\".format(frame_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2480, -0.2322,  0.0630, -0.1238, -0.0873,  0.1134,  0.1539,  0.0085,\n",
       "         0.0692, -0.0862])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original['pts_linears.1.weight'][4][5:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1702, -0.2176,  0.0619, -0.1270, -0.0907,  0.1337,  0.1742,  0.0024,\n",
       "         0.0702, -0.0826])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed['pts_linears.1.weight'][4][5:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compression Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "Uncompressed MLP File Size (In MB): 71.781115\n",
      "Compressed MLP File Size (In MB): 4.133173\n",
      "Compression Ratio (Tar VS LC-Checkpoint):\n",
      "1736.7%\n",
      "Space Savings (Tar VS LC-Checkpoint):\n",
      "94.19999999999999%\n"
     ]
    }
   ],
   "source": [
    "uncompressed_size = sum(os.path.getsize(MLP_LOC + \"/\" + f) for f in os.listdir(MLP_LOC))\n",
    "compressed_size = sum(os.path.getsize(COMPRESSED_SAVELOC + \"/\" + f) for f in os.listdir(COMPRESSED_SAVELOC))\n",
    "\n",
    "print(\"RESULTS\")\n",
    "print(\"Uncompressed MLP File Size (In MB): \" + str(uncompressed_size / (10**6)))\n",
    "print(\"Compressed MLP File Size (In MB): \" + str(compressed_size / (10**6)))\n",
    "\n",
    "# Compression Ratio = uncompressed / compressed\n",
    "\n",
    "print(\"Compression Ratio (Tar VS LC-Checkpoint):\")\n",
    "print(\"{}%\".format(round((uncompressed_size / compressed_size), 3) * 100))\n",
    "\n",
    "# Space Savings = 1 - (compressed / uncompressed)\n",
    "\n",
    "print(\"Space Savings (Tar VS LC-Checkpoint):\")\n",
    "print(\"{}%\".format(round(1 - (compressed_size / uncompressed_size), 3) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save the torch dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    compressed = lc.read_decompressed_state_dict(DECOMPRESSED_SAVELOC + \"/decompressed_frame{}.pt\".format(i))\n",
    "    torch.save(compressed, HHD + \"/MLP/test/frame_{}.pt\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test original:\n",
      "tensor([-0.0529,  0.0227, -0.0604, -0.0509, -0.0415])\n",
      "Test restored:\n",
      "tensor([-0.0529,  0.0227, -0.0604, -0.0509, -0.0415])\n",
      "Test original:\n",
      "tensor([-0.1419, -0.1430, -0.0833, -0.1399, -0.0644])\n",
      "Test restored:\n",
      "tensor([-0.1713, -0.1642, -0.0814, -0.1256, -0.0692])\n",
      "Test original:\n",
      "tensor([-0.0531, -0.0542, -0.1290, -0.1169, -0.0189])\n",
      "Test restored:\n",
      "tensor([-0.0514, -0.0233, -0.1458, -0.1110, -0.0050])\n",
      "Test original:\n",
      "tensor([-0.1436, -0.0426,  0.0437, -0.0939,  0.2938])\n",
      "Test restored:\n",
      "tensor([-0.1628, -0.0399,  0.0876, -0.0959,  0.2464])\n",
      "Test original:\n",
      "tensor([-0.0529,  0.0033, -0.0472, -0.0968, -0.0209])\n",
      "Test restored:\n",
      "tensor([-0.0411, -0.0046, -0.0278, -0.0970, -0.0264])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print(\"Test original:\")\n",
    "    print(torch.load(HHD + \"/MLP/test/frame_{}.pt\".format(i))['pts_linears.1.weight'][2][10:15])\n",
    "    print(\"Test restored:\")\n",
    "    print(torch.load(MLP_LOC + \"/frame{}.tar\".format(i), \n",
    "                     map_location = torch.device('cpu'))[\"network_fn_state_dict\"]['pts_linears.1.weight'][2][10:15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
