{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Efficient Checkpointing on LeNet** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these 3 approaches : \n",
    "1. **Initial accuracy measurement:** Train LeNet on MNIST and achieve a baseline accuracy of around 99.9% without considering poisoned models.\n",
    "2. **Incremental learning:** Implement incremental learning on the divided MNIST subsets and measure the accuracy drop due to this method.\n",
    "3. **LC-checkpoint and Delta LoRA:** Apply LC-checkpoint and Delta LoRA on top of incremental learning and observe the resulting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy as spy\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import ssl\n",
    "import pickle, json\n",
    "import src.main as lc\n",
    "import old_lc.main as olc\n",
    "from src.models.LeNet import LeNet\n",
    "import src.compression.deltaCompress as lc_compress\n",
    "from src.models.LeNet_LowRank import getBase, LeNet_LowRank, load_sd_decomp\n",
    "from src.utils.utils import evaluate_accuracy, evaluate_accuracy_gpu, lazy_restore,lazy_restore_gpu, evaluate_compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Connexion to wandb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Bradf\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Connect to W&B\n",
    "wandb.login(key=\"beb938fdf67db528128a4298e19b9997afd83dfd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Variables and Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 1000\n",
    "num_work = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader():\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(0.1307, 0.3081)\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                          download=True, transform=transform)\n",
    "\n",
    "    trainset.data = trainset.data.clone()[:]\n",
    "    trainset.targets = trainset.targets.clone()[:]\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size = train_batch_size,\n",
    "                                              shuffle=True, num_workers=num_work)\n",
    "\n",
    "    testset = datasets.MNIST(root='./data', train=False,\n",
    "                                         download=True, transform=transform)\n",
    "\n",
    "    testset.data = testset.data.clone()[:]\n",
    "    testset.targets = testset.targets.clone()[:]\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = test_batch_size,\n",
    "                                             shuffle=False, num_workers=num_work)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bypass using SSL unverified\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# MNIST dataset \n",
    "train_loader, test_loader = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bypass the matplotlib error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Verify if data loaded correctly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verify the 10 classes of training dataset and 10 classes of testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Going through the dataloader to extract an image per class\n",
    "def get_images_by_class(dataloader):\n",
    "    images_by_class = {i: None for i in range(10)}\n",
    "    for images, labels in dataloader:\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i].item()\n",
    "            if images_by_class[label] is None:\n",
    "                images_by_class[label] = images[i]\n",
    "            if all(v is not None for v in images_by_class.values()):\n",
    "                return images_by_class\n",
    "    return images_by_class\n",
    "\n",
    "def plot_images(images_by_class, title):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(15, 1.5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    for i in range(10):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images_by_class[i].squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_images = get_images_by_class(train_loader)\n",
    "test_images = get_images_by_class(test_loader)\n",
    "\n",
    "plot_images(train_images, \"Trainset Images by Class\")\n",
    "plot_images(test_images, \"Testset Images by Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verify that the 10 first images are visually different**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_first_images(dataloader, title, num_images=10):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 1.5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    images_shown = 0\n",
    "    for images, labels in dataloader:\n",
    "        for i in range(len(images)):\n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "            ax = axes[images_shown]\n",
    "            ax.imshow(images[i].squeeze(), cmap='gray')\n",
    "            ax.axis('off')\n",
    "            images_shown += 1\n",
    "        if images_shown >= num_images:\n",
    "            break\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_first_images(train_loader, \"First 10 Trainset Images\")\n",
    "plot_first_images(test_loader, \"First 10 Testset Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting the dataset into three subsets having each all classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train_loader1: 14995\n",
      "Size of train_loader2: 15002\n",
      "Size of train_loader3: 14998\n",
      "Size of train_loader4: 15005\n",
      "Size of train_loader: 60000\n",
      "Size of test_loader: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "def stratified_split(dataset, proportions):\n",
    "    class_indices = [np.where(np.array(dataset.targets) == i)[0] for i in range(10)]\n",
    "    \n",
    "    split_indices = []\n",
    "    for proportion in proportions:\n",
    "        class_split_indices = [np.split(indices, [int(proportion[0]*len(indices)), int((proportion[0]+proportion[1])*len(indices)), int((proportion[0]+proportion[1]+proportion[2])*len(indices))]) for indices in class_indices]\n",
    "        split_indices.append([np.concatenate([split[i] for split in class_split_indices]) for i in range(4)])\n",
    "    \n",
    "    return split_indices\n",
    "\n",
    "def data_loader():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    # Load the whole MNIST dataset\n",
    "    full_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    \n",
    "    # Proportions pour les splits\n",
    "    proportions = [(0.25, 0.25, 0.25, 0.25)] * 10\n",
    "    \n",
    "    # Obtenir les indices pour chaque split\n",
    "    split_indices = stratified_split(full_trainset, proportions)\n",
    "    \n",
    "    # Créer des Subsets\n",
    "    trainset1 = Subset(full_trainset, split_indices[0][0])\n",
    "    trainset2 = Subset(full_trainset, split_indices[0][1])\n",
    "    trainset3 = Subset(full_trainset, split_indices[0][2])\n",
    "    trainset4 = Subset(full_trainset, split_indices[0][3])\n",
    "\n",
    "    # Créer des DataLoaders pour chacun des sous-ensembles\n",
    "    train_loader1 = DataLoader(trainset1, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "    train_loader2 = DataLoader(trainset2, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "    train_loader3 = DataLoader(trainset3, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "    train_loader4 = DataLoader(trainset4, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Charger le jeu de données de test complet\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(testset, batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader1, train_loader2, train_loader3, train_loader4, test_loader\n",
    "\n",
    "# Load DataLoaders\n",
    "train_loader1, train_loader2, train_loader3, train_loader4, test_loader = data_loader()\n",
    "\n",
    "# Vérification des tailles des DataLoaders\n",
    "print(f'Size of train_loader1: {len(train_loader1.dataset)}')\n",
    "print(f'Size of train_loader2: {len(train_loader2.dataset)}')\n",
    "print(f'Size of train_loader3: {len(train_loader3.dataset)}')\n",
    "print(f'Size of train_loader4: {len(train_loader4.dataset)}')\n",
    "print(f'Size of train_loader: {len(train_loader1.dataset) + len(train_loader2.dataset) + len(train_loader3.dataset) + len(train_loader4.dataset)}')\n",
    "print(f'Size of test_loader: {len(test_loader.dataset)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Verify the content of train_loader subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verify the 10 classes of training dataset and 10 classes of testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Going through the dataloader to extract an image per class\n",
    "\n",
    "train_images1 = get_images_by_class(train_loader1)\n",
    "train_images2 = get_images_by_class(train_loader2)\n",
    "train_images3 = get_images_by_class(train_loader3)\n",
    "train_images4 = get_images_by_class(train_loader4)\n",
    "test_images = get_images_by_class(test_loader)\n",
    "\n",
    "plot_images(train_images1, \"Trainset Subset 1 Images by Class\")\n",
    "plot_images(train_images2, \"Trainset Subset 2 Images by Class\")\n",
    "plot_images(train_images3, \"Trainset Subset 3 Images by Class\")\n",
    "plot_images(train_images4, \"Trainset Subset 4 Images by Class\")\n",
    "plot_images(test_images, \"Testset Images by Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verify that the 10 first images are visually different**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAACOCAYAAABwisJiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2aElEQVR4nO3deXhN1/oH8G8kIYmQiEiMCYIQU0QMrSHBVWIs4deWVgylNbV1lbqGG3qVltZUJUrMbbWGXLSUW5JIKJXGWENjCCFEDDGmQrJ/f7hZd6+dnOPkODvj9/M8nuddec/ee+Xss885WfZ6l5WiKAqIiIiIiIiIiIgsrFRBd4CIiIiIiIiIiIonDjwREREREREREZEuOPBERERERERERES64MATERERERERERHpggNPRERERERERESkCw48ERERERERERGRLjjwREREREREREREuuDAExERERERERER6YIDT0REREREREREpAsOPBERkVCzZk1YWVkZ/bdgwQIAQGBgIKysrBAVFVWgfTZFUlISli1bhhEjRqB58+YoU6YMrKys8Pbbb5u0/e+//47+/fvD3d0ddnZ2qFWrFsaOHYsbN26Y3IfVq1c/97nN7d/q1avN/K2Nyz7XiYmJuuy/sMrKysLq1avRuXNnuLm5wdbWFi4uLqhXrx569eqFOXPmWOw5iYqKgpWVFQIDAy2yv8Lm7Nmz+PLLLzF48GA0btwYNjY2sLKywsyZM83e5+DBg2FlZYXBgwdbrqNERERUoGwKugNERFT4tGnTBnXq1Mk15+Pjk8+9efbH6Jo1a7Bq1Sqz/iDdvHkzxo0bZ9axN23ahDfeeANPnz5FixYtUKtWLcTFxWHx4sXYuHEjYmNjDT5XanXq1EFISEiOn8fGxuL8+fPw8vJC27Ztc92OnomKikKHDh0QEBBg1oDnw4cP0bNnT0RGRgIA/Pz80L59e1hbW+PChQv4+eefsX37djg4OGDMmDEW7n3hExgYiOjoaERGRpo1OLZ06VIsXLjQ8h0jIiKiYoUDT0RElMPbb7/93AGetWvX4tGjR/Dw8MifTr2A7DuU/Pz84Ofnhx9++AGffPLJc7dLTk5GSEgInj59Ku6YAoDMzEwMHjwY69evx4ABA3Do0CFYWVkZ3Vfbtm1zHVgaPHgwzp8/j7Zt2+p2d1Nu9uzZgydPnqBatWr5dsyCNn36dERGRqJq1arYuXMnmjRpIuXv3r2LzZs3o0qVKgXUw6KlUaNG+PDDD9GsWTP4+flh1qxZWLduXUF3i4iIiAoZDjwREZFZisKAU7bevXujd+/eor1lyxaTtluwYAEePXqEv/3tb2LQCQCsra2xdOlSbN++HYcPH8bu3bvRpUsXi/dbT15eXgXdhXy3YcMGAEBoaGiOQScAcHJywtChQ/O7W0WWdqpqqVKs4EBEREQ58RsCERGZxVCNp+waLatXr8bJkyfx2muvoUqVKrC2tsb06dPF4zZu3Ii//e1vqFixImxtbVGxYkX4+Phg+PDhOH78OAAgMTERVlZWWLNmDQBgyJAhUv0j9f70EBERAQAYMGBAjpyjoyN69eoFwPSBrLxS12HaunUrOnbsCBcXF+l5T01NxaJFi9CtWzfUqlUL9vb2KF++PPz9/fHZZ5/hr7/+eu6+1dTn9ejRo+jbty9cXV1RpkwZ+Pj44IsvvoCiKDn29/jxY8ydOxfNmzdHuXLlULp0aVSuXBktWrTAxIkTcfv27RzbpKen44svvkDr1q3h7OwMOzs7eHt7Y+LEibh161aOfnXo0AEAEB0dLb0OatasadLzmZKSAgBwc3Mz6fHZpk+fbvT1Zkotp0ePHmHy5MmoU6cO7OzsULVqVQwbNgxXr17N9fG///47XnvtNVSvXh2lS5dG+fLlUbt2bQQHB2Pr1q0Gtxk4cCA8PDxQpkwZuLi4oEuXLtixY0eu/Y2OjgYAdOjQIV/qir0I9XP8+PFjzJgxA/Xq1YOdnR08PDzw0Ucfidf63bt38eGHH6J27dqws7NDzZo1MX36dDx9+jTHfs29fgDg5MmTCA4OhqurKxwcHNC4cWMsWLAAWVlZRmuoPX36FCtWrEBgYCBcXFxQpkwZ1KpVCyNHjkRSUlKux/rll1/Qs2dPuLu7w9bWFhUqVEDdunXx5ptvYt++feY9qURERPmEdzwREZEuDhw4gHfffRdVqlRB+/btkZ6ejnLlygEAPv74Y4SGhsLGxgYvv/wyqlWrhrt37+Ly5csIDw9Hw4YN0aRJEzg6OiIkJETUQdLWnvL19dWt//fv38e5c+cAAP7+/rk+xt/fH+vWrcORI0d06wcAfPHFF1i8eDH8/f3RtWtXJCcnw9raGgCwa9cuvP/++6hWrRrq1KmD1q1bIzU1FYcOHcKkSZOwdetWREZGokyZMnk65q5duzBv3jx4eXmhc+fOuHbtGmJjY/Hhhx8iKSlJFJkHnhXs7t69O/bs2YPy5cujXbt2cHZ2RmpqKhISEjB37lwMGDAALi4uYpvk5GR07doVJ06cgIuLC1q0aIFy5cohPj4ec+fOxcaNGxEVFQVPT08AQNeuXWFnZ4ddu3bB3d0dXbt2FftydXU16Xfy8PDA+fPnERYWhqCgoDw/J+bKyMhAp06dcPz4cQQGBsLPzw+xsbFYuXIlduzYgX379qFu3bri8Xv27EFQUBCePHmCpk2b4qWXXkJmZiauXr2Kn376CZmZmdIdfACwcOFC/P3vf0dWVhZ8fX3RqlUrXL9+HVFRUdi9ezdmzJiBf/7znwCAypUrIyQkBD///DNSUlLQpUsXVK5cWeyrMNcVy8jIQJcuXXDkyBEEBgbC29sbMTExmDNnDk6dOoU1a9bg5Zdfxu3bt9G+fXvUrVsX+/btw4wZM5CSkoKlS5dK+zP3+omOjkZQUBDS09PFNXLr1i189NFHOHjwoMH+379/H7169UJUVBQcHR3RvHlzVKpUCSdOnEBYWBg2btyI//znP2jWrJnYZs2aNRgyZAgAoGXLlujQoQPS09Nx5coVbNiwAa6urmjfvr0Fn2UiIiILU4iIiP7L09NTAaCsWrXquY8NCAhQACiRkZHSz0NCQhQACgBl0qRJSmZmppT/66+/FHt7e8XR0VE5c+ZMjv0mJiYqp0+fznWfpvTLFKGhoQoAZdiwYQYfc/z4cfF7pKWl5fqYLVu2KAAUV1dXs/uS/buFhITkyGWfD2tra2Xr1q25bn/q1Cnl119/zfHz27dvK6+88ooCQJkzZ47BfV+8eFH6efZ5BaCEhYVJuT179ihWVlaKtbW1kpSUJH4eHR2tAFCaNWum3Lt3L8exDh8+rNy8eVO0s7KylDZt2ohzoN7myZMnyvjx4xUASocOHaT9REZGKgCUgICAXJ+L55k/f7743dzd3ZXhw4cr4eHhSnx8vPL06VOD22W/XkJDQ3PNG+pX9s8BKHXq1FEuXbokcunp6UpwcLACQGndurW0XYcOHRQAyvr163McKy0tLcf5/vnnnxUrKyvF1dVViY6OlnLHjx9XqlevrgBQoqKipJyha9hc2a/lf/3rXy+8D+31oH4uW7ZsKb2eEhMTlQoVKigAlMaNGys9e/ZUHj58KPKHDx9WbGxslFKlSknnQFHMu34ePXqkVKtWTQGgjB8/XnqP++OPPxR3d3fRV+31NWDAAAWA0qNHDyUlJUXKZb8+69atK70ea9WqpQBQYmJicvQzJSVFiY+Pz/FzIiKiwoRT7YiIKAftlLbsf3lZ+apevXqYOXNmjrov9+7dQ3p6OmrXrg1vb+8c23l6eqJ+/fov+iu8sPv374u4bNmyuT7G0dERwLPfSU8hISFiWp9WgwYN0Lp16xw/r1ChAr788ksAz6Y15lXfvn3xzjvvSD/r2LEjunTpgszMTLEyHPC/KWzt2rUTd7Wp+fv7o2LFiqK9a9cu7N+/H76+vggLC5O2sbGxwZw5c9CoUSNERkbi5MmTee67IR988AE++eQTlC1bFikpKVi+fDmGDRsGPz8/VKhQASEhITh79qzFjqf2+eefS3XR7OzssGTJEjg4OODgwYM4cOCAyGU/n926dcuxHycnpxznOzQ0FIqiICwsLMedL40bN8a8efMAQLweijIrKyuEh4dLrydPT0+89dZbAICLFy9ixYoVcHBwEHl/f38EBQUhKysrx9Rgc66fTZs24erVq/D09MTs2bOl9zgfHx9MmzYt176fPn0a3333HapWrYpvv/02x5TPDz74AN26dUNCQgJ27twpfp6SkgInJ6dcFydwc3OT7o4iIiIqjDjVjoiIctBOacuWlwGhV199VUwHU6tUqRJq1qyJ48ePY/z48Rg2bBh8fHxeqL/FXb9+/YzmMzMzERUVhQMHDuDatWtIT0+HoiiiFpM5gyk9e/bM9ecNGjTAzz//LNUm8vPzg7W1NVauXIl69eqhb9++RleG++mnnwAAwcHBsLHJ+VWkVKlSaN++PU6ePIkDBw6gUaNGee6/IZMnT8aoUaOwdetWREdHIz4+HidPnsT9+/exdu1abNy4EZs2bcp10Mdczs7OuQ4curm5oWvXrtiyZQuioqLw8ssvA3g2nerUqVMYOHAgJk+ejNatW+f6PAHAzZs38dtvv8He3t7gOcseMFYPbhVVHh4eub4esqcqNm/ePNcaXtn55OTkHLm8Xj/ZtbH69+8PW1vbHPsbOHAgxowZk+PnO3bsgKIoCAoKynWAFnh2rnbs2IEDBw6gR48eAJ69HqKiojBo0CC8//77aNasGQu5ExFRkcKBJyIiyuHtt9/G4MGDX2gfxgo+r127Fv369cO8efMwb948uLi4oFWrVujcuTPeeustk2v26En9h+HDhw/h5OSU4zEPHjwAAJQvX17Xvhh7LhMSEtCnTx/88ccfBh9jzh1ZhlYtzP5d1UWXvby8MH/+fEyYMAFjxozBmDFj4OnpiZdeegk9evRA//79Ubp0afH4CxcuAACmTZtm8O6QbKmpqXnu+/M4OzsjJCQEISEhAIA7d+4gIiICU6dOxbVr1xASEoJLly5Jd828iOxC07mpVasWAODKlSviZ7Nnz8bx48exc+dO7Ny5E/b29vDz80NgYCAGDhyIBg0aiMdevHgRiqIgPT39uTWr9Hgu85uh12X23YeG8tnXs7ZYuDnXT/a5MnRdOjs7w8nJCXfv3pV+nv26Dw8PR3h4uMHjAfK5WrJkCXr06IF169Zh3bp1KFeuHFq0aIGOHTvirbfeKlIrjBIRUcnEgSciItKFvb29wVy7du2QmJiIn376CdHR0Thw4AB27dqFnTt3IjQ0FBEREejUqVM+9jan7KLWAHD58mU0btw4x2OyV6AydVU1cxl7Lvv164c//vgDPXr0wMSJE+Hj44Py5cvD1tYWGRkZZhfQzusdFWPHjsX//d//Ydu2bYiNjUVsbCw2bNiADRs2IDQ0FDExMeIuqKysLABA27Zt4eXlZXS/DRs2NKv/eVGhQgUMHToUzZo1g5+fH27evIn9+/ejc+fOJm2f/fu8CEW1UmDlypURFxeH6Oho/PLLL9i/fz8OHTqE/fv3Y9asWZg9ezY++ugj6diOjo4IDg5+4X4Uds97Xeb1dfsi14+hwURDuexz5evri6ZNmxrtV6tWrUTcoEEDnD17Frt378bevXtx4MABxMTEYO/evfj4448RHh6ON99883m/KhERUYHhwBMRERUIe3t79OvXT0wjS01NxdSpU/H1119j6NChuHTpUoH2r3z58qhTpw7OnTuHuLi4XAee4uLiADybalYQzpw5g+PHj8PNzQ0RERE5pmMlJCTka3/c3d0xfPhwDB8+XPRv6NCh+PXXXzFp0iSsWbMGAFCjRg0AQO/evfHhhx/max+NadasGVxdXXHz5k3cvHlT/Dz7bi113S+1571WExMTn5urXr269PPsmmrZ0+T++usvrF69GqNHj8bkyZPRr18/eHl5iefSysoKK1eu5BSsPDD3+qlWrRoAw+f17t27SEtLy/Hz7HPVpk0bLF68OE99tbGxQbdu3cQU0Hv37mHevHmYMWMG3nnnHfTp08dgLToiIqKCxm8nRERUKFSqVAlz5swB8OwOozt37ohc9h/+T58+zdc+9enTBwDw7bff5sg9ePAA27dvB/CsEHdBuH37NgCgatWqudYAWr9+fX53SVK/fn1xZ87Ro0fFz4OCggA8K9qsvtPneV70dfC8Y6WlpYlpVeqBoOyBhtOnT+e6XXbNKmP7zX6tqKWmpuLnn38GgOcW7rezs8O7776LJk2aICsrC8ePHwfw7Nw3adIE9+/fF/syVUFdV4WFuddPdgH3jRs35vrc5fZ+Afzvdb9t27YcU/7yqnz58pg+fTqcnZ3x6NEj/Pnnny+0PyIiIj1x4ImIiPLVpUuXsGLFilzrDmX/cV6hQgWpblL2IICxOix6+OCDD+Dg4IBffvkFy5cvFz/PzMzEqFGjkJaWhhYtWuCVV17J135lq1evHqytrXHixIkcq3Vt374d8+fPz5d+7N27Fzt27MCTJ0+knyuKgh9//BGAPHWxd+/eaNGiBX777TcMGTIk19pDd+7cQVhYmPSHffbrICEhIcexTNGyZUssWbJEDDioXb9+HSEhIcjIyBD1qbJ17NgRpUqVwq5du0Rh6ezfb9GiRdi8efNzjz1+/HipjtPjx48xevRoPHz4EC1btkSbNm1E7vPPP8fly5dz7OPMmTPiLhz18zlz5kwAz1ajzG2AS1EUHDp0CLt375Z+XlDXVWFh7vXTv39/VKlSBYmJiZgyZYo01fLMmTP4+OOPc92uWbNmCA4ORlJSEvr27ZvrHVMPHz7EN998I1Y2fPToEebNm5frNRITE4O0tDRYW1vnuGOOiIioMOFUOyIiyld37tzB8OHDMWrUKPj6+oriygkJCThy5AisrKwwd+5caUW8V199FTNmzMCiRYtw8uRJ1KhRA6VKlUKvXr1yXS1M69q1a+LuJeB/xYG3bdsmLaW+ZMkSadpc1apVsXr1arzxxhsYMWIEwsPDUbNmTRw+fBgXLlyAu7s7vv32W6O1XvTk6uqKMWPGYOHChejUqRPatWuHqlWr4uzZs4iPj8fUqVPFoISejh8/jnHjxqF8+fLw8/ND1apVkZ6ejvj4eFy6dAlOTk7SH+OlSpXCv//9b3Tv3h1r1qzBpk2b0LRpU3h4eCAjIwMXLlzAiRMnkJmZicGDB4u7UTw8PODv7y+mPvr7+8POzg6urq749NNPn9vPhIQEjB49Gu+99x4aN24MLy8v2NjY4OrVqzh06BCePHkCFxcXbNiwQboDpkaNGhg7dqz0PLu4uODYsWO4fPkyJk2aZPT4L730ErKysuDt7Y2OHTvCwcEBsbGxSE5OhpubG9auXSs9fubMmZgwYQLq16+PBg0awN7eHsnJyYiNjcXTp08xaNAg6XXas2dPLFy4EOPHj0evXr1Qp04deHt7w8nJCampqTh27Bhu3LiBjz76SBokDQ4OxqpVqzBx4kT88ssvcHNzg5WVFYYOHSpW2DMmPj4eo0aNEu3z588DAJYtWyYGHAEgIiLC6CqHBcXc68fBwQHr169H9+7dMWfOHGzZsgX+/v64ffs2oqKi0Lt3bxw6dAiXL1+WiuoDwKpVq5CWloadO3fC29sbTZs2Ra1ataAoChITE3Hs2DFkZGTg9OnTcHd3R0ZGBsaPH48JEyagcePGqFu3LmxtbZGYmIiDBw8CAKZMmYJKlSrly3NGRERkFoWIiOi/PD09FQDKqlWrnvvYgIAABYASGRkp/TwkJMToPu7du6csWLBA6dOnj1K3bl3F0dFRKVu2rFKvXj1l0KBBSlxcXK7bRUREKG3atFHKlSunWFlZKQCU0NBQk36vixcvKgCe+0/7u2SLi4tT+vbtq1SqVEkpXbq04unpqYwePVq5fv26Scc3Jvv5CgkJyZHLPh8XL140uH1WVpYSHh6uNG/eXHF0dFScnJyUtm3bKhs2bFAURRG/m6n7NnRes4WGhuZ47s+dO6dMnz5d6dSpk+Lh4aHY2dkpFSpUUJo0aaJMmjRJSUpKynVff/31lxIWFqZ06NBBqVixomJjY6O4ubkpvr6+yujRo5Vdu3bl2ObSpUvKgAEDlCpVqig2NjYKAMXT09Pg86N24sQJZf78+UrPnj2V+vXrK87OzoqNjY3i4uKivPzyy8qMGTOU1NTUXLfNyspSvvjiC6VBgwZK6dKlFRcXF6Vnz57K77//rkRGRioAlICAAGkb9c8fPHigTJgwQalVq5ZSunRpxd3dXRk8eLBy+fLlHMdav369MmTIEKVRo0aKi4uLUqZMGcXT01MJCgpSIiIilKysLIO/34gRI5S6desqdnZ2ioODg1K7dm2lS5cuyqJFi5SrV6/m2Gb58uWKn5+f4uDgIF4rplz/6t/vef+MvX61DF0Php7jbKtWrTJ4HSlK7q9bRTH/+lEURTl27JjSp08fxcXFRbGzs1N8fHyUuXPnKo8fP1ZKly6tlCpVSklPT8+xXWZmpvLtt98q3bp1U9zd3RVbW1ulYsWKSqNGjZQhQ4YoERERSkZGhqIoivLkyRMlLCxMeeONN5T69esrTk5Oir29veLl5aUEBwcre/bsMfxkEhERFRJWipKH4gpERERERGTQvn37EBAQgMaNG4taXERERCUZazwREREREeVBamoqLl68mOPnJ0+eFKs6DhkyJL+7RUREVCjxjiciIiIiojyIiopChw4d4OPjg9q1a8Pe3h4XL15EfHw8srKy0LlzZ+zYsSPX1fKIiIhKGg48ERERERHlQXJyMmbNmoXo6GhcvXoV9+/fR7ly5dCwYUMMGDAAw4cP56ATERHRf3HgiYiIiIiIiIiIdMEaT0REREREREREpAsOPBERERERERERkS5MnnxuZWWlZz8oDyw5O5LntfDgeS2eLD2bmee28OA1WzzxvBZPPK/FEz9jiy9es8UTz2vxZMp55R1PRERERERERESkCw48ERERERERERGRLjjwREREREREREREuuDAExERERERERER6YIDT0REREREREREpAsOPBERERERERERkS5sCroDREREVDSVK1dOxF9++aWUK126tNQeMGBAvvSJ8m7YsGFS++uvvxZxTEyMlOvdu7fUvnv3rn4dIyIik7zzzjsiXrJkiZRLTk4WccuWLaXctWvX9O0Y0X/xjiciIiIiIiIiItIFB56IiIiIiIiIiEgXHHgiIiIiIiIiIiJdsMYTERERmaRatWpSe+HChSIODg6WckePHs2PLpGZAgICRDxixAgppyiKiNu1ayflXF1dpTZrPBER5T91TScAmDVrlojV7+EAYGPzvz/5ra2t9e0YkQG844mIiIiIiIiIiHTBgSciIiIiIiIiItIFp9oRUYGpVKmS1H7vvfdEPHnyZCmnvoUYAGbPni3iR48e6dA7IgKAmjVrivhf//qXlFNPr4uKipJyXKK54FlZWYnYy8tLyq1atUrEHh4eBvexbds2qc3zSkSUP9Sfv3PnzpVyffv2ldra6XVqp06dEvGVK1cs0zmiPOIdT0REREREREREpAsOPBERERERERERkS448ERERERERERERLoo0TWegoKCpPbHH38sYn9/fymnnjf7ww8/SLkbN26IePHixVLuzz//fOF+EhVXa9euldqvvPKKiLVz1bXLfS9fvlzEly9f1qF3RCVT6dKlpbb6s7Ft27ZSTl3zadGiRVJOW3+C9Keu6QTINbg2bNhg1j7nz58vtVlTj6jwUX9nysrKknKffvqp1J4yZUq+9Inyrn79+lJ7yZIlIm7fvr3J+7l06ZLUXr9+/Yt1jCyqU6dOIg4NDZVy7dq1k9rqmrfq1wMA3L17V4fe6Yd3PBERERERERERkS448ERERERERERERLqwUoytvah+oOb27aKiTp06Ig4LC5NyAQEBUtva2vqFj5eamiq1R40aJeLNmze/8P4B48tl5lVRPa/FUUk5r+PGjRPx559/LuXU/dY+Hw0bNpTa6ikk2luKY2JiDObymyXPK2C5c6vej4uLi0X2aczTp09FXNRuDTakuF6zy5Ytk9rqaa7a6eRjx44VcaNGjaScehp6bu3CqiifV/V3HgA4c+aMSdulpaVJbfU0yX379r1wvwqDonxeybDC+hmrNx8fH6l94sQJEWufk4SEBKndoEED/TpmQSXxmj19+rTUrlu3rsHHan+nf//73yL+4IMPpFxSUtIL981SSuJ5ffvtt6X2V199JWIbG7nykfZ3Uj9fbdq0kXIHDx60VBdfmCnnlXc8ERERERERERGRLjjwREREREREREREuuDAExERERERERER6cLm+Q8pWmrWrCm1161bJ+JWrVqZvJ+4uDip/cMPPxh87MCBA0XctGlTKTd79mwRW6rGU1Fja2sr4ubNm0s5ddvX19fgPnr27Cm13d3dLdK39PR0g8fYs2ePRY5BsldffVXExuYDf/LJJ1JbW6vk1KlTIt60aZOUU9d4evfdd43up6RaunSpiIcPH6778VJSUkS8cOFCKbd27VqpfevWLRFnZGTo2zECAHTv3l3Eb775ppRT14YYP368wX2cPHnS8h2j56pUqZKItdeWqbR1nIpLXafiSv1dd/To0VLO0dFRxNraiGra76TR0dFSW10HSPt9qKjUayvO1LX3qGhbtGiRiOvVq2fwcXfu3JHagYGBUpufwYVXy5Ytpba2rlNJwTueiIiIiIiIiIhIFxx4IiIiIiIiIiIiXVgpJq5pWJiXK1RPodu5c6eUc3Z2NrjdlStXpPY333wjYvVtjwBw7do1g/tRT6/77bffpJx6Kpd2Gp65y7wX9mUoy5QpI7V//PFHEXfq1Mnix3uezMxMEVtbWxt8nPYW1tq1a4s4P5Z/L+zn1VzqaSCAPOVK+zvHx8eLuEWLFiYfIywsTGqrp46p95nX/VpCYV3qWd2vrKwsi+zTUoKCgkS8e/fuAuyJccXpmo2IiBBxkyZNpJz6fTsxMTG/ulRgitp5VV8v27dvN3k79fLO6s9pALh58+aLd6yQKWrnVU27hPa2bdtEXKFCBd2Pr/1u27p1a92PaarC+hmrtwULFkjtsWPHilj7nKSlpUntvn37irgwT6stytesMU5OTlI7NjZWxOoprgCQmpoq4t69e0s57XVZVBTX82rM/fv3pbaDg4PBx2p/J/Xzpf0sOHjwoAV6ZxmmnFfe8URERERERERERLrgwBMREREREREREemCA09ERERERERERKSLIrmWn3Zu7I4dO0RsrKbT/v37pfbIkSOltrqOk3o57+c5duyYiP/8808pp17KVl1PAQCmTZtm8jGKkkGDBkltdX0Q7VKf6nnN3t7eBveprT9x/fp1k/ujPq979+41+LgNGzZI7fyo61QSrF27Vmqr5wBr5wPPmjXLIse0dM2H4mjlypUi7tGjh5T7/vvvRXz48GGz9t+vXz+pra5xV6NGDaPbrlixQsTt2rWTcubWxiPZP/7xD6n96quvivjNN9+UciWhrlNRpq7XYkx0dLTUVtf14udd4dO+fXsRa78DlStXTsTqOpaA/L3q4sWLUk5dD0z7XVpbn1NNWxtx+vTpucZUOGn/NlLX8SvMNZ6KE3t7exFfuHBByqmvRe3316+//lrERbWmE1E23vFERERERERERES64MATERERERERERHposhMtVMvLbh06VIpZ2wp2YyMDBGPGzdOymmnfVmCejlTQJ7a1bJlS4sfrzBav3691FY/B9opcg8fPtS9P126dDGYUy9TOmHCBN37UlKULVtWxB4eHlJOfS1rl+xWT/3Ii+XLl0vt4cOHm7WfkmTEiBEirlu3rpQ7c+bMC+9/3bp1UrtixYoi1k5r7dixo9SuVq2aiIcNGybl/vnPf75w3yin27dvizgyMrIAe0LP895770ntoUOHmrTdkiVLpDan1xUu6vc9QP48dHR0lHLq71Lazzv1tLxSpeT/X65cubKIO3fuLOXU068B+bNau7x3t27dRPzZZ59JufT0dJD+LPE5TfrRTm/84YcfDObU0+u++eYbKRcaGmrxvlH+27x5s9R+6623zNpP9+7dpfbBgwfN7lNB4B1PRERERERERESkCw48ERERERERERGRLjjwREREREREREREuigyNZ6aN28u4tdff93g47Q1hNS1Q/JjPrT2+GqtWrXS/fiFgXZ+//nz5/P1+C4uLlJbvTS7lnqp4UePHunWp5Kmfv36Ivb29pZy6rnsW7ZsscjxtLWi1LW7KHfqJbjz473x1q1bIp45c6aU09Z4UjNWw4/MFxAQILUPHDgg4uTk5PzuDho2bCjiuXPnSrmEhASD261du1bEv//+u+U7VghNmTJFamuX31ZTX2vaGhP5rVKlSlLb39/frP3ExcWJuDi91wcGBkptY+9977//vojVNZ20srKypLb62l6zZo2UU9f9A4CXXnrJ4H7V507bT9Z4yh9hYWFS+6uvviqgnlBufH19pbax7zlqW7dutcjx7e3tpfbgwYNF/P3330s5dY1H0oex7zF5of0bt6jhHU9ERERERERERKQLDjwREREREREREZEuCu1Uuzp16kht9e30xqhvJQS43GhJ1LJlS6mtXaJYbdasWXp3p0RST6nQLsOsbVvCpUuXpHZSUpLFj0GW89prr5n82PDwcB17UrKol1bX3oafH9Ow1O/N2teAemlh7ZSsoKAgg/tUT72vUaOGlMvIyDCrn4Wdq6ur1DY21U47DVkP6s9Y7RLR7du3F3HFihWlnLqEgpb6c0L7+23fvl3Effr0yVtnCzE/Pz+DOe1UmH379ln8+Nqpqsam2hGRcer3PkB+T9N+D37vvfdEHBERYfIx7OzspPYrr7wiYu2UbPX02MWLF0s59d9Cn376qZR7+PChyf0hw6Kjowu6C4UC73giIiIiIiIiIiJdcOCJiIiIiIiIiIh0wYEnIiIiIiIiIiLSRaGt8bRp0yaprV6eXWvFihUi/s9//qNbn6hoUNf8eJ6jR4/q15ES7B//+IeIjdUfyctcdnNp66Go2/lR/4Se6dq1q4j79+9v9LHqeiYPHjzQrU8ljboWj7b+xPr16y1+vBkzZkht9RLwTk5OUu7+/fsinjt3rpT79ddfRbxq1Sop5+bmJmLt6+qbb77JY4/JFD4+PlJbXXPJ09NTyhmr1WSudu3aiVj7Otaj9lF+efz4scFcenq61L5+/bre3TFZs2bNpHZycnIB9aRkU9fwy8rKKsCelFzOzs4iHjVqlJRTv/9p65Ia+6xSf8YFBARIuQ8//FBqG6ubZ+z9d/LkySL29vaWcuq6fcbeo8i4p0+fSu3Y2FgRt23bNr+7U2B4xxMREREREREREemCA09ERERERERERKSLQjXVbvTo0SJu0KCBydsdOHBAxJa6ldtcvr6+BnNpaWn51o+SRLv09htvvGHwsXv37pXaV65c0aVP9D/aZWPVbUtNdStbtqzUdnBwELF26oeHh4fFj0/Pp35/d3FxMfrYgwcPivjcuXO69Yn+Rz1FIC+qV68u4h9//FHKNW3a1OB2GzZskNojR44UsbHPyiNHjkjtqKgoEbdo0ULKFdepduopNYD+02rUS30DwPz5803e1tTpP9opcoGBgQa3q1ChgoibNGlidD9FycqVK6X2pEmT8vX4v/zyi9QeM2aMSdu1bNlSav/0008W6xOZTn2dFPTfQiVVmzZtRKwt86Cm/twC5M887XaffvqpiAcNGiTltN+vLXHe+/btK7XV09t37tz5wvsvqbSlgNQlhTjVjoiIiIiIiIiI6AVx4ImIiIiIiIiIiHTBgSciIiIiIiIiItJFgdZ4srOzk9pTp04Vsa2trZS7ePGiiB89eiTlxo0bJ+K1a9dKufxeUrRfv34Gc1988UU+9qTk0D7n2teO2p07d6S2epnQLl26SLkaNWqIePHixVLu+++/z3M/S5L69euLOD9qDaiPB8jLwWqPr64fFx8fr2/HSjDtOXn55ZdN3lZb64T016dPHxHPnTvX4OOsra2l9nfffSdibU2nlJQUqR0SEiLi3377TcqZWgMxMTFRal+7dk3E2tdccaX9XmPsPVa7NLapfHx8RDxlyhSTj6elrvt1+vRpKbds2TIRa2s17t+/3+Dx1K+BdevWmdyXwu7u3btSW12DsnLlylJO/X3yk08+kXLqaykv34EvXLhg8mPVTp48adZ2RMWNv7+/SY87fPiwwdzWrVuldqtWrQw+Vvv3sPpzVXuM9PR0EU+bNs2kfgJy7UTWeDJf586dpfb06dNFbKwWrpa6rnVRxDueiIiIiIiIiIhIFxx4IiIiIiIiIiIiXXDgiYiIiIiIiIiIdFGgNZ7U9XUAwN3dXcSZmZlSrn///iK+fv26lNu3b5+IS5WSx9Lyo8aTuhZCt27dpNyDBw9EzLmxeaOuAaZ+jrW082aNCQ4ONtpWi42NFbG63gQ9X0REhIiHDx8u5YzNXTaXsWNoj1dS6sAUhPLly4t49uzZUs7Z2dngdjdu3JDaf/zxh0X7Rc/cunVLxNq6LPXq1ROxtk5FXFyciOfNmyfl2rZtK2JtzbRBgwZJbUuc17Jly0pt9Wtu8uTJL7z/oiA1NVVqu7q6GnzsyJEjRayuGQTI59LNzU3Kbd++3eD+tTWXMjIyRKytZamuJVKzZk0pV7VqVRHnpVaTuq6Xti5SUaY9r5999pmI58+fL+XUtU3VMQBERUWJ+Ny5c1IuISFBxNr6Xy+99FLeOvxf/H5E9Iyp9c4aN24stdU1Zo3VidLuX/s3zPnz5w1uq/7s1NZj7N27t+HOki7Uf7s+r26iOu/r6yvlvvnmG4v2S2+844mIiIiIiIiIiHTBgSciIiIiIiIiItJFgU61Gz9+vMHc3r17pbaxZc/79esnYu0UPT1op/ONHTtWxOrpYQCQlJQkYu0tzyRTT/UAgB9++EHETZo0scgxnjx5IrU/+ugjEatvTwfkW1qfPn1qkeOXFGfOnBFxXpbethRjx1RPAyTL8vDwEHGvXr1M3u67776T2n/++afF+kT/o156WTv1e8KECQZz4eHhIh41apSUU099f+2116ScHp952tfKvXv3RBwZGWnx4xVG6mkZALBr1y4RG5t298knn0ht9bRj7ZRkT09Pk/ujfl2VK1dOyi1cuFDEb775ppRzcnIyaf+nTp2S2tr9FFdfffWViI8cOSLl/vnPf4r4lVdekXKBgYG5xnrRTvf58ssvdT8m5aT+2yQ/yoxQTurPoPv370s59bRw7WdlTEyMiB8/fizl1FPktNPVjU2t06pWrZqI27dvL+WMvXbUfSPzaac2m8vBwcEi+ykovOOJiIiIiIiIiIh0wYEnIiIiIiIiIiLSBQeeiIiIiIiIiIhIFwVa46lKlSoGc59//rnJ+zl69KgFemM67RLR77zzjoi1c3q1jyXDpk6dKrUtVddp+fLlIlafK9JPbGysiLW1Q7Rtc/Xp00fEI0aMkHLqGk/q+iO5tangqev0AUD37t3N2o+6DkpKSoqU69q1q4jnzJkj5X7//XcR5/fnSUHZsmWL1P773/8uYm2dIHUtPC11zaULFy6Y3R9ra2sRly5dWspNmjRJxOrzCOR87ZQEx44dk9o//vijiIcMGWLyfkz9fqKta6mtAVKhQgURq2tearfNS90Z9Xbq93oAuHTpksn7KS4OHDggtbt16yZi7fLrU6ZMEbG2Hpj6HKhfNwDQsGFDqa2u2aeuM6N19uxZgznKPzNmzBCx9vu0ljq/ePFi3fpU0ty+fVvES5YskXLqz1FnZ2cpN2/ePBHb2tpKOfX3WW1tqIEDBxrsi7bm8BtvvGHw+Or3hRUrVkg59fd5Ml/16tULuguFAu94IiIiIiIiIiIiXXDgiYiIiIiIiIiIdJHvU+2aNm0qYu1tgGpJSUn50R2DtLeWL1u2TMSDBw+Wcnfv3hXx/PnzpVx0dLTlO1dMjRkzRmpv3rxZxGfOnJFyoaGhIn799del3NWrV6X2tGnTLNVFMpF6+WvtUtg+Pj4i1k6hiI+PN7jPSpUqSW31rcnqW5G1be1rR9umgqde5vdF1KlTx6THff3111L73r17IlZPGyrODh48KLXV1+L3338v5ezt7Q3uZ9y4cSL28/OTctr3YrXLly9L7aCgIBGrvydoqaf2AcC2bdsMPrakCAsLE3Ht2rWlnHbZbHNop8hp329N3TYv26mnV2pfKyQ/r7/99puU6927t4i10/DU2xn7vAWA8ePHi3ju3LkGH+fl5WW8s5Qvbt26ZfJjtdOpyfLUZT4A+TPW29tbymm/35pqz549Uls9XVb7d6yLi4vB/Tx48EDEa9askXJPnjwxq28ka9WqldnbPn78WMT79u2zRHcKDO94IiIiIiIiIiIiXXDgiYiIiIiIiIiIdMGBJyIiIiIiIiIi0kW+13hSL8+qXTKyoNWoUUPEX375pZTr1auXiNU1nQBgwYIFIv7444/16VwJoK6zAgBbt241+FhHR0eDuYsXL0rtGzduvFjHKM8ePXok4itXrki5Ro0aibhv375STr2Mq7YGQVxcnNRW16owttx3TEyMqd2mF6ReSlh7HdaqVStf+3Ly5EmpbWxe/P79+/XuTqG3fft2EauXXQbk2oU1a9aUclZWViIOCAgw+/jqOhIJCQlSbvbs2SJeu3at2ccortTvjT179pRybdu2FbH6uwoAlC1bVsRVq1bVp3MqiYmJUvvatWsinjlzppTbtWuX7v0pCbSfm3mxc+dOEWvPT5kyZURcuXJls49BVFxp3+/U9U1HjBgh5dSfcU5OTiYfIzAwUGqr6+hdunRJyp04cULEGzZskHJ79+4V8fnz500+PpkuL8+ruuYWIH8H09bgLGp4xxMREREREREREemCA09ERERERERERKSLfJ9qp759TLtEr3q6TPny5S1+bO1S2+rlegH5FnXt0pb3798X8QcffCDltEtPkuVpl9fu1q2bwcceOXJE7+5QHrz11ltSOyUlRcTaJWXVy0JXrFhRyhlb0lubO3XqlIhnzZqVxx6TuZKTk0Xs6+sr5UqXLp2vfVEvPwsADx8+zNfjF2Xaac7qtnrqFgAEBweLWLt0u/YaVl+z2iXgo6KiRMzPVPNpX+fqKWsNGjSQcp6eniIeMmSIlJs6darBY2inXbVv317EW7ZsMbjdunXrpLa2bAEVLurPUe37qXqqHRUO6mnP6pgKn6+//lpq7969W8Tjx4+XciNHjjTrGEFBQVL7zz//NGs/ZBk3b96U2nv27BFxp06dpJx6WiaQs2RJUcY7noiIiIiIiIiISBcceCIiIiIiIiIiIl1w4ImIiIiIiIiIiHRhpaiLLhh7oA7zhSMjI6W2einm69evS7nVq1eL+PDhw1LOzs5OxNWrV5dy6uXamzVrJuW0NUfU9aeOHj0q5aZNmybi6OhoFCQTT5lJiso88G+//VZqv/766yLWLlHZoUMHqV1U5saWlPPap08fEWuXRnd0dBSxsRpw2nx8fLyUGzdunIhjY2PN76wFWPK8AoX73JY0JeWaLWl4XosnnlfzffbZZ1J7woQJIv7888+l3MSJE/OlT9n4GftMr169RLx+/Xop5+DgYHA7G5t8L/drMl6zxVNJPK+ffvqp1Fb/nfL9999LuUGDBuVLnyzNlPPKO56IiIiIiIiIiEgXHHgiIiIiIiIiIiJdFOhUO2dnZ6l97NgxEdeoUcPix9MuB6tdZv27774T8blz5yx+fEspibcoxsTESO02bdqIeOnSpVJu9OjR+dInSyuJ51U97Q4ABg4cKGLt86FdijQiIkLE2ql22scWJE4DKL5K4jVbEvC8Fk88r+arXLmy1D5x4oSItVO1vL29RXzjxg19OwZ+xubm7NmzUtvLy8vgYznVjvJbSTyv2vdCJycnEa9cuVLKjRw5Ml/6ZGmcakdERERERERERAWGA09ERERERERERKQLDjwREREREREREZEuCnRib1pamtRu0qSJiGfPni3l3NzcRNy3b18pt2/fPhEnJSVJuS1btohYPScdKNx1nIhKAnWdptzaREREVLCuX78utQ8fPizirl27Srlly5aJODg4WMplZWXp0DvS2rx5s9SeOHFiAfWEiADgyJEjUjsyMlLEa9asye/uFBje8URERERERERERLrgwBMREREREREREenCSjFxTcOislxhSVASl6GMiYmR2m3atBFxy5YtpVxcXFy+9MnSSuJ5LQm41HPxxWu2eOJ5LZ54Xi1n2LBhIl6yZImUs7W1FXG9evWknB4lLvgZW3zxmi2eeF6LJ1POK+94IiIiIiIiIiIiXXDgiYiIiIiIiIiIdMGBJyIiIiIiIiIi0oVNQXeAyBy3bt0S8Y0bNwqwJ0REREQlR3h4uIgbN24s5YKDg0V89+7dfOsTEREVbrzjiYiIiIiIiIiIdMGBJyIiIiIiIiIi0oWVYuKahlyusPDgMpTFE89r8cSlnosvXrPFE89r8cTzWjzxM7b44jVbPPG8Fk+mnFfe8URERERERERERLrgwBMREREREREREemCA09ERERERERERKQLk2s8ERERERERERER5QXveCIiIiIiIiIiIl1w4ImIiIiIiIiIiHTBgSciIiIiIiIiItIFB56IiIiIiIiIiEgXHHgiIiIiIiIiIiJdcOCJiIiIiIiIiIh0wYEnIiIiIiIiIiLSBQeeiIiIiIiIiIhIFxx4IiIiIiIiIiIiXfw/5N103L+no08AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x150 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_first_images(train_loader1, \"First 10 Trainset Subset 1 Images\")\n",
    "plot_first_images(train_loader2, \"First 10 Trainset Subset 2 Images\")\n",
    "plot_first_images(train_loader3, \"First 10 Trainset Subset 3 Images\")\n",
    "plot_first_images(train_loader4, \"First 10 Trainset Subset 4 Images\")\n",
    "plot_first_images(test_loader, \"First 10 Testset Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defining some variables and creating files & folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDFP = \"./volumes/Ultra Touch\" # Load HHD\n",
    "\n",
    "SAVE_LOC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch\"\n",
    "if not os.path.exists(SAVE_LOC):\n",
    "    os.makedirs(SAVE_LOC)\n",
    "\n",
    "SAVE_LOC_OLC = HDFP + \"/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc\"\n",
    "if not os.path.exists(SAVE_LOC_OLC):\n",
    "    os.makedirs(SAVE_LOC_OLC)\n",
    "\n",
    "SAVE_BRANCH_PRETRAINING = HDFP + \"/lobranch-snapshot/branchpoints/lenet/pretraining\"\n",
    "if not os.path.exists(SAVE_BRANCH_PRETRAINING):\n",
    "    os.makedirs(SAVE_BRANCH_PRETRAINING)\n",
    "\n",
    "SAVE_BRANCH = HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch\"\n",
    "if not os.path.exists(SAVE_BRANCH):\n",
    "    os.makedirs(SAVE_BRANCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pretraining the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Personal\\Singapour\\PFE\\code_of_shu-heng_with_models\\pfe_lc_lora\\wandb\\run-20240716_145235-qh7kbknh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace' target=\"_blank\">LeNet-Pretraining-Without-Incremental-Learning</a></strong> to <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of model training...\n",
      "Epoch: [0/49], Training Loss: 1.891492, Validation Loss: 1.149016, Training Accuracy: 0.558367, Validation Accuracy: 0.745900\n",
      "End of model training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fd4f2601174255831e67b3ff03c978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.55837</td></tr><tr><td>train_loss</td><td>1.89149</td></tr><tr><td>valid_accuracy</td><td>0.7459</td></tr><tr><td>valid_loss</td><td>1.14902</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-Pretraining-Without-Incremental-Learning</strong> at: <a href='https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet/runs/qh7kbknh/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240716_145235-qh7kbknh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_for_checkpoint = LeNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_for_checkpoint = nn.DataParallel(model_for_checkpoint)\n",
    "    model_for_checkpoint.to(device)\n",
    "else:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU!\")\n",
    "    model_for_checkpoint.to(device)\n",
    "\n",
    "# Training code\n",
    "NUM_EPOCHES = 50\n",
    "learning_rate = 0.005\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-Pretraining-Without-Incremental-Learning\", \n",
    "           tags=[\"LeNet\", \"Pretraining\", \"Without-Incremental-Learning\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"train dataset\": \"MNIST train dataset[:]\",\n",
    "                    \"test dataset\": \"MNIST test dataset[:]\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"optimizer\": \"SGD\",\n",
    "                }\n",
    "           )\n",
    "\n",
    "print(\"Start of model training...\")\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_for_checkpoint.train()\n",
    "        for iter, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_for_checkpoint(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_for_checkpoint.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_for_checkpoint(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    if valid_accuracy > 0.70:\n",
    "        torch.save(model_for_checkpoint.state_dict(), SAVE_BRANCH_PRETRAINING + \"/branch_{:.3f}.pt\".format(valid_accuracy))\n",
    "        print(\"Model saved with accuracy: {:.3f} in the file: branch_{:.3f}.pt\".format(valid_accuracy, valid_accuracy))\n",
    "        # Comment the line below if you want to train on the whole dataset\n",
    "        isLoop = False\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training...\")\n",
    "\n",
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First version : LeNet without Incremental Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_for_checkpoint = LeNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_for_checkpoint = nn.DataParallel(model_for_checkpoint)\n",
    "    model_for_checkpoint.to(device)\n",
    "else:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU!\")\n",
    "    model_for_checkpoint.to(device)\n",
    "\n",
    "# Training code\n",
    "NUM_EPOCHES = 50\n",
    "learning_rate = 0.02\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_for_checkpoint.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-Without-Incremental-Learning\", \n",
    "           tags=[\"LeNet\", \"Without-Incremental-Learning\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"train dataset\": \"MNIST train dataset[:]\",\n",
    "                    \"test dataset\": \"MNIST test dataset[:]\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"optimizer\": \"SGD\",\n",
    "                }\n",
    "           )\n",
    "\n",
    "print(\"Start of model training...\")\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_for_checkpoint.train()\n",
    "        for iter, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_for_checkpoint(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_for_checkpoint.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_for_checkpoint(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training...\")\n",
    "\n",
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Second version : LeNet with Incremental Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training on trainloader1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_with_incremental_learning = LeNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_with_incremental_learning = nn.DataParallel(model_with_incremental_learning)\n",
    "    model_with_incremental_learning.to(device)\n",
    "else:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU!\")\n",
    "    model_with_incremental_learning.to(device)\n",
    "\n",
    "# Training code\n",
    "NUM_EPOCHES = 45\n",
    "learning_rate = 0.01\n",
    "isLoop = True\n",
    "optimizer = torch.optim.SGD(model_with_incremental_learning.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-With-Incremental-Learning\", \n",
    "           tags=[\"LeNet\", \"With-Incremental-Learning\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"train dataset\": \"CIFAR10 train dataloader1\",\n",
    "                    \"test dataset\": \"CIFAR10 test dataset[:]\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"optimizer\": \"SGD\",\n",
    "                }\n",
    "           )\n",
    "\n",
    "\n",
    "\n",
    "print(\"Start of model training on dataloader1...\")\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_with_incremental_learning.train()\n",
    "        for iter, data in enumerate(train_loader1):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_with_incremental_learning(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_with_incremental_learning.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_with_incremental_learning(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader1.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training on dataloader1...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training on trainloader2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "# Training code on dataloader2\n",
    "print(\"Start of model training on dataloader2...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_with_incremental_learning.train()\n",
    "        for iter, data in enumerate(train_loader2):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_with_incremental_learning(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_with_incremental_learning.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_with_incremental_learning(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader2.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training on dataloader2...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training on trainloader3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "# Training code on dataloader2\n",
    "print(\"Start of model training on dataloader3...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_with_incremental_learning.train()\n",
    "        for iter, data in enumerate(train_loader3):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_with_incremental_learning(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_with_incremental_learning.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_with_incremental_learning(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader3.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "        \"epoch\": epoch\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"End of model training on dataloader3...\")\n",
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Third version : LeNet with Incremental Learning, LC-checkpoint, and Delta-LoRA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Personal\\Singapour\\PFE\\code_of_shu-heng_with_models\\pfe_lc_lora\\wandb\\run-20240705_131328-uwimhxwh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bryanbradfo/LeNet/runs/uwimhxwh/workspace' target=\"_blank\">LeNet-With-Incremental-Learning_LC_DLORA-Without-Restore_25_25_25_25</a></strong> to <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bryanbradfo/LeNet' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bryanbradfo/LeNet/runs/uwimhxwh/workspace' target=\"_blank\">https://wandb.ai/bryanbradfo/LeNet/runs/uwimhxwh/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of model training on dataloader1...\n",
      "Epoch: [0/29], Training Loss: 2.263898, Validation Loss: 2.211693, Training Accuracy: 0.247016, Validation Accuracy: 0.452200\n",
      "Epoch: [1/29], Training Loss: 2.111947, Validation Loss: 1.965460, Training Accuracy: 0.541380, Validation Accuracy: 0.571200\n",
      "Epoch: [2/29], Training Loss: 1.775779, Validation Loss: 1.560456, Training Accuracy: 0.561387, Validation Accuracy: 0.603400\n",
      "Model saved at accuracy: 0.7024\n",
      "End of model training on dataloader1...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_with_incremental_learning_lc_dlora = LeNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_with_incremental_learning_lc_dlora = nn.DataParallel(model_with_incremental_learning_lc_dlora)\n",
    "    model_with_incremental_learning_lc_dlora.to(device)\n",
    "else:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPU!\")\n",
    "    model_with_incremental_learning_lc_dlora.to(device)\n",
    "\n",
    "# Training code\n",
    "NUM_EPOCHES = 30\n",
    "learning_rate = 0.1\n",
    "learning_rate_dloralc = 0.1\n",
    "learning_rate1 = 0.005\n",
    "# super_step = len(train_loader2)\n",
    "# super_step = 20\n",
    "isLoop = True\n",
    "\n",
    "optimizer = torch.optim.SGD(model_with_incremental_learning_lc_dlora.parameters(), lr=learning_rate1)\n",
    "\n",
    "# Initialize a new W&B run\n",
    "wandb.init(project=\"LeNet\", \n",
    "           name=\"LeNet-With-Incremental-Learning_LC_DLORA-Without-Restore_25_25_25_25\", \n",
    "           tags=[\"LeNet\", \"With-Incremental-Learning_LC_DLORA\", \"MNIST\"],\n",
    "           config={\"num_epoches\": NUM_EPOCHES,\n",
    "                    \"model\": \"LeNet\",\n",
    "                    \"splitting\": \"25-25-25-25\",\n",
    "                    \"train dataset 1\": \"MNIST train dataloader1\",\n",
    "                    \"test dataset\": \"MNIST test dataset[:]\",\n",
    "                    \"batch_size on training\": train_batch_size,\n",
    "                    \"batch_size on testing\": test_batch_size,\n",
    "                    \"num_workers\": num_work,\n",
    "                    \"learning_rate_nothing\": learning_rate,\n",
    "                    \"learning_rate_dloralc\": learning_rate_dloralc,\n",
    "                    \"optimizer\": \"SGD\"\n",
    "                }\n",
    "           )\n",
    "\n",
    "print(\"Start of model training on dataloader1...\")\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if not isLoop:\n",
    "        break\n",
    "    else:\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        \n",
    "        model_with_incremental_learning_lc_dlora.train()\n",
    "        for iter, data in enumerate(train_loader1):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model_with_incremental_learning_lc_dlora(inputs)\n",
    "\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_acc = torch.eq(output.argmax(-1), labels).float().mean()\n",
    "\n",
    "        model_with_incremental_learning_lc_dlora.eval()\n",
    "        with torch.no_grad():  # Gradient computation is not needed for validation\n",
    "            for data, target in test_loader:\n",
    "                # Move data and target to the correct device\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model_with_incremental_learning_lc_dlora(data)\n",
    "                loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                valid_correct += (predicted == target).sum().item()\n",
    "                valid_total += target.size(0)\n",
    "\n",
    "                valid_acc = torch.eq(output.argmax(-1), target).float().mean()\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader1.dataset)\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "\n",
    "    train_accuarcy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "    if valid_accuracy > 0.7:\n",
    "        rounded_valid_acc = round(valid_accuracy, 4)\n",
    "        # torch.save(model_for_checkpoint.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/vit/branch_{}.pt\".format(rounded_valid_acc))\n",
    "        torch.save(model_with_incremental_learning_lc_dlora.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch_{}.pt\".format(rounded_valid_acc))\n",
    "        print(\"Model saved at accuracy: {:.4f}\".format(rounded_valid_acc))\n",
    "        isLoop = False\n",
    "        break\n",
    "    # if valid_accuracy > 0.90:\n",
    "    #     isLoop = False\n",
    "    #     break\n",
    "\n",
    "    print(\"Epoch: [{}/{}], Training Loss: {:.6f}, Validation Loss: {:.6f}, Training Accuracy: {:.6f}, Validation Accuracy: {:.6f}\".format(epoch, NUM_EPOCHES-1, train_loss, valid_loss, train_accuarcy, valid_accuracy))\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss_dloralc\": train_loss,\n",
    "        \"valid_loss_dloralc\": valid_loss,\n",
    "        \"train_accuracy_dloralc\": train_accuarcy,\n",
    "        \"valid_accuracy_dloralc\": valid_accuracy,\n",
    "        \"train_loss_lc\": train_loss,\n",
    "        \"valid_loss_lc\": valid_loss,\n",
    "        \"train_accuracy_lc\": train_accuarcy,\n",
    "        \"valid_accuracy_lc\": valid_accuracy, \n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"train_accuracy\": train_accuarcy,\n",
    "        \"valid_accuracy\": valid_accuracy,\n",
    "        \"epoch\": epoch,\n",
    "    })\n",
    "    # wandb.log({\n",
    "    #     \"train_loss_dloralc\": train_loss,\n",
    "    #     \"valid_loss_dloralc\": valid_loss,\n",
    "    #     \"train_accuracy_dloralc\": train_accuarcy,\n",
    "    #     \"valid_accuracy_dloralc\": valid_accuracy,\n",
    "    #     \"train_loss_lc\": train_loss,\n",
    "    #     \"valid_loss_lc\": valid_loss,\n",
    "    #     \"train_accuracy_lc\": train_accuarcy,\n",
    "    #     \"valid_accuracy_lc\": valid_accuracy, \n",
    "    #     \"train_loss\": train_loss,\n",
    "    #     \"valid_loss\": valid_loss,\n",
    "    #     \"train_accuracy\": train_accuarcy,\n",
    "    #     \"valid_accuracy\": valid_accuracy,\n",
    "    #     \"valid_loss_dloralc_restored\": valid_loss,\n",
    "    #     \"valid_accuracy_dloralc_restored\": valid_accuracy,\n",
    "    #     \"epoch\": epoch,\n",
    "    # })\n",
    "\n",
    "print(\"End of model training on dataloader1...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Working on training with delta-LoRA and LC-checkpoint** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECOMPOSED_LAYERS = [\"classifier.1.weight\", \"classifier.3.weight\"]\n",
    "RANK = -1\n",
    "SCALING = -1\n",
    "BRANCH_ACC = \"0.746\"\n",
    "learning_rate = 0.02\n",
    "learning_rate_dloralc = 0.1\n",
    "NUM_EPOCHES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "original = LeNet().to(device)\n",
    "model_original = LeNet().to(device)\n",
    "model_no_touch = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BRANCH_LOC = HDFP + \"/lobranch-snapshot/branchpoints/lenet/pretraining/branch_{}.pt\".format(BRANCH_ACC)\n",
    "original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "model_original.load_state_dict(torch.load(BRANCH_LOC))\n",
    "model_no_touch.load_state_dict(torch.load(BRANCH_LOC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = getBase(original)\n",
    "model = LeNet_LowRank(w, b, rank = RANK).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['feature.0.weight', 'feature.0.bias', 'feature.3.weight', 'feature.3.bias', 'classifier.1.alpha', 'classifier.1.beta', 'classifier.1.bias', 'classifier.3.alpha', 'classifier.3.beta', 'classifier.3.bias', 'classifier.5.weight', 'classifier.5.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sd_decomp(torch.load(BRANCH_LOC, map_location=device), model, DECOMPOSED_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate_dloralc)\n",
    "optimizer_lc_only = torch.optim.SGD(model_original.parameters(), lr=learning_rate)\n",
    "optimizer_no_touch = torch.optim.SGD(model_no_touch.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_accuracy = []\n",
    "decomposed_full_accuracy = []\n",
    "restored_accuracy = []\n",
    "lc_accuracy = []\n",
    "\n",
    "# Initialize the current iteration and set to 0\n",
    "current_iter = 0\n",
    "current_set = 0\n",
    "\n",
    "# Initialize the current iteration and set to 0 for the old LC method\n",
    "current_iter_old_lc = 0\n",
    "current_set_old_lc = 0\n",
    "\n",
    "acc = lambda x, y : (torch.max(x, 1)[1] == y).sum().item() / y.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Beginning of model training on train_loader1...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.1522830724716187\n",
      "LC Training Loss (Full): 1.1522830724716187\n",
      "Training Accuracy | Decomposed: 0.71875, Full : 0.71875\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.0814765691757202\n",
      "LC Training Loss (Full): 1.0913501977920532\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.1497668027877808\n",
      "LC Training Loss (Full): 1.1652253866195679\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.046074390411377\n",
      "LC Training Loss (Full): 1.0753167867660522\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.061497449874878\n",
      "LC Training Loss (Full): 1.0935132503509521\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.0272276401519775\n",
      "LC Training Loss (Full): 1.067211627960205\n",
      "Full accuracy (w/o dLoRA+LC): 0.7464, LC accuracy: 0.7463, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7406, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7417\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.1093250513076782\n",
      "LC Training Loss (Full): 1.1473454236984253\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.0632659196853638\n",
      "LC Training Loss (Full): 1.1121095418930054\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.1171038150787354\n",
      "LC Training Loss (Full): 1.173160433769226\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 1.042296290397644\n",
      "LC Training Loss (Full): 1.1103630065917969\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.065747857093811\n",
      "LC Training Loss (Full): 1.1007229089736938\n",
      "Full accuracy (w/o dLoRA+LC): 0.7537, LC accuracy: 0.7532, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7524, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7515\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.0855172872543335\n",
      "LC Training Loss (Full): 1.1173053979873657\n",
      "Epoch: 0, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.005049228668213\n",
      "LC Training Loss (Full): 1.0345022678375244\n",
      "Epoch: 0, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.0499095916748047\n",
      "LC Training Loss (Full): 1.0784157514572144\n",
      "Epoch: 0, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.1610643863677979\n",
      "LC Training Loss (Full): 1.18387770652771\n",
      "Epoch: 0, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.0529749393463135\n",
      "LC Training Loss (Full): 1.0766375064849854\n",
      "Full accuracy (w/o dLoRA+LC): 0.7537, LC accuracy: 0.7534, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7518, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7513\n",
      "Epoch: 0, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.136171579360962\n",
      "LC Training Loss (Full): 1.1518820524215698\n",
      "Epoch: 0, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.039664387702942\n",
      "LC Training Loss (Full): 1.0534015893936157\n",
      "Epoch: 0, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.1757944822311401\n",
      "LC Training Loss (Full): 1.1926349401474\n",
      "Epoch: 0, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 1.061938762664795\n",
      "LC Training Loss (Full): 1.077677845954895\n",
      "Epoch: 0, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0224884748458862\n",
      "LC Training Loss (Full): 1.0184481143951416\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.75\n",
      "Full accuracy (w/o dLoRA+LC): 0.7489, LC accuracy: 0.7492, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7487, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7495\n",
      "Epoch: 0, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.025344967842102\n",
      "LC Training Loss (Full): 1.0286445617675781\n",
      "Epoch: 0, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.1418554782867432\n",
      "LC Training Loss (Full): 1.1404139995574951\n",
      "Epoch: 0, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.958634614944458\n",
      "LC Training Loss (Full): 0.9506320953369141\n",
      "Epoch: 0, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.1095378398895264\n",
      "LC Training Loss (Full): 1.10440993309021\n",
      "Epoch: 0, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.118718147277832\n",
      "LC Training Loss (Full): 1.1074522733688354\n",
      "Full accuracy (w/o dLoRA+LC): 0.7566, LC accuracy: 0.7496, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7518, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7504\n",
      "Epoch: 0, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.0852153301239014\n",
      "LC Training Loss (Full): 1.0845794677734375\n",
      "Epoch: 0, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9319168329238892\n",
      "LC Training Loss (Full): 0.921083927154541\n",
      "Epoch: 0, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.0464966297149658\n",
      "LC Training Loss (Full): 1.0337167978286743\n",
      "Epoch: 0, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 1.0210026502609253\n",
      "LC Training Loss (Full): 1.0068427324295044\n",
      "Epoch: 0, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.1840004920959473\n",
      "LC Training Loss (Full): 1.1539480686187744\n",
      "Full accuracy (w/o dLoRA+LC): 0.7598, LC accuracy: 0.7583, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7525, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.753\n",
      "Epoch: 0, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 1.0381478071212769\n",
      "LC Training Loss (Full): 1.0124599933624268\n",
      "Epoch: 0, Iteration: 32\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 1.2429124116897583\n",
      "LC Training Loss (Full): 1.2174350023269653\n",
      "Epoch: 0, Iteration: 33\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 1.0916540622711182\n",
      "LC Training Loss (Full): 1.072669506072998\n",
      "Epoch: 0, Iteration: 34\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 1.0723438262939453\n",
      "LC Training Loss (Full): 1.0408371686935425\n",
      "Epoch: 0, Iteration: 35\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 1.0695778131484985\n",
      "LC Training Loss (Full): 1.0368088483810425\n",
      "Full accuracy (w/o dLoRA+LC): 0.7689, LC accuracy: 0.7587, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7561, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7545\n",
      "Epoch: 0, Iteration: 36\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 1.001704454421997\n",
      "LC Training Loss (Full): 0.9698887467384338\n",
      "Epoch: 0, Iteration: 37\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 1.0808777809143066\n",
      "LC Training Loss (Full): 1.037698745727539\n",
      "Epoch: 0, Iteration: 38\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.994748592376709\n",
      "LC Training Loss (Full): 0.9523682594299316\n",
      "Epoch: 0, Iteration: 39\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.9941797852516174\n",
      "LC Training Loss (Full): 0.9493990540504456\n",
      "Epoch: 0, Iteration: 40\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9905997514724731\n",
      "LC Training Loss (Full): 0.9478921294212341\n",
      "Training Accuracy | Decomposed: 0.6875, Full : 0.75\n",
      "Full accuracy (w/o dLoRA+LC): 0.7687, LC accuracy: 0.7723, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7549, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7549\n",
      "Epoch: 0, Iteration: 41\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.9490379095077515\n",
      "LC Training Loss (Full): 0.9026867747306824\n",
      "Epoch: 0, Iteration: 42\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.128454327583313\n",
      "LC Training Loss (Full): 1.0808616876602173\n",
      "Epoch: 0, Iteration: 43\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.9547665119171143\n",
      "LC Training Loss (Full): 0.9035495519638062\n",
      "Epoch: 0, Iteration: 44\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.0164899826049805\n",
      "LC Training Loss (Full): 0.960815966129303\n",
      "Epoch: 0, Iteration: 45\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.1121227741241455\n",
      "LC Training Loss (Full): 1.0536539554595947\n",
      "Full accuracy (w/o dLoRA+LC): 0.7706, LC accuracy: 0.7722, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7556, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7555\n",
      "Epoch: 0, Iteration: 46\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.9792315363883972\n",
      "LC Training Loss (Full): 0.9129381775856018\n",
      "Epoch: 0, Iteration: 47\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.9011834263801575\n",
      "LC Training Loss (Full): 0.8469685316085815\n",
      "Epoch: 0, Iteration: 48\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.0348036289215088\n",
      "LC Training Loss (Full): 0.9832422137260437\n",
      "Epoch: 0, Iteration: 49\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 1.1193702220916748\n",
      "LC Training Loss (Full): 1.0536696910858154\n",
      "Epoch: 0, Iteration: 50\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.910504162311554\n",
      "LC Training Loss (Full): 0.8306702375411987\n",
      "Full accuracy (w/o dLoRA+LC): 0.7742, LC accuracy: 0.7756, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7565, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7559\n",
      "Epoch: 0, Iteration: 51\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.2551794052124023\n",
      "LC Training Loss (Full): 1.1877171993255615\n",
      "Epoch: 0, Iteration: 52\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.1139249801635742\n",
      "LC Training Loss (Full): 1.0204368829727173\n",
      "Epoch: 0, Iteration: 53\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.0402588844299316\n",
      "LC Training Loss (Full): 0.9573070406913757\n",
      "Epoch: 0, Iteration: 54\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.9729213118553162\n",
      "LC Training Loss (Full): 0.903029203414917\n",
      "Epoch: 0, Iteration: 55\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.9682568907737732\n",
      "LC Training Loss (Full): 0.8687257766723633\n",
      "Full accuracy (w/o dLoRA+LC): 0.7839, LC accuracy: 0.7762, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7588, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7574\n",
      "Epoch: 0, Iteration: 56\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.9451001286506653\n",
      "LC Training Loss (Full): 0.8608920574188232\n",
      "Epoch: 0, Iteration: 57\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.9273505210876465\n",
      "LC Training Loss (Full): 0.8543676137924194\n",
      "Epoch: 0, Iteration: 58\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.0429383516311646\n",
      "LC Training Loss (Full): 0.9762084484100342\n",
      "Epoch: 0, Iteration: 59\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 1.038893461227417\n",
      "LC Training Loss (Full): 0.9626531004905701\n",
      "Epoch: 0, Iteration: 60\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0293524265289307\n",
      "LC Training Loss (Full): 0.9278630018234253\n",
      "Training Accuracy | Decomposed: 0.71875, Full : 0.75\n",
      "Full accuracy (w/o dLoRA+LC): 0.7833, LC accuracy: 0.7836, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7575, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7575\n",
      "Epoch: 0, Iteration: 61\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.1562631130218506\n",
      "LC Training Loss (Full): 1.061767816543579\n",
      "Epoch: 0, Iteration: 62\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.9932132959365845\n",
      "LC Training Loss (Full): 0.8992438912391663\n",
      "Epoch: 0, Iteration: 63\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.877213716506958\n",
      "LC Training Loss (Full): 0.7951378226280212\n",
      "Epoch: 0, Iteration: 64\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.0422489643096924\n",
      "LC Training Loss (Full): 0.9288336038589478\n",
      "Epoch: 0, Iteration: 65\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.017856240272522\n",
      "LC Training Loss (Full): 0.9298818111419678\n",
      "Full accuracy (w/o dLoRA+LC): 0.7897, LC accuracy: 0.7843, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7596, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7581\n",
      "Epoch: 0, Iteration: 66\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.9891712665557861\n",
      "LC Training Loss (Full): 0.9000750184059143\n",
      "Epoch: 0, Iteration: 67\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.952341616153717\n",
      "LC Training Loss (Full): 0.8629504442214966\n",
      "Epoch: 0, Iteration: 68\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.9708029627799988\n",
      "LC Training Loss (Full): 0.8486242294311523\n",
      "Epoch: 0, Iteration: 69\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 1.152712106704712\n",
      "LC Training Loss (Full): 1.0501834154129028\n",
      "Epoch: 0, Iteration: 70\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0042742490768433\n",
      "LC Training Loss (Full): 0.8734139204025269\n",
      "Full accuracy (w/o dLoRA+LC): 0.7949, LC accuracy: 0.7936, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7586, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7588\n",
      "Epoch: 0, Iteration: 71\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 1.0146421194076538\n",
      "LC Training Loss (Full): 0.900275707244873\n",
      "Epoch: 0, Iteration: 72\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.9948725700378418\n",
      "LC Training Loss (Full): 0.8812295198440552\n",
      "Epoch: 0, Iteration: 73\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 1.0981998443603516\n",
      "LC Training Loss (Full): 0.9850621819496155\n",
      "Epoch: 0, Iteration: 74\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 1.0364822149276733\n",
      "LC Training Loss (Full): 0.9050540328025818\n",
      "Epoch: 0, Iteration: 75\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 1.0024898052215576\n",
      "LC Training Loss (Full): 0.8892392516136169\n",
      "Full accuracy (w/o dLoRA+LC): 0.7955, LC accuracy: 0.7937, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7593, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7594\n",
      "Epoch: 0, Iteration: 76\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 1.065778136253357\n",
      "LC Training Loss (Full): 0.9496662020683289\n",
      "Epoch: 0, Iteration: 77\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 1.0099233388900757\n",
      "LC Training Loss (Full): 0.887576699256897\n",
      "Epoch: 0, Iteration: 78\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.991021990776062\n",
      "LC Training Loss (Full): 0.8629541993141174\n",
      "Epoch: 0, Iteration: 79\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 1.0329440832138062\n",
      "LC Training Loss (Full): 0.9052619338035583\n",
      "Epoch: 0, Iteration: 80\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0121312141418457\n",
      "LC Training Loss (Full): 0.9056915044784546\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.796875\n",
      "Full accuracy (w/o dLoRA+LC): 0.7983, LC accuracy: 0.7976, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7591, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.759\n",
      "Epoch: 0, Iteration: 81\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.9889926910400391\n",
      "LC Training Loss (Full): 0.8491337299346924\n",
      "Epoch: 0, Iteration: 82\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.0424684286117554\n",
      "LC Training Loss (Full): 0.9016910791397095\n",
      "Epoch: 0, Iteration: 83\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.1233102083206177\n",
      "LC Training Loss (Full): 0.9768869876861572\n",
      "Epoch: 0, Iteration: 84\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.1159642934799194\n",
      "LC Training Loss (Full): 0.9547935128211975\n",
      "Epoch: 0, Iteration: 85\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.9788432121276855\n",
      "LC Training Loss (Full): 0.8308233022689819\n",
      "Full accuracy (w/o dLoRA+LC): 0.8009, LC accuracy: 0.7983, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7594, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7585\n",
      "Epoch: 0, Iteration: 86\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.8388795852661133\n",
      "LC Training Loss (Full): 0.7115102410316467\n",
      "Epoch: 0, Iteration: 87\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.1100647449493408\n",
      "LC Training Loss (Full): 0.9832633137702942\n",
      "Epoch: 0, Iteration: 88\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.9454978704452515\n",
      "LC Training Loss (Full): 0.8228418231010437\n",
      "Epoch: 0, Iteration: 89\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 1.0400991439819336\n",
      "LC Training Loss (Full): 0.9169471859931946\n",
      "Epoch: 0, Iteration: 90\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0023154020309448\n",
      "LC Training Loss (Full): 0.8565798997879028\n",
      "Full accuracy (w/o dLoRA+LC): 0.8006, LC accuracy: 0.8027, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7593, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7593\n",
      "Epoch: 0, Iteration: 91\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.932770311832428\n",
      "LC Training Loss (Full): 0.7862100601196289\n",
      "Epoch: 0, Iteration: 92\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.945254921913147\n",
      "LC Training Loss (Full): 0.8062494993209839\n",
      "Epoch: 0, Iteration: 93\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.0066652297973633\n",
      "LC Training Loss (Full): 0.8620181679725647\n",
      "Epoch: 0, Iteration: 94\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.9597582221031189\n",
      "LC Training Loss (Full): 0.8126267194747925\n",
      "Epoch: 0, Iteration: 95\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.1911070346832275\n",
      "LC Training Loss (Full): 1.0359218120574951\n",
      "Full accuracy (w/o dLoRA+LC): 0.808, LC accuracy: 0.8031, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7636, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7619\n",
      "Epoch: 0, Iteration: 96\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.990494430065155\n",
      "LC Training Loss (Full): 0.820349931716919\n",
      "Epoch: 0, Iteration: 97\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 1.0195801258087158\n",
      "LC Training Loss (Full): 0.8676108121871948\n",
      "Epoch: 0, Iteration: 98\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.9596824645996094\n",
      "LC Training Loss (Full): 0.7992611527442932\n",
      "Epoch: 0, Iteration: 99\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.9818323254585266\n",
      "LC Training Loss (Full): 0.8072899580001831\n",
      "Epoch: 0, Iteration: 100\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0598987340927124\n",
      "LC Training Loss (Full): 0.8895310759544373\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.8125\n",
      "Full accuracy (w/o dLoRA+LC): 0.8091, LC accuracy: 0.8095, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7633, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.763\n",
      "Epoch: 0, Iteration: 101\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.9618953466415405\n",
      "LC Training Loss (Full): 0.7887621521949768\n",
      "Epoch: 0, Iteration: 102\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.9643027782440186\n",
      "LC Training Loss (Full): 0.8181361556053162\n",
      "Epoch: 0, Iteration: 103\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.9619068503379822\n",
      "LC Training Loss (Full): 0.7961304783821106\n",
      "Epoch: 0, Iteration: 104\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.9566181302070618\n",
      "LC Training Loss (Full): 0.7758236527442932\n",
      "Epoch: 0, Iteration: 105\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.0005269050598145\n",
      "LC Training Loss (Full): 0.8366253972053528\n",
      "Full accuracy (w/o dLoRA+LC): 0.8132, LC accuracy: 0.8101, Decomposed-Full (w/dLoRA+LC) accuracy: 0.765, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7633\n",
      "Epoch: 0, Iteration: 106\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.1238646507263184\n",
      "LC Training Loss (Full): 0.9336214661598206\n",
      "Epoch: 0, Iteration: 107\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.9347342252731323\n",
      "LC Training Loss (Full): 0.7545185685157776\n",
      "Epoch: 0, Iteration: 108\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 1.0342936515808105\n",
      "LC Training Loss (Full): 0.8555497527122498\n",
      "Epoch: 0, Iteration: 109\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.9611724615097046\n",
      "LC Training Loss (Full): 0.7822242975234985\n",
      "Epoch: 0, Iteration: 110\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0362472534179688\n",
      "LC Training Loss (Full): 0.8437718152999878\n",
      "Full accuracy (w/o dLoRA+LC): 0.813, LC accuracy: 0.8117, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7634, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7628\n",
      "Epoch: 0, Iteration: 111\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.9986445307731628\n",
      "LC Training Loss (Full): 0.799508273601532\n",
      "Epoch: 0, Iteration: 112\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.8700393438339233\n",
      "LC Training Loss (Full): 0.6536259651184082\n",
      "Epoch: 0, Iteration: 113\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.991113007068634\n",
      "LC Training Loss (Full): 0.8025022149085999\n",
      "Epoch: 0, Iteration: 114\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.998822033405304\n",
      "LC Training Loss (Full): 0.8488617539405823\n",
      "Epoch: 0, Iteration: 115\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.9431831240653992\n",
      "LC Training Loss (Full): 0.789030134677887\n",
      "Full accuracy (w/o dLoRA+LC): 0.8168, LC accuracy: 0.8124, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7662, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7641\n",
      "Epoch: 0, Iteration: 116\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 1.0796048641204834\n",
      "LC Training Loss (Full): 0.8876597881317139\n",
      "Epoch: 0, Iteration: 117\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 1.0365614891052246\n",
      "LC Training Loss (Full): 0.8607941269874573\n",
      "Epoch: 0, Iteration: 118\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.9374896883964539\n",
      "LC Training Loss (Full): 0.7421823143959045\n",
      "Epoch: 0, Iteration: 119\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 1.0380674600601196\n",
      "LC Training Loss (Full): 0.8557493090629578\n",
      "Epoch: 0, Iteration: 120\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0055314302444458\n",
      "LC Training Loss (Full): 0.81124347448349\n",
      "Training Accuracy | Decomposed: 0.6875, Full : 0.75\n",
      "Full accuracy (w/o dLoRA+LC): 0.8192, LC accuracy: 0.8192, Decomposed-Full (w/dLoRA+LC) accuracy: 0.766, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7656\n",
      "Epoch: 0, Iteration: 121\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.9702008366584778\n",
      "LC Training Loss (Full): 0.7417608499526978\n",
      "Epoch: 0, Iteration: 122\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.9694598913192749\n",
      "LC Training Loss (Full): 0.7727828025817871\n",
      "Epoch: 0, Iteration: 123\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.9943045377731323\n",
      "LC Training Loss (Full): 0.8243524432182312\n",
      "Epoch: 0, Iteration: 124\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.8873487710952759\n",
      "LC Training Loss (Full): 0.7110819816589355\n",
      "Epoch: 0, Iteration: 125\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.9006290435791016\n",
      "LC Training Loss (Full): 0.7043126821517944\n",
      "Full accuracy (w/o dLoRA+LC): 0.8217, LC accuracy: 0.8189, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7673, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7658\n",
      "Epoch: 0, Iteration: 126\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.8841499090194702\n",
      "LC Training Loss (Full): 0.6659538745880127\n",
      "Epoch: 0, Iteration: 127\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.9198383688926697\n",
      "LC Training Loss (Full): 0.7224180102348328\n",
      "Epoch: 0, Iteration: 128\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 1.0638405084609985\n",
      "LC Training Loss (Full): 0.8523114323616028\n",
      "Epoch: 0, Iteration: 129\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.8930699229240417\n",
      "LC Training Loss (Full): 0.6944113373756409\n",
      "Epoch: 0, Iteration: 130\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0712978839874268\n",
      "LC Training Loss (Full): 0.8464218378067017\n",
      "Full accuracy (w/o dLoRA+LC): 0.8247, LC accuracy: 0.8207, Decomposed-Full (w/dLoRA+LC) accuracy: 0.767, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7658\n",
      "Epoch: 0, Iteration: 131\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8880571722984314\n",
      "LC Training Loss (Full): 0.7177480459213257\n",
      "Epoch: 0, Iteration: 132\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8534905314445496\n",
      "LC Training Loss (Full): 0.6637930274009705\n",
      "Epoch: 0, Iteration: 133\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.066097378730774\n",
      "LC Training Loss (Full): 0.863606870174408\n",
      "Epoch: 0, Iteration: 134\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 1.029582142829895\n",
      "LC Training Loss (Full): 0.8000138998031616\n",
      "Epoch: 0, Iteration: 135\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.9181026816368103\n",
      "LC Training Loss (Full): 0.7009329795837402\n",
      "Full accuracy (w/o dLoRA+LC): 0.8253, LC accuracy: 0.821, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7686, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7675\n",
      "Epoch: 0, Iteration: 136\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8265554904937744\n",
      "LC Training Loss (Full): 0.6345016360282898\n",
      "Epoch: 0, Iteration: 137\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.9790302515029907\n",
      "LC Training Loss (Full): 0.7964410185813904\n",
      "Epoch: 0, Iteration: 138\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.9912370443344116\n",
      "LC Training Loss (Full): 0.7791784405708313\n",
      "Epoch: 0, Iteration: 139\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.9606215357780457\n",
      "LC Training Loss (Full): 0.723867654800415\n",
      "Epoch: 0, Iteration: 140\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 1.0361015796661377\n",
      "LC Training Loss (Full): 0.8213717937469482\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.765625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8263, LC accuracy: 0.8246, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7675, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7667\n",
      "Epoch: 0, Iteration: 141\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.9006698131561279\n",
      "LC Training Loss (Full): 0.6635742783546448\n",
      "Epoch: 0, Iteration: 142\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.9558125734329224\n",
      "LC Training Loss (Full): 0.7091116309165955\n",
      "Epoch: 0, Iteration: 143\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.878108024597168\n",
      "LC Training Loss (Full): 0.6824555993080139\n",
      "Epoch: 0, Iteration: 144\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.014631748199463\n",
      "LC Training Loss (Full): 0.8273782134056091\n",
      "Epoch: 0, Iteration: 145\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.9290837049484253\n",
      "LC Training Loss (Full): 0.7225861549377441\n",
      "Full accuracy (w/o dLoRA+LC): 0.8292, LC accuracy: 0.8248, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7691, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7677\n",
      "Epoch: 0, Iteration: 146\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.9560627341270447\n",
      "LC Training Loss (Full): 0.7330605387687683\n",
      "Epoch: 0, Iteration: 147\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.9070625305175781\n",
      "LC Training Loss (Full): 0.7312957048416138\n",
      "Epoch: 0, Iteration: 148\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 1.083046317100525\n",
      "LC Training Loss (Full): 0.8525022864341736\n",
      "Epoch: 0, Iteration: 149\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.9835376739501953\n",
      "LC Training Loss (Full): 0.7760065197944641\n",
      "Epoch: 0, Iteration: 150\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9130876064300537\n",
      "LC Training Loss (Full): 0.707835853099823\n",
      "Full accuracy (w/o dLoRA+LC): 0.8267, LC accuracy: 0.8277, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7665, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7668\n",
      "Epoch: 0, Iteration: 151\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.975102961063385\n",
      "LC Training Loss (Full): 0.7761973738670349\n",
      "Epoch: 0, Iteration: 152\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.8424333333969116\n",
      "LC Training Loss (Full): 0.6037155389785767\n",
      "Epoch: 0, Iteration: 153\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.9928032755851746\n",
      "LC Training Loss (Full): 0.7650859355926514\n",
      "Epoch: 0, Iteration: 154\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.9587552547454834\n",
      "LC Training Loss (Full): 0.7602100372314453\n",
      "Epoch: 0, Iteration: 155\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 1.0201164484024048\n",
      "LC Training Loss (Full): 0.8126163482666016\n",
      "Full accuracy (w/o dLoRA+LC): 0.8299, LC accuracy: 0.8277, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7686, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7681\n",
      "Epoch: 0, Iteration: 156\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.9072583913803101\n",
      "LC Training Loss (Full): 0.6645451784133911\n",
      "Epoch: 0, Iteration: 157\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.9829369783401489\n",
      "LC Training Loss (Full): 0.722294807434082\n",
      "Epoch: 0, Iteration: 158\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.9076327681541443\n",
      "LC Training Loss (Full): 0.6941762566566467\n",
      "Epoch: 0, Iteration: 159\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.8844748735427856\n",
      "LC Training Loss (Full): 0.6377331018447876\n",
      "Epoch: 0, Iteration: 160\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9579615592956543\n",
      "LC Training Loss (Full): 0.7149784564971924\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.859375\n",
      "Full accuracy (w/o dLoRA+LC): 0.8334, LC accuracy: 0.8336, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7695, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7689\n",
      "Epoch: 0, Iteration: 161\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 1.061488389968872\n",
      "LC Training Loss (Full): 0.76140296459198\n",
      "Epoch: 0, Iteration: 162\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.9623311161994934\n",
      "LC Training Loss (Full): 0.6945114135742188\n",
      "Epoch: 0, Iteration: 163\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.9074918031692505\n",
      "LC Training Loss (Full): 0.6717365384101868\n",
      "Epoch: 0, Iteration: 164\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.8492384552955627\n",
      "LC Training Loss (Full): 0.6364394426345825\n",
      "Epoch: 0, Iteration: 165\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.9982222318649292\n",
      "LC Training Loss (Full): 0.7709333300590515\n",
      "Full accuracy (w/o dLoRA+LC): 0.8357, LC accuracy: 0.8337, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7713, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7702\n",
      "Epoch: 0, Iteration: 166\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.948782742023468\n",
      "LC Training Loss (Full): 0.6814954280853271\n",
      "Epoch: 0, Iteration: 167\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.8836950659751892\n",
      "LC Training Loss (Full): 0.6554235219955444\n",
      "Epoch: 0, Iteration: 168\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.9122710824012756\n",
      "LC Training Loss (Full): 0.6389322876930237\n",
      "Epoch: 0, Iteration: 169\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.9723037481307983\n",
      "LC Training Loss (Full): 0.7520709037780762\n",
      "Epoch: 0, Iteration: 170\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8244688510894775\n",
      "LC Training Loss (Full): 0.5954753756523132\n",
      "Full accuracy (w/o dLoRA+LC): 0.8356, LC accuracy: 0.8373, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7699, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.771\n",
      "Epoch: 0, Iteration: 171\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8606137633323669\n",
      "LC Training Loss (Full): 0.5874282717704773\n",
      "Epoch: 0, Iteration: 172\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.9056409597396851\n",
      "LC Training Loss (Full): 0.6740530133247375\n",
      "Epoch: 0, Iteration: 173\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.9641510248184204\n",
      "LC Training Loss (Full): 0.6832034587860107\n",
      "Epoch: 0, Iteration: 174\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.9035370945930481\n",
      "LC Training Loss (Full): 0.6585289835929871\n",
      "Epoch: 0, Iteration: 175\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.9048868417739868\n",
      "LC Training Loss (Full): 0.6422483325004578\n",
      "Full accuracy (w/o dLoRA+LC): 0.838, LC accuracy: 0.8372, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7711, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7703\n",
      "Epoch: 0, Iteration: 176\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.0554661750793457\n",
      "LC Training Loss (Full): 0.8140970468521118\n",
      "Epoch: 0, Iteration: 177\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8686655163764954\n",
      "LC Training Loss (Full): 0.6163433790206909\n",
      "Epoch: 0, Iteration: 178\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.1105754375457764\n",
      "LC Training Loss (Full): 0.9395939707756042\n",
      "Epoch: 0, Iteration: 179\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 1.0548744201660156\n",
      "LC Training Loss (Full): 0.8244019746780396\n",
      "Epoch: 0, Iteration: 180\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8797965049743652\n",
      "LC Training Loss (Full): 0.611559271812439\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.84375\n",
      "Full accuracy (w/o dLoRA+LC): 0.8391, LC accuracy: 0.8397, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7709, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7709\n",
      "Epoch: 0, Iteration: 181\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.9707682132720947\n",
      "LC Training Loss (Full): 0.6483741402626038\n",
      "Epoch: 0, Iteration: 182\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.9046593904495239\n",
      "LC Training Loss (Full): 0.592766284942627\n",
      "Epoch: 0, Iteration: 183\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.9440653324127197\n",
      "LC Training Loss (Full): 0.646439254283905\n",
      "Epoch: 0, Iteration: 184\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.973651647567749\n",
      "LC Training Loss (Full): 0.7072664499282837\n",
      "Epoch: 0, Iteration: 185\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.9838775396347046\n",
      "LC Training Loss (Full): 0.7367877960205078\n",
      "Full accuracy (w/o dLoRA+LC): 0.8392, LC accuracy: 0.8407, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7734, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7716\n",
      "Epoch: 0, Iteration: 186\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.819859504699707\n",
      "LC Training Loss (Full): 0.62664794921875\n",
      "Epoch: 0, Iteration: 187\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.9019044637680054\n",
      "LC Training Loss (Full): 0.6346332430839539\n",
      "Epoch: 0, Iteration: 188\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.9886109828948975\n",
      "LC Training Loss (Full): 0.7393813729286194\n",
      "Epoch: 0, Iteration: 189\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.8556734919548035\n",
      "LC Training Loss (Full): 0.6206452250480652\n",
      "Epoch: 0, Iteration: 190\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9331541657447815\n",
      "LC Training Loss (Full): 0.6762616038322449\n",
      "Full accuracy (w/o dLoRA+LC): 0.8383, LC accuracy: 0.8389, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7708, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7696\n",
      "Epoch: 0, Iteration: 191\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.9252446293830872\n",
      "LC Training Loss (Full): 0.6340171098709106\n",
      "Epoch: 0, Iteration: 192\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.8860158324241638\n",
      "LC Training Loss (Full): 0.6505593061447144\n",
      "Epoch: 0, Iteration: 193\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.9340774416923523\n",
      "LC Training Loss (Full): 0.6758553385734558\n",
      "Epoch: 0, Iteration: 194\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.9618650078773499\n",
      "LC Training Loss (Full): 0.642802357673645\n",
      "Epoch: 0, Iteration: 195\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 1.1581284999847412\n",
      "LC Training Loss (Full): 0.8501753807067871\n",
      "Full accuracy (w/o dLoRA+LC): 0.8418, LC accuracy: 0.8392, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7733, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7718\n",
      "Epoch: 0, Iteration: 196\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.9395925402641296\n",
      "LC Training Loss (Full): 0.6469638347625732\n",
      "Epoch: 0, Iteration: 197\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 1.0528942346572876\n",
      "LC Training Loss (Full): 0.7359407544136047\n",
      "Epoch: 0, Iteration: 198\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.958267092704773\n",
      "LC Training Loss (Full): 0.6449994444847107\n",
      "Epoch: 0, Iteration: 199\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.8038036227226257\n",
      "LC Training Loss (Full): 0.5225426554679871\n",
      "Epoch: 0, Iteration: 200\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.873762309551239\n",
      "LC Training Loss (Full): 0.628858208656311\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.796875\n",
      "Full accuracy (w/o dLoRA+LC): 0.8432, LC accuracy: 0.8428, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7734, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7725\n",
      "Epoch: 0, Iteration: 201\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.9003934264183044\n",
      "LC Training Loss (Full): 0.6111921072006226\n",
      "Epoch: 0, Iteration: 202\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.9096576571464539\n",
      "LC Training Loss (Full): 0.6194947361946106\n",
      "Epoch: 0, Iteration: 203\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.8770884871482849\n",
      "LC Training Loss (Full): 0.6023209095001221\n",
      "Epoch: 0, Iteration: 204\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 1.0290826559066772\n",
      "LC Training Loss (Full): 0.8337961435317993\n",
      "Epoch: 0, Iteration: 205\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.8504239916801453\n",
      "LC Training Loss (Full): 0.5980934500694275\n",
      "Full accuracy (w/o dLoRA+LC): 0.8474, LC accuracy: 0.8432, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7753, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7726\n",
      "Epoch: 0, Iteration: 206\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.8103576302528381\n",
      "LC Training Loss (Full): 0.5374158024787903\n",
      "Epoch: 0, Iteration: 207\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7999789118766785\n",
      "LC Training Loss (Full): 0.5560168623924255\n",
      "Epoch: 0, Iteration: 208\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7162359356880188\n",
      "LC Training Loss (Full): 0.48967644572257996\n",
      "Epoch: 0, Iteration: 209\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.9801362752914429\n",
      "LC Training Loss (Full): 0.6744514107704163\n",
      "Epoch: 0, Iteration: 210\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8325709700584412\n",
      "LC Training Loss (Full): 0.5994027256965637\n",
      "Full accuracy (w/o dLoRA+LC): 0.8468, LC accuracy: 0.8464, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7736, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7738\n",
      "Epoch: 0, Iteration: 211\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.8232041001319885\n",
      "LC Training Loss (Full): 0.5667275190353394\n",
      "Epoch: 0, Iteration: 212\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 1.0472725629806519\n",
      "LC Training Loss (Full): 0.7982051372528076\n",
      "Epoch: 0, Iteration: 213\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.8265827894210815\n",
      "LC Training Loss (Full): 0.555159330368042\n",
      "Epoch: 0, Iteration: 214\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.8060171008110046\n",
      "LC Training Loss (Full): 0.6007117033004761\n",
      "Epoch: 0, Iteration: 215\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.841375470161438\n",
      "LC Training Loss (Full): 0.5596240758895874\n",
      "Full accuracy (w/o dLoRA+LC): 0.8479, LC accuracy: 0.8463, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7747, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7747\n",
      "Epoch: 0, Iteration: 216\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.7871446013450623\n",
      "LC Training Loss (Full): 0.5783743262290955\n",
      "Epoch: 0, Iteration: 217\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.828525722026825\n",
      "LC Training Loss (Full): 0.4948239326477051\n",
      "Epoch: 0, Iteration: 218\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.7573803663253784\n",
      "LC Training Loss (Full): 0.4738323390483856\n",
      "Epoch: 0, Iteration: 219\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.7614440321922302\n",
      "LC Training Loss (Full): 0.5224611759185791\n",
      "Epoch: 0, Iteration: 220\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8344741463661194\n",
      "LC Training Loss (Full): 0.5671760439872742\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.8125\n",
      "Full accuracy (w/o dLoRA+LC): 0.8475, LC accuracy: 0.8482, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7731, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7748\n",
      "Epoch: 0, Iteration: 221\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 1.0691691637039185\n",
      "LC Training Loss (Full): 0.8596281409263611\n",
      "Epoch: 0, Iteration: 222\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.7935059070587158\n",
      "LC Training Loss (Full): 0.5447095036506653\n",
      "Epoch: 0, Iteration: 223\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.933524489402771\n",
      "LC Training Loss (Full): 0.6994768381118774\n",
      "Epoch: 0, Iteration: 224\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.9503149390220642\n",
      "LC Training Loss (Full): 0.6872755289077759\n",
      "Epoch: 0, Iteration: 225\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.9218340516090393\n",
      "LC Training Loss (Full): 0.6046664714813232\n",
      "Full accuracy (w/o dLoRA+LC): 0.8474, LC accuracy: 0.8483, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7739, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7737\n",
      "Epoch: 0, Iteration: 226\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.7942877411842346\n",
      "LC Training Loss (Full): 0.5790559649467468\n",
      "Epoch: 0, Iteration: 227\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.780961275100708\n",
      "LC Training Loss (Full): 0.5410869717597961\n",
      "Epoch: 0, Iteration: 228\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.8564561009407043\n",
      "LC Training Loss (Full): 0.6526352763175964\n",
      "Epoch: 0, Iteration: 229\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.8747319579124451\n",
      "LC Training Loss (Full): 0.590781569480896\n",
      "Epoch: 0, Iteration: 230\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_23\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8845758438110352\n",
      "LC Training Loss (Full): 0.586081326007843\n",
      "Full accuracy (w/o dLoRA+LC): 0.8501, LC accuracy: 0.8493, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7742, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7726\n",
      "Epoch: 0, Iteration: 231\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.9743528962135315\n",
      "LC Training Loss (Full): 0.6873769164085388\n",
      "Epoch: 0, Iteration: 232\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.7426428198814392\n",
      "LC Training Loss (Full): 0.49948763847351074\n",
      "Epoch: 0, Iteration: 233\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 1.0588164329528809\n",
      "LC Training Loss (Full): 0.751151978969574\n",
      "Epoch: 0, Iteration: 234\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 1.067273497581482\n",
      "LC Training Loss (Full): 0.7069210410118103\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8984713554382324\n",
      "LC Training Loss (Full): 0.5981839895248413\n",
      "Training Accuracy | Decomposed: 0.6875, Full : 0.828125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.9124581217765808\n",
      "LC Training Loss (Full): 0.6017852425575256\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.9888803958892822\n",
      "LC Training Loss (Full): 0.7477051019668579\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7436694502830505\n",
      "LC Training Loss (Full): 0.4673035740852356\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.8211390376091003\n",
      "LC Training Loss (Full): 0.5003474950790405\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.8435612916946411\n",
      "LC Training Loss (Full): 0.5830828547477722\n",
      "Full accuracy (w/o dLoRA+LC): 0.8521, LC accuracy: 0.8503, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7734, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7736\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.833153486251831\n",
      "LC Training Loss (Full): 0.5264574289321899\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.756624162197113\n",
      "LC Training Loss (Full): 0.5147112607955933\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.8538753390312195\n",
      "LC Training Loss (Full): 0.5964539051055908\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.937677264213562\n",
      "LC Training Loss (Full): 0.6597861051559448\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9559726119041443\n",
      "LC Training Loss (Full): 0.669369101524353\n",
      "Full accuracy (w/o dLoRA+LC): 0.852, LC accuracy: 0.8518, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7742, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7749\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7300280332565308\n",
      "LC Training Loss (Full): 0.4349307119846344\n",
      "Epoch: 1, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.8427992463111877\n",
      "LC Training Loss (Full): 0.5418440699577332\n",
      "Epoch: 1, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.100595474243164\n",
      "LC Training Loss (Full): 0.7782055139541626\n",
      "Epoch: 1, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7628355026245117\n",
      "LC Training Loss (Full): 0.4236811697483063\n",
      "Epoch: 1, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.831204354763031\n",
      "LC Training Loss (Full): 0.45932283997535706\n",
      "Full accuracy (w/o dLoRA+LC): 0.8536, LC accuracy: 0.852, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7778, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7756\n",
      "Epoch: 1, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.0165458917617798\n",
      "LC Training Loss (Full): 0.672886073589325\n",
      "Epoch: 1, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.9986118078231812\n",
      "LC Training Loss (Full): 0.7361260056495667\n",
      "Epoch: 1, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.9367290139198303\n",
      "LC Training Loss (Full): 0.6596595048904419\n",
      "Epoch: 1, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.020706057548523\n",
      "LC Training Loss (Full): 0.7485095262527466\n",
      "Epoch: 1, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9651002883911133\n",
      "LC Training Loss (Full): 0.5500421524047852\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.858, LC accuracy: 0.8579, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7772, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7774\n",
      "Epoch: 1, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6655416488647461\n",
      "LC Training Loss (Full): 0.40879684686660767\n",
      "Epoch: 1, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.9735403656959534\n",
      "LC Training Loss (Full): 0.6028643250465393\n",
      "Epoch: 1, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.8557749390602112\n",
      "LC Training Loss (Full): 0.5366887450218201\n",
      "Epoch: 1, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.9747178554534912\n",
      "LC Training Loss (Full): 0.6064291596412659\n",
      "Epoch: 1, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.8916400074958801\n",
      "LC Training Loss (Full): 0.5921108722686768\n",
      "Full accuracy (w/o dLoRA+LC): 0.8568, LC accuracy: 0.858, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7767, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7763\n",
      "Epoch: 1, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.9818614721298218\n",
      "LC Training Loss (Full): 0.6462124586105347\n",
      "Epoch: 1, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.9348943829536438\n",
      "LC Training Loss (Full): 0.623382031917572\n",
      "Epoch: 1, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.8223390579223633\n",
      "LC Training Loss (Full): 0.5707539319992065\n",
      "Epoch: 1, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.898494303226471\n",
      "LC Training Loss (Full): 0.6853493452072144\n",
      "Epoch: 1, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9501514434814453\n",
      "LC Training Loss (Full): 0.633566677570343\n",
      "Full accuracy (w/o dLoRA+LC): 0.8597, LC accuracy: 0.8584, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7775, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7776\n",
      "Epoch: 1, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.935703694820404\n",
      "LC Training Loss (Full): 0.5559407472610474\n",
      "Epoch: 1, Iteration: 32\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 1.0886272192001343\n",
      "LC Training Loss (Full): 0.7613773941993713\n",
      "Epoch: 1, Iteration: 33\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.8877441883087158\n",
      "LC Training Loss (Full): 0.619500458240509\n",
      "Epoch: 1, Iteration: 34\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.789164662361145\n",
      "LC Training Loss (Full): 0.47101321816444397\n",
      "Epoch: 1, Iteration: 35\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.8013515472412109\n",
      "LC Training Loss (Full): 0.4993295669555664\n",
      "Full accuracy (w/o dLoRA+LC): 0.8597, LC accuracy: 0.8587, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7796, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7789\n",
      "Epoch: 1, Iteration: 36\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.7114762663841248\n",
      "LC Training Loss (Full): 0.4231529235839844\n",
      "Epoch: 1, Iteration: 37\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.7943860292434692\n",
      "LC Training Loss (Full): 0.4607091546058655\n",
      "Epoch: 1, Iteration: 38\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.974567711353302\n",
      "LC Training Loss (Full): 0.6109342575073242\n",
      "Epoch: 1, Iteration: 39\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.8818971514701843\n",
      "LC Training Loss (Full): 0.6537286043167114\n",
      "Epoch: 1, Iteration: 40\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9960505962371826\n",
      "LC Training Loss (Full): 0.7347621917724609\n",
      "Training Accuracy | Decomposed: 0.671875, Full : 0.78125\n",
      "Full accuracy (w/o dLoRA+LC): 0.8602, LC accuracy: 0.8605, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7792, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7791\n",
      "Epoch: 1, Iteration: 41\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.8607483506202698\n",
      "LC Training Loss (Full): 0.5492456555366516\n",
      "Epoch: 1, Iteration: 42\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.768355131149292\n",
      "LC Training Loss (Full): 0.45351558923721313\n",
      "Epoch: 1, Iteration: 43\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.8621243238449097\n",
      "LC Training Loss (Full): 0.5640074610710144\n",
      "Epoch: 1, Iteration: 44\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.8783828020095825\n",
      "LC Training Loss (Full): 0.5164304375648499\n",
      "Epoch: 1, Iteration: 45\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.8261829614639282\n",
      "LC Training Loss (Full): 0.515231192111969\n",
      "Full accuracy (w/o dLoRA+LC): 0.8612, LC accuracy: 0.8604, Decomposed-Full (w/dLoRA+LC) accuracy: 0.782, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7796\n",
      "Epoch: 1, Iteration: 46\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.855938196182251\n",
      "LC Training Loss (Full): 0.5273438692092896\n",
      "Epoch: 1, Iteration: 47\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.774777889251709\n",
      "LC Training Loss (Full): 0.40770235657691956\n",
      "Epoch: 1, Iteration: 48\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.8328961133956909\n",
      "LC Training Loss (Full): 0.507970929145813\n",
      "Epoch: 1, Iteration: 49\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6806807518005371\n",
      "LC Training Loss (Full): 0.4761064052581787\n",
      "Epoch: 1, Iteration: 50\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8552846312522888\n",
      "LC Training Loss (Full): 0.5052226781845093\n",
      "Full accuracy (w/o dLoRA+LC): 0.862, LC accuracy: 0.8617, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7801, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.78\n",
      "Epoch: 1, Iteration: 51\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7585605978965759\n",
      "LC Training Loss (Full): 0.47152236104011536\n",
      "Epoch: 1, Iteration: 52\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.9720602631568909\n",
      "LC Training Loss (Full): 0.6415460705757141\n",
      "Epoch: 1, Iteration: 53\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7867922782897949\n",
      "LC Training Loss (Full): 0.49446141719818115\n",
      "Epoch: 1, Iteration: 54\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.9774472117424011\n",
      "LC Training Loss (Full): 0.7361654043197632\n",
      "Epoch: 1, Iteration: 55\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.8697250485420227\n",
      "LC Training Loss (Full): 0.503961443901062\n",
      "Full accuracy (w/o dLoRA+LC): 0.859, LC accuracy: 0.8613, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7829, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7817\n",
      "Epoch: 1, Iteration: 56\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.8722664713859558\n",
      "LC Training Loss (Full): 0.49507004022598267\n",
      "Epoch: 1, Iteration: 57\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7135544419288635\n",
      "LC Training Loss (Full): 0.4687677323818207\n",
      "Epoch: 1, Iteration: 58\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.906408965587616\n",
      "LC Training Loss (Full): 0.6825653910636902\n",
      "Epoch: 1, Iteration: 59\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7532085180282593\n",
      "LC Training Loss (Full): 0.3990677297115326\n",
      "Epoch: 1, Iteration: 60\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8987622857093811\n",
      "LC Training Loss (Full): 0.5327770709991455\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.84375\n",
      "Full accuracy (w/o dLoRA+LC): 0.8599, LC accuracy: 0.8578, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7822, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7802\n",
      "Epoch: 1, Iteration: 61\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.9342280626296997\n",
      "LC Training Loss (Full): 0.5536928176879883\n",
      "Epoch: 1, Iteration: 62\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.0068506002426147\n",
      "LC Training Loss (Full): 0.7025514841079712\n",
      "Epoch: 1, Iteration: 63\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.8272493481636047\n",
      "LC Training Loss (Full): 0.48730847239494324\n",
      "Epoch: 1, Iteration: 64\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.8552167415618896\n",
      "LC Training Loss (Full): 0.5570024847984314\n",
      "Epoch: 1, Iteration: 65\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.8756685853004456\n",
      "LC Training Loss (Full): 0.5581552982330322\n",
      "Full accuracy (w/o dLoRA+LC): 0.8614, LC accuracy: 0.8578, Decomposed-Full (w/dLoRA+LC) accuracy: 0.782, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7811\n",
      "Epoch: 1, Iteration: 66\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7113713026046753\n",
      "LC Training Loss (Full): 0.42884525656700134\n",
      "Epoch: 1, Iteration: 67\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7069332003593445\n",
      "LC Training Loss (Full): 0.34695062041282654\n",
      "Epoch: 1, Iteration: 68\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7230153679847717\n",
      "LC Training Loss (Full): 0.38720977306365967\n",
      "Epoch: 1, Iteration: 69\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7949194312095642\n",
      "LC Training Loss (Full): 0.4684869945049286\n",
      "Epoch: 1, Iteration: 70\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8066660761833191\n",
      "LC Training Loss (Full): 0.4575088620185852\n",
      "Full accuracy (w/o dLoRA+LC): 0.8639, LC accuracy: 0.8627, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7828, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.782\n",
      "Epoch: 1, Iteration: 71\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7907418012619019\n",
      "LC Training Loss (Full): 0.47547608613967896\n",
      "Epoch: 1, Iteration: 72\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.8967766165733337\n",
      "LC Training Loss (Full): 0.5619975328445435\n",
      "Epoch: 1, Iteration: 73\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.9458770751953125\n",
      "LC Training Loss (Full): 0.6907870769500732\n",
      "Epoch: 1, Iteration: 74\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.8280856013298035\n",
      "LC Training Loss (Full): 0.53950035572052\n",
      "Epoch: 1, Iteration: 75\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.9494110345840454\n",
      "LC Training Loss (Full): 0.6274686455726624\n",
      "Full accuracy (w/o dLoRA+LC): 0.8655, LC accuracy: 0.863, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7813, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7826\n",
      "Epoch: 1, Iteration: 76\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.9335584044456482\n",
      "LC Training Loss (Full): 0.6567573547363281\n",
      "Epoch: 1, Iteration: 77\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.6730867028236389\n",
      "LC Training Loss (Full): 0.3713689148426056\n",
      "Epoch: 1, Iteration: 78\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.8968135714530945\n",
      "LC Training Loss (Full): 0.5509617924690247\n",
      "Epoch: 1, Iteration: 79\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.8535510301589966\n",
      "LC Training Loss (Full): 0.5367861986160278\n",
      "Epoch: 1, Iteration: 80\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8045486807823181\n",
      "LC Training Loss (Full): 0.4164082109928131\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.8664, LC accuracy: 0.8655, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7821, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7822\n",
      "Epoch: 1, Iteration: 81\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.6205962896347046\n",
      "LC Training Loss (Full): 0.32875025272369385\n",
      "Epoch: 1, Iteration: 82\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.7943881750106812\n",
      "LC Training Loss (Full): 0.4720650911331177\n",
      "Epoch: 1, Iteration: 83\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.9824494123458862\n",
      "LC Training Loss (Full): 0.6728870868682861\n",
      "Epoch: 1, Iteration: 84\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.8253931999206543\n",
      "LC Training Loss (Full): 0.5037463307380676\n",
      "Epoch: 1, Iteration: 85\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.9496820569038391\n",
      "LC Training Loss (Full): 0.5781022906303406\n",
      "Full accuracy (w/o dLoRA+LC): 0.8698, LC accuracy: 0.8655, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7861, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7827\n",
      "Epoch: 1, Iteration: 86\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.9178941249847412\n",
      "LC Training Loss (Full): 0.5479232668876648\n",
      "Epoch: 1, Iteration: 87\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.9273737072944641\n",
      "LC Training Loss (Full): 0.6140499114990234\n",
      "Epoch: 1, Iteration: 88\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.955830991268158\n",
      "LC Training Loss (Full): 0.6217396855354309\n",
      "Epoch: 1, Iteration: 89\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.8038038015365601\n",
      "LC Training Loss (Full): 0.4728875756263733\n",
      "Epoch: 1, Iteration: 90\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7798723578453064\n",
      "LC Training Loss (Full): 0.5079405903816223\n",
      "Full accuracy (w/o dLoRA+LC): 0.8684, LC accuracy: 0.8687, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7821, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7833\n",
      "Epoch: 1, Iteration: 91\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.9284439086914062\n",
      "LC Training Loss (Full): 0.6467183232307434\n",
      "Epoch: 1, Iteration: 92\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.8462839722633362\n",
      "LC Training Loss (Full): 0.5068098902702332\n",
      "Epoch: 1, Iteration: 93\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.7421270608901978\n",
      "LC Training Loss (Full): 0.45081961154937744\n",
      "Epoch: 1, Iteration: 94\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 1.0492953062057495\n",
      "LC Training Loss (Full): 0.6420717835426331\n",
      "Epoch: 1, Iteration: 95\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.9181263446807861\n",
      "LC Training Loss (Full): 0.5569295287132263\n",
      "Full accuracy (w/o dLoRA+LC): 0.8685, LC accuracy: 0.8688, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7858, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7842\n",
      "Epoch: 1, Iteration: 96\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.7856895923614502\n",
      "LC Training Loss (Full): 0.5098923444747925\n",
      "Epoch: 1, Iteration: 97\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.724342942237854\n",
      "LC Training Loss (Full): 0.3910905122756958\n",
      "Epoch: 1, Iteration: 98\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.9003718495368958\n",
      "LC Training Loss (Full): 0.5748734474182129\n",
      "Epoch: 1, Iteration: 99\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.7713499665260315\n",
      "LC Training Loss (Full): 0.45303305983543396\n",
      "Epoch: 1, Iteration: 100\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8615740537643433\n",
      "LC Training Loss (Full): 0.5365814566612244\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.859375\n",
      "Full accuracy (w/o dLoRA+LC): 0.8698, LC accuracy: 0.8694, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7856, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7855\n",
      "Epoch: 1, Iteration: 101\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.8427495360374451\n",
      "LC Training Loss (Full): 0.5112462043762207\n",
      "Epoch: 1, Iteration: 102\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7976838946342468\n",
      "LC Training Loss (Full): 0.5433028936386108\n",
      "Epoch: 1, Iteration: 103\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.9376918077468872\n",
      "LC Training Loss (Full): 0.6033821702003479\n",
      "Epoch: 1, Iteration: 104\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7423354387283325\n",
      "LC Training Loss (Full): 0.3316296935081482\n",
      "Epoch: 1, Iteration: 105\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.9224511981010437\n",
      "LC Training Loss (Full): 0.5776002407073975\n",
      "Full accuracy (w/o dLoRA+LC): 0.8704, LC accuracy: 0.8695, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7847, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.784\n",
      "Epoch: 1, Iteration: 106\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.910746693611145\n",
      "LC Training Loss (Full): 0.5952180624008179\n",
      "Epoch: 1, Iteration: 107\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7636419534683228\n",
      "LC Training Loss (Full): 0.4644862711429596\n",
      "Epoch: 1, Iteration: 108\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 1.0103355646133423\n",
      "LC Training Loss (Full): 0.6254551410675049\n",
      "Epoch: 1, Iteration: 109\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.8301578164100647\n",
      "LC Training Loss (Full): 0.4323173761367798\n",
      "Epoch: 1, Iteration: 110\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9406169652938843\n",
      "LC Training Loss (Full): 0.5918663740158081\n",
      "Full accuracy (w/o dLoRA+LC): 0.8716, LC accuracy: 0.8709, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7869, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7853\n",
      "Epoch: 1, Iteration: 111\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.855920672416687\n",
      "LC Training Loss (Full): 0.5299939513206482\n",
      "Epoch: 1, Iteration: 112\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7908374071121216\n",
      "LC Training Loss (Full): 0.3717254400253296\n",
      "Epoch: 1, Iteration: 113\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 1.0543136596679688\n",
      "LC Training Loss (Full): 0.6936448812484741\n",
      "Epoch: 1, Iteration: 114\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.9772195219993591\n",
      "LC Training Loss (Full): 0.6233425140380859\n",
      "Epoch: 1, Iteration: 115\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7463627457618713\n",
      "LC Training Loss (Full): 0.39450037479400635\n",
      "Full accuracy (w/o dLoRA+LC): 0.8725, LC accuracy: 0.8709, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7886, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7866\n",
      "Epoch: 1, Iteration: 116\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7726684808731079\n",
      "LC Training Loss (Full): 0.4430624842643738\n",
      "Epoch: 1, Iteration: 117\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.964192271232605\n",
      "LC Training Loss (Full): 0.6001808047294617\n",
      "Epoch: 1, Iteration: 118\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7331134080886841\n",
      "LC Training Loss (Full): 0.4135321080684662\n",
      "Epoch: 1, Iteration: 119\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7182469964027405\n",
      "LC Training Loss (Full): 0.41265010833740234\n",
      "Epoch: 1, Iteration: 120\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.972743809223175\n",
      "LC Training Loss (Full): 0.5665260553359985\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.828125\n",
      "Full accuracy (w/o dLoRA+LC): 0.8726, LC accuracy: 0.8737, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7876, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7875\n",
      "Epoch: 1, Iteration: 121\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.9133729338645935\n",
      "LC Training Loss (Full): 0.5918117165565491\n",
      "Epoch: 1, Iteration: 122\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.8373166918754578\n",
      "LC Training Loss (Full): 0.486041784286499\n",
      "Epoch: 1, Iteration: 123\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7999400496482849\n",
      "LC Training Loss (Full): 0.43768978118896484\n",
      "Epoch: 1, Iteration: 124\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7748184204101562\n",
      "LC Training Loss (Full): 0.44034919142723083\n",
      "Epoch: 1, Iteration: 125\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.8146114945411682\n",
      "LC Training Loss (Full): 0.49856582283973694\n",
      "Full accuracy (w/o dLoRA+LC): 0.8721, LC accuracy: 0.8742, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7889, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7875\n",
      "Epoch: 1, Iteration: 126\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7770408391952515\n",
      "LC Training Loss (Full): 0.48431631922721863\n",
      "Epoch: 1, Iteration: 127\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.9345012903213501\n",
      "LC Training Loss (Full): 0.5908876657485962\n",
      "Epoch: 1, Iteration: 128\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.8794971108436584\n",
      "LC Training Loss (Full): 0.5006318688392639\n",
      "Epoch: 1, Iteration: 129\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7826346755027771\n",
      "LC Training Loss (Full): 0.5361950397491455\n",
      "Epoch: 1, Iteration: 130\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8443855047225952\n",
      "LC Training Loss (Full): 0.5888143181800842\n",
      "Full accuracy (w/o dLoRA+LC): 0.8743, LC accuracy: 0.8742, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7874, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7864\n",
      "Epoch: 1, Iteration: 131\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.8994183540344238\n",
      "LC Training Loss (Full): 0.5166285037994385\n",
      "Epoch: 1, Iteration: 132\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 1.0146645307540894\n",
      "LC Training Loss (Full): 0.6033921837806702\n",
      "Epoch: 1, Iteration: 133\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7402672171592712\n",
      "LC Training Loss (Full): 0.38812246918678284\n",
      "Epoch: 1, Iteration: 134\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7418835759162903\n",
      "LC Training Loss (Full): 0.48428747057914734\n",
      "Epoch: 1, Iteration: 135\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.9082509875297546\n",
      "LC Training Loss (Full): 0.6458678841590881\n",
      "Full accuracy (w/o dLoRA+LC): 0.875, LC accuracy: 0.8741, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7887, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7884\n",
      "Epoch: 1, Iteration: 136\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7649579048156738\n",
      "LC Training Loss (Full): 0.5424174666404724\n",
      "Epoch: 1, Iteration: 137\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.9842068552970886\n",
      "LC Training Loss (Full): 0.6539658904075623\n",
      "Epoch: 1, Iteration: 138\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.808085560798645\n",
      "LC Training Loss (Full): 0.4979122579097748\n",
      "Epoch: 1, Iteration: 139\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6958723664283752\n",
      "LC Training Loss (Full): 0.35853898525238037\n",
      "Epoch: 1, Iteration: 140\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6804907321929932\n",
      "LC Training Loss (Full): 0.36887848377227783\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.8753, LC accuracy: 0.8752, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7874, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7876\n",
      "Epoch: 1, Iteration: 141\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.8866882920265198\n",
      "LC Training Loss (Full): 0.5336730480194092\n",
      "Epoch: 1, Iteration: 142\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.8894122242927551\n",
      "LC Training Loss (Full): 0.555170476436615\n",
      "Epoch: 1, Iteration: 143\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7530820369720459\n",
      "LC Training Loss (Full): 0.41789692640304565\n",
      "Epoch: 1, Iteration: 144\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.8058773875236511\n",
      "LC Training Loss (Full): 0.3860190212726593\n",
      "Epoch: 1, Iteration: 145\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7985817193984985\n",
      "LC Training Loss (Full): 0.46175190806388855\n",
      "Full accuracy (w/o dLoRA+LC): 0.8751, LC accuracy: 0.875, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7887, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7886\n",
      "Epoch: 1, Iteration: 146\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7621845602989197\n",
      "LC Training Loss (Full): 0.4832770824432373\n",
      "Epoch: 1, Iteration: 147\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7598245739936829\n",
      "LC Training Loss (Full): 0.3526620864868164\n",
      "Epoch: 1, Iteration: 148\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.9681758880615234\n",
      "LC Training Loss (Full): 0.605941116809845\n",
      "Epoch: 1, Iteration: 149\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.8457932472229004\n",
      "LC Training Loss (Full): 0.4544316232204437\n",
      "Epoch: 1, Iteration: 150\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7043159008026123\n",
      "LC Training Loss (Full): 0.36000412702560425\n",
      "Full accuracy (w/o dLoRA+LC): 0.8771, LC accuracy: 0.8774, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7887, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7885\n",
      "Epoch: 1, Iteration: 151\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7184221744537354\n",
      "LC Training Loss (Full): 0.438909113407135\n",
      "Epoch: 1, Iteration: 152\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.8567877411842346\n",
      "LC Training Loss (Full): 0.46618661284446716\n",
      "Epoch: 1, Iteration: 153\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 1.024600863456726\n",
      "LC Training Loss (Full): 0.713395893573761\n",
      "Epoch: 1, Iteration: 154\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7586153745651245\n",
      "LC Training Loss (Full): 0.39039796590805054\n",
      "Epoch: 1, Iteration: 155\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7920167446136475\n",
      "LC Training Loss (Full): 0.43205487728118896\n",
      "Full accuracy (w/o dLoRA+LC): 0.8791, LC accuracy: 0.8776, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7909, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7895\n",
      "Epoch: 1, Iteration: 156\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.8449314832687378\n",
      "LC Training Loss (Full): 0.4967901110649109\n",
      "Epoch: 1, Iteration: 157\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 1.021484136581421\n",
      "LC Training Loss (Full): 0.6678748726844788\n",
      "Epoch: 1, Iteration: 158\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7761844992637634\n",
      "LC Training Loss (Full): 0.46637818217277527\n",
      "Epoch: 1, Iteration: 159\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.837965190410614\n",
      "LC Training Loss (Full): 0.5012709498405457\n",
      "Epoch: 1, Iteration: 160\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7812631726264954\n",
      "LC Training Loss (Full): 0.4488919675350189\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8797, LC accuracy: 0.8799, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7908, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7896\n",
      "Epoch: 1, Iteration: 161\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.8373494744300842\n",
      "LC Training Loss (Full): 0.4722013771533966\n",
      "Epoch: 1, Iteration: 162\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 1.08733332157135\n",
      "LC Training Loss (Full): 0.6237251162528992\n",
      "Epoch: 1, Iteration: 163\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.8396461009979248\n",
      "LC Training Loss (Full): 0.5116139054298401\n",
      "Epoch: 1, Iteration: 164\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.7556516528129578\n",
      "LC Training Loss (Full): 0.44337302446365356\n",
      "Epoch: 1, Iteration: 165\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.8160390257835388\n",
      "LC Training Loss (Full): 0.4615069627761841\n",
      "Full accuracy (w/o dLoRA+LC): 0.8796, LC accuracy: 0.8798, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7916, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7901\n",
      "Epoch: 1, Iteration: 166\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.826088011264801\n",
      "LC Training Loss (Full): 0.4937020242214203\n",
      "Epoch: 1, Iteration: 167\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.8484426736831665\n",
      "LC Training Loss (Full): 0.5142146944999695\n",
      "Epoch: 1, Iteration: 168\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6907801032066345\n",
      "LC Training Loss (Full): 0.4280126690864563\n",
      "Epoch: 1, Iteration: 169\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.8131077885627747\n",
      "LC Training Loss (Full): 0.36025869846343994\n",
      "Epoch: 1, Iteration: 170\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8845696449279785\n",
      "LC Training Loss (Full): 0.4650420844554901\n",
      "Full accuracy (w/o dLoRA+LC): 0.8801, LC accuracy: 0.8791, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7894, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7903\n",
      "Epoch: 1, Iteration: 171\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.8394187092781067\n",
      "LC Training Loss (Full): 0.362326979637146\n",
      "Epoch: 1, Iteration: 172\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 1.0322388410568237\n",
      "LC Training Loss (Full): 0.6368198990821838\n",
      "Epoch: 1, Iteration: 173\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.8415796160697937\n",
      "LC Training Loss (Full): 0.5167158842086792\n",
      "Epoch: 1, Iteration: 174\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.6733313798904419\n",
      "LC Training Loss (Full): 0.3299615979194641\n",
      "Epoch: 1, Iteration: 175\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7988282442092896\n",
      "LC Training Loss (Full): 0.5042234659194946\n",
      "Full accuracy (w/o dLoRA+LC): 0.8809, LC accuracy: 0.8789, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7913, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7911\n",
      "Epoch: 1, Iteration: 176\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7618035674095154\n",
      "LC Training Loss (Full): 0.4226427376270294\n",
      "Epoch: 1, Iteration: 177\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.8513427972793579\n",
      "LC Training Loss (Full): 0.48361799120903015\n",
      "Epoch: 1, Iteration: 178\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.8081340789794922\n",
      "LC Training Loss (Full): 0.49658602476119995\n",
      "Epoch: 1, Iteration: 179\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.8802488446235657\n",
      "LC Training Loss (Full): 0.48945295810699463\n",
      "Epoch: 1, Iteration: 180\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7009897232055664\n",
      "LC Training Loss (Full): 0.2996910512447357\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.8816, LC accuracy: 0.8821, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7896, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7907\n",
      "Epoch: 1, Iteration: 181\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.7514243125915527\n",
      "LC Training Loss (Full): 0.3706595301628113\n",
      "Epoch: 1, Iteration: 182\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.9938424229621887\n",
      "LC Training Loss (Full): 0.6870285272598267\n",
      "Epoch: 1, Iteration: 183\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.8486020565032959\n",
      "LC Training Loss (Full): 0.5483686327934265\n",
      "Epoch: 1, Iteration: 184\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.8693283796310425\n",
      "LC Training Loss (Full): 0.4718710780143738\n",
      "Epoch: 1, Iteration: 185\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 1.0014431476593018\n",
      "LC Training Loss (Full): 0.6120431423187256\n",
      "Full accuracy (w/o dLoRA+LC): 0.884, LC accuracy: 0.8819, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7914, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.79\n",
      "Epoch: 1, Iteration: 186\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.9440875053405762\n",
      "LC Training Loss (Full): 0.5014548301696777\n",
      "Epoch: 1, Iteration: 187\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.8024447560310364\n",
      "LC Training Loss (Full): 0.4237772822380066\n",
      "Epoch: 1, Iteration: 188\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6184080839157104\n",
      "LC Training Loss (Full): 0.309214323759079\n",
      "Epoch: 1, Iteration: 189\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.755567729473114\n",
      "LC Training Loss (Full): 0.3867921531200409\n",
      "Epoch: 1, Iteration: 190\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8992099761962891\n",
      "LC Training Loss (Full): 0.4937148690223694\n",
      "Full accuracy (w/o dLoRA+LC): 0.8836, LC accuracy: 0.8829, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7912, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7906\n",
      "Epoch: 1, Iteration: 191\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.8405978679656982\n",
      "LC Training Loss (Full): 0.49315476417541504\n",
      "Epoch: 1, Iteration: 192\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6645303964614868\n",
      "LC Training Loss (Full): 0.3001173436641693\n",
      "Epoch: 1, Iteration: 193\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.8989214301109314\n",
      "LC Training Loss (Full): 0.5278522372245789\n",
      "Epoch: 1, Iteration: 194\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.7820764183998108\n",
      "LC Training Loss (Full): 0.3768708109855652\n",
      "Epoch: 1, Iteration: 195\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.7146148681640625\n",
      "LC Training Loss (Full): 0.3666822612285614\n",
      "Full accuracy (w/o dLoRA+LC): 0.8833, LC accuracy: 0.883, Decomposed-Full (w/dLoRA+LC) accuracy: 0.791, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7914\n",
      "Epoch: 1, Iteration: 196\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.7043313980102539\n",
      "LC Training Loss (Full): 0.31182432174682617\n",
      "Epoch: 1, Iteration: 197\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.9589788913726807\n",
      "LC Training Loss (Full): 0.5875113010406494\n",
      "Epoch: 1, Iteration: 198\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6865235567092896\n",
      "LC Training Loss (Full): 0.33010903000831604\n",
      "Epoch: 1, Iteration: 199\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.8804576992988586\n",
      "LC Training Loss (Full): 0.4846886098384857\n",
      "Epoch: 1, Iteration: 200\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6041510105133057\n",
      "LC Training Loss (Full): 0.28822338581085205\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.8841, LC accuracy: 0.8851, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7901, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7911\n",
      "Epoch: 1, Iteration: 201\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.802337110042572\n",
      "LC Training Loss (Full): 0.4154345691204071\n",
      "Epoch: 1, Iteration: 202\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7325717210769653\n",
      "LC Training Loss (Full): 0.3218270540237427\n",
      "Epoch: 1, Iteration: 203\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7821481227874756\n",
      "LC Training Loss (Full): 0.4103195071220398\n",
      "Epoch: 1, Iteration: 204\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.8421316146850586\n",
      "LC Training Loss (Full): 0.5258824229240417\n",
      "Epoch: 1, Iteration: 205\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.9596183896064758\n",
      "LC Training Loss (Full): 0.5350522994995117\n",
      "Full accuracy (w/o dLoRA+LC): 0.8842, LC accuracy: 0.8849, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7909, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7911\n",
      "Epoch: 1, Iteration: 206\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.65090012550354\n",
      "LC Training Loss (Full): 0.3559263050556183\n",
      "Epoch: 1, Iteration: 207\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.8020363450050354\n",
      "LC Training Loss (Full): 0.5037478804588318\n",
      "Epoch: 1, Iteration: 208\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7173828482627869\n",
      "LC Training Loss (Full): 0.34453898668289185\n",
      "Epoch: 1, Iteration: 209\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7134838700294495\n",
      "LC Training Loss (Full): 0.38555222749710083\n",
      "Epoch: 1, Iteration: 210\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8716614246368408\n",
      "LC Training Loss (Full): 0.5090681910514832\n",
      "Full accuracy (w/o dLoRA+LC): 0.8857, LC accuracy: 0.8845, Decomposed-Full (w/dLoRA+LC) accuracy: 0.791, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7901\n",
      "Epoch: 1, Iteration: 211\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7813474535942078\n",
      "LC Training Loss (Full): 0.40479138493537903\n",
      "Epoch: 1, Iteration: 212\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7663084864616394\n",
      "LC Training Loss (Full): 0.4014166295528412\n",
      "Epoch: 1, Iteration: 213\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7791366577148438\n",
      "LC Training Loss (Full): 0.46479836106300354\n",
      "Epoch: 1, Iteration: 214\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7048823833465576\n",
      "LC Training Loss (Full): 0.3956153988838196\n",
      "Epoch: 1, Iteration: 215\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.9241227507591248\n",
      "LC Training Loss (Full): 0.525181233882904\n",
      "Full accuracy (w/o dLoRA+LC): 0.8875, LC accuracy: 0.8845, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7922, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7913\n",
      "Epoch: 1, Iteration: 216\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 1.0677776336669922\n",
      "LC Training Loss (Full): 0.817234456539154\n",
      "Epoch: 1, Iteration: 217\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7052008509635925\n",
      "LC Training Loss (Full): 0.41775402426719666\n",
      "Epoch: 1, Iteration: 218\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7760800719261169\n",
      "LC Training Loss (Full): 0.4593086242675781\n",
      "Epoch: 1, Iteration: 219\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.8363794088363647\n",
      "LC Training Loss (Full): 0.4580953121185303\n",
      "Epoch: 1, Iteration: 220\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.801822304725647\n",
      "LC Training Loss (Full): 0.37092557549476624\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.8878, LC accuracy: 0.8872, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7913, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7906\n",
      "Epoch: 1, Iteration: 221\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.7811697721481323\n",
      "LC Training Loss (Full): 0.3577488660812378\n",
      "Epoch: 1, Iteration: 222\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5847514867782593\n",
      "LC Training Loss (Full): 0.26152631640434265\n",
      "Epoch: 1, Iteration: 223\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.9166918992996216\n",
      "LC Training Loss (Full): 0.5227850079536438\n",
      "Epoch: 1, Iteration: 224\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.8237285017967224\n",
      "LC Training Loss (Full): 0.5074443221092224\n",
      "Epoch: 1, Iteration: 225\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.8626013994216919\n",
      "LC Training Loss (Full): 0.49733975529670715\n",
      "Full accuracy (w/o dLoRA+LC): 0.8864, LC accuracy: 0.8872, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7912, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7907\n",
      "Epoch: 1, Iteration: 226\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.7596559524536133\n",
      "LC Training Loss (Full): 0.38259953260421753\n",
      "Epoch: 1, Iteration: 227\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.7913575768470764\n",
      "LC Training Loss (Full): 0.464213103055954\n",
      "Epoch: 1, Iteration: 228\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.848152220249176\n",
      "LC Training Loss (Full): 0.5369095802307129\n",
      "Epoch: 1, Iteration: 229\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.9351213574409485\n",
      "LC Training Loss (Full): 0.49360042810440063\n",
      "Epoch: 1, Iteration: 230\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_47\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.76111900806427\n",
      "LC Training Loss (Full): 0.3173201382160187\n",
      "Full accuracy (w/o dLoRA+LC): 0.8879, LC accuracy: 0.8886, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7923, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7909\n",
      "Epoch: 1, Iteration: 231\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.9902912974357605\n",
      "LC Training Loss (Full): 0.5076281428337097\n",
      "Epoch: 1, Iteration: 232\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.6565122008323669\n",
      "LC Training Loss (Full): 0.2527008056640625\n",
      "Epoch: 1, Iteration: 233\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.8238703012466431\n",
      "LC Training Loss (Full): 0.40650975704193115\n",
      "Epoch: 1, Iteration: 234\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader1/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader1/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.8098257780075073\n",
      "LC Training Loss (Full): 0.3237077593803406\n",
      "End of model training on train_loader1...\n",
      "Model saved at accuracy: 0.7923\n",
      "--------------------------\n",
      "Beginning of model training on train_loader2...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7363287210464478\n",
      "LC Training Loss (Full): 0.33069509267807007\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6784805059432983\n",
      "LC Training Loss (Full): 0.3165266215801239\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9240887761116028\n",
      "LC Training Loss (Full): 0.505638599395752\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7730712890625\n",
      "LC Training Loss (Full): 0.48326194286346436\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8279204964637756\n",
      "LC Training Loss (Full): 0.48007944226264954\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5871305465698242\n",
      "LC Training Loss (Full): 0.22986367344856262\n",
      "Full accuracy (w/o dLoRA+LC): 0.8882, LC accuracy: 0.8875, Decomposed-Full (w/dLoRA+LC) accuracy: 0.798, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7947\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8392290472984314\n",
      "LC Training Loss (Full): 0.5478376746177673\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7244742512702942\n",
      "LC Training Loss (Full): 0.3734639585018158\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6583274006843567\n",
      "LC Training Loss (Full): 0.4836878776550293\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8139206767082214\n",
      "LC Training Loss (Full): 0.4997488558292389\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6824747323989868\n",
      "LC Training Loss (Full): 0.3748617470264435\n",
      "Full accuracy (w/o dLoRA+LC): 0.888, LC accuracy: 0.8885, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7941, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7946\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7594127655029297\n",
      "LC Training Loss (Full): 0.35002651810646057\n",
      "Epoch: 0, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7903252243995667\n",
      "LC Training Loss (Full): 0.4419783651828766\n",
      "Epoch: 0, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7744464874267578\n",
      "LC Training Loss (Full): 0.5228596925735474\n",
      "Epoch: 0, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.8794817924499512\n",
      "LC Training Loss (Full): 0.5592814683914185\n",
      "Epoch: 0, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.8092660307884216\n",
      "LC Training Loss (Full): 0.5019784569740295\n",
      "Full accuracy (w/o dLoRA+LC): 0.8881, LC accuracy: 0.8888, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7965, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7954\n",
      "Epoch: 0, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7452117204666138\n",
      "LC Training Loss (Full): 0.4434758126735687\n",
      "Epoch: 0, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.708306610584259\n",
      "LC Training Loss (Full): 0.3712120056152344\n",
      "Epoch: 0, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7067956328392029\n",
      "LC Training Loss (Full): 0.3513743579387665\n",
      "Epoch: 0, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6944228410720825\n",
      "LC Training Loss (Full): 0.37076300382614136\n",
      "Epoch: 0, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7822213768959045\n",
      "LC Training Loss (Full): 0.435707688331604\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8889, LC accuracy: 0.8882, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7961, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7955\n",
      "Epoch: 0, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6336652636528015\n",
      "LC Training Loss (Full): 0.3112105429172516\n",
      "Epoch: 0, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6663941740989685\n",
      "LC Training Loss (Full): 0.3915036618709564\n",
      "Epoch: 0, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.817362904548645\n",
      "LC Training Loss (Full): 0.46286091208457947\n",
      "Epoch: 0, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7643930912017822\n",
      "LC Training Loss (Full): 0.4164097309112549\n",
      "Epoch: 0, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7113017439842224\n",
      "LC Training Loss (Full): 0.41556116938591003\n",
      "Full accuracy (w/o dLoRA+LC): 0.8899, LC accuracy: 0.8882, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7965, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7964\n",
      "Epoch: 0, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.9022713303565979\n",
      "LC Training Loss (Full): 0.5462832450866699\n",
      "Epoch: 0, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6846882104873657\n",
      "LC Training Loss (Full): 0.32158786058425903\n",
      "Epoch: 0, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8306095600128174\n",
      "LC Training Loss (Full): 0.5651040077209473\n",
      "Epoch: 0, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6234433054924011\n",
      "LC Training Loss (Full): 0.2761382758617401\n",
      "Epoch: 0, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6501620411872864\n",
      "LC Training Loss (Full): 0.31422650814056396\n",
      "Full accuracy (w/o dLoRA+LC): 0.8901, LC accuracy: 0.8902, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7949, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7959\n",
      "Epoch: 0, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8343601822853088\n",
      "LC Training Loss (Full): 0.43669819831848145\n",
      "Epoch: 0, Iteration: 32\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8150421380996704\n",
      "LC Training Loss (Full): 0.4105954170227051\n",
      "Epoch: 0, Iteration: 33\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.640113890171051\n",
      "LC Training Loss (Full): 0.2673276960849762\n",
      "Epoch: 0, Iteration: 34\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8009169101715088\n",
      "LC Training Loss (Full): 0.4237450957298279\n",
      "Epoch: 0, Iteration: 35\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7678937911987305\n",
      "LC Training Loss (Full): 0.4081365168094635\n",
      "Full accuracy (w/o dLoRA+LC): 0.8897, LC accuracy: 0.8902, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7995, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7974\n",
      "Epoch: 0, Iteration: 36\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8297041654586792\n",
      "LC Training Loss (Full): 0.4494873583316803\n",
      "Epoch: 0, Iteration: 37\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7893710732460022\n",
      "LC Training Loss (Full): 0.48610758781433105\n",
      "Epoch: 0, Iteration: 38\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8527933955192566\n",
      "LC Training Loss (Full): 0.542050302028656\n",
      "Epoch: 0, Iteration: 39\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8696871399879456\n",
      "LC Training Loss (Full): 0.47235727310180664\n",
      "Epoch: 0, Iteration: 40\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.749677836894989\n",
      "LC Training Loss (Full): 0.45175880193710327\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8916, LC accuracy: 0.8913, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7981, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7972\n",
      "Epoch: 0, Iteration: 41\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7861993312835693\n",
      "LC Training Loss (Full): 0.40214112401008606\n",
      "Epoch: 0, Iteration: 42\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.822974681854248\n",
      "LC Training Loss (Full): 0.4551531970500946\n",
      "Epoch: 0, Iteration: 43\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7620508670806885\n",
      "LC Training Loss (Full): 0.4191378057003021\n",
      "Epoch: 0, Iteration: 44\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.9501907825469971\n",
      "LC Training Loss (Full): 0.5901097655296326\n",
      "Epoch: 0, Iteration: 45\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7900410294532776\n",
      "LC Training Loss (Full): 0.4121081829071045\n",
      "Full accuracy (w/o dLoRA+LC): 0.8905, LC accuracy: 0.8912, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7995, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7976\n",
      "Epoch: 0, Iteration: 46\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.807044267654419\n",
      "LC Training Loss (Full): 0.39797088503837585\n",
      "Epoch: 0, Iteration: 47\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.6812969446182251\n",
      "LC Training Loss (Full): 0.3875575065612793\n",
      "Epoch: 0, Iteration: 48\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7989548444747925\n",
      "LC Training Loss (Full): 0.41088011860847473\n",
      "Epoch: 0, Iteration: 49\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.6707419753074646\n",
      "LC Training Loss (Full): 0.3401376008987427\n",
      "Epoch: 0, Iteration: 50\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8265644907951355\n",
      "LC Training Loss (Full): 0.48849594593048096\n",
      "Full accuracy (w/o dLoRA+LC): 0.8917, LC accuracy: 0.8932, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7987, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7985\n",
      "Epoch: 0, Iteration: 51\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.6431078910827637\n",
      "LC Training Loss (Full): 0.2784339189529419\n",
      "Epoch: 0, Iteration: 52\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7613659501075745\n",
      "LC Training Loss (Full): 0.3808688521385193\n",
      "Epoch: 0, Iteration: 53\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.879388153553009\n",
      "LC Training Loss (Full): 0.5559866428375244\n",
      "Epoch: 0, Iteration: 54\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.9000316262245178\n",
      "LC Training Loss (Full): 0.5576488375663757\n",
      "Epoch: 0, Iteration: 55\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.8225911855697632\n",
      "LC Training Loss (Full): 0.4946066737174988\n",
      "Full accuracy (w/o dLoRA+LC): 0.8922, LC accuracy: 0.8932, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7995, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7985\n",
      "Epoch: 0, Iteration: 56\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7845810055732727\n",
      "LC Training Loss (Full): 0.4005482792854309\n",
      "Epoch: 0, Iteration: 57\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7571426630020142\n",
      "LC Training Loss (Full): 0.45801275968551636\n",
      "Epoch: 0, Iteration: 58\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.703294038772583\n",
      "LC Training Loss (Full): 0.3534720242023468\n",
      "Epoch: 0, Iteration: 59\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.6547483205795288\n",
      "LC Training Loss (Full): 0.2596169710159302\n",
      "Epoch: 0, Iteration: 60\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6279112100601196\n",
      "LC Training Loss (Full): 0.29036945104599\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8929, LC accuracy: 0.8918, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7994, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7976\n",
      "Epoch: 0, Iteration: 61\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6826440691947937\n",
      "LC Training Loss (Full): 0.309123694896698\n",
      "Epoch: 0, Iteration: 62\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.848815381526947\n",
      "LC Training Loss (Full): 0.543474555015564\n",
      "Epoch: 0, Iteration: 63\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.8135444521903992\n",
      "LC Training Loss (Full): 0.37489286065101624\n",
      "Epoch: 0, Iteration: 64\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.8869548439979553\n",
      "LC Training Loss (Full): 0.5515050888061523\n",
      "Epoch: 0, Iteration: 65\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.5821868181228638\n",
      "LC Training Loss (Full): 0.2569214403629303\n",
      "Full accuracy (w/o dLoRA+LC): 0.8926, LC accuracy: 0.8919, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8007, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.798\n",
      "Epoch: 0, Iteration: 66\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.7007105350494385\n",
      "LC Training Loss (Full): 0.38400304317474365\n",
      "Epoch: 0, Iteration: 67\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.5509034395217896\n",
      "LC Training Loss (Full): 0.2921145558357239\n",
      "Epoch: 0, Iteration: 68\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.7969114780426025\n",
      "LC Training Loss (Full): 0.3498048186302185\n",
      "Epoch: 0, Iteration: 69\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.8770698308944702\n",
      "LC Training Loss (Full): 0.5147714614868164\n",
      "Epoch: 0, Iteration: 70\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7239906787872314\n",
      "LC Training Loss (Full): 0.38523587584495544\n",
      "Full accuracy (w/o dLoRA+LC): 0.892, LC accuracy: 0.8926, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7984, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7982\n",
      "Epoch: 0, Iteration: 71\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.6875102519989014\n",
      "LC Training Loss (Full): 0.4052603542804718\n",
      "Epoch: 0, Iteration: 72\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.8339844346046448\n",
      "LC Training Loss (Full): 0.4365464150905609\n",
      "Epoch: 0, Iteration: 73\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.5705552101135254\n",
      "LC Training Loss (Full): 0.3411407768726349\n",
      "Epoch: 0, Iteration: 74\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7043132185935974\n",
      "LC Training Loss (Full): 0.28284376859664917\n",
      "Epoch: 0, Iteration: 75\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7066294550895691\n",
      "LC Training Loss (Full): 0.42957422137260437\n",
      "Full accuracy (w/o dLoRA+LC): 0.8937, LC accuracy: 0.8926, Decomposed-Full (w/dLoRA+LC) accuracy: 0.7999, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7991\n",
      "Epoch: 0, Iteration: 76\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7625612616539001\n",
      "LC Training Loss (Full): 0.3840097188949585\n",
      "Epoch: 0, Iteration: 77\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7963851690292358\n",
      "LC Training Loss (Full): 0.3904220759868622\n",
      "Epoch: 0, Iteration: 78\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7848717570304871\n",
      "LC Training Loss (Full): 0.3858376145362854\n",
      "Epoch: 0, Iteration: 79\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.769968569278717\n",
      "LC Training Loss (Full): 0.39860549569129944\n",
      "Epoch: 0, Iteration: 80\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8527835607528687\n",
      "LC Training Loss (Full): 0.509081244468689\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.875\n",
      "Full accuracy (w/o dLoRA+LC): 0.8943, LC accuracy: 0.8933, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7991\n",
      "Epoch: 0, Iteration: 81\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.68030846118927\n",
      "LC Training Loss (Full): 0.3108901083469391\n",
      "Epoch: 0, Iteration: 82\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7430763840675354\n",
      "LC Training Loss (Full): 0.4229675829410553\n",
      "Epoch: 0, Iteration: 83\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.8529631495475769\n",
      "LC Training Loss (Full): 0.5137923955917358\n",
      "Epoch: 0, Iteration: 84\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7643293738365173\n",
      "LC Training Loss (Full): 0.48859477043151855\n",
      "Epoch: 0, Iteration: 85\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.8283849954605103\n",
      "LC Training Loss (Full): 0.4377838671207428\n",
      "Full accuracy (w/o dLoRA+LC): 0.8928, LC accuracy: 0.8936, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8025, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7999\n",
      "Epoch: 0, Iteration: 86\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7853689789772034\n",
      "LC Training Loss (Full): 0.35066738724708557\n",
      "Epoch: 0, Iteration: 87\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.6659120321273804\n",
      "LC Training Loss (Full): 0.36898908019065857\n",
      "Epoch: 0, Iteration: 88\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7793416976928711\n",
      "LC Training Loss (Full): 0.4706035256385803\n",
      "Epoch: 0, Iteration: 89\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.6989385485649109\n",
      "LC Training Loss (Full): 0.39588767290115356\n",
      "Epoch: 0, Iteration: 90\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6592260599136353\n",
      "LC Training Loss (Full): 0.26707029342651367\n",
      "Full accuracy (w/o dLoRA+LC): 0.8957, LC accuracy: 0.8944, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8015, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8003\n",
      "Epoch: 0, Iteration: 91\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7358510494232178\n",
      "LC Training Loss (Full): 0.32969698309898376\n",
      "Epoch: 0, Iteration: 92\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6653766632080078\n",
      "LC Training Loss (Full): 0.3526436686515808\n",
      "Epoch: 0, Iteration: 93\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7783877849578857\n",
      "LC Training Loss (Full): 0.4386177659034729\n",
      "Epoch: 0, Iteration: 94\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6519156694412231\n",
      "LC Training Loss (Full): 0.3900989592075348\n",
      "Epoch: 0, Iteration: 95\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.8342231512069702\n",
      "LC Training Loss (Full): 0.5706833004951477\n",
      "Full accuracy (w/o dLoRA+LC): 0.8961, LC accuracy: 0.8945, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8032, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7998\n",
      "Epoch: 0, Iteration: 96\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6783434748649597\n",
      "LC Training Loss (Full): 0.3590584993362427\n",
      "Epoch: 0, Iteration: 97\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7911203503608704\n",
      "LC Training Loss (Full): 0.32532721757888794\n",
      "Epoch: 0, Iteration: 98\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.7621706128120422\n",
      "LC Training Loss (Full): 0.2981756329536438\n",
      "Epoch: 0, Iteration: 99\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6216444373130798\n",
      "LC Training Loss (Full): 0.28270721435546875\n",
      "Epoch: 0, Iteration: 100\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7396335005760193\n",
      "LC Training Loss (Full): 0.40708643198013306\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8957, LC accuracy: 0.8946, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8004, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8003\n",
      "Epoch: 0, Iteration: 101\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.8156395554542542\n",
      "LC Training Loss (Full): 0.5809495449066162\n",
      "Epoch: 0, Iteration: 102\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.5773091912269592\n",
      "LC Training Loss (Full): 0.21911150217056274\n",
      "Epoch: 0, Iteration: 103\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.676193356513977\n",
      "LC Training Loss (Full): 0.34765735268592834\n",
      "Epoch: 0, Iteration: 104\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.784855306148529\n",
      "LC Training Loss (Full): 0.41628822684288025\n",
      "Epoch: 0, Iteration: 105\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.7785903811454773\n",
      "LC Training Loss (Full): 0.41731613874435425\n",
      "Full accuracy (w/o dLoRA+LC): 0.8948, LC accuracy: 0.8943, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8008, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7992\n",
      "Epoch: 0, Iteration: 106\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.8370012044906616\n",
      "LC Training Loss (Full): 0.4782847464084625\n",
      "Epoch: 0, Iteration: 107\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.8461416959762573\n",
      "LC Training Loss (Full): 0.5895540118217468\n",
      "Epoch: 0, Iteration: 108\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.8532751202583313\n",
      "LC Training Loss (Full): 0.4788174033164978\n",
      "Epoch: 0, Iteration: 109\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6405280828475952\n",
      "LC Training Loss (Full): 0.2638709843158722\n",
      "Epoch: 0, Iteration: 110\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8299303650856018\n",
      "LC Training Loss (Full): 0.5715139508247375\n",
      "Full accuracy (w/o dLoRA+LC): 0.8947, LC accuracy: 0.8954, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8004, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.7996\n",
      "Epoch: 0, Iteration: 111\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.9048586487770081\n",
      "LC Training Loss (Full): 0.3710865378379822\n",
      "Epoch: 0, Iteration: 112\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.6284363269805908\n",
      "LC Training Loss (Full): 0.23090258240699768\n",
      "Epoch: 0, Iteration: 113\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.6196341514587402\n",
      "LC Training Loss (Full): 0.31168830394744873\n",
      "Epoch: 0, Iteration: 114\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.7022646069526672\n",
      "LC Training Loss (Full): 0.376282274723053\n",
      "Epoch: 0, Iteration: 115\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.7228894233703613\n",
      "LC Training Loss (Full): 0.3684369623661041\n",
      "Full accuracy (w/o dLoRA+LC): 0.8971, LC accuracy: 0.8953, Decomposed-Full (w/dLoRA+LC) accuracy: 0.802, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8006\n",
      "Epoch: 0, Iteration: 116\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.7200948596000671\n",
      "LC Training Loss (Full): 0.34246283769607544\n",
      "Epoch: 0, Iteration: 117\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.9792998433113098\n",
      "LC Training Loss (Full): 0.5706525444984436\n",
      "Epoch: 0, Iteration: 118\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.8599790334701538\n",
      "LC Training Loss (Full): 0.5724513530731201\n",
      "Epoch: 0, Iteration: 119\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.6697515249252319\n",
      "LC Training Loss (Full): 0.41164442896842957\n",
      "Epoch: 0, Iteration: 120\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6436079740524292\n",
      "LC Training Loss (Full): 0.3443746566772461\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8978, LC accuracy: 0.8977, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8007, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8007\n",
      "Epoch: 0, Iteration: 121\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7763369679450989\n",
      "LC Training Loss (Full): 0.4725436270236969\n",
      "Epoch: 0, Iteration: 122\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.737293541431427\n",
      "LC Training Loss (Full): 0.40342098474502563\n",
      "Epoch: 0, Iteration: 123\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7397566437721252\n",
      "LC Training Loss (Full): 0.40454521775245667\n",
      "Epoch: 0, Iteration: 124\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.6528788805007935\n",
      "LC Training Loss (Full): 0.28837722539901733\n",
      "Epoch: 0, Iteration: 125\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7948706746101379\n",
      "LC Training Loss (Full): 0.47920387983322144\n",
      "Full accuracy (w/o dLoRA+LC): 0.8955, LC accuracy: 0.8976, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8017, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8003\n",
      "Epoch: 0, Iteration: 126\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7348254919052124\n",
      "LC Training Loss (Full): 0.4272494614124298\n",
      "Epoch: 0, Iteration: 127\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.8428475260734558\n",
      "LC Training Loss (Full): 0.39814266562461853\n",
      "Epoch: 0, Iteration: 128\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7247856855392456\n",
      "LC Training Loss (Full): 0.3803989887237549\n",
      "Epoch: 0, Iteration: 129\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7628998756408691\n",
      "LC Training Loss (Full): 0.3834208548069\n",
      "Epoch: 0, Iteration: 130\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6939405798912048\n",
      "LC Training Loss (Full): 0.3962796628475189\n",
      "Full accuracy (w/o dLoRA+LC): 0.8952, LC accuracy: 0.8952, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8002, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8\n",
      "Epoch: 0, Iteration: 131\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6964035630226135\n",
      "LC Training Loss (Full): 0.34244558215141296\n",
      "Epoch: 0, Iteration: 132\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7726870775222778\n",
      "LC Training Loss (Full): 0.38051632046699524\n",
      "Epoch: 0, Iteration: 133\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8238111734390259\n",
      "LC Training Loss (Full): 0.39792969822883606\n",
      "Epoch: 0, Iteration: 134\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6385579109191895\n",
      "LC Training Loss (Full): 0.29706525802612305\n",
      "Epoch: 0, Iteration: 135\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6769558787345886\n",
      "LC Training Loss (Full): 0.3293541371822357\n",
      "Full accuracy (w/o dLoRA+LC): 0.8985, LC accuracy: 0.8955, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8013, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8005\n",
      "Epoch: 0, Iteration: 136\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.9118790030479431\n",
      "LC Training Loss (Full): 0.4341210722923279\n",
      "Epoch: 0, Iteration: 137\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7535602450370789\n",
      "LC Training Loss (Full): 0.45140939950942993\n",
      "Epoch: 0, Iteration: 138\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7344427704811096\n",
      "LC Training Loss (Full): 0.3247978687286377\n",
      "Epoch: 0, Iteration: 139\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8142306804656982\n",
      "LC Training Loss (Full): 0.4200762212276459\n",
      "Epoch: 0, Iteration: 140\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7257771492004395\n",
      "LC Training Loss (Full): 0.4588914215564728\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8984, LC accuracy: 0.8983, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8015, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8005\n",
      "Epoch: 0, Iteration: 141\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.7534326910972595\n",
      "LC Training Loss (Full): 0.30371546745300293\n",
      "Epoch: 0, Iteration: 142\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.648124635219574\n",
      "LC Training Loss (Full): 0.325080007314682\n",
      "Epoch: 0, Iteration: 143\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6787070035934448\n",
      "LC Training Loss (Full): 0.2688806653022766\n",
      "Epoch: 0, Iteration: 144\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.7937777042388916\n",
      "LC Training Loss (Full): 0.39827147126197815\n",
      "Epoch: 0, Iteration: 145\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.7412119507789612\n",
      "LC Training Loss (Full): 0.37900352478027344\n",
      "Full accuracy (w/o dLoRA+LC): 0.8995, LC accuracy: 0.8984, Decomposed-Full (w/dLoRA+LC) accuracy: 0.803, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.801\n",
      "Epoch: 0, Iteration: 146\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.9508816003799438\n",
      "LC Training Loss (Full): 0.4098636209964752\n",
      "Epoch: 0, Iteration: 147\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.8521101474761963\n",
      "LC Training Loss (Full): 0.46474120020866394\n",
      "Epoch: 0, Iteration: 148\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.7780734300613403\n",
      "LC Training Loss (Full): 0.37603190541267395\n",
      "Epoch: 0, Iteration: 149\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.587436318397522\n",
      "LC Training Loss (Full): 0.2255357950925827\n",
      "Epoch: 0, Iteration: 150\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5985245108604431\n",
      "LC Training Loss (Full): 0.2501388490200043\n",
      "Full accuracy (w/o dLoRA+LC): 0.9003, LC accuracy: 0.9005, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8021, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8019\n",
      "Epoch: 0, Iteration: 151\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.7675550580024719\n",
      "LC Training Loss (Full): 0.4885527789592743\n",
      "Epoch: 0, Iteration: 152\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.6947125792503357\n",
      "LC Training Loss (Full): 0.42431721091270447\n",
      "Epoch: 0, Iteration: 153\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.5665448904037476\n",
      "LC Training Loss (Full): 0.271932452917099\n",
      "Epoch: 0, Iteration: 154\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.7154161334037781\n",
      "LC Training Loss (Full): 0.31363365054130554\n",
      "Epoch: 0, Iteration: 155\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.5657040476799011\n",
      "LC Training Loss (Full): 0.329220175743103\n",
      "Full accuracy (w/o dLoRA+LC): 0.8995, LC accuracy: 0.9003, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8025, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8011\n",
      "Epoch: 0, Iteration: 156\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.7634118795394897\n",
      "LC Training Loss (Full): 0.37294745445251465\n",
      "Epoch: 0, Iteration: 157\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.6735345721244812\n",
      "LC Training Loss (Full): 0.37946727871894836\n",
      "Epoch: 0, Iteration: 158\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.7836748957633972\n",
      "LC Training Loss (Full): 0.36834433674812317\n",
      "Epoch: 0, Iteration: 159\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.9069821238517761\n",
      "LC Training Loss (Full): 0.5070303082466125\n",
      "Epoch: 0, Iteration: 160\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8476006984710693\n",
      "LC Training Loss (Full): 0.4392584562301636\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9002, LC accuracy: 0.9, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8035, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8017\n",
      "Epoch: 0, Iteration: 161\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6909709572792053\n",
      "LC Training Loss (Full): 0.4184620678424835\n",
      "Epoch: 0, Iteration: 162\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.770583987236023\n",
      "LC Training Loss (Full): 0.32556796073913574\n",
      "Epoch: 0, Iteration: 163\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.8210090398788452\n",
      "LC Training Loss (Full): 0.493027001619339\n",
      "Epoch: 0, Iteration: 164\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.7847386598587036\n",
      "LC Training Loss (Full): 0.35468170046806335\n",
      "Epoch: 0, Iteration: 165\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6962469220161438\n",
      "LC Training Loss (Full): 0.3198704123497009\n",
      "Full accuracy (w/o dLoRA+LC): 0.9012, LC accuracy: 0.9, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8034, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8018\n",
      "Epoch: 0, Iteration: 166\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6895413994789124\n",
      "LC Training Loss (Full): 0.3505555987358093\n",
      "Epoch: 0, Iteration: 167\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.8952323198318481\n",
      "LC Training Loss (Full): 0.49501919746398926\n",
      "Epoch: 0, Iteration: 168\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6915225982666016\n",
      "LC Training Loss (Full): 0.3903405964374542\n",
      "Epoch: 0, Iteration: 169\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6995698809623718\n",
      "LC Training Loss (Full): 0.3150150179862976\n",
      "Epoch: 0, Iteration: 170\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7798913717269897\n",
      "LC Training Loss (Full): 0.3914923071861267\n",
      "Full accuracy (w/o dLoRA+LC): 0.9001, LC accuracy: 0.901, Decomposed-Full (w/dLoRA+LC) accuracy: 0.802, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8026\n",
      "Epoch: 0, Iteration: 171\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8039225339889526\n",
      "LC Training Loss (Full): 0.43071767687797546\n",
      "Epoch: 0, Iteration: 172\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.6759175062179565\n",
      "LC Training Loss (Full): 0.34823209047317505\n",
      "Epoch: 0, Iteration: 173\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.7151727080345154\n",
      "LC Training Loss (Full): 0.404958039522171\n",
      "Epoch: 0, Iteration: 174\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.7623578310012817\n",
      "LC Training Loss (Full): 0.4439166188240051\n",
      "Epoch: 0, Iteration: 175\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.802993655204773\n",
      "LC Training Loss (Full): 0.4556475579738617\n",
      "Full accuracy (w/o dLoRA+LC): 0.8994, LC accuracy: 0.901, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8028, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8032\n",
      "Epoch: 0, Iteration: 176\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.6442611217498779\n",
      "LC Training Loss (Full): 0.3784196674823761\n",
      "Epoch: 0, Iteration: 177\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.7596381306648254\n",
      "LC Training Loss (Full): 0.3876677453517914\n",
      "Epoch: 0, Iteration: 178\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.7873647809028625\n",
      "LC Training Loss (Full): 0.45164090394973755\n",
      "Epoch: 0, Iteration: 179\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8491091728210449\n",
      "LC Training Loss (Full): 0.49333253502845764\n",
      "Epoch: 0, Iteration: 180\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7162824869155884\n",
      "LC Training Loss (Full): 0.34933969378471375\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.8989, LC accuracy: 0.8978, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8015, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8013\n",
      "Epoch: 0, Iteration: 181\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6963551640510559\n",
      "LC Training Loss (Full): 0.41235315799713135\n",
      "Epoch: 0, Iteration: 182\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.7459083199501038\n",
      "LC Training Loss (Full): 0.3502829074859619\n",
      "Epoch: 0, Iteration: 183\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.80438631772995\n",
      "LC Training Loss (Full): 0.37099966406822205\n",
      "Epoch: 0, Iteration: 184\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6309036612510681\n",
      "LC Training Loss (Full): 0.2709946036338806\n",
      "Epoch: 0, Iteration: 185\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6506388783454895\n",
      "LC Training Loss (Full): 0.2820418179035187\n",
      "Full accuracy (w/o dLoRA+LC): 0.9035, LC accuracy: 0.8981, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8054, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.803\n",
      "Epoch: 0, Iteration: 186\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6900297403335571\n",
      "LC Training Loss (Full): 0.32595738768577576\n",
      "Epoch: 0, Iteration: 187\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.7931006550788879\n",
      "LC Training Loss (Full): 0.32076576352119446\n",
      "Epoch: 0, Iteration: 188\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6689607501029968\n",
      "LC Training Loss (Full): 0.3891212046146393\n",
      "Epoch: 0, Iteration: 189\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.773159921169281\n",
      "LC Training Loss (Full): 0.3568575084209442\n",
      "Epoch: 0, Iteration: 190\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9533570408821106\n",
      "LC Training Loss (Full): 0.6582844853401184\n",
      "Full accuracy (w/o dLoRA+LC): 0.9034, LC accuracy: 0.9037, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8041, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8033\n",
      "Epoch: 0, Iteration: 191\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.8505467772483826\n",
      "LC Training Loss (Full): 0.41641104221343994\n",
      "Epoch: 0, Iteration: 192\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.8654415607452393\n",
      "LC Training Loss (Full): 0.5204195380210876\n",
      "Epoch: 0, Iteration: 193\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.6590775847434998\n",
      "LC Training Loss (Full): 0.41232529282569885\n",
      "Epoch: 0, Iteration: 194\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.8349366188049316\n",
      "LC Training Loss (Full): 0.4906418025493622\n",
      "Epoch: 0, Iteration: 195\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.6636989116668701\n",
      "LC Training Loss (Full): 0.33251968026161194\n",
      "Full accuracy (w/o dLoRA+LC): 0.9025, LC accuracy: 0.9034, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8054, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8029\n",
      "Epoch: 0, Iteration: 196\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.7575669288635254\n",
      "LC Training Loss (Full): 0.3201702833175659\n",
      "Epoch: 0, Iteration: 197\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.691818356513977\n",
      "LC Training Loss (Full): 0.41677552461624146\n",
      "Epoch: 0, Iteration: 198\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.5350617170333862\n",
      "LC Training Loss (Full): 0.2942701578140259\n",
      "Epoch: 0, Iteration: 199\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.7081831097602844\n",
      "LC Training Loss (Full): 0.37321484088897705\n",
      "Epoch: 0, Iteration: 200\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7457203269004822\n",
      "LC Training Loss (Full): 0.4651853144168854\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.859375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9042, LC accuracy: 0.9028, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8043, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8027\n",
      "Epoch: 0, Iteration: 201\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6508266925811768\n",
      "LC Training Loss (Full): 0.2774840295314789\n",
      "Epoch: 0, Iteration: 202\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7632583975791931\n",
      "LC Training Loss (Full): 0.41447141766548157\n",
      "Epoch: 0, Iteration: 203\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7555022835731506\n",
      "LC Training Loss (Full): 0.3879264295101166\n",
      "Epoch: 0, Iteration: 204\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7059903144836426\n",
      "LC Training Loss (Full): 0.36060574650764465\n",
      "Epoch: 0, Iteration: 205\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7734388709068298\n",
      "LC Training Loss (Full): 0.4906051754951477\n",
      "Full accuracy (w/o dLoRA+LC): 0.9036, LC accuracy: 0.903, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8042, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8035\n",
      "Epoch: 0, Iteration: 206\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7866707444190979\n",
      "LC Training Loss (Full): 0.4067717492580414\n",
      "Epoch: 0, Iteration: 207\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7802808284759521\n",
      "LC Training Loss (Full): 0.3674969971179962\n",
      "Epoch: 0, Iteration: 208\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7917202115058899\n",
      "LC Training Loss (Full): 0.4816999137401581\n",
      "Epoch: 0, Iteration: 209\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6294189691543579\n",
      "LC Training Loss (Full): 0.33206906914711\n",
      "Epoch: 0, Iteration: 210\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8111162781715393\n",
      "LC Training Loss (Full): 0.47615551948547363\n",
      "Full accuracy (w/o dLoRA+LC): 0.9044, LC accuracy: 0.9024, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8043, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8017\n",
      "Epoch: 0, Iteration: 211\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.632344663143158\n",
      "LC Training Loss (Full): 0.26494574546813965\n",
      "Epoch: 0, Iteration: 212\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6734104752540588\n",
      "LC Training Loss (Full): 0.32339075207710266\n",
      "Epoch: 0, Iteration: 213\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.75969398021698\n",
      "LC Training Loss (Full): 0.35667911171913147\n",
      "Epoch: 0, Iteration: 214\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.818414568901062\n",
      "LC Training Loss (Full): 0.4582957327365875\n",
      "Epoch: 0, Iteration: 215\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.8341858386993408\n",
      "LC Training Loss (Full): 0.4485473036766052\n",
      "Full accuracy (w/o dLoRA+LC): 0.9048, LC accuracy: 0.9023, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8054, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8027\n",
      "Epoch: 0, Iteration: 216\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6813923120498657\n",
      "LC Training Loss (Full): 0.2843523323535919\n",
      "Epoch: 0, Iteration: 217\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6429585218429565\n",
      "LC Training Loss (Full): 0.3539060056209564\n",
      "Epoch: 0, Iteration: 218\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.8211446404457092\n",
      "LC Training Loss (Full): 0.4619092345237732\n",
      "Epoch: 0, Iteration: 219\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.7004282474517822\n",
      "LC Training Loss (Full): 0.3599129021167755\n",
      "Epoch: 0, Iteration: 220\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5881699323654175\n",
      "LC Training Loss (Full): 0.2922167181968689\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9057, LC accuracy: 0.9044, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8046, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8042\n",
      "Epoch: 0, Iteration: 221\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6738668084144592\n",
      "LC Training Loss (Full): 0.36123061180114746\n",
      "Epoch: 0, Iteration: 222\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6901401877403259\n",
      "LC Training Loss (Full): 0.32851988077163696\n",
      "Epoch: 0, Iteration: 223\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6949632167816162\n",
      "LC Training Loss (Full): 0.29579436779022217\n",
      "Epoch: 0, Iteration: 224\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.7405688762664795\n",
      "LC Training Loss (Full): 0.40086159110069275\n",
      "Epoch: 0, Iteration: 225\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6159954071044922\n",
      "LC Training Loss (Full): 0.36714881658554077\n",
      "Full accuracy (w/o dLoRA+LC): 0.9032, LC accuracy: 0.9044, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8034, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8041\n",
      "Epoch: 0, Iteration: 226\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6486162543296814\n",
      "LC Training Loss (Full): 0.36867693066596985\n",
      "Epoch: 0, Iteration: 227\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.8939357399940491\n",
      "LC Training Loss (Full): 0.46921852231025696\n",
      "Epoch: 0, Iteration: 228\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6442016959190369\n",
      "LC Training Loss (Full): 0.2851770520210266\n",
      "Epoch: 0, Iteration: 229\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6542409658432007\n",
      "LC Training Loss (Full): 0.3258610665798187\n",
      "Epoch: 0, Iteration: 230\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_23\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6789712905883789\n",
      "LC Training Loss (Full): 0.30293041467666626\n",
      "Full accuracy (w/o dLoRA+LC): 0.905, LC accuracy: 0.9046, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8058, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8045\n",
      "Epoch: 0, Iteration: 231\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.8673328757286072\n",
      "LC Training Loss (Full): 0.4097922146320343\n",
      "Epoch: 0, Iteration: 232\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.8053968548774719\n",
      "LC Training Loss (Full): 0.4472760260105133\n",
      "Epoch: 0, Iteration: 233\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.6024627089500427\n",
      "LC Training Loss (Full): 0.2310047149658203\n",
      "Epoch: 0, Iteration: 234\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.8132787942886353\n",
      "LC Training Loss (Full): 0.42397215962409973\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8020333051681519\n",
      "LC Training Loss (Full): 0.4239988625049591\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.84375\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7210094332695007\n",
      "LC Training Loss (Full): 0.40401649475097656\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.5964230298995972\n",
      "LC Training Loss (Full): 0.25966835021972656\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.8407450914382935\n",
      "LC Training Loss (Full): 0.4855227470397949\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6531264185905457\n",
      "LC Training Loss (Full): 0.29170477390289307\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7627887725830078\n",
      "LC Training Loss (Full): 0.43316274881362915\n",
      "Full accuracy (w/o dLoRA+LC): 0.904, LC accuracy: 0.9046, Decomposed-Full (w/dLoRA+LC) accuracy: 0.806, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.805\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.700543999671936\n",
      "LC Training Loss (Full): 0.34510576725006104\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7349669933319092\n",
      "LC Training Loss (Full): 0.37463369965553284\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6519815325737\n",
      "LC Training Loss (Full): 0.32665959000587463\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6750438213348389\n",
      "LC Training Loss (Full): 0.41186872124671936\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6697919964790344\n",
      "LC Training Loss (Full): 0.28040581941604614\n",
      "Full accuracy (w/o dLoRA+LC): 0.9037, LC accuracy: 0.9045, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8053, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8045\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.8066230416297913\n",
      "LC Training Loss (Full): 0.4042838215827942\n",
      "Epoch: 1, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7893111109733582\n",
      "LC Training Loss (Full): 0.34239256381988525\n",
      "Epoch: 1, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 1.0436327457427979\n",
      "LC Training Loss (Full): 0.766982913017273\n",
      "Epoch: 1, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.5465522408485413\n",
      "LC Training Loss (Full): 0.17288197576999664\n",
      "Epoch: 1, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.674907922744751\n",
      "LC Training Loss (Full): 0.3268178403377533\n",
      "Full accuracy (w/o dLoRA+LC): 0.9041, LC accuracy: 0.9045, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8076, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8053\n",
      "Epoch: 1, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.5285346508026123\n",
      "LC Training Loss (Full): 0.2237168252468109\n",
      "Epoch: 1, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.6275978684425354\n",
      "LC Training Loss (Full): 0.2873271107673645\n",
      "Epoch: 1, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.8995603322982788\n",
      "LC Training Loss (Full): 0.44836679100990295\n",
      "Epoch: 1, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7078148126602173\n",
      "LC Training Loss (Full): 0.41214680671691895\n",
      "Epoch: 1, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.634339451789856\n",
      "LC Training Loss (Full): 0.26982757449150085\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9031, LC accuracy: 0.9031, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8062, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.805\n",
      "Epoch: 1, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.7556650638580322\n",
      "LC Training Loss (Full): 0.3691043257713318\n",
      "Epoch: 1, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.553665816783905\n",
      "LC Training Loss (Full): 0.24400180578231812\n",
      "Epoch: 1, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.7442045211791992\n",
      "LC Training Loss (Full): 0.26022806763648987\n",
      "Epoch: 1, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6426472663879395\n",
      "LC Training Loss (Full): 0.23811456561088562\n",
      "Epoch: 1, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.5973247289657593\n",
      "LC Training Loss (Full): 0.3015149235725403\n",
      "Full accuracy (w/o dLoRA+LC): 0.9039, LC accuracy: 0.903, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8062, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8044\n",
      "Epoch: 1, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6119447350502014\n",
      "LC Training Loss (Full): 0.26982611417770386\n",
      "Epoch: 1, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.7746268510818481\n",
      "LC Training Loss (Full): 0.2850097119808197\n",
      "Epoch: 1, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6966224312782288\n",
      "LC Training Loss (Full): 0.4119704067707062\n",
      "Epoch: 1, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6165685653686523\n",
      "LC Training Loss (Full): 0.24539950489997864\n",
      "Epoch: 1, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7321703433990479\n",
      "LC Training Loss (Full): 0.42027953267097473\n",
      "Full accuracy (w/o dLoRA+LC): 0.9034, LC accuracy: 0.9036, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8057, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8056\n",
      "Epoch: 1, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.7591698169708252\n",
      "LC Training Loss (Full): 0.4561972916126251\n",
      "Epoch: 1, Iteration: 32\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.7019968628883362\n",
      "LC Training Loss (Full): 0.2910042703151703\n",
      "Epoch: 1, Iteration: 33\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6350598335266113\n",
      "LC Training Loss (Full): 0.27550816535949707\n",
      "Epoch: 1, Iteration: 34\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.8434701561927795\n",
      "LC Training Loss (Full): 0.41085749864578247\n",
      "Epoch: 1, Iteration: 35\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.8905084729194641\n",
      "LC Training Loss (Full): 0.4630416929721832\n",
      "Full accuracy (w/o dLoRA+LC): 0.9049, LC accuracy: 0.9035, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8063, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8049\n",
      "Epoch: 1, Iteration: 36\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6021876931190491\n",
      "LC Training Loss (Full): 0.21424923837184906\n",
      "Epoch: 1, Iteration: 37\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.8516283631324768\n",
      "LC Training Loss (Full): 0.49402984976768494\n",
      "Epoch: 1, Iteration: 38\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.774770200252533\n",
      "LC Training Loss (Full): 0.38617950677871704\n",
      "Epoch: 1, Iteration: 39\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6689431667327881\n",
      "LC Training Loss (Full): 0.3441075086593628\n",
      "Epoch: 1, Iteration: 40\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6747593283653259\n",
      "LC Training Loss (Full): 0.24421824514865875\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9061, LC accuracy: 0.9056, Decomposed-Full (w/dLoRA+LC) accuracy: 0.807, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8055\n",
      "Epoch: 1, Iteration: 41\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.7906460165977478\n",
      "LC Training Loss (Full): 0.426012247800827\n",
      "Epoch: 1, Iteration: 42\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.7943981885910034\n",
      "LC Training Loss (Full): 0.42469775676727295\n",
      "Epoch: 1, Iteration: 43\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.7581480145454407\n",
      "LC Training Loss (Full): 0.2813728451728821\n",
      "Epoch: 1, Iteration: 44\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.7352045178413391\n",
      "LC Training Loss (Full): 0.3392356336116791\n",
      "Epoch: 1, Iteration: 45\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.7203171849250793\n",
      "LC Training Loss (Full): 0.2839222252368927\n",
      "Full accuracy (w/o dLoRA+LC): 0.908, LC accuracy: 0.9056, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8089, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8069\n",
      "Epoch: 1, Iteration: 46\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6184729337692261\n",
      "LC Training Loss (Full): 0.24024292826652527\n",
      "Epoch: 1, Iteration: 47\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.680348813533783\n",
      "LC Training Loss (Full): 0.3061835467815399\n",
      "Epoch: 1, Iteration: 48\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6813976764678955\n",
      "LC Training Loss (Full): 0.26087120175361633\n",
      "Epoch: 1, Iteration: 49\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6398820281028748\n",
      "LC Training Loss (Full): 0.2920989692211151\n",
      "Epoch: 1, Iteration: 50\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6435762047767639\n",
      "LC Training Loss (Full): 0.3103179931640625\n",
      "Full accuracy (w/o dLoRA+LC): 0.909, LC accuracy: 0.9089, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8079, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8074\n",
      "Epoch: 1, Iteration: 51\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6894833445549011\n",
      "LC Training Loss (Full): 0.3229539692401886\n",
      "Epoch: 1, Iteration: 52\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.8074848055839539\n",
      "LC Training Loss (Full): 0.4705835282802582\n",
      "Epoch: 1, Iteration: 53\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7093523740768433\n",
      "LC Training Loss (Full): 0.31600356101989746\n",
      "Epoch: 1, Iteration: 54\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6272051930427551\n",
      "LC Training Loss (Full): 0.2768155038356781\n",
      "Epoch: 1, Iteration: 55\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6634393334388733\n",
      "LC Training Loss (Full): 0.28926345705986023\n",
      "Full accuracy (w/o dLoRA+LC): 0.9072, LC accuracy: 0.9088, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8081, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8069\n",
      "Epoch: 1, Iteration: 56\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7747461795806885\n",
      "LC Training Loss (Full): 0.35650017857551575\n",
      "Epoch: 1, Iteration: 57\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6405537128448486\n",
      "LC Training Loss (Full): 0.25348028540611267\n",
      "Epoch: 1, Iteration: 58\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6263203024864197\n",
      "LC Training Loss (Full): 0.2782173454761505\n",
      "Epoch: 1, Iteration: 59\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7096555829048157\n",
      "LC Training Loss (Full): 0.41514286398887634\n",
      "Epoch: 1, Iteration: 60\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6041683554649353\n",
      "LC Training Loss (Full): 0.2945047616958618\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9087, LC accuracy: 0.9084, Decomposed-Full (w/dLoRA+LC) accuracy: 0.807, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8069\n",
      "Epoch: 1, Iteration: 61\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.8099617958068848\n",
      "LC Training Loss (Full): 0.5132420063018799\n",
      "Epoch: 1, Iteration: 62\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.6144380569458008\n",
      "LC Training Loss (Full): 0.29520854353904724\n",
      "Epoch: 1, Iteration: 63\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.6589229106903076\n",
      "LC Training Loss (Full): 0.2973574995994568\n",
      "Epoch: 1, Iteration: 64\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7216179966926575\n",
      "LC Training Loss (Full): 0.3594565689563751\n",
      "Epoch: 1, Iteration: 65\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.8807348608970642\n",
      "LC Training Loss (Full): 0.5084000825881958\n",
      "Full accuracy (w/o dLoRA+LC): 0.9099, LC accuracy: 0.9088, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8085, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8067\n",
      "Epoch: 1, Iteration: 66\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.6863636374473572\n",
      "LC Training Loss (Full): 0.3827091157436371\n",
      "Epoch: 1, Iteration: 67\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.837706983089447\n",
      "LC Training Loss (Full): 0.43347322940826416\n",
      "Epoch: 1, Iteration: 68\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 1.0143238306045532\n",
      "LC Training Loss (Full): 0.6014432311058044\n",
      "Epoch: 1, Iteration: 69\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.6033712029457092\n",
      "LC Training Loss (Full): 0.2578204274177551\n",
      "Epoch: 1, Iteration: 70\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8407140970230103\n",
      "LC Training Loss (Full): 0.39831429719924927\n",
      "Full accuracy (w/o dLoRA+LC): 0.9094, LC accuracy: 0.91, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8081, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8076\n",
      "Epoch: 1, Iteration: 71\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7659813761711121\n",
      "LC Training Loss (Full): 0.33355340361595154\n",
      "Epoch: 1, Iteration: 72\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.610134482383728\n",
      "LC Training Loss (Full): 0.29903823137283325\n",
      "Epoch: 1, Iteration: 73\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.6365360021591187\n",
      "LC Training Loss (Full): 0.20655196905136108\n",
      "Epoch: 1, Iteration: 74\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7127876281738281\n",
      "LC Training Loss (Full): 0.32224953174591064\n",
      "Epoch: 1, Iteration: 75\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7254290580749512\n",
      "LC Training Loss (Full): 0.31053438782691956\n",
      "Full accuracy (w/o dLoRA+LC): 0.9081, LC accuracy: 0.9098, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8078, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8072\n",
      "Epoch: 1, Iteration: 76\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.5918654203414917\n",
      "LC Training Loss (Full): 0.27160075306892395\n",
      "Epoch: 1, Iteration: 77\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.4833359122276306\n",
      "LC Training Loss (Full): 0.2249574065208435\n",
      "Epoch: 1, Iteration: 78\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.6190112233161926\n",
      "LC Training Loss (Full): 0.2582799792289734\n",
      "Epoch: 1, Iteration: 79\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.6243031620979309\n",
      "LC Training Loss (Full): 0.27637118101119995\n",
      "Epoch: 1, Iteration: 80\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6622104644775391\n",
      "LC Training Loss (Full): 0.3600684702396393\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9087, LC accuracy: 0.9082, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8073, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8074\n",
      "Epoch: 1, Iteration: 81\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.6312594413757324\n",
      "LC Training Loss (Full): 0.2083999663591385\n",
      "Epoch: 1, Iteration: 82\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.7042652368545532\n",
      "LC Training Loss (Full): 0.398806631565094\n",
      "Epoch: 1, Iteration: 83\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.6963168382644653\n",
      "LC Training Loss (Full): 0.3220154941082001\n",
      "Epoch: 1, Iteration: 84\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.7473687529563904\n",
      "LC Training Loss (Full): 0.3732129633426666\n",
      "Epoch: 1, Iteration: 85\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.6937240958213806\n",
      "LC Training Loss (Full): 0.28125786781311035\n",
      "Full accuracy (w/o dLoRA+LC): 0.9102, LC accuracy: 0.9082, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8083, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8071\n",
      "Epoch: 1, Iteration: 86\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.7271633744239807\n",
      "LC Training Loss (Full): 0.2940029501914978\n",
      "Epoch: 1, Iteration: 87\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.7157803773880005\n",
      "LC Training Loss (Full): 0.31849220395088196\n",
      "Epoch: 1, Iteration: 88\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.6950451731681824\n",
      "LC Training Loss (Full): 0.31412747502326965\n",
      "Epoch: 1, Iteration: 89\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.8275374174118042\n",
      "LC Training Loss (Full): 0.46779972314834595\n",
      "Epoch: 1, Iteration: 90\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7644715905189514\n",
      "LC Training Loss (Full): 0.2935521900653839\n",
      "Full accuracy (w/o dLoRA+LC): 0.9117, LC accuracy: 0.9114, Decomposed-Full (w/dLoRA+LC) accuracy: 0.809, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8077\n",
      "Epoch: 1, Iteration: 91\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.8157320618629456\n",
      "LC Training Loss (Full): 0.38487446308135986\n",
      "Epoch: 1, Iteration: 92\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.7127697467803955\n",
      "LC Training Loss (Full): 0.34075596928596497\n",
      "Epoch: 1, Iteration: 93\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.926787257194519\n",
      "LC Training Loss (Full): 0.4607639014720917\n",
      "Epoch: 1, Iteration: 94\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.700547456741333\n",
      "LC Training Loss (Full): 0.3158915638923645\n",
      "Epoch: 1, Iteration: 95\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.8448328971862793\n",
      "LC Training Loss (Full): 0.44129273295402527\n",
      "Full accuracy (w/o dLoRA+LC): 0.9113, LC accuracy: 0.9114, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8105, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8083\n",
      "Epoch: 1, Iteration: 96\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6342909932136536\n",
      "LC Training Loss (Full): 0.29357224702835083\n",
      "Epoch: 1, Iteration: 97\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.701300859451294\n",
      "LC Training Loss (Full): 0.26510605216026306\n",
      "Epoch: 1, Iteration: 98\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.8055288791656494\n",
      "LC Training Loss (Full): 0.4470018446445465\n",
      "Epoch: 1, Iteration: 99\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6781415343284607\n",
      "LC Training Loss (Full): 0.30041009187698364\n",
      "Epoch: 1, Iteration: 100\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.710791289806366\n",
      "LC Training Loss (Full): 0.33533215522766113\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9107, LC accuracy: 0.9103, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8094, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8075\n",
      "Epoch: 1, Iteration: 101\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 1.104584813117981\n",
      "LC Training Loss (Full): 0.6885314583778381\n",
      "Epoch: 1, Iteration: 102\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7152127623558044\n",
      "LC Training Loss (Full): 0.30909764766693115\n",
      "Epoch: 1, Iteration: 103\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.9287930130958557\n",
      "LC Training Loss (Full): 0.5576959848403931\n",
      "Epoch: 1, Iteration: 104\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.8567671179771423\n",
      "LC Training Loss (Full): 0.3984069228172302\n",
      "Epoch: 1, Iteration: 105\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7363236546516418\n",
      "LC Training Loss (Full): 0.446251779794693\n",
      "Full accuracy (w/o dLoRA+LC): 0.913, LC accuracy: 0.9104, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8098, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8086\n",
      "Epoch: 1, Iteration: 106\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.6938276886940002\n",
      "LC Training Loss (Full): 0.3353605270385742\n",
      "Epoch: 1, Iteration: 107\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.5794205069541931\n",
      "LC Training Loss (Full): 0.2421460747718811\n",
      "Epoch: 1, Iteration: 108\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.6044327616691589\n",
      "LC Training Loss (Full): 0.2582682967185974\n",
      "Epoch: 1, Iteration: 109\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.6378279328346252\n",
      "LC Training Loss (Full): 0.28471997380256653\n",
      "Epoch: 1, Iteration: 110\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7528937458992004\n",
      "LC Training Loss (Full): 0.2597631514072418\n",
      "Full accuracy (w/o dLoRA+LC): 0.9113, LC accuracy: 0.9111, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8097, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.808\n",
      "Epoch: 1, Iteration: 111\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.5629260540008545\n",
      "LC Training Loss (Full): 0.31135016679763794\n",
      "Epoch: 1, Iteration: 112\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.8617175221443176\n",
      "LC Training Loss (Full): 0.43812084197998047\n",
      "Epoch: 1, Iteration: 113\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.5588974356651306\n",
      "LC Training Loss (Full): 0.2217303067445755\n",
      "Epoch: 1, Iteration: 114\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7379951477050781\n",
      "LC Training Loss (Full): 0.3821808397769928\n",
      "Epoch: 1, Iteration: 115\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.8043779134750366\n",
      "LC Training Loss (Full): 0.364401638507843\n",
      "Full accuracy (w/o dLoRA+LC): 0.9112, LC accuracy: 0.9112, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8091, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8079\n",
      "Epoch: 1, Iteration: 116\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.6880204081535339\n",
      "LC Training Loss (Full): 0.32001739740371704\n",
      "Epoch: 1, Iteration: 117\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.6986918449401855\n",
      "LC Training Loss (Full): 0.4808797538280487\n",
      "Epoch: 1, Iteration: 118\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.5025224685668945\n",
      "LC Training Loss (Full): 0.18216736614704132\n",
      "Epoch: 1, Iteration: 119\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.8237130045890808\n",
      "LC Training Loss (Full): 0.3716837763786316\n",
      "Epoch: 1, Iteration: 120\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.908983051776886\n",
      "LC Training Loss (Full): 0.5998005867004395\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9123, LC accuracy: 0.9112, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8089, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8085\n",
      "Epoch: 1, Iteration: 121\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7704230546951294\n",
      "LC Training Loss (Full): 0.3835689127445221\n",
      "Epoch: 1, Iteration: 122\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7581015229225159\n",
      "LC Training Loss (Full): 0.2998832166194916\n",
      "Epoch: 1, Iteration: 123\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5778980255126953\n",
      "LC Training Loss (Full): 0.2569310963153839\n",
      "Epoch: 1, Iteration: 124\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7142282128334045\n",
      "LC Training Loss (Full): 0.2982002794742584\n",
      "Epoch: 1, Iteration: 125\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.6598427891731262\n",
      "LC Training Loss (Full): 0.28808316588401794\n",
      "Full accuracy (w/o dLoRA+LC): 0.911, LC accuracy: 0.9112, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8091, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8078\n",
      "Epoch: 1, Iteration: 126\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.71511310338974\n",
      "LC Training Loss (Full): 0.3769601881504059\n",
      "Epoch: 1, Iteration: 127\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7917379140853882\n",
      "LC Training Loss (Full): 0.36618322134017944\n",
      "Epoch: 1, Iteration: 128\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7803911566734314\n",
      "LC Training Loss (Full): 0.36837080121040344\n",
      "Epoch: 1, Iteration: 129\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.6256036162376404\n",
      "LC Training Loss (Full): 0.2213715761899948\n",
      "Epoch: 1, Iteration: 130\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6732703447341919\n",
      "LC Training Loss (Full): 0.33630314469337463\n",
      "Full accuracy (w/o dLoRA+LC): 0.9118, LC accuracy: 0.911, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8088, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8075\n",
      "Epoch: 1, Iteration: 131\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.8180789351463318\n",
      "LC Training Loss (Full): 0.4060823917388916\n",
      "Epoch: 1, Iteration: 132\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6744124889373779\n",
      "LC Training Loss (Full): 0.2329186350107193\n",
      "Epoch: 1, Iteration: 133\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6351600885391235\n",
      "LC Training Loss (Full): 0.2776470184326172\n",
      "Epoch: 1, Iteration: 134\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7839105129241943\n",
      "LC Training Loss (Full): 0.39412057399749756\n",
      "Epoch: 1, Iteration: 135\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6583635807037354\n",
      "LC Training Loss (Full): 0.26544123888015747\n",
      "Full accuracy (w/o dLoRA+LC): 0.9113, LC accuracy: 0.9109, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8102, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.808\n",
      "Epoch: 1, Iteration: 136\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6509775519371033\n",
      "LC Training Loss (Full): 0.2989254891872406\n",
      "Epoch: 1, Iteration: 137\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6257192492485046\n",
      "LC Training Loss (Full): 0.262449711561203\n",
      "Epoch: 1, Iteration: 138\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6553446650505066\n",
      "LC Training Loss (Full): 0.3022180497646332\n",
      "Epoch: 1, Iteration: 139\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.8171463012695312\n",
      "LC Training Loss (Full): 0.45352813601493835\n",
      "Epoch: 1, Iteration: 140\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6969431638717651\n",
      "LC Training Loss (Full): 0.385661780834198\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9112, LC accuracy: 0.9117, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8079, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8081\n",
      "Epoch: 1, Iteration: 141\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.8263705968856812\n",
      "LC Training Loss (Full): 0.5283055901527405\n",
      "Epoch: 1, Iteration: 142\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.6359954476356506\n",
      "LC Training Loss (Full): 0.32203546166419983\n",
      "Epoch: 1, Iteration: 143\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7681189179420471\n",
      "LC Training Loss (Full): 0.4127267301082611\n",
      "Epoch: 1, Iteration: 144\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.8957748413085938\n",
      "LC Training Loss (Full): 0.3847435712814331\n",
      "Epoch: 1, Iteration: 145\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.46613553166389465\n",
      "LC Training Loss (Full): 0.13043035566806793\n",
      "Full accuracy (w/o dLoRA+LC): 0.9117, LC accuracy: 0.9116, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8087, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.808\n",
      "Epoch: 1, Iteration: 146\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7999229431152344\n",
      "LC Training Loss (Full): 0.4420104920864105\n",
      "Epoch: 1, Iteration: 147\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.834828794002533\n",
      "LC Training Loss (Full): 0.37250402569770813\n",
      "Epoch: 1, Iteration: 148\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7356786131858826\n",
      "LC Training Loss (Full): 0.43076732754707336\n",
      "Epoch: 1, Iteration: 149\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7522063851356506\n",
      "LC Training Loss (Full): 0.2826998829841614\n",
      "Epoch: 1, Iteration: 150\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6542003154754639\n",
      "LC Training Loss (Full): 0.21028666198253632\n",
      "Full accuracy (w/o dLoRA+LC): 0.9129, LC accuracy: 0.9123, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8085, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8065\n",
      "Epoch: 1, Iteration: 151\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7541996240615845\n",
      "LC Training Loss (Full): 0.4445565640926361\n",
      "Epoch: 1, Iteration: 152\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7067288160324097\n",
      "LC Training Loss (Full): 0.3059690296649933\n",
      "Epoch: 1, Iteration: 153\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.8258243203163147\n",
      "LC Training Loss (Full): 0.4596918225288391\n",
      "Epoch: 1, Iteration: 154\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7656614780426025\n",
      "LC Training Loss (Full): 0.37411952018737793\n",
      "Epoch: 1, Iteration: 155\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7912389039993286\n",
      "LC Training Loss (Full): 0.404171884059906\n",
      "Full accuracy (w/o dLoRA+LC): 0.9137, LC accuracy: 0.9124, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8092, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8084\n",
      "Epoch: 1, Iteration: 156\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7251442074775696\n",
      "LC Training Loss (Full): 0.3263924717903137\n",
      "Epoch: 1, Iteration: 157\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.6205962300300598\n",
      "LC Training Loss (Full): 0.27535203099250793\n",
      "Epoch: 1, Iteration: 158\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.8535054922103882\n",
      "LC Training Loss (Full): 0.44661784172058105\n",
      "Epoch: 1, Iteration: 159\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.6087048053741455\n",
      "LC Training Loss (Full): 0.2699257731437683\n",
      "Epoch: 1, Iteration: 160\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5780277252197266\n",
      "LC Training Loss (Full): 0.3065328299999237\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9125, LC accuracy: 0.9124, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8085, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8078\n",
      "Epoch: 1, Iteration: 161\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.8732748031616211\n",
      "LC Training Loss (Full): 0.6135716438293457\n",
      "Epoch: 1, Iteration: 162\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6315894722938538\n",
      "LC Training Loss (Full): 0.2348528802394867\n",
      "Epoch: 1, Iteration: 163\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5240675210952759\n",
      "LC Training Loss (Full): 0.19765838980674744\n",
      "Epoch: 1, Iteration: 164\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5968449711799622\n",
      "LC Training Loss (Full): 0.24629241228103638\n",
      "Epoch: 1, Iteration: 165\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.955371081829071\n",
      "LC Training Loss (Full): 0.5013185143470764\n",
      "Full accuracy (w/o dLoRA+LC): 0.9125, LC accuracy: 0.9125, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8114, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.809\n",
      "Epoch: 1, Iteration: 166\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6342995166778564\n",
      "LC Training Loss (Full): 0.36687013506889343\n",
      "Epoch: 1, Iteration: 167\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6341580748558044\n",
      "LC Training Loss (Full): 0.33249351382255554\n",
      "Epoch: 1, Iteration: 168\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.7502699494361877\n",
      "LC Training Loss (Full): 0.5081072449684143\n",
      "Epoch: 1, Iteration: 169\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6778008341789246\n",
      "LC Training Loss (Full): 0.30521443486213684\n",
      "Epoch: 1, Iteration: 170\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8446032404899597\n",
      "LC Training Loss (Full): 0.4869259297847748\n",
      "Full accuracy (w/o dLoRA+LC): 0.9133, LC accuracy: 0.914, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8094, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8085\n",
      "Epoch: 1, Iteration: 171\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.738343358039856\n",
      "LC Training Loss (Full): 0.4251173734664917\n",
      "Epoch: 1, Iteration: 172\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.8536651730537415\n",
      "LC Training Loss (Full): 0.3928006589412689\n",
      "Epoch: 1, Iteration: 173\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7011635899543762\n",
      "LC Training Loss (Full): 0.35432910919189453\n",
      "Epoch: 1, Iteration: 174\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5730825066566467\n",
      "LC Training Loss (Full): 0.2156645655632019\n",
      "Epoch: 1, Iteration: 175\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.8492291569709778\n",
      "LC Training Loss (Full): 0.5044126510620117\n",
      "Full accuracy (w/o dLoRA+LC): 0.9149, LC accuracy: 0.9142, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8131, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8104\n",
      "Epoch: 1, Iteration: 176\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5175936222076416\n",
      "LC Training Loss (Full): 0.19158324599266052\n",
      "Epoch: 1, Iteration: 177\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7923538684844971\n",
      "LC Training Loss (Full): 0.4020620882511139\n",
      "Epoch: 1, Iteration: 178\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.8162515163421631\n",
      "LC Training Loss (Full): 0.4213721752166748\n",
      "Epoch: 1, Iteration: 179\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7209306955337524\n",
      "LC Training Loss (Full): 0.2615659832954407\n",
      "Epoch: 1, Iteration: 180\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7379653453826904\n",
      "LC Training Loss (Full): 0.3061091899871826\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.915, LC accuracy: 0.915, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8106, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8105\n",
      "Epoch: 1, Iteration: 181\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5086126327514648\n",
      "LC Training Loss (Full): 0.17544956505298615\n",
      "Epoch: 1, Iteration: 182\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6289564371109009\n",
      "LC Training Loss (Full): 0.3144063651561737\n",
      "Epoch: 1, Iteration: 183\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6860446929931641\n",
      "LC Training Loss (Full): 0.3114868104457855\n",
      "Epoch: 1, Iteration: 184\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6227510571479797\n",
      "LC Training Loss (Full): 0.2823149561882019\n",
      "Epoch: 1, Iteration: 185\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.8039356470108032\n",
      "LC Training Loss (Full): 0.35582539439201355\n",
      "Full accuracy (w/o dLoRA+LC): 0.916, LC accuracy: 0.915, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8116, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8106\n",
      "Epoch: 1, Iteration: 186\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6548898816108704\n",
      "LC Training Loss (Full): 0.33863091468811035\n",
      "Epoch: 1, Iteration: 187\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6612098813056946\n",
      "LC Training Loss (Full): 0.3768036663532257\n",
      "Epoch: 1, Iteration: 188\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5204121470451355\n",
      "LC Training Loss (Full): 0.22329829633235931\n",
      "Epoch: 1, Iteration: 189\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6013744473457336\n",
      "LC Training Loss (Full): 0.23155061900615692\n",
      "Epoch: 1, Iteration: 190\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5049328804016113\n",
      "LC Training Loss (Full): 0.23103082180023193\n",
      "Full accuracy (w/o dLoRA+LC): 0.9148, LC accuracy: 0.9148, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8105, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8101\n",
      "Epoch: 1, Iteration: 191\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5895845890045166\n",
      "LC Training Loss (Full): 0.1828259378671646\n",
      "Epoch: 1, Iteration: 192\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5461034774780273\n",
      "LC Training Loss (Full): 0.19748032093048096\n",
      "Epoch: 1, Iteration: 193\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6630651354789734\n",
      "LC Training Loss (Full): 0.24207934737205505\n",
      "Epoch: 1, Iteration: 194\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5713276267051697\n",
      "LC Training Loss (Full): 0.26331624388694763\n",
      "Epoch: 1, Iteration: 195\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6397905349731445\n",
      "LC Training Loss (Full): 0.27837908267974854\n",
      "Full accuracy (w/o dLoRA+LC): 0.915, LC accuracy: 0.915, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8105, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8094\n",
      "Epoch: 1, Iteration: 196\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.704632043838501\n",
      "LC Training Loss (Full): 0.3241843283176422\n",
      "Epoch: 1, Iteration: 197\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6582661271095276\n",
      "LC Training Loss (Full): 0.2824862599372864\n",
      "Epoch: 1, Iteration: 198\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.7107834815979004\n",
      "LC Training Loss (Full): 0.3199853301048279\n",
      "Epoch: 1, Iteration: 199\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6588139533996582\n",
      "LC Training Loss (Full): 0.2787218391895294\n",
      "Epoch: 1, Iteration: 200\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7162445187568665\n",
      "LC Training Loss (Full): 0.25669264793395996\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9148, LC accuracy: 0.9144, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8109, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.81\n",
      "Epoch: 1, Iteration: 201\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5165128707885742\n",
      "LC Training Loss (Full): 0.22695638239383698\n",
      "Epoch: 1, Iteration: 202\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.6851428151130676\n",
      "LC Training Loss (Full): 0.4437110424041748\n",
      "Epoch: 1, Iteration: 203\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7061364054679871\n",
      "LC Training Loss (Full): 0.3119536340236664\n",
      "Epoch: 1, Iteration: 204\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.9992693662643433\n",
      "LC Training Loss (Full): 0.7252101302146912\n",
      "Epoch: 1, Iteration: 205\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7201986908912659\n",
      "LC Training Loss (Full): 0.26552432775497437\n",
      "Full accuracy (w/o dLoRA+LC): 0.9159, LC accuracy: 0.9144, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8124, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8104\n",
      "Epoch: 1, Iteration: 206\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.6212153434753418\n",
      "LC Training Loss (Full): 0.3495252728462219\n",
      "Epoch: 1, Iteration: 207\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7019032835960388\n",
      "LC Training Loss (Full): 0.27437567710876465\n",
      "Epoch: 1, Iteration: 208\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7842382192611694\n",
      "LC Training Loss (Full): 0.3476102352142334\n",
      "Epoch: 1, Iteration: 209\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7090047001838684\n",
      "LC Training Loss (Full): 0.3361991345882416\n",
      "Epoch: 1, Iteration: 210\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8153921961784363\n",
      "LC Training Loss (Full): 0.3533024191856384\n",
      "Full accuracy (w/o dLoRA+LC): 0.9154, LC accuracy: 0.9151, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8099, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8104\n",
      "Epoch: 1, Iteration: 211\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6042101383209229\n",
      "LC Training Loss (Full): 0.18038444221019745\n",
      "Epoch: 1, Iteration: 212\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6908541321754456\n",
      "LC Training Loss (Full): 0.33736714720726013\n",
      "Epoch: 1, Iteration: 213\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5750784873962402\n",
      "LC Training Loss (Full): 0.2659666836261749\n",
      "Epoch: 1, Iteration: 214\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.8228208422660828\n",
      "LC Training Loss (Full): 0.4974763095378876\n",
      "Epoch: 1, Iteration: 215\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6085532307624817\n",
      "LC Training Loss (Full): 0.26612067222595215\n",
      "Full accuracy (w/o dLoRA+LC): 0.9151, LC accuracy: 0.9151, Decomposed-Full (w/dLoRA+LC) accuracy: 0.81, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8085\n",
      "Epoch: 1, Iteration: 216\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.590663492679596\n",
      "LC Training Loss (Full): 0.28524652123451233\n",
      "Epoch: 1, Iteration: 217\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.4984499514102936\n",
      "LC Training Loss (Full): 0.21898816525936127\n",
      "Epoch: 1, Iteration: 218\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6432031393051147\n",
      "LC Training Loss (Full): 0.2971464991569519\n",
      "Epoch: 1, Iteration: 219\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6703552007675171\n",
      "LC Training Loss (Full): 0.34102994203567505\n",
      "Epoch: 1, Iteration: 220\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6764680743217468\n",
      "LC Training Loss (Full): 0.3147464692592621\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9151, LC accuracy: 0.9152, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8093, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8086\n",
      "Epoch: 1, Iteration: 221\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5597444772720337\n",
      "LC Training Loss (Full): 0.27000635862350464\n",
      "Epoch: 1, Iteration: 222\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6409969329833984\n",
      "LC Training Loss (Full): 0.32676762342453003\n",
      "Epoch: 1, Iteration: 223\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.7455813884735107\n",
      "LC Training Loss (Full): 0.37440404295921326\n",
      "Epoch: 1, Iteration: 224\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6299073696136475\n",
      "LC Training Loss (Full): 0.2774048447608948\n",
      "Epoch: 1, Iteration: 225\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6881747245788574\n",
      "LC Training Loss (Full): 0.3074045777320862\n",
      "Full accuracy (w/o dLoRA+LC): 0.9145, LC accuracy: 0.9153, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8095, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8081\n",
      "Epoch: 1, Iteration: 226\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.7884677648544312\n",
      "LC Training Loss (Full): 0.32633066177368164\n",
      "Epoch: 1, Iteration: 227\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.7436068654060364\n",
      "LC Training Loss (Full): 0.27957600355148315\n",
      "Epoch: 1, Iteration: 228\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6399713158607483\n",
      "LC Training Loss (Full): 0.27222853899002075\n",
      "Epoch: 1, Iteration: 229\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5191720724105835\n",
      "LC Training Loss (Full): 0.16550947725772858\n",
      "Epoch: 1, Iteration: 230\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_47\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.663585901260376\n",
      "LC Training Loss (Full): 0.23340463638305664\n",
      "Full accuracy (w/o dLoRA+LC): 0.9144, LC accuracy: 0.915, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8093, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8086\n",
      "Epoch: 1, Iteration: 231\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.8260611891746521\n",
      "LC Training Loss (Full): 0.4385117292404175\n",
      "Epoch: 1, Iteration: 232\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.8216053247451782\n",
      "LC Training Loss (Full): 0.4218434989452362\n",
      "Epoch: 1, Iteration: 233\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.6304309964179993\n",
      "LC Training Loss (Full): 0.255008339881897\n",
      "Epoch: 1, Iteration: 234\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader2/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader2/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.4625712037086487\n",
      "LC Training Loss (Full): 0.11884231120347977\n",
      "End of model training on train_loader2...\n",
      "Model saved at accuracy: 0.8093\n",
      "--------------------------\n",
      "Beginning of model training on train_loader3...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6538603901863098\n",
      "LC Training Loss (Full): 0.31826502084732056\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.890625\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6860544085502625\n",
      "LC Training Loss (Full): 0.2680897116661072\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.540880560874939\n",
      "LC Training Loss (Full): 0.2622591257095337\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6047532558441162\n",
      "LC Training Loss (Full): 0.22685757279396057\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.8400542140007019\n",
      "LC Training Loss (Full): 0.39956244826316833\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5213688015937805\n",
      "LC Training Loss (Full): 0.2913801372051239\n",
      "Full accuracy (w/o dLoRA+LC): 0.9152, LC accuracy: 0.9142, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8096, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8087\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5791193246841431\n",
      "LC Training Loss (Full): 0.18039004504680634\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5324570536613464\n",
      "LC Training Loss (Full): 0.24380932748317719\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.9047589898109436\n",
      "LC Training Loss (Full): 0.44617581367492676\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6848840117454529\n",
      "LC Training Loss (Full): 0.37781500816345215\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6134254932403564\n",
      "LC Training Loss (Full): 0.2799835801124573\n",
      "Full accuracy (w/o dLoRA+LC): 0.9145, LC accuracy: 0.9142, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8065, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8076\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7862414717674255\n",
      "LC Training Loss (Full): 0.339546799659729\n",
      "Epoch: 0, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.8483574986457825\n",
      "LC Training Loss (Full): 0.3277446925640106\n",
      "Epoch: 0, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6934286952018738\n",
      "LC Training Loss (Full): 0.21704360842704773\n",
      "Epoch: 0, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.8132349848747253\n",
      "LC Training Loss (Full): 0.4297366440296173\n",
      "Epoch: 0, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6430869102478027\n",
      "LC Training Loss (Full): 0.3314010500907898\n",
      "Full accuracy (w/o dLoRA+LC): 0.9153, LC accuracy: 0.9141, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8083, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8072\n",
      "Epoch: 0, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5504022240638733\n",
      "LC Training Loss (Full): 0.26498204469680786\n",
      "Epoch: 0, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7705889940261841\n",
      "LC Training Loss (Full): 0.36266520619392395\n",
      "Epoch: 0, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7439490556716919\n",
      "LC Training Loss (Full): 0.3245757520198822\n",
      "Epoch: 0, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7668073177337646\n",
      "LC Training Loss (Full): 0.3802630305290222\n",
      "Epoch: 0, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6734065413475037\n",
      "LC Training Loss (Full): 0.23030661046504974\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9175, LC accuracy: 0.9168, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8074, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8072\n",
      "Epoch: 0, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6725265979766846\n",
      "LC Training Loss (Full): 0.31020474433898926\n",
      "Epoch: 0, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7372265458106995\n",
      "LC Training Loss (Full): 0.3373816907405853\n",
      "Epoch: 0, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.8473069667816162\n",
      "LC Training Loss (Full): 0.29863670468330383\n",
      "Epoch: 0, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6425644755363464\n",
      "LC Training Loss (Full): 0.24914143979549408\n",
      "Epoch: 0, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6309144496917725\n",
      "LC Training Loss (Full): 0.3156359791755676\n",
      "Full accuracy (w/o dLoRA+LC): 0.9175, LC accuracy: 0.9168, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8103, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8075\n",
      "Epoch: 0, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6677381992340088\n",
      "LC Training Loss (Full): 0.2730039060115814\n",
      "Epoch: 0, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.685640811920166\n",
      "LC Training Loss (Full): 0.3114471733570099\n",
      "Epoch: 0, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.559258759021759\n",
      "LC Training Loss (Full): 0.2340942919254303\n",
      "Epoch: 0, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.7602902054786682\n",
      "LC Training Loss (Full): 0.32073071599006653\n",
      "Epoch: 0, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7986583709716797\n",
      "LC Training Loss (Full): 0.3878783881664276\n",
      "Full accuracy (w/o dLoRA+LC): 0.9188, LC accuracy: 0.9171, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8094, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8079\n",
      "Epoch: 0, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6336666941642761\n",
      "LC Training Loss (Full): 0.19738073647022247\n",
      "Epoch: 0, Iteration: 32\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5481663942337036\n",
      "LC Training Loss (Full): 0.18952080607414246\n",
      "Epoch: 0, Iteration: 33\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5836315751075745\n",
      "LC Training Loss (Full): 0.32631251215934753\n",
      "Epoch: 0, Iteration: 34\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7176141142845154\n",
      "LC Training Loss (Full): 0.3213523030281067\n",
      "Epoch: 0, Iteration: 35\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8775885105133057\n",
      "LC Training Loss (Full): 0.5011178851127625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9191, LC accuracy: 0.9171, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8103, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8084\n",
      "Epoch: 0, Iteration: 36\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6628671288490295\n",
      "LC Training Loss (Full): 0.2553379237651825\n",
      "Epoch: 0, Iteration: 37\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.8421304225921631\n",
      "LC Training Loss (Full): 0.4904034733772278\n",
      "Epoch: 0, Iteration: 38\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7321452498435974\n",
      "LC Training Loss (Full): 0.3406265676021576\n",
      "Epoch: 0, Iteration: 39\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5629448890686035\n",
      "LC Training Loss (Full): 0.2084718942642212\n",
      "Epoch: 0, Iteration: 40\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.910446286201477\n",
      "LC Training Loss (Full): 0.48940548300743103\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.78125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9171, LC accuracy: 0.9178, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8101, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8094\n",
      "Epoch: 0, Iteration: 41\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.821158230304718\n",
      "LC Training Loss (Full): 0.49482205510139465\n",
      "Epoch: 0, Iteration: 42\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.6456357836723328\n",
      "LC Training Loss (Full): 0.2887795567512512\n",
      "Epoch: 0, Iteration: 43\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.8860781788825989\n",
      "LC Training Loss (Full): 0.508439838886261\n",
      "Epoch: 0, Iteration: 44\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7962701320648193\n",
      "LC Training Loss (Full): 0.4259416460990906\n",
      "Epoch: 0, Iteration: 45\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7785524725914001\n",
      "LC Training Loss (Full): 0.4730798304080963\n",
      "Full accuracy (w/o dLoRA+LC): 0.9162, LC accuracy: 0.9178, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8117, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8097\n",
      "Epoch: 0, Iteration: 46\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7849318385124207\n",
      "LC Training Loss (Full): 0.4411669671535492\n",
      "Epoch: 0, Iteration: 47\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.8854709267616272\n",
      "LC Training Loss (Full): 0.4357251822948456\n",
      "Epoch: 0, Iteration: 48\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7352263331413269\n",
      "LC Training Loss (Full): 0.40688252449035645\n",
      "Epoch: 0, Iteration: 49\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.5468863248825073\n",
      "LC Training Loss (Full): 0.18135619163513184\n",
      "Epoch: 0, Iteration: 50\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7444820404052734\n",
      "LC Training Loss (Full): 0.3918074667453766\n",
      "Full accuracy (w/o dLoRA+LC): 0.9166, LC accuracy: 0.9166, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8107, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8103\n",
      "Epoch: 0, Iteration: 51\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7295971512794495\n",
      "LC Training Loss (Full): 0.3512391149997711\n",
      "Epoch: 0, Iteration: 52\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.6468799114227295\n",
      "LC Training Loss (Full): 0.23133721947669983\n",
      "Epoch: 0, Iteration: 53\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.51512211561203\n",
      "LC Training Loss (Full): 0.14073744416236877\n",
      "Epoch: 0, Iteration: 54\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.6612504124641418\n",
      "LC Training Loss (Full): 0.26654675602912903\n",
      "Epoch: 0, Iteration: 55\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.5767515897750854\n",
      "LC Training Loss (Full): 0.21396461129188538\n",
      "Full accuracy (w/o dLoRA+LC): 0.9182, LC accuracy: 0.9167, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8113, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8103\n",
      "Epoch: 0, Iteration: 56\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.6009970903396606\n",
      "LC Training Loss (Full): 0.2209995836019516\n",
      "Epoch: 0, Iteration: 57\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.6101832389831543\n",
      "LC Training Loss (Full): 0.21182896196842194\n",
      "Epoch: 0, Iteration: 58\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.6806486248970032\n",
      "LC Training Loss (Full): 0.3432469666004181\n",
      "Epoch: 0, Iteration: 59\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.5395439863204956\n",
      "LC Training Loss (Full): 0.20800913870334625\n",
      "Epoch: 0, Iteration: 60\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.837736964225769\n",
      "LC Training Loss (Full): 0.41314905881881714\n",
      "Training Accuracy | Decomposed: 0.6875, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.918, LC accuracy: 0.9182, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8106, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8109\n",
      "Epoch: 0, Iteration: 61\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6676605343818665\n",
      "LC Training Loss (Full): 0.27928465604782104\n",
      "Epoch: 0, Iteration: 62\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.7738572955131531\n",
      "LC Training Loss (Full): 0.4334750473499298\n",
      "Epoch: 0, Iteration: 63\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6974436044692993\n",
      "LC Training Loss (Full): 0.31600821018218994\n",
      "Epoch: 0, Iteration: 64\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.8714450001716614\n",
      "LC Training Loss (Full): 0.4753684103488922\n",
      "Epoch: 0, Iteration: 65\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.7963535189628601\n",
      "LC Training Loss (Full): 0.45675578713417053\n",
      "Full accuracy (w/o dLoRA+LC): 0.9193, LC accuracy: 0.9183, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8127, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8108\n",
      "Epoch: 0, Iteration: 66\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6549316048622131\n",
      "LC Training Loss (Full): 0.22064059972763062\n",
      "Epoch: 0, Iteration: 67\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6444942951202393\n",
      "LC Training Loss (Full): 0.2852918207645416\n",
      "Epoch: 0, Iteration: 68\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6721169948577881\n",
      "LC Training Loss (Full): 0.25937533378601074\n",
      "Epoch: 0, Iteration: 69\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.7430877089500427\n",
      "LC Training Loss (Full): 0.2931915521621704\n",
      "Epoch: 0, Iteration: 70\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6458934545516968\n",
      "LC Training Loss (Full): 0.23554526269435883\n",
      "Full accuracy (w/o dLoRA+LC): 0.9184, LC accuracy: 0.9189, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8108, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8109\n",
      "Epoch: 0, Iteration: 71\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7302234172821045\n",
      "LC Training Loss (Full): 0.41833746433258057\n",
      "Epoch: 0, Iteration: 72\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.5250729322433472\n",
      "LC Training Loss (Full): 0.2082493007183075\n",
      "Epoch: 0, Iteration: 73\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7800467014312744\n",
      "LC Training Loss (Full): 0.35191309452056885\n",
      "Epoch: 0, Iteration: 74\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.8585975170135498\n",
      "LC Training Loss (Full): 0.5212875604629517\n",
      "Epoch: 0, Iteration: 75\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7186118960380554\n",
      "LC Training Loss (Full): 0.3546748459339142\n",
      "Full accuracy (w/o dLoRA+LC): 0.9183, LC accuracy: 0.9187, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8119, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8109\n",
      "Epoch: 0, Iteration: 76\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.6342952847480774\n",
      "LC Training Loss (Full): 0.2226393073797226\n",
      "Epoch: 0, Iteration: 77\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.621923565864563\n",
      "LC Training Loss (Full): 0.2816354036331177\n",
      "Epoch: 0, Iteration: 78\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.823560893535614\n",
      "LC Training Loss (Full): 0.3955356776714325\n",
      "Epoch: 0, Iteration: 79\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.5621489882469177\n",
      "LC Training Loss (Full): 0.23513977229595184\n",
      "Epoch: 0, Iteration: 80\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6780372262001038\n",
      "LC Training Loss (Full): 0.2516840994358063\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9189, LC accuracy: 0.9187, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8107, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8108\n",
      "Epoch: 0, Iteration: 81\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.6314271092414856\n",
      "LC Training Loss (Full): 0.239266037940979\n",
      "Epoch: 0, Iteration: 82\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5462930202484131\n",
      "LC Training Loss (Full): 0.27747994661331177\n",
      "Epoch: 0, Iteration: 83\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5817601084709167\n",
      "LC Training Loss (Full): 0.29834192991256714\n",
      "Epoch: 0, Iteration: 84\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.6403270959854126\n",
      "LC Training Loss (Full): 0.24374496936798096\n",
      "Epoch: 0, Iteration: 85\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7099144458770752\n",
      "LC Training Loss (Full): 0.2772469222545624\n",
      "Full accuracy (w/o dLoRA+LC): 0.9196, LC accuracy: 0.9187, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8132, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8117\n",
      "Epoch: 0, Iteration: 86\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7481094002723694\n",
      "LC Training Loss (Full): 0.29884880781173706\n",
      "Epoch: 0, Iteration: 87\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5904812216758728\n",
      "LC Training Loss (Full): 0.2822304666042328\n",
      "Epoch: 0, Iteration: 88\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.837566077709198\n",
      "LC Training Loss (Full): 0.34346795082092285\n",
      "Epoch: 0, Iteration: 89\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.673200786113739\n",
      "LC Training Loss (Full): 0.23896586894989014\n",
      "Epoch: 0, Iteration: 90\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7471159100532532\n",
      "LC Training Loss (Full): 0.2717825174331665\n",
      "Full accuracy (w/o dLoRA+LC): 0.9188, LC accuracy: 0.9183, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8112, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8122\n",
      "Epoch: 0, Iteration: 91\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6906232237815857\n",
      "LC Training Loss (Full): 0.2763412594795227\n",
      "Epoch: 0, Iteration: 92\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.5444877743721008\n",
      "LC Training Loss (Full): 0.22326014935970306\n",
      "Epoch: 0, Iteration: 93\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6645272374153137\n",
      "LC Training Loss (Full): 0.2539093792438507\n",
      "Epoch: 0, Iteration: 94\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6391675472259521\n",
      "LC Training Loss (Full): 0.3464355170726776\n",
      "Epoch: 0, Iteration: 95\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6098396182060242\n",
      "LC Training Loss (Full): 0.23613379895687103\n",
      "Full accuracy (w/o dLoRA+LC): 0.9187, LC accuracy: 0.9185, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8132, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8123\n",
      "Epoch: 0, Iteration: 96\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.5623572468757629\n",
      "LC Training Loss (Full): 0.18497063219547272\n",
      "Epoch: 0, Iteration: 97\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6427843570709229\n",
      "LC Training Loss (Full): 0.24027787148952484\n",
      "Epoch: 0, Iteration: 98\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6903553605079651\n",
      "LC Training Loss (Full): 0.3272526264190674\n",
      "Epoch: 0, Iteration: 99\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6513594388961792\n",
      "LC Training Loss (Full): 0.38396432995796204\n",
      "Epoch: 0, Iteration: 100\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6129996180534363\n",
      "LC Training Loss (Full): 0.27013054490089417\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9188, LC accuracy: 0.919, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8124, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8121\n",
      "Epoch: 0, Iteration: 101\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6996116042137146\n",
      "LC Training Loss (Full): 0.32098791003227234\n",
      "Epoch: 0, Iteration: 102\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.5872910022735596\n",
      "LC Training Loss (Full): 0.18760377168655396\n",
      "Epoch: 0, Iteration: 103\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6883132457733154\n",
      "LC Training Loss (Full): 0.238077774643898\n",
      "Epoch: 0, Iteration: 104\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.7336402535438538\n",
      "LC Training Loss (Full): 0.4286746084690094\n",
      "Epoch: 0, Iteration: 105\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.8136102557182312\n",
      "LC Training Loss (Full): 0.4510784149169922\n",
      "Full accuracy (w/o dLoRA+LC): 0.918, LC accuracy: 0.919, Decomposed-Full (w/dLoRA+LC) accuracy: 0.814, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8121\n",
      "Epoch: 0, Iteration: 106\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6231958270072937\n",
      "LC Training Loss (Full): 0.3212072551250458\n",
      "Epoch: 0, Iteration: 107\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.7663623690605164\n",
      "LC Training Loss (Full): 0.4590413570404053\n",
      "Epoch: 0, Iteration: 108\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.7421119809150696\n",
      "LC Training Loss (Full): 0.4063659608364105\n",
      "Epoch: 0, Iteration: 109\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6487185955047607\n",
      "LC Training Loss (Full): 0.2764803469181061\n",
      "Epoch: 0, Iteration: 110\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6748901009559631\n",
      "LC Training Loss (Full): 0.2834382653236389\n",
      "Full accuracy (w/o dLoRA+LC): 0.9189, LC accuracy: 0.9199, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8113, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8117\n",
      "Epoch: 0, Iteration: 111\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.6846653819084167\n",
      "LC Training Loss (Full): 0.43414920568466187\n",
      "Epoch: 0, Iteration: 112\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.6566523313522339\n",
      "LC Training Loss (Full): 0.3298262655735016\n",
      "Epoch: 0, Iteration: 113\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.5936041474342346\n",
      "LC Training Loss (Full): 0.21113647520542145\n",
      "Epoch: 0, Iteration: 114\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.808867335319519\n",
      "LC Training Loss (Full): 0.547458291053772\n",
      "Epoch: 0, Iteration: 115\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.5700309872627258\n",
      "LC Training Loss (Full): 0.2906284034252167\n",
      "Full accuracy (w/o dLoRA+LC): 0.9192, LC accuracy: 0.92, Decomposed-Full (w/dLoRA+LC) accuracy: 0.812, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8122\n",
      "Epoch: 0, Iteration: 116\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.7368654608726501\n",
      "LC Training Loss (Full): 0.3344319462776184\n",
      "Epoch: 0, Iteration: 117\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.7486549615859985\n",
      "LC Training Loss (Full): 0.38339921832084656\n",
      "Epoch: 0, Iteration: 118\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.6899207830429077\n",
      "LC Training Loss (Full): 0.25902441143989563\n",
      "Epoch: 0, Iteration: 119\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.5822995901107788\n",
      "LC Training Loss (Full): 0.213858500123024\n",
      "Epoch: 0, Iteration: 120\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6468724012374878\n",
      "LC Training Loss (Full): 0.4654342234134674\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.859375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9202, LC accuracy: 0.9194, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8121, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8118\n",
      "Epoch: 0, Iteration: 121\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.5342953205108643\n",
      "LC Training Loss (Full): 0.19252437353134155\n",
      "Epoch: 0, Iteration: 122\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.8661168217658997\n",
      "LC Training Loss (Full): 0.505437433719635\n",
      "Epoch: 0, Iteration: 123\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7023869752883911\n",
      "LC Training Loss (Full): 0.35976964235305786\n",
      "Epoch: 0, Iteration: 124\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7301985621452332\n",
      "LC Training Loss (Full): 0.3626316487789154\n",
      "Epoch: 0, Iteration: 125\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7150521278381348\n",
      "LC Training Loss (Full): 0.30406323075294495\n",
      "Full accuracy (w/o dLoRA+LC): 0.9214, LC accuracy: 0.9198, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8126, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8116\n",
      "Epoch: 0, Iteration: 126\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.8514999151229858\n",
      "LC Training Loss (Full): 0.3515773117542267\n",
      "Epoch: 0, Iteration: 127\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7190781831741333\n",
      "LC Training Loss (Full): 0.35926157236099243\n",
      "Epoch: 0, Iteration: 128\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7452541589736938\n",
      "LC Training Loss (Full): 0.34958162903785706\n",
      "Epoch: 0, Iteration: 129\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7355068922042847\n",
      "LC Training Loss (Full): 0.2812228500843048\n",
      "Epoch: 0, Iteration: 130\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6501174569129944\n",
      "LC Training Loss (Full): 0.2880946695804596\n",
      "Full accuracy (w/o dLoRA+LC): 0.9203, LC accuracy: 0.9204, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8119, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8113\n",
      "Epoch: 0, Iteration: 131\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.638451099395752\n",
      "LC Training Loss (Full): 0.30175715684890747\n",
      "Epoch: 0, Iteration: 132\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7373006939888\n",
      "LC Training Loss (Full): 0.3783780634403229\n",
      "Epoch: 0, Iteration: 133\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6909170746803284\n",
      "LC Training Loss (Full): 0.32533565163612366\n",
      "Epoch: 0, Iteration: 134\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.621740996837616\n",
      "LC Training Loss (Full): 0.22634176909923553\n",
      "Epoch: 0, Iteration: 135\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8381701707839966\n",
      "LC Training Loss (Full): 0.4699128568172455\n",
      "Full accuracy (w/o dLoRA+LC): 0.9209, LC accuracy: 0.9207, Decomposed-Full (w/dLoRA+LC) accuracy: 0.813, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8114\n",
      "Epoch: 0, Iteration: 136\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7613351345062256\n",
      "LC Training Loss (Full): 0.22517207264900208\n",
      "Epoch: 0, Iteration: 137\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7982308268547058\n",
      "LC Training Loss (Full): 0.4033149182796478\n",
      "Epoch: 0, Iteration: 138\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.9130597710609436\n",
      "LC Training Loss (Full): 0.44663098454475403\n",
      "Epoch: 0, Iteration: 139\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6708573698997498\n",
      "LC Training Loss (Full): 0.3672383725643158\n",
      "Epoch: 0, Iteration: 140\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7652039527893066\n",
      "LC Training Loss (Full): 0.343788743019104\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9191, LC accuracy: 0.92, Decomposed-Full (w/dLoRA+LC) accuracy: 0.812, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.812\n",
      "Epoch: 0, Iteration: 141\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.7203425168991089\n",
      "LC Training Loss (Full): 0.41452401876449585\n",
      "Epoch: 0, Iteration: 142\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5762617588043213\n",
      "LC Training Loss (Full): 0.3036971390247345\n",
      "Epoch: 0, Iteration: 143\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6412800550460815\n",
      "LC Training Loss (Full): 0.11271186172962189\n",
      "Epoch: 0, Iteration: 144\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5245811939239502\n",
      "LC Training Loss (Full): 0.1977023482322693\n",
      "Epoch: 0, Iteration: 145\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6421563625335693\n",
      "LC Training Loss (Full): 0.2952424883842468\n",
      "Full accuracy (w/o dLoRA+LC): 0.9202, LC accuracy: 0.92, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8127, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8123\n",
      "Epoch: 0, Iteration: 146\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6909027695655823\n",
      "LC Training Loss (Full): 0.33779630064964294\n",
      "Epoch: 0, Iteration: 147\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.8136493563652039\n",
      "LC Training Loss (Full): 0.35866275429725647\n",
      "Epoch: 0, Iteration: 148\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6235504150390625\n",
      "LC Training Loss (Full): 0.24478304386138916\n",
      "Epoch: 0, Iteration: 149\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6508457064628601\n",
      "LC Training Loss (Full): 0.23915600776672363\n",
      "Epoch: 0, Iteration: 150\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5501963496208191\n",
      "LC Training Loss (Full): 0.2890062928199768\n",
      "Full accuracy (w/o dLoRA+LC): 0.9198, LC accuracy: 0.9195, Decomposed-Full (w/dLoRA+LC) accuracy: 0.811, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8122\n",
      "Epoch: 0, Iteration: 151\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.9021361470222473\n",
      "LC Training Loss (Full): 0.4364777207374573\n",
      "Epoch: 0, Iteration: 152\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.6971970796585083\n",
      "LC Training Loss (Full): 0.38486239314079285\n",
      "Epoch: 0, Iteration: 153\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.6267762184143066\n",
      "LC Training Loss (Full): 0.31723451614379883\n",
      "Epoch: 0, Iteration: 154\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.7664623856544495\n",
      "LC Training Loss (Full): 0.2818126082420349\n",
      "Epoch: 0, Iteration: 155\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.8519940376281738\n",
      "LC Training Loss (Full): 0.39926862716674805\n",
      "Full accuracy (w/o dLoRA+LC): 0.9215, LC accuracy: 0.9195, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8138, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.812\n",
      "Epoch: 0, Iteration: 156\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.6338803768157959\n",
      "LC Training Loss (Full): 0.2543753981590271\n",
      "Epoch: 0, Iteration: 157\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.7257887125015259\n",
      "LC Training Loss (Full): 0.398092120885849\n",
      "Epoch: 0, Iteration: 158\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.5618492960929871\n",
      "LC Training Loss (Full): 0.28625231981277466\n",
      "Epoch: 0, Iteration: 159\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.7014227509498596\n",
      "LC Training Loss (Full): 0.32246944308280945\n",
      "Epoch: 0, Iteration: 160\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.910217821598053\n",
      "LC Training Loss (Full): 0.40802451968193054\n",
      "Training Accuracy | Decomposed: 0.734375, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9218, LC accuracy: 0.9208, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8131, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.812\n",
      "Epoch: 0, Iteration: 161\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6689910888671875\n",
      "LC Training Loss (Full): 0.3463607430458069\n",
      "Epoch: 0, Iteration: 162\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.9622705578804016\n",
      "LC Training Loss (Full): 0.4148443043231964\n",
      "Epoch: 0, Iteration: 163\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6905748844146729\n",
      "LC Training Loss (Full): 0.25836417078971863\n",
      "Epoch: 0, Iteration: 164\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.7095571756362915\n",
      "LC Training Loss (Full): 0.2694615423679352\n",
      "Epoch: 0, Iteration: 165\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.8096898198127747\n",
      "LC Training Loss (Full): 0.36583197116851807\n",
      "Full accuracy (w/o dLoRA+LC): 0.9209, LC accuracy: 0.9208, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8137, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8117\n",
      "Epoch: 0, Iteration: 166\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.707092821598053\n",
      "LC Training Loss (Full): 0.3835730254650116\n",
      "Epoch: 0, Iteration: 167\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5907271504402161\n",
      "LC Training Loss (Full): 0.2604636549949646\n",
      "Epoch: 0, Iteration: 168\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5794849395751953\n",
      "LC Training Loss (Full): 0.16876071691513062\n",
      "Epoch: 0, Iteration: 169\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.47925570607185364\n",
      "LC Training Loss (Full): 0.20217110216617584\n",
      "Epoch: 0, Iteration: 170\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.631377637386322\n",
      "LC Training Loss (Full): 0.24413134157657623\n",
      "Full accuracy (w/o dLoRA+LC): 0.9194, LC accuracy: 0.9197, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8125, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8119\n",
      "Epoch: 0, Iteration: 171\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.5306975245475769\n",
      "LC Training Loss (Full): 0.16839417815208435\n",
      "Epoch: 0, Iteration: 172\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.5814816355705261\n",
      "LC Training Loss (Full): 0.23140595853328705\n",
      "Epoch: 0, Iteration: 173\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.7395730018615723\n",
      "LC Training Loss (Full): 0.4596329629421234\n",
      "Epoch: 0, Iteration: 174\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.4442088305950165\n",
      "LC Training Loss (Full): 0.13469715416431427\n",
      "Epoch: 0, Iteration: 175\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.5761874318122864\n",
      "LC Training Loss (Full): 0.22523464262485504\n",
      "Full accuracy (w/o dLoRA+LC): 0.9221, LC accuracy: 0.9198, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8111, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8124\n",
      "Epoch: 0, Iteration: 176\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8046289086341858\n",
      "LC Training Loss (Full): 0.3312859833240509\n",
      "Epoch: 0, Iteration: 177\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.6120829582214355\n",
      "LC Training Loss (Full): 0.20570549368858337\n",
      "Epoch: 0, Iteration: 178\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.5588502883911133\n",
      "LC Training Loss (Full): 0.2161678671836853\n",
      "Epoch: 0, Iteration: 179\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8569761514663696\n",
      "LC Training Loss (Full): 0.46853670477867126\n",
      "Epoch: 0, Iteration: 180\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8219976425170898\n",
      "LC Training Loss (Full): 0.4128447473049164\n",
      "Training Accuracy | Decomposed: 0.703125, Full : 0.875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9213, LC accuracy: 0.9214, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8131, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.813\n",
      "Epoch: 0, Iteration: 181\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.7634103894233704\n",
      "LC Training Loss (Full): 0.43096327781677246\n",
      "Epoch: 0, Iteration: 182\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6554674506187439\n",
      "LC Training Loss (Full): 0.3290175795555115\n",
      "Epoch: 0, Iteration: 183\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.5630912184715271\n",
      "LC Training Loss (Full): 0.22198089957237244\n",
      "Epoch: 0, Iteration: 184\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.8121115565299988\n",
      "LC Training Loss (Full): 0.3181207478046417\n",
      "Epoch: 0, Iteration: 185\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.7879067659378052\n",
      "LC Training Loss (Full): 0.4854815900325775\n",
      "Full accuracy (w/o dLoRA+LC): 0.9226, LC accuracy: 0.9216, Decomposed-Full (w/dLoRA+LC) accuracy: 0.812, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.812\n",
      "Epoch: 0, Iteration: 186\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6937323212623596\n",
      "LC Training Loss (Full): 0.30877014994621277\n",
      "Epoch: 0, Iteration: 187\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.7011154294013977\n",
      "LC Training Loss (Full): 0.24918314814567566\n",
      "Epoch: 0, Iteration: 188\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6464652419090271\n",
      "LC Training Loss (Full): 0.3978949785232544\n",
      "Epoch: 0, Iteration: 189\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.743923008441925\n",
      "LC Training Loss (Full): 0.3753000795841217\n",
      "Epoch: 0, Iteration: 190\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8195391893386841\n",
      "LC Training Loss (Full): 0.4590587615966797\n",
      "Full accuracy (w/o dLoRA+LC): 0.9225, LC accuracy: 0.922, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8128, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8115\n",
      "Epoch: 0, Iteration: 191\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.5203214883804321\n",
      "LC Training Loss (Full): 0.3077845871448517\n",
      "Epoch: 0, Iteration: 192\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.8283971548080444\n",
      "LC Training Loss (Full): 0.4802045226097107\n",
      "Epoch: 0, Iteration: 193\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.6592705249786377\n",
      "LC Training Loss (Full): 0.27299925684928894\n",
      "Epoch: 0, Iteration: 194\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.8077429533004761\n",
      "LC Training Loss (Full): 0.3409058749675751\n",
      "Epoch: 0, Iteration: 195\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.6470390558242798\n",
      "LC Training Loss (Full): 0.2700987458229065\n",
      "Full accuracy (w/o dLoRA+LC): 0.922, LC accuracy: 0.9223, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8116, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8114\n",
      "Epoch: 0, Iteration: 196\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.666159987449646\n",
      "LC Training Loss (Full): 0.2311394363641739\n",
      "Epoch: 0, Iteration: 197\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.7208056449890137\n",
      "LC Training Loss (Full): 0.35804206132888794\n",
      "Epoch: 0, Iteration: 198\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.6223677396774292\n",
      "LC Training Loss (Full): 0.25706225633621216\n",
      "Epoch: 0, Iteration: 199\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.6179428100585938\n",
      "LC Training Loss (Full): 0.19461096823215485\n",
      "Epoch: 0, Iteration: 200\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8032640814781189\n",
      "LC Training Loss (Full): 0.24442189931869507\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9235, LC accuracy: 0.9231, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8118, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8111\n",
      "Epoch: 0, Iteration: 201\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.8822402358055115\n",
      "LC Training Loss (Full): 0.4932202696800232\n",
      "Epoch: 0, Iteration: 202\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7654203772544861\n",
      "LC Training Loss (Full): 0.25445443391799927\n",
      "Epoch: 0, Iteration: 203\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6371421217918396\n",
      "LC Training Loss (Full): 0.2508337199687958\n",
      "Epoch: 0, Iteration: 204\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.5363562107086182\n",
      "LC Training Loss (Full): 0.19828614592552185\n",
      "Epoch: 0, Iteration: 205\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6402354836463928\n",
      "LC Training Loss (Full): 0.3213077783584595\n",
      "Full accuracy (w/o dLoRA+LC): 0.9242, LC accuracy: 0.9231, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8128, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8114\n",
      "Epoch: 0, Iteration: 206\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7037599086761475\n",
      "LC Training Loss (Full): 0.3507416248321533\n",
      "Epoch: 0, Iteration: 207\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6452770829200745\n",
      "LC Training Loss (Full): 0.2543806731700897\n",
      "Epoch: 0, Iteration: 208\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.7938694953918457\n",
      "LC Training Loss (Full): 0.3780723214149475\n",
      "Epoch: 0, Iteration: 209\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6560736298561096\n",
      "LC Training Loss (Full): 0.21052613854408264\n",
      "Epoch: 0, Iteration: 210\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7295117378234863\n",
      "LC Training Loss (Full): 0.27475371956825256\n",
      "Full accuracy (w/o dLoRA+LC): 0.9242, LC accuracy: 0.9244, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8129, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.812\n",
      "Epoch: 0, Iteration: 211\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.5228859782218933\n",
      "LC Training Loss (Full): 0.20645368099212646\n",
      "Epoch: 0, Iteration: 212\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.5656399130821228\n",
      "LC Training Loss (Full): 0.1928320825099945\n",
      "Epoch: 0, Iteration: 213\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.8034741282463074\n",
      "LC Training Loss (Full): 0.3628506064414978\n",
      "Epoch: 0, Iteration: 214\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6434061527252197\n",
      "LC Training Loss (Full): 0.3423859179019928\n",
      "Epoch: 0, Iteration: 215\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.7479023337364197\n",
      "LC Training Loss (Full): 0.36920809745788574\n",
      "Full accuracy (w/o dLoRA+LC): 0.9248, LC accuracy: 0.9244, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8123, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8118\n",
      "Epoch: 0, Iteration: 216\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.7932867407798767\n",
      "LC Training Loss (Full): 0.29095765948295593\n",
      "Epoch: 0, Iteration: 217\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6810191869735718\n",
      "LC Training Loss (Full): 0.22038795053958893\n",
      "Epoch: 0, Iteration: 218\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.9561930894851685\n",
      "LC Training Loss (Full): 0.45273733139038086\n",
      "Epoch: 0, Iteration: 219\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6759259700775146\n",
      "LC Training Loss (Full): 0.26383379101753235\n",
      "Epoch: 0, Iteration: 220\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6568941473960876\n",
      "LC Training Loss (Full): 0.3212013244628906\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9241, LC accuracy: 0.9245, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8114, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8114\n",
      "Epoch: 0, Iteration: 221\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.5336992144584656\n",
      "LC Training Loss (Full): 0.15105152130126953\n",
      "Epoch: 0, Iteration: 222\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.647190272808075\n",
      "LC Training Loss (Full): 0.3567969799041748\n",
      "Epoch: 0, Iteration: 223\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.5055960416793823\n",
      "LC Training Loss (Full): 0.15341748297214508\n",
      "Epoch: 0, Iteration: 224\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.775215208530426\n",
      "LC Training Loss (Full): 0.3341391980648041\n",
      "Epoch: 0, Iteration: 225\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.7998151779174805\n",
      "LC Training Loss (Full): 0.31585532426834106\n",
      "Full accuracy (w/o dLoRA+LC): 0.9255, LC accuracy: 0.9249, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8127, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8121\n",
      "Epoch: 0, Iteration: 226\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6847327351570129\n",
      "LC Training Loss (Full): 0.2105482667684555\n",
      "Epoch: 0, Iteration: 227\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6901158094406128\n",
      "LC Training Loss (Full): 0.3310757279396057\n",
      "Epoch: 0, Iteration: 228\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.715539276599884\n",
      "LC Training Loss (Full): 0.31837746500968933\n",
      "Epoch: 0, Iteration: 229\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6071488857269287\n",
      "LC Training Loss (Full): 0.21911662817001343\n",
      "Epoch: 0, Iteration: 230\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_23\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9236767888069153\n",
      "LC Training Loss (Full): 0.4335390031337738\n",
      "Full accuracy (w/o dLoRA+LC): 0.9244, LC accuracy: 0.9238, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8125, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8121\n",
      "Epoch: 0, Iteration: 231\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.8476575613021851\n",
      "LC Training Loss (Full): 0.3044450581073761\n",
      "Epoch: 0, Iteration: 232\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.7727460265159607\n",
      "LC Training Loss (Full): 0.33773279190063477\n",
      "Epoch: 0, Iteration: 233\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.7878351211547852\n",
      "LC Training Loss (Full): 0.28153836727142334\n",
      "Epoch: 0, Iteration: 234\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.922684907913208\n",
      "LC Training Loss (Full): 0.31751689314842224\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6243494749069214\n",
      "LC Training Loss (Full): 0.18977834284305573\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.953125\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7785887718200684\n",
      "LC Training Loss (Full): 0.3630656599998474\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6842359304428101\n",
      "LC Training Loss (Full): 0.4240237772464752\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7053046226501465\n",
      "LC Training Loss (Full): 0.29432326555252075\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7396289110183716\n",
      "LC Training Loss (Full): 0.30666083097457886\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.710600733757019\n",
      "LC Training Loss (Full): 0.2632257640361786\n",
      "Full accuracy (w/o dLoRA+LC): 0.9259, LC accuracy: 0.9228, Decomposed-Full (w/dLoRA+LC) accuracy: 0.814, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8134\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.5934228897094727\n",
      "LC Training Loss (Full): 0.18838441371917725\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7060139179229736\n",
      "LC Training Loss (Full): 0.326213538646698\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7284139394760132\n",
      "LC Training Loss (Full): 0.19491402804851532\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7048853635787964\n",
      "LC Training Loss (Full): 0.3788564205169678\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8013375401496887\n",
      "LC Training Loss (Full): 0.4352734684944153\n",
      "Full accuracy (w/o dLoRA+LC): 0.9245, LC accuracy: 0.9242, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8138, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8138\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.560252845287323\n",
      "LC Training Loss (Full): 0.30436137318611145\n",
      "Epoch: 1, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.732667863368988\n",
      "LC Training Loss (Full): 0.2719968557357788\n",
      "Epoch: 1, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.5180590748786926\n",
      "LC Training Loss (Full): 0.2154768854379654\n",
      "Epoch: 1, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.701860785484314\n",
      "LC Training Loss (Full): 0.4087902009487152\n",
      "Epoch: 1, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.783367395401001\n",
      "LC Training Loss (Full): 0.4377591013908386\n",
      "Full accuracy (w/o dLoRA+LC): 0.9259, LC accuracy: 0.9243, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8134, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8137\n",
      "Epoch: 1, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.6834699511528015\n",
      "LC Training Loss (Full): 0.2541864514350891\n",
      "Epoch: 1, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.8874974846839905\n",
      "LC Training Loss (Full): 0.31882673501968384\n",
      "Epoch: 1, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.6852354407310486\n",
      "LC Training Loss (Full): 0.30859288573265076\n",
      "Epoch: 1, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7822616100311279\n",
      "LC Training Loss (Full): 0.42964884638786316\n",
      "Epoch: 1, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6373832821846008\n",
      "LC Training Loss (Full): 0.2725030779838562\n",
      "Training Accuracy | Decomposed: 0.796875, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9258, LC accuracy: 0.9256, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8138, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8138\n",
      "Epoch: 1, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.5173707604408264\n",
      "LC Training Loss (Full): 0.15814761817455292\n",
      "Epoch: 1, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.5562803745269775\n",
      "LC Training Loss (Full): 0.26575830578804016\n",
      "Epoch: 1, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.7031728029251099\n",
      "LC Training Loss (Full): 0.2418222427368164\n",
      "Epoch: 1, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6470420360565186\n",
      "LC Training Loss (Full): 0.33882802724838257\n",
      "Epoch: 1, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6284234523773193\n",
      "LC Training Loss (Full): 0.21244826912879944\n",
      "Full accuracy (w/o dLoRA+LC): 0.9252, LC accuracy: 0.9256, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8137, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8137\n",
      "Epoch: 1, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.7557201385498047\n",
      "LC Training Loss (Full): 0.25878003239631653\n",
      "Epoch: 1, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6212165951728821\n",
      "LC Training Loss (Full): 0.22558093070983887\n",
      "Epoch: 1, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.4564468562602997\n",
      "LC Training Loss (Full): 0.12750163674354553\n",
      "Epoch: 1, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6753527522087097\n",
      "LC Training Loss (Full): 0.29844895005226135\n",
      "Epoch: 1, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5487065315246582\n",
      "LC Training Loss (Full): 0.18816180527210236\n",
      "Full accuracy (w/o dLoRA+LC): 0.9267, LC accuracy: 0.9266, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8139, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8145\n",
      "Epoch: 1, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6487531065940857\n",
      "LC Training Loss (Full): 0.22872117161750793\n",
      "Epoch: 1, Iteration: 32\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.5920182466506958\n",
      "LC Training Loss (Full): 0.1962473839521408\n",
      "Epoch: 1, Iteration: 33\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.7921079397201538\n",
      "LC Training Loss (Full): 0.4630090892314911\n",
      "Epoch: 1, Iteration: 34\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.7553858160972595\n",
      "LC Training Loss (Full): 0.3180524408817291\n",
      "Epoch: 1, Iteration: 35\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6701334714889526\n",
      "LC Training Loss (Full): 0.2938534915447235\n",
      "Full accuracy (w/o dLoRA+LC): 0.9253, LC accuracy: 0.9266, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8153, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8147\n",
      "Epoch: 1, Iteration: 36\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6142892241477966\n",
      "LC Training Loss (Full): 0.16856861114501953\n",
      "Epoch: 1, Iteration: 37\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.7327299118041992\n",
      "LC Training Loss (Full): 0.26732128858566284\n",
      "Epoch: 1, Iteration: 38\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.7089049220085144\n",
      "LC Training Loss (Full): 0.24988692998886108\n",
      "Epoch: 1, Iteration: 39\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.5994278788566589\n",
      "LC Training Loss (Full): 0.248281791806221\n",
      "Epoch: 1, Iteration: 40\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7230712175369263\n",
      "LC Training Loss (Full): 0.308292031288147\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9252, LC accuracy: 0.9256, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8144, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8144\n",
      "Epoch: 1, Iteration: 41\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.9101236462593079\n",
      "LC Training Loss (Full): 0.3625715374946594\n",
      "Epoch: 1, Iteration: 42\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.8131816387176514\n",
      "LC Training Loss (Full): 0.3587167263031006\n",
      "Epoch: 1, Iteration: 43\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.60850590467453\n",
      "LC Training Loss (Full): 0.24632278084754944\n",
      "Epoch: 1, Iteration: 44\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6021881699562073\n",
      "LC Training Loss (Full): 0.2460949718952179\n",
      "Epoch: 1, Iteration: 45\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6948281526565552\n",
      "LC Training Loss (Full): 0.2628091275691986\n",
      "Full accuracy (w/o dLoRA+LC): 0.9261, LC accuracy: 0.9255, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8144, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8145\n",
      "Epoch: 1, Iteration: 46\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5519164204597473\n",
      "LC Training Loss (Full): 0.17243127524852753\n",
      "Epoch: 1, Iteration: 47\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.8154736161231995\n",
      "LC Training Loss (Full): 0.3664180636405945\n",
      "Epoch: 1, Iteration: 48\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5417535305023193\n",
      "LC Training Loss (Full): 0.2017509639263153\n",
      "Epoch: 1, Iteration: 49\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5622686147689819\n",
      "LC Training Loss (Full): 0.21807551383972168\n",
      "Epoch: 1, Iteration: 50\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5780542492866516\n",
      "LC Training Loss (Full): 0.22011491656303406\n",
      "Full accuracy (w/o dLoRA+LC): 0.9258, LC accuracy: 0.9262, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8145, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8146\n",
      "Epoch: 1, Iteration: 51\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6694525480270386\n",
      "LC Training Loss (Full): 0.39977601170539856\n",
      "Epoch: 1, Iteration: 52\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7388884425163269\n",
      "LC Training Loss (Full): 0.20491546392440796\n",
      "Epoch: 1, Iteration: 53\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.5689882040023804\n",
      "LC Training Loss (Full): 0.27909916639328003\n",
      "Epoch: 1, Iteration: 54\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.615260899066925\n",
      "LC Training Loss (Full): 0.1430760771036148\n",
      "Epoch: 1, Iteration: 55\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7654445767402649\n",
      "LC Training Loss (Full): 0.4427081048488617\n",
      "Full accuracy (w/o dLoRA+LC): 0.9256, LC accuracy: 0.9261, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8158, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8149\n",
      "Epoch: 1, Iteration: 56\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7426486611366272\n",
      "LC Training Loss (Full): 0.3406790792942047\n",
      "Epoch: 1, Iteration: 57\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7376596331596375\n",
      "LC Training Loss (Full): 0.3455778956413269\n",
      "Epoch: 1, Iteration: 58\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6002331972122192\n",
      "LC Training Loss (Full): 0.35264530777931213\n",
      "Epoch: 1, Iteration: 59\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.7004208564758301\n",
      "LC Training Loss (Full): 0.3150596618652344\n",
      "Epoch: 1, Iteration: 60\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6794907450675964\n",
      "LC Training Loss (Full): 0.23091670870780945\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9261, LC accuracy: 0.9258, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8141, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8149\n",
      "Epoch: 1, Iteration: 61\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.585729718208313\n",
      "LC Training Loss (Full): 0.21089743077754974\n",
      "Epoch: 1, Iteration: 62\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5659617185592651\n",
      "LC Training Loss (Full): 0.36764878034591675\n",
      "Epoch: 1, Iteration: 63\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7867163419723511\n",
      "LC Training Loss (Full): 0.3707488775253296\n",
      "Epoch: 1, Iteration: 64\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.622519850730896\n",
      "LC Training Loss (Full): 0.21113015711307526\n",
      "Epoch: 1, Iteration: 65\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.8117200136184692\n",
      "LC Training Loss (Full): 0.44816312193870544\n",
      "Full accuracy (w/o dLoRA+LC): 0.9258, LC accuracy: 0.9259, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8154, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8133\n",
      "Epoch: 1, Iteration: 66\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5566616058349609\n",
      "LC Training Loss (Full): 0.19754166901111603\n",
      "Epoch: 1, Iteration: 67\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5497907400131226\n",
      "LC Training Loss (Full): 0.19472551345825195\n",
      "Epoch: 1, Iteration: 68\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7182690501213074\n",
      "LC Training Loss (Full): 0.22172394394874573\n",
      "Epoch: 1, Iteration: 69\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.6142901182174683\n",
      "LC Training Loss (Full): 0.24978096783161163\n",
      "Epoch: 1, Iteration: 70\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7584806680679321\n",
      "LC Training Loss (Full): 0.27092596888542175\n",
      "Full accuracy (w/o dLoRA+LC): 0.9249, LC accuracy: 0.9261, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8144, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8143\n",
      "Epoch: 1, Iteration: 71\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.6337878108024597\n",
      "LC Training Loss (Full): 0.23000076413154602\n",
      "Epoch: 1, Iteration: 72\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7097063660621643\n",
      "LC Training Loss (Full): 0.3475063443183899\n",
      "Epoch: 1, Iteration: 73\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.5315443873405457\n",
      "LC Training Loss (Full): 0.24947324395179749\n",
      "Epoch: 1, Iteration: 74\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7306548357009888\n",
      "LC Training Loss (Full): 0.2830207347869873\n",
      "Epoch: 1, Iteration: 75\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7018113732337952\n",
      "LC Training Loss (Full): 0.3007984161376953\n",
      "Full accuracy (w/o dLoRA+LC): 0.9255, LC accuracy: 0.9262, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8154, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8147\n",
      "Epoch: 1, Iteration: 76\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7604798078536987\n",
      "LC Training Loss (Full): 0.3208676278591156\n",
      "Epoch: 1, Iteration: 77\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.8483194708824158\n",
      "LC Training Loss (Full): 0.32758334279060364\n",
      "Epoch: 1, Iteration: 78\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.7691895365715027\n",
      "LC Training Loss (Full): 0.4206705689430237\n",
      "Epoch: 1, Iteration: 79\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.5294669270515442\n",
      "LC Training Loss (Full): 0.14576101303100586\n",
      "Epoch: 1, Iteration: 80\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7118415832519531\n",
      "LC Training Loss (Full): 0.37825796008110046\n",
      "Training Accuracy | Decomposed: 0.75, Full : 0.875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9269, LC accuracy: 0.9271, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8134, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8152\n",
      "Epoch: 1, Iteration: 81\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.8718288540840149\n",
      "LC Training Loss (Full): 0.37960588932037354\n",
      "Epoch: 1, Iteration: 82\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5798596143722534\n",
      "LC Training Loss (Full): 0.1714525818824768\n",
      "Epoch: 1, Iteration: 83\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.6205974221229553\n",
      "LC Training Loss (Full): 0.196612149477005\n",
      "Epoch: 1, Iteration: 84\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5664079189300537\n",
      "LC Training Loss (Full): 0.19834643602371216\n",
      "Epoch: 1, Iteration: 85\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5113680362701416\n",
      "LC Training Loss (Full): 0.2284773886203766\n",
      "Full accuracy (w/o dLoRA+LC): 0.9267, LC accuracy: 0.9273, Decomposed-Full (w/dLoRA+LC) accuracy: 0.815, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8154\n",
      "Epoch: 1, Iteration: 86\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.7574388980865479\n",
      "LC Training Loss (Full): 0.29639407992362976\n",
      "Epoch: 1, Iteration: 87\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.707490861415863\n",
      "LC Training Loss (Full): 0.22826775908470154\n",
      "Epoch: 1, Iteration: 88\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5214715003967285\n",
      "LC Training Loss (Full): 0.29277661442756653\n",
      "Epoch: 1, Iteration: 89\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.6220455765724182\n",
      "LC Training Loss (Full): 0.17419788241386414\n",
      "Epoch: 1, Iteration: 90\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6000667214393616\n",
      "LC Training Loss (Full): 0.30174028873443604\n",
      "Full accuracy (w/o dLoRA+LC): 0.9259, LC accuracy: 0.9262, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8141, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.815\n",
      "Epoch: 1, Iteration: 91\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.609072208404541\n",
      "LC Training Loss (Full): 0.28321248292922974\n",
      "Epoch: 1, Iteration: 92\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6562647819519043\n",
      "LC Training Loss (Full): 0.18010398745536804\n",
      "Epoch: 1, Iteration: 93\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.7046028971672058\n",
      "LC Training Loss (Full): 0.28828349709510803\n",
      "Epoch: 1, Iteration: 94\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6769372224807739\n",
      "LC Training Loss (Full): 0.2740877568721771\n",
      "Epoch: 1, Iteration: 95\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6106044054031372\n",
      "LC Training Loss (Full): 0.2058120220899582\n",
      "Full accuracy (w/o dLoRA+LC): 0.9278, LC accuracy: 0.9263, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8154, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8142\n",
      "Epoch: 1, Iteration: 96\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.7501324415206909\n",
      "LC Training Loss (Full): 0.2838328778743744\n",
      "Epoch: 1, Iteration: 97\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.8543544411659241\n",
      "LC Training Loss (Full): 0.4965198338031769\n",
      "Epoch: 1, Iteration: 98\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6887753009796143\n",
      "LC Training Loss (Full): 0.2276369333267212\n",
      "Epoch: 1, Iteration: 99\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.5748066306114197\n",
      "LC Training Loss (Full): 0.15312369167804718\n",
      "Epoch: 1, Iteration: 100\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6026773452758789\n",
      "LC Training Loss (Full): 0.18324248492717743\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9279, LC accuracy: 0.9284, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8154, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8148\n",
      "Epoch: 1, Iteration: 101\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7096462249755859\n",
      "LC Training Loss (Full): 0.2856651842594147\n",
      "Epoch: 1, Iteration: 102\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7766042351722717\n",
      "LC Training Loss (Full): 0.3702327311038971\n",
      "Epoch: 1, Iteration: 103\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.839642345905304\n",
      "LC Training Loss (Full): 0.4054791033267975\n",
      "Epoch: 1, Iteration: 104\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7931696176528931\n",
      "LC Training Loss (Full): 0.30628320574760437\n",
      "Epoch: 1, Iteration: 105\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.5315124988555908\n",
      "LC Training Loss (Full): 0.1405201405286789\n",
      "Full accuracy (w/o dLoRA+LC): 0.9281, LC accuracy: 0.9284, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8174, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.816\n",
      "Epoch: 1, Iteration: 106\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.745107889175415\n",
      "LC Training Loss (Full): 0.3379024267196655\n",
      "Epoch: 1, Iteration: 107\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.6361213326454163\n",
      "LC Training Loss (Full): 0.22754210233688354\n",
      "Epoch: 1, Iteration: 108\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7097721099853516\n",
      "LC Training Loss (Full): 0.1908460110425949\n",
      "Epoch: 1, Iteration: 109\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.6366000771522522\n",
      "LC Training Loss (Full): 0.29452842473983765\n",
      "Epoch: 1, Iteration: 110\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.752882182598114\n",
      "LC Training Loss (Full): 0.29848289489746094\n",
      "Full accuracy (w/o dLoRA+LC): 0.9273, LC accuracy: 0.9269, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8158, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.816\n",
      "Epoch: 1, Iteration: 111\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.766117513179779\n",
      "LC Training Loss (Full): 0.40722253918647766\n",
      "Epoch: 1, Iteration: 112\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.8459261655807495\n",
      "LC Training Loss (Full): 0.38627418875694275\n",
      "Epoch: 1, Iteration: 113\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.6083861589431763\n",
      "LC Training Loss (Full): 0.20471277832984924\n",
      "Epoch: 1, Iteration: 114\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.695101261138916\n",
      "LC Training Loss (Full): 0.37021902203559875\n",
      "Epoch: 1, Iteration: 115\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7546730041503906\n",
      "LC Training Loss (Full): 0.39422380924224854\n",
      "Full accuracy (w/o dLoRA+LC): 0.9274, LC accuracy: 0.9268, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8155, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8154\n",
      "Epoch: 1, Iteration: 116\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.6166425347328186\n",
      "LC Training Loss (Full): 0.273537814617157\n",
      "Epoch: 1, Iteration: 117\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7696197032928467\n",
      "LC Training Loss (Full): 0.4201248586177826\n",
      "Epoch: 1, Iteration: 118\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.6506132483482361\n",
      "LC Training Loss (Full): 0.2473042756319046\n",
      "Epoch: 1, Iteration: 119\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.8398405313491821\n",
      "LC Training Loss (Full): 0.4596591591835022\n",
      "Epoch: 1, Iteration: 120\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5578917860984802\n",
      "LC Training Loss (Full): 0.15566116571426392\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9271, LC accuracy: 0.9279, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8151, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8153\n",
      "Epoch: 1, Iteration: 121\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7583237290382385\n",
      "LC Training Loss (Full): 0.3914809823036194\n",
      "Epoch: 1, Iteration: 122\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7515056729316711\n",
      "LC Training Loss (Full): 0.2887721657752991\n",
      "Epoch: 1, Iteration: 123\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.8452028632164001\n",
      "LC Training Loss (Full): 0.3794958293437958\n",
      "Epoch: 1, Iteration: 124\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.760629415512085\n",
      "LC Training Loss (Full): 0.3744281828403473\n",
      "Epoch: 1, Iteration: 125\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.6068453788757324\n",
      "LC Training Loss (Full): 0.292635440826416\n",
      "Full accuracy (w/o dLoRA+LC): 0.9284, LC accuracy: 0.928, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8157, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8157\n",
      "Epoch: 1, Iteration: 126\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7731291055679321\n",
      "LC Training Loss (Full): 0.320730596780777\n",
      "Epoch: 1, Iteration: 127\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7384146451950073\n",
      "LC Training Loss (Full): 0.2867588400840759\n",
      "Epoch: 1, Iteration: 128\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5860476493835449\n",
      "LC Training Loss (Full): 0.43376046419143677\n",
      "Epoch: 1, Iteration: 129\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.48441019654273987\n",
      "LC Training Loss (Full): 0.14789730310440063\n",
      "Epoch: 1, Iteration: 130\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6648104190826416\n",
      "LC Training Loss (Full): 0.1872912049293518\n",
      "Full accuracy (w/o dLoRA+LC): 0.9279, LC accuracy: 0.9279, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8159, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8158\n",
      "Epoch: 1, Iteration: 131\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6675325632095337\n",
      "LC Training Loss (Full): 0.23784717917442322\n",
      "Epoch: 1, Iteration: 132\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7208858132362366\n",
      "LC Training Loss (Full): 0.2600330412387848\n",
      "Epoch: 1, Iteration: 133\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6389850378036499\n",
      "LC Training Loss (Full): 0.4164963364601135\n",
      "Epoch: 1, Iteration: 134\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7362300157546997\n",
      "LC Training Loss (Full): 0.4006108045578003\n",
      "Epoch: 1, Iteration: 135\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.9830042123794556\n",
      "LC Training Loss (Full): 0.45063045620918274\n",
      "Full accuracy (w/o dLoRA+LC): 0.9275, LC accuracy: 0.9279, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8172, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8157\n",
      "Epoch: 1, Iteration: 136\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6658087372779846\n",
      "LC Training Loss (Full): 0.26094308495521545\n",
      "Epoch: 1, Iteration: 137\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.7087477445602417\n",
      "LC Training Loss (Full): 0.32863885164260864\n",
      "Epoch: 1, Iteration: 138\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6237718462944031\n",
      "LC Training Loss (Full): 0.25880855321884155\n",
      "Epoch: 1, Iteration: 139\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.4917494058609009\n",
      "LC Training Loss (Full): 0.16542364656925201\n",
      "Epoch: 1, Iteration: 140\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6919887065887451\n",
      "LC Training Loss (Full): 0.22683534026145935\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9278, LC accuracy: 0.9279, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8158, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8155\n",
      "Epoch: 1, Iteration: 141\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5910165905952454\n",
      "LC Training Loss (Full): 0.17271600663661957\n",
      "Epoch: 1, Iteration: 142\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.47687703371047974\n",
      "LC Training Loss (Full): 0.21860428154468536\n",
      "Epoch: 1, Iteration: 143\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.6602326035499573\n",
      "LC Training Loss (Full): 0.4934318959712982\n",
      "Epoch: 1, Iteration: 144\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5116763114929199\n",
      "LC Training Loss (Full): 0.16133955121040344\n",
      "Epoch: 1, Iteration: 145\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.6419585347175598\n",
      "LC Training Loss (Full): 0.2238832414150238\n",
      "Full accuracy (w/o dLoRA+LC): 0.9284, LC accuracy: 0.928, Decomposed-Full (w/dLoRA+LC) accuracy: 0.817, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8161\n",
      "Epoch: 1, Iteration: 146\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.6240027546882629\n",
      "LC Training Loss (Full): 0.16467180848121643\n",
      "Epoch: 1, Iteration: 147\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.7715363502502441\n",
      "LC Training Loss (Full): 0.30402645468711853\n",
      "Epoch: 1, Iteration: 148\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.6812587976455688\n",
      "LC Training Loss (Full): 0.3618415296077728\n",
      "Epoch: 1, Iteration: 149\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5576461553573608\n",
      "LC Training Loss (Full): 0.2768118679523468\n",
      "Epoch: 1, Iteration: 150\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6880420446395874\n",
      "LC Training Loss (Full): 0.25155001878738403\n",
      "Full accuracy (w/o dLoRA+LC): 0.9284, LC accuracy: 0.9283, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8151, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8151\n",
      "Epoch: 1, Iteration: 151\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.4787254333496094\n",
      "LC Training Loss (Full): 0.15441963076591492\n",
      "Epoch: 1, Iteration: 152\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.5304694771766663\n",
      "LC Training Loss (Full): 0.1423654705286026\n",
      "Epoch: 1, Iteration: 153\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.6035877466201782\n",
      "LC Training Loss (Full): 0.3209163248538971\n",
      "Epoch: 1, Iteration: 154\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7799050211906433\n",
      "LC Training Loss (Full): 0.42735472321510315\n",
      "Epoch: 1, Iteration: 155\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.6191297173500061\n",
      "LC Training Loss (Full): 0.30452728271484375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9287, LC accuracy: 0.9284, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8151, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8152\n",
      "Epoch: 1, Iteration: 156\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7341614961624146\n",
      "LC Training Loss (Full): 0.3117012679576874\n",
      "Epoch: 1, Iteration: 157\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.7648428082466125\n",
      "LC Training Loss (Full): 0.32223162055015564\n",
      "Epoch: 1, Iteration: 158\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.5592955946922302\n",
      "LC Training Loss (Full): 0.11364146322011948\n",
      "Epoch: 1, Iteration: 159\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.594372570514679\n",
      "LC Training Loss (Full): 0.28140416741371155\n",
      "Epoch: 1, Iteration: 160\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6509866714477539\n",
      "LC Training Loss (Full): 0.1958995908498764\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.96875\n",
      "Full accuracy (w/o dLoRA+LC): 0.929, LC accuracy: 0.9289, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8147, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8152\n",
      "Epoch: 1, Iteration: 161\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5551012754440308\n",
      "LC Training Loss (Full): 0.15339110791683197\n",
      "Epoch: 1, Iteration: 162\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5766331553459167\n",
      "LC Training Loss (Full): 0.27231016755104065\n",
      "Epoch: 1, Iteration: 163\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5717059969902039\n",
      "LC Training Loss (Full): 0.12015309929847717\n",
      "Epoch: 1, Iteration: 164\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5589095950126648\n",
      "LC Training Loss (Full): 0.21539616584777832\n",
      "Epoch: 1, Iteration: 165\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6439167261123657\n",
      "LC Training Loss (Full): 0.21115157008171082\n",
      "Full accuracy (w/o dLoRA+LC): 0.9291, LC accuracy: 0.9288, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8155, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8155\n",
      "Epoch: 1, Iteration: 166\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5828169584274292\n",
      "LC Training Loss (Full): 0.3102216124534607\n",
      "Epoch: 1, Iteration: 167\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.7643883228302002\n",
      "LC Training Loss (Full): 0.3217273950576782\n",
      "Epoch: 1, Iteration: 168\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6176515221595764\n",
      "LC Training Loss (Full): 0.22309504449367523\n",
      "Epoch: 1, Iteration: 169\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6780399680137634\n",
      "LC Training Loss (Full): 0.2175549864768982\n",
      "Epoch: 1, Iteration: 170\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8660479187965393\n",
      "LC Training Loss (Full): 0.3313651382923126\n",
      "Full accuracy (w/o dLoRA+LC): 0.9273, LC accuracy: 0.9276, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8149, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8155\n",
      "Epoch: 1, Iteration: 171\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5282077789306641\n",
      "LC Training Loss (Full): 0.15220320224761963\n",
      "Epoch: 1, Iteration: 172\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.6866934895515442\n",
      "LC Training Loss (Full): 0.3074820935726166\n",
      "Epoch: 1, Iteration: 173\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7742533087730408\n",
      "LC Training Loss (Full): 0.3082513213157654\n",
      "Epoch: 1, Iteration: 174\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5807762742042542\n",
      "LC Training Loss (Full): 0.22611863911151886\n",
      "Epoch: 1, Iteration: 175\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5969846248626709\n",
      "LC Training Loss (Full): 0.24019619822502136\n",
      "Full accuracy (w/o dLoRA+LC): 0.9285, LC accuracy: 0.9276, Decomposed-Full (w/dLoRA+LC) accuracy: 0.815, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8146\n",
      "Epoch: 1, Iteration: 176\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.9278198480606079\n",
      "LC Training Loss (Full): 0.36185547709465027\n",
      "Epoch: 1, Iteration: 177\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5409814119338989\n",
      "LC Training Loss (Full): 0.2126629650592804\n",
      "Epoch: 1, Iteration: 178\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7387029528617859\n",
      "LC Training Loss (Full): 0.3089136779308319\n",
      "Epoch: 1, Iteration: 179\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.7896977066993713\n",
      "LC Training Loss (Full): 0.35662558674812317\n",
      "Epoch: 1, Iteration: 180\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7867997884750366\n",
      "LC Training Loss (Full): 0.2815704941749573\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.890625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9284, LC accuracy: 0.9285, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8153, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8151\n",
      "Epoch: 1, Iteration: 181\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6287564039230347\n",
      "LC Training Loss (Full): 0.22142334282398224\n",
      "Epoch: 1, Iteration: 182\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.663626492023468\n",
      "LC Training Loss (Full): 0.2660093605518341\n",
      "Epoch: 1, Iteration: 183\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5593635439872742\n",
      "LC Training Loss (Full): 0.17677222192287445\n",
      "Epoch: 1, Iteration: 184\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.78046715259552\n",
      "LC Training Loss (Full): 0.3411600887775421\n",
      "Epoch: 1, Iteration: 185\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5303436517715454\n",
      "LC Training Loss (Full): 0.2552562952041626\n",
      "Full accuracy (w/o dLoRA+LC): 0.9282, LC accuracy: 0.9285, Decomposed-Full (w/dLoRA+LC) accuracy: 0.816, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8152\n",
      "Epoch: 1, Iteration: 186\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.48460277915000916\n",
      "LC Training Loss (Full): 0.20301911234855652\n",
      "Epoch: 1, Iteration: 187\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5746670961380005\n",
      "LC Training Loss (Full): 0.15020792186260223\n",
      "Epoch: 1, Iteration: 188\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5785399675369263\n",
      "LC Training Loss (Full): 0.20633986592292786\n",
      "Epoch: 1, Iteration: 189\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6292305588722229\n",
      "LC Training Loss (Full): 0.2843855619430542\n",
      "Epoch: 1, Iteration: 190\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.9781538248062134\n",
      "LC Training Loss (Full): 0.5282389521598816\n",
      "Full accuracy (w/o dLoRA+LC): 0.9297, LC accuracy: 0.9293, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8154, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8148\n",
      "Epoch: 1, Iteration: 191\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5568522810935974\n",
      "LC Training Loss (Full): 0.1512863039970398\n",
      "Epoch: 1, Iteration: 192\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.7977149486541748\n",
      "LC Training Loss (Full): 0.4150526523590088\n",
      "Epoch: 1, Iteration: 193\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.7823668718338013\n",
      "LC Training Loss (Full): 0.4184405207633972\n",
      "Epoch: 1, Iteration: 194\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5903469324111938\n",
      "LC Training Loss (Full): 0.23655572533607483\n",
      "Epoch: 1, Iteration: 195\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.7525191903114319\n",
      "LC Training Loss (Full): 0.3436804413795471\n",
      "Full accuracy (w/o dLoRA+LC): 0.9294, LC accuracy: 0.9294, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8156, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.814\n",
      "Epoch: 1, Iteration: 196\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.8068862557411194\n",
      "LC Training Loss (Full): 0.3040482699871063\n",
      "Epoch: 1, Iteration: 197\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.536253035068512\n",
      "LC Training Loss (Full): 0.19003215432167053\n",
      "Epoch: 1, Iteration: 198\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6303884387016296\n",
      "LC Training Loss (Full): 0.33353501558303833\n",
      "Epoch: 1, Iteration: 199\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6801905035972595\n",
      "LC Training Loss (Full): 0.22788883745670319\n",
      "Epoch: 1, Iteration: 200\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6197641491889954\n",
      "LC Training Loss (Full): 0.16700515151023865\n",
      "Training Accuracy | Decomposed: 0.765625, Full : 0.96875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9294, LC accuracy: 0.9294, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8145, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8137\n",
      "Epoch: 1, Iteration: 201\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.6738519072532654\n",
      "LC Training Loss (Full): 0.31736114621162415\n",
      "Epoch: 1, Iteration: 202\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.6182215809822083\n",
      "LC Training Loss (Full): 0.2987630367279053\n",
      "Epoch: 1, Iteration: 203\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.8316147923469543\n",
      "LC Training Loss (Full): 0.3254915475845337\n",
      "Epoch: 1, Iteration: 204\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.6248828768730164\n",
      "LC Training Loss (Full): 0.21855227649211884\n",
      "Epoch: 1, Iteration: 205\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7551594972610474\n",
      "LC Training Loss (Full): 0.2661774158477783\n",
      "Full accuracy (w/o dLoRA+LC): 0.9299, LC accuracy: 0.9293, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8148, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8142\n",
      "Epoch: 1, Iteration: 206\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.8185762166976929\n",
      "LC Training Loss (Full): 0.3854879140853882\n",
      "Epoch: 1, Iteration: 207\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5528774261474609\n",
      "LC Training Loss (Full): 0.14702652394771576\n",
      "Epoch: 1, Iteration: 208\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7381758093833923\n",
      "LC Training Loss (Full): 0.280585378408432\n",
      "Epoch: 1, Iteration: 209\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.7135497331619263\n",
      "LC Training Loss (Full): 0.33130335807800293\n",
      "Epoch: 1, Iteration: 210\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6274252533912659\n",
      "LC Training Loss (Full): 0.27073773741722107\n",
      "Full accuracy (w/o dLoRA+LC): 0.9292, LC accuracy: 0.929, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8144, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8148\n",
      "Epoch: 1, Iteration: 211\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7282489538192749\n",
      "LC Training Loss (Full): 0.25337594747543335\n",
      "Epoch: 1, Iteration: 212\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6494959592819214\n",
      "LC Training Loss (Full): 0.23671193420886993\n",
      "Epoch: 1, Iteration: 213\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.8098289370536804\n",
      "LC Training Loss (Full): 0.4169749617576599\n",
      "Epoch: 1, Iteration: 214\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7800702452659607\n",
      "LC Training Loss (Full): 0.36865493655204773\n",
      "Epoch: 1, Iteration: 215\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6904435753822327\n",
      "LC Training Loss (Full): 0.2807244658470154\n",
      "Full accuracy (w/o dLoRA+LC): 0.9305, LC accuracy: 0.9289, Decomposed-Full (w/dLoRA+LC) accuracy: 0.816, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8151\n",
      "Epoch: 1, Iteration: 216\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.4868723452091217\n",
      "LC Training Loss (Full): 0.18301737308502197\n",
      "Epoch: 1, Iteration: 217\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.737571656703949\n",
      "LC Training Loss (Full): 0.323701947927475\n",
      "Epoch: 1, Iteration: 218\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.8769193887710571\n",
      "LC Training Loss (Full): 0.37679389119148254\n",
      "Epoch: 1, Iteration: 219\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6925526857376099\n",
      "LC Training Loss (Full): 0.2471100091934204\n",
      "Epoch: 1, Iteration: 220\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5650238990783691\n",
      "LC Training Loss (Full): 0.16473984718322754\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9305, LC accuracy: 0.9309, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8145, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8153\n",
      "Epoch: 1, Iteration: 221\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5836797952651978\n",
      "LC Training Loss (Full): 0.1958661675453186\n",
      "Epoch: 1, Iteration: 222\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5026818513870239\n",
      "LC Training Loss (Full): 0.12807175517082214\n",
      "Epoch: 1, Iteration: 223\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.8082492351531982\n",
      "LC Training Loss (Full): 0.4039074778556824\n",
      "Epoch: 1, Iteration: 224\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6489654779434204\n",
      "LC Training Loss (Full): 0.28630557656288147\n",
      "Epoch: 1, Iteration: 225\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5568965077400208\n",
      "LC Training Loss (Full): 0.19516079127788544\n",
      "Full accuracy (w/o dLoRA+LC): 0.9298, LC accuracy: 0.931, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8155, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8149\n",
      "Epoch: 1, Iteration: 226\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6598676443099976\n",
      "LC Training Loss (Full): 0.2820916175842285\n",
      "Epoch: 1, Iteration: 227\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5749875903129578\n",
      "LC Training Loss (Full): 0.1497325748205185\n",
      "Epoch: 1, Iteration: 228\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.9263611435890198\n",
      "LC Training Loss (Full): 0.4980422258377075\n",
      "Epoch: 1, Iteration: 229\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.8189904689788818\n",
      "LC Training Loss (Full): 0.31829094886779785\n",
      "Epoch: 1, Iteration: 230\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_47\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7156262397766113\n",
      "LC Training Loss (Full): 0.38145336508750916\n",
      "Full accuracy (w/o dLoRA+LC): 0.9296, LC accuracy: 0.9297, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8154, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8151\n",
      "Epoch: 1, Iteration: 231\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.8583983778953552\n",
      "LC Training Loss (Full): 0.39854663610458374\n",
      "Epoch: 1, Iteration: 232\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.7150238156318665\n",
      "LC Training Loss (Full): 0.2338535040616989\n",
      "Epoch: 1, Iteration: 233\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.689827561378479\n",
      "LC Training Loss (Full): 0.2914726436138153\n",
      "Epoch: 1, Iteration: 234\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader3/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader3/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.4828217327594757\n",
      "LC Training Loss (Full): 0.11004144698381424\n",
      "End of model training on train_loader3...\n",
      "Model saved at accuracy: 0.8154\n",
      "--------------------------\n",
      "Beginning of model training on train_loader4...\n",
      "Epoch: 0, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4413076639175415\n",
      "LC Training Loss (Full): 0.14016366004943848\n",
      "Training Accuracy | Decomposed: 0.90625, Full : 0.9375\n",
      "Epoch: 0, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6477267742156982\n",
      "LC Training Loss (Full): 0.23413869738578796\n",
      "Epoch: 0, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6096561551094055\n",
      "LC Training Loss (Full): 0.315660297870636\n",
      "Epoch: 0, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5598739981651306\n",
      "LC Training Loss (Full): 0.17694684863090515\n",
      "Epoch: 0, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7080487012863159\n",
      "LC Training Loss (Full): 0.31432875990867615\n",
      "Epoch: 0, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.6337447166442871\n",
      "LC Training Loss (Full): 0.2623000741004944\n",
      "Full accuracy (w/o dLoRA+LC): 0.9306, LC accuracy: 0.9298, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8235, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8176\n",
      "Epoch: 0, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.527842104434967\n",
      "LC Training Loss (Full): 0.25218909978866577\n",
      "Epoch: 0, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5915480852127075\n",
      "LC Training Loss (Full): 0.35126185417175293\n",
      "Epoch: 0, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.5521994829177856\n",
      "LC Training Loss (Full): 0.25344395637512207\n",
      "Epoch: 0, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_0\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_0\n",
      "LoRA+LC Training Loss (Decomposed): 0.7052264213562012\n",
      "LC Training Loss (Full): 0.25902265310287476\n",
      "Epoch: 0, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5056645274162292\n",
      "LC Training Loss (Full): 0.2113034725189209\n",
      "Full accuracy (w/o dLoRA+LC): 0.9302, LC accuracy: 0.9297, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8159, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8159\n",
      "Epoch: 0, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.4310896098613739\n",
      "LC Training Loss (Full): 0.11220423877239227\n",
      "Epoch: 0, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5592460036277771\n",
      "LC Training Loss (Full): 0.1881147027015686\n",
      "Epoch: 0, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.7838205099105835\n",
      "LC Training Loss (Full): 0.44465112686157227\n",
      "Epoch: 0, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6826373338699341\n",
      "LC Training Loss (Full): 0.3436407446861267\n",
      "Epoch: 0, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5420170426368713\n",
      "LC Training Loss (Full): 0.19392472505569458\n",
      "Full accuracy (w/o dLoRA+LC): 0.9311, LC accuracy: 0.9297, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8182, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8166\n",
      "Epoch: 0, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.5106172561645508\n",
      "LC Training Loss (Full): 0.11727731674909592\n",
      "Epoch: 0, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6568953394889832\n",
      "LC Training Loss (Full): 0.21618124842643738\n",
      "Epoch: 0, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.6852827668190002\n",
      "LC Training Loss (Full): 0.23978103697299957\n",
      "Epoch: 0, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_1\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_1\n",
      "LoRA+LC Training Loss (Decomposed): 0.44440871477127075\n",
      "LC Training Loss (Full): 0.24567216634750366\n",
      "Epoch: 0, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5700949430465698\n",
      "LC Training Loss (Full): 0.15750686824321747\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.96875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9315, LC accuracy: 0.9308, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8174, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8169\n",
      "Epoch: 0, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5660476684570312\n",
      "LC Training Loss (Full): 0.29750925302505493\n",
      "Epoch: 0, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4667382538318634\n",
      "LC Training Loss (Full): 0.12173208594322205\n",
      "Epoch: 0, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.582731306552887\n",
      "LC Training Loss (Full): 0.23936785757541656\n",
      "Epoch: 0, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5308659076690674\n",
      "LC Training Loss (Full): 0.2906847298145294\n",
      "Epoch: 0, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6340184807777405\n",
      "LC Training Loss (Full): 0.28715795278549194\n",
      "Full accuracy (w/o dLoRA+LC): 0.9314, LC accuracy: 0.9309, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8175, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8179\n",
      "Epoch: 0, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6087700128555298\n",
      "LC Training Loss (Full): 0.31401437520980835\n",
      "Epoch: 0, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.5602040886878967\n",
      "LC Training Loss (Full): 0.1406596451997757\n",
      "Epoch: 0, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.4985988438129425\n",
      "LC Training Loss (Full): 0.15714837610721588\n",
      "Epoch: 0, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_2\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_2\n",
      "LoRA+LC Training Loss (Decomposed): 0.6576796174049377\n",
      "LC Training Loss (Full): 0.23234127461910248\n",
      "Epoch: 0, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.49493294954299927\n",
      "LC Training Loss (Full): 0.1413000375032425\n",
      "Full accuracy (w/o dLoRA+LC): 0.9308, LC accuracy: 0.9305, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8173, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8184\n",
      "Epoch: 0, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5079851150512695\n",
      "LC Training Loss (Full): 0.13800743222236633\n",
      "Epoch: 0, Iteration: 32\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6535396575927734\n",
      "LC Training Loss (Full): 0.20485371351242065\n",
      "Epoch: 0, Iteration: 33\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5795568823814392\n",
      "LC Training Loss (Full): 0.1736895591020584\n",
      "Epoch: 0, Iteration: 34\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7773305773735046\n",
      "LC Training Loss (Full): 0.3672579228878021\n",
      "Epoch: 0, Iteration: 35\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.7753639817237854\n",
      "LC Training Loss (Full): 0.3404197692871094\n",
      "Full accuracy (w/o dLoRA+LC): 0.9326, LC accuracy: 0.9305, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8197, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8179\n",
      "Epoch: 0, Iteration: 36\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5598129630088806\n",
      "LC Training Loss (Full): 0.12892769277095795\n",
      "Epoch: 0, Iteration: 37\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.5147750973701477\n",
      "LC Training Loss (Full): 0.1243535503745079\n",
      "Epoch: 0, Iteration: 38\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6067997813224792\n",
      "LC Training Loss (Full): 0.2605900466442108\n",
      "Epoch: 0, Iteration: 39\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_3\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_3\n",
      "LoRA+LC Training Loss (Decomposed): 0.6010345816612244\n",
      "LC Training Loss (Full): 0.23996534943580627\n",
      "Epoch: 0, Iteration: 40\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.574069082736969\n",
      "LC Training Loss (Full): 0.2095179557800293\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9317, LC accuracy: 0.9318, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8181, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8185\n",
      "Epoch: 0, Iteration: 41\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.562549889087677\n",
      "LC Training Loss (Full): 0.24834328889846802\n",
      "Epoch: 0, Iteration: 42\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.6483798623085022\n",
      "LC Training Loss (Full): 0.27965012192726135\n",
      "Epoch: 0, Iteration: 43\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.5738531947135925\n",
      "LC Training Loss (Full): 0.1802624762058258\n",
      "Epoch: 0, Iteration: 44\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.7210017442703247\n",
      "LC Training Loss (Full): 0.2708550691604614\n",
      "Epoch: 0, Iteration: 45\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.5302756428718567\n",
      "LC Training Loss (Full): 0.14470621943473816\n",
      "Full accuracy (w/o dLoRA+LC): 0.9333, LC accuracy: 0.9319, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8194, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8188\n",
      "Epoch: 0, Iteration: 46\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.53879714012146\n",
      "LC Training Loss (Full): 0.190903440117836\n",
      "Epoch: 0, Iteration: 47\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.5532619953155518\n",
      "LC Training Loss (Full): 0.23206627368927002\n",
      "Epoch: 0, Iteration: 48\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.6403972506523132\n",
      "LC Training Loss (Full): 0.3099103569984436\n",
      "Epoch: 0, Iteration: 49\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_4\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_4\n",
      "LoRA+LC Training Loss (Decomposed): 0.4956192374229431\n",
      "LC Training Loss (Full): 0.1457577347755432\n",
      "Epoch: 0, Iteration: 50\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.563454270362854\n",
      "LC Training Loss (Full): 0.3572605550289154\n",
      "Full accuracy (w/o dLoRA+LC): 0.932, LC accuracy: 0.9326, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8182, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8188\n",
      "Epoch: 0, Iteration: 51\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.5343478918075562\n",
      "LC Training Loss (Full): 0.2508943974971771\n",
      "Epoch: 0, Iteration: 52\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.5534327626228333\n",
      "LC Training Loss (Full): 0.26560357213020325\n",
      "Epoch: 0, Iteration: 53\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7329010963439941\n",
      "LC Training Loss (Full): 0.25757256150245667\n",
      "Epoch: 0, Iteration: 54\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.5338257551193237\n",
      "LC Training Loss (Full): 0.24574963748455048\n",
      "Epoch: 0, Iteration: 55\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.5853563547134399\n",
      "LC Training Loss (Full): 0.2059493064880371\n",
      "Full accuracy (w/o dLoRA+LC): 0.9328, LC accuracy: 0.9325, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8185, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8191\n",
      "Epoch: 0, Iteration: 56\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.6006152629852295\n",
      "LC Training Loss (Full): 0.18081848323345184\n",
      "Epoch: 0, Iteration: 57\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.5853514671325684\n",
      "LC Training Loss (Full): 0.35199594497680664\n",
      "Epoch: 0, Iteration: 58\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7285634875297546\n",
      "LC Training Loss (Full): 0.32078588008880615\n",
      "Epoch: 0, Iteration: 59\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_5\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_5\n",
      "LoRA+LC Training Loss (Decomposed): 0.7710832953453064\n",
      "LC Training Loss (Full): 0.4444373846054077\n",
      "Epoch: 0, Iteration: 60\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5452677607536316\n",
      "LC Training Loss (Full): 0.21361248195171356\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9337, LC accuracy: 0.9328, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8189, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8189\n",
      "Epoch: 0, Iteration: 61\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.5377660393714905\n",
      "LC Training Loss (Full): 0.28681495785713196\n",
      "Epoch: 0, Iteration: 62\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.4225133955478668\n",
      "LC Training Loss (Full): 0.12931494414806366\n",
      "Epoch: 0, Iteration: 63\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.5855475068092346\n",
      "LC Training Loss (Full): 0.2268247753381729\n",
      "Epoch: 0, Iteration: 64\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6052784323692322\n",
      "LC Training Loss (Full): 0.21284371614456177\n",
      "Epoch: 0, Iteration: 65\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.774755597114563\n",
      "LC Training Loss (Full): 0.21323709189891815\n",
      "Full accuracy (w/o dLoRA+LC): 0.9343, LC accuracy: 0.9328, Decomposed-Full (w/dLoRA+LC) accuracy: 0.82, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.819\n",
      "Epoch: 0, Iteration: 66\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.5474213361740112\n",
      "LC Training Loss (Full): 0.15292835235595703\n",
      "Epoch: 0, Iteration: 67\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.5204921960830688\n",
      "LC Training Loss (Full): 0.18560267984867096\n",
      "Epoch: 0, Iteration: 68\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.6266192197799683\n",
      "LC Training Loss (Full): 0.25001654028892517\n",
      "Epoch: 0, Iteration: 69\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_6\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_6\n",
      "LoRA+LC Training Loss (Decomposed): 0.7070420980453491\n",
      "LC Training Loss (Full): 0.2935222089290619\n",
      "Epoch: 0, Iteration: 70\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.38418319821357727\n",
      "LC Training Loss (Full): 0.11727757751941681\n",
      "Full accuracy (w/o dLoRA+LC): 0.9326, LC accuracy: 0.9333, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8194, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8194\n",
      "Epoch: 0, Iteration: 71\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.5491344928741455\n",
      "LC Training Loss (Full): 0.2187996357679367\n",
      "Epoch: 0, Iteration: 72\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.6751542687416077\n",
      "LC Training Loss (Full): 0.20781755447387695\n",
      "Epoch: 0, Iteration: 73\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.6357929110527039\n",
      "LC Training Loss (Full): 0.25313305854797363\n",
      "Epoch: 0, Iteration: 74\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.6988542079925537\n",
      "LC Training Loss (Full): 0.33963268995285034\n",
      "Epoch: 0, Iteration: 75\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.6299525499343872\n",
      "LC Training Loss (Full): 0.1688503623008728\n",
      "Full accuracy (w/o dLoRA+LC): 0.9337, LC accuracy: 0.9334, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8206, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8184\n",
      "Epoch: 0, Iteration: 76\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7669228911399841\n",
      "LC Training Loss (Full): 0.30788370966911316\n",
      "Epoch: 0, Iteration: 77\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.7359932661056519\n",
      "LC Training Loss (Full): 0.3969222605228424\n",
      "Epoch: 0, Iteration: 78\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.599513828754425\n",
      "LC Training Loss (Full): 0.21420885622501373\n",
      "Epoch: 0, Iteration: 79\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_7\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_7\n",
      "LoRA+LC Training Loss (Decomposed): 0.5891543030738831\n",
      "LC Training Loss (Full): 0.25185078382492065\n",
      "Epoch: 0, Iteration: 80\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6673023700714111\n",
      "LC Training Loss (Full): 0.33421239256858826\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.9334, Decomposed-Full (w/dLoRA+LC) accuracy: 0.819, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.819\n",
      "Epoch: 0, Iteration: 81\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.6709672212600708\n",
      "LC Training Loss (Full): 0.3311477601528168\n",
      "Epoch: 0, Iteration: 82\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.6828208565711975\n",
      "LC Training Loss (Full): 0.36348065733909607\n",
      "Epoch: 0, Iteration: 83\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5686326026916504\n",
      "LC Training Loss (Full): 0.26472851634025574\n",
      "Epoch: 0, Iteration: 84\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.606351375579834\n",
      "LC Training Loss (Full): 0.2255505472421646\n",
      "Epoch: 0, Iteration: 85\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5365316271781921\n",
      "LC Training Loss (Full): 0.24585966765880585\n",
      "Full accuracy (w/o dLoRA+LC): 0.932, LC accuracy: 0.9334, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8206, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8191\n",
      "Epoch: 0, Iteration: 86\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.7520561218261719\n",
      "LC Training Loss (Full): 0.2900918424129486\n",
      "Epoch: 0, Iteration: 87\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.5430908799171448\n",
      "LC Training Loss (Full): 0.2713775038719177\n",
      "Epoch: 0, Iteration: 88\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.4939546585083008\n",
      "LC Training Loss (Full): 0.17865338921546936\n",
      "Epoch: 0, Iteration: 89\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_8\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_8\n",
      "LoRA+LC Training Loss (Decomposed): 0.4587126076221466\n",
      "LC Training Loss (Full): 0.14216673374176025\n",
      "Epoch: 0, Iteration: 90\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6148821115493774\n",
      "LC Training Loss (Full): 0.2717570662498474\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.9332, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8199, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8186\n",
      "Epoch: 0, Iteration: 91\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.5074232816696167\n",
      "LC Training Loss (Full): 0.18961508572101593\n",
      "Epoch: 0, Iteration: 92\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6693824529647827\n",
      "LC Training Loss (Full): 0.21675732731819153\n",
      "Epoch: 0, Iteration: 93\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.5504662990570068\n",
      "LC Training Loss (Full): 0.1207422986626625\n",
      "Epoch: 0, Iteration: 94\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.5692609548568726\n",
      "LC Training Loss (Full): 0.3162021338939667\n",
      "Epoch: 0, Iteration: 95\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6900303959846497\n",
      "LC Training Loss (Full): 0.269508957862854\n",
      "Full accuracy (w/o dLoRA+LC): 0.9334, LC accuracy: 0.9331, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8195, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8186\n",
      "Epoch: 0, Iteration: 96\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.5451163649559021\n",
      "LC Training Loss (Full): 0.26846596598625183\n",
      "Epoch: 0, Iteration: 97\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.6318937540054321\n",
      "LC Training Loss (Full): 0.2489566057920456\n",
      "Epoch: 0, Iteration: 98\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.552696704864502\n",
      "LC Training Loss (Full): 0.17669667303562164\n",
      "Epoch: 0, Iteration: 99\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_9\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_9\n",
      "LoRA+LC Training Loss (Decomposed): 0.5552052855491638\n",
      "LC Training Loss (Full): 0.20925723016262054\n",
      "Epoch: 0, Iteration: 100\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4970584511756897\n",
      "LC Training Loss (Full): 0.11873474717140198\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.96875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9334, LC accuracy: 0.9339, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8192, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8185\n",
      "Epoch: 0, Iteration: 101\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6151322722434998\n",
      "LC Training Loss (Full): 0.19062349200248718\n",
      "Epoch: 0, Iteration: 102\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.503957986831665\n",
      "LC Training Loss (Full): 0.2659471333026886\n",
      "Epoch: 0, Iteration: 103\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6054684519767761\n",
      "LC Training Loss (Full): 0.1910220980644226\n",
      "Epoch: 0, Iteration: 104\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6842944025993347\n",
      "LC Training Loss (Full): 0.2526009976863861\n",
      "Epoch: 0, Iteration: 105\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.5081923007965088\n",
      "LC Training Loss (Full): 0.14675256609916687\n",
      "Full accuracy (w/o dLoRA+LC): 0.9339, LC accuracy: 0.9339, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8204, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8185\n",
      "Epoch: 0, Iteration: 106\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.7629018425941467\n",
      "LC Training Loss (Full): 0.2927100360393524\n",
      "Epoch: 0, Iteration: 107\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.40990760922431946\n",
      "LC Training Loss (Full): 0.08808226883411407\n",
      "Epoch: 0, Iteration: 108\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.4523613452911377\n",
      "LC Training Loss (Full): 0.12340833246707916\n",
      "Epoch: 0, Iteration: 109\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_10\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_10\n",
      "LoRA+LC Training Loss (Decomposed): 0.6102202534675598\n",
      "LC Training Loss (Full): 0.28102317452430725\n",
      "Epoch: 0, Iteration: 110\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5483756065368652\n",
      "LC Training Loss (Full): 0.1698579490184784\n",
      "Full accuracy (w/o dLoRA+LC): 0.9329, LC accuracy: 0.933, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8194, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8189\n",
      "Epoch: 0, Iteration: 111\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.6907525658607483\n",
      "LC Training Loss (Full): 0.22761857509613037\n",
      "Epoch: 0, Iteration: 112\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.5926777720451355\n",
      "LC Training Loss (Full): 0.21934983134269714\n",
      "Epoch: 0, Iteration: 113\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.703323483467102\n",
      "LC Training Loss (Full): 0.3715265989303589\n",
      "Epoch: 0, Iteration: 114\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.7332571148872375\n",
      "LC Training Loss (Full): 0.3808504045009613\n",
      "Epoch: 0, Iteration: 115\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.542718231678009\n",
      "LC Training Loss (Full): 0.17651554942131042\n",
      "Full accuracy (w/o dLoRA+LC): 0.933, LC accuracy: 0.933, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8198, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8192\n",
      "Epoch: 0, Iteration: 116\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.5994781255722046\n",
      "LC Training Loss (Full): 0.26701056957244873\n",
      "Epoch: 0, Iteration: 117\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.5069379806518555\n",
      "LC Training Loss (Full): 0.15372420847415924\n",
      "Epoch: 0, Iteration: 118\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.7828821539878845\n",
      "LC Training Loss (Full): 0.2260155975818634\n",
      "Epoch: 0, Iteration: 119\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_11\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_11\n",
      "LoRA+LC Training Loss (Decomposed): 0.8235185146331787\n",
      "LC Training Loss (Full): 0.3491383492946625\n",
      "Epoch: 0, Iteration: 120\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6644070148468018\n",
      "LC Training Loss (Full): 0.3059886693954468\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9331, LC accuracy: 0.934, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8194, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8187\n",
      "Epoch: 0, Iteration: 121\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.6530895233154297\n",
      "LC Training Loss (Full): 0.2753343880176544\n",
      "Epoch: 0, Iteration: 122\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.6001314520835876\n",
      "LC Training Loss (Full): 0.2829133868217468\n",
      "Epoch: 0, Iteration: 123\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.6186944842338562\n",
      "LC Training Loss (Full): 0.19159317016601562\n",
      "Epoch: 0, Iteration: 124\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.5937976241111755\n",
      "LC Training Loss (Full): 0.18970848619937897\n",
      "Epoch: 0, Iteration: 125\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.7345697283744812\n",
      "LC Training Loss (Full): 0.32196301221847534\n",
      "Full accuracy (w/o dLoRA+LC): 0.9328, LC accuracy: 0.934, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8194, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8185\n",
      "Epoch: 0, Iteration: 126\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.5049886703491211\n",
      "LC Training Loss (Full): 0.20860055088996887\n",
      "Epoch: 0, Iteration: 127\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.6644346117973328\n",
      "LC Training Loss (Full): 0.24174761772155762\n",
      "Epoch: 0, Iteration: 128\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.5944271683692932\n",
      "LC Training Loss (Full): 0.20679661631584167\n",
      "Epoch: 0, Iteration: 129\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_12\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_12\n",
      "LoRA+LC Training Loss (Decomposed): 0.567299485206604\n",
      "LC Training Loss (Full): 0.21558988094329834\n",
      "Epoch: 0, Iteration: 130\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.44390618801116943\n",
      "LC Training Loss (Full): 0.11710840463638306\n",
      "Full accuracy (w/o dLoRA+LC): 0.9332, LC accuracy: 0.9332, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8193, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8187\n",
      "Epoch: 0, Iteration: 131\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.5742043852806091\n",
      "LC Training Loss (Full): 0.17875438928604126\n",
      "Epoch: 0, Iteration: 132\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.5435009598731995\n",
      "LC Training Loss (Full): 0.35256749391555786\n",
      "Epoch: 0, Iteration: 133\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.8114957809448242\n",
      "LC Training Loss (Full): 0.39834603667259216\n",
      "Epoch: 0, Iteration: 134\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.7032442092895508\n",
      "LC Training Loss (Full): 0.4182173013687134\n",
      "Epoch: 0, Iteration: 135\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6932676434516907\n",
      "LC Training Loss (Full): 0.35755521059036255\n",
      "Full accuracy (w/o dLoRA+LC): 0.9323, LC accuracy: 0.9332, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8195, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8186\n",
      "Epoch: 0, Iteration: 136\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.6635763049125671\n",
      "LC Training Loss (Full): 0.2953658699989319\n",
      "Epoch: 0, Iteration: 137\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.538352906703949\n",
      "LC Training Loss (Full): 0.19270601868629456\n",
      "Epoch: 0, Iteration: 138\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.5796117782592773\n",
      "LC Training Loss (Full): 0.18213599920272827\n",
      "Epoch: 0, Iteration: 139\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_13\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_13\n",
      "LoRA+LC Training Loss (Decomposed): 0.5688469409942627\n",
      "LC Training Loss (Full): 0.31583264470100403\n",
      "Epoch: 0, Iteration: 140\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7136030793190002\n",
      "LC Training Loss (Full): 0.32936644554138184\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9332, LC accuracy: 0.9332, Decomposed-Full (w/dLoRA+LC) accuracy: 0.819, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8186\n",
      "Epoch: 0, Iteration: 141\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6525866985321045\n",
      "LC Training Loss (Full): 0.23896825313568115\n",
      "Epoch: 0, Iteration: 142\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.7094356417655945\n",
      "LC Training Loss (Full): 0.24409405887126923\n",
      "Epoch: 0, Iteration: 143\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5011139512062073\n",
      "LC Training Loss (Full): 0.14446446299552917\n",
      "Epoch: 0, Iteration: 144\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5110804438591003\n",
      "LC Training Loss (Full): 0.10860762000083923\n",
      "Epoch: 0, Iteration: 145\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5665228366851807\n",
      "LC Training Loss (Full): 0.22667750716209412\n",
      "Full accuracy (w/o dLoRA+LC): 0.9328, LC accuracy: 0.9333, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8194, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8183\n",
      "Epoch: 0, Iteration: 146\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.575188934803009\n",
      "LC Training Loss (Full): 0.15822182595729828\n",
      "Epoch: 0, Iteration: 147\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.5924780964851379\n",
      "LC Training Loss (Full): 0.2535852789878845\n",
      "Epoch: 0, Iteration: 148\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6113359928131104\n",
      "LC Training Loss (Full): 0.25812411308288574\n",
      "Epoch: 0, Iteration: 149\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_14\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_14\n",
      "LoRA+LC Training Loss (Decomposed): 0.6512960195541382\n",
      "LC Training Loss (Full): 0.1821364164352417\n",
      "Epoch: 0, Iteration: 150\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7319707870483398\n",
      "LC Training Loss (Full): 0.44270020723342896\n",
      "Full accuracy (w/o dLoRA+LC): 0.9343, LC accuracy: 0.9331, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8185, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8178\n",
      "Epoch: 0, Iteration: 151\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.6898534893989563\n",
      "LC Training Loss (Full): 0.2906780242919922\n",
      "Epoch: 0, Iteration: 152\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.829704999923706\n",
      "LC Training Loss (Full): 0.3032292425632477\n",
      "Epoch: 0, Iteration: 153\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.7045246958732605\n",
      "LC Training Loss (Full): 0.32809576392173767\n",
      "Epoch: 0, Iteration: 154\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.567659318447113\n",
      "LC Training Loss (Full): 0.13220979273319244\n",
      "Epoch: 0, Iteration: 155\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.49752435088157654\n",
      "LC Training Loss (Full): 0.17202982306480408\n",
      "Full accuracy (w/o dLoRA+LC): 0.9346, LC accuracy: 0.933, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8208, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8187\n",
      "Epoch: 0, Iteration: 156\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.5587431192398071\n",
      "LC Training Loss (Full): 0.1671513319015503\n",
      "Epoch: 0, Iteration: 157\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.4832064211368561\n",
      "LC Training Loss (Full): 0.15842892229557037\n",
      "Epoch: 0, Iteration: 158\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.5414321422576904\n",
      "LC Training Loss (Full): 0.20471277832984924\n",
      "Epoch: 0, Iteration: 159\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_15\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_15\n",
      "LoRA+LC Training Loss (Decomposed): 0.8592719435691833\n",
      "LC Training Loss (Full): 0.299494206905365\n",
      "Epoch: 0, Iteration: 160\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5813360214233398\n",
      "LC Training Loss (Full): 0.1794327199459076\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9341, LC accuracy: 0.9344, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8204, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8197\n",
      "Epoch: 0, Iteration: 161\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6877787709236145\n",
      "LC Training Loss (Full): 0.2646511495113373\n",
      "Epoch: 0, Iteration: 162\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.8461480736732483\n",
      "LC Training Loss (Full): 0.4324570894241333\n",
      "Epoch: 0, Iteration: 163\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5756757855415344\n",
      "LC Training Loss (Full): 0.25002577900886536\n",
      "Epoch: 0, Iteration: 164\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5449478626251221\n",
      "LC Training Loss (Full): 0.20795811712741852\n",
      "Epoch: 0, Iteration: 165\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5386134386062622\n",
      "LC Training Loss (Full): 0.13324998319149017\n",
      "Full accuracy (w/o dLoRA+LC): 0.9346, LC accuracy: 0.9346, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8232, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8212\n",
      "Epoch: 0, Iteration: 166\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5426537990570068\n",
      "LC Training Loss (Full): 0.2165210247039795\n",
      "Epoch: 0, Iteration: 167\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.7350746989250183\n",
      "LC Training Loss (Full): 0.3139064311981201\n",
      "Epoch: 0, Iteration: 168\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.5094668865203857\n",
      "LC Training Loss (Full): 0.17853261530399323\n",
      "Epoch: 0, Iteration: 169\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_16\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_16\n",
      "LoRA+LC Training Loss (Decomposed): 0.6319589614868164\n",
      "LC Training Loss (Full): 0.23840239644050598\n",
      "Epoch: 0, Iteration: 170\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6591663360595703\n",
      "LC Training Loss (Full): 0.14017024636268616\n",
      "Full accuracy (w/o dLoRA+LC): 0.9351, LC accuracy: 0.9355, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8204, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8205\n",
      "Epoch: 0, Iteration: 171\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.45260894298553467\n",
      "LC Training Loss (Full): 0.14593619108200073\n",
      "Epoch: 0, Iteration: 172\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.6712417006492615\n",
      "LC Training Loss (Full): 0.18570967018604279\n",
      "Epoch: 0, Iteration: 173\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.4498286545276642\n",
      "LC Training Loss (Full): 0.24638564884662628\n",
      "Epoch: 0, Iteration: 174\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.682976245880127\n",
      "LC Training Loss (Full): 0.2588613033294678\n",
      "Epoch: 0, Iteration: 175\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.4661751389503479\n",
      "LC Training Loss (Full): 0.11202917993068695\n",
      "Full accuracy (w/o dLoRA+LC): 0.9349, LC accuracy: 0.9355, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8199, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8196\n",
      "Epoch: 0, Iteration: 176\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.4971437156200409\n",
      "LC Training Loss (Full): 0.1592797040939331\n",
      "Epoch: 0, Iteration: 177\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.5164969563484192\n",
      "LC Training Loss (Full): 0.19063030183315277\n",
      "Epoch: 0, Iteration: 178\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.4855325520038605\n",
      "LC Training Loss (Full): 0.26039010286331177\n",
      "Epoch: 0, Iteration: 179\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_17\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_17\n",
      "LoRA+LC Training Loss (Decomposed): 0.8837328553199768\n",
      "LC Training Loss (Full): 0.4168279767036438\n",
      "Epoch: 0, Iteration: 180\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5686621069908142\n",
      "LC Training Loss (Full): 0.20554739236831665\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9343, LC accuracy: 0.9342, Decomposed-Full (w/dLoRA+LC) accuracy: 0.822, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8195\n",
      "Epoch: 0, Iteration: 181\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6825112700462341\n",
      "LC Training Loss (Full): 0.20269940793514252\n",
      "Epoch: 0, Iteration: 182\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.717673122882843\n",
      "LC Training Loss (Full): 0.33735892176628113\n",
      "Epoch: 0, Iteration: 183\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.44951215386390686\n",
      "LC Training Loss (Full): 0.1702573299407959\n",
      "Epoch: 0, Iteration: 184\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6731367707252502\n",
      "LC Training Loss (Full): 0.18740825355052948\n",
      "Epoch: 0, Iteration: 185\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.564531147480011\n",
      "LC Training Loss (Full): 0.20701515674591064\n",
      "Full accuracy (w/o dLoRA+LC): 0.9343, LC accuracy: 0.9343, Decomposed-Full (w/dLoRA+LC) accuracy: 0.822, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8201\n",
      "Epoch: 0, Iteration: 186\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6612355709075928\n",
      "LC Training Loss (Full): 0.2512187063694\n",
      "Epoch: 0, Iteration: 187\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.6634879112243652\n",
      "LC Training Loss (Full): 0.3966546654701233\n",
      "Epoch: 0, Iteration: 188\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.5033766627311707\n",
      "LC Training Loss (Full): 0.13495223224163055\n",
      "Epoch: 0, Iteration: 189\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_18\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_18\n",
      "LoRA+LC Training Loss (Decomposed): 0.4775891602039337\n",
      "LC Training Loss (Full): 0.12281368672847748\n",
      "Epoch: 0, Iteration: 190\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5342786312103271\n",
      "LC Training Loss (Full): 0.11753831058740616\n",
      "Full accuracy (w/o dLoRA+LC): 0.9352, LC accuracy: 0.9352, Decomposed-Full (w/dLoRA+LC) accuracy: 0.821, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8209\n",
      "Epoch: 0, Iteration: 191\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.5073711276054382\n",
      "LC Training Loss (Full): 0.199834406375885\n",
      "Epoch: 0, Iteration: 192\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.5921273231506348\n",
      "LC Training Loss (Full): 0.28964343667030334\n",
      "Epoch: 0, Iteration: 193\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.660412609577179\n",
      "LC Training Loss (Full): 0.2657721936702728\n",
      "Epoch: 0, Iteration: 194\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.8094789385795593\n",
      "LC Training Loss (Full): 0.255834698677063\n",
      "Epoch: 0, Iteration: 195\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.5660406947135925\n",
      "LC Training Loss (Full): 0.18913401663303375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9354, LC accuracy: 0.9354, Decomposed-Full (w/dLoRA+LC) accuracy: 0.821, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8203\n",
      "Epoch: 0, Iteration: 196\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.7779299020767212\n",
      "LC Training Loss (Full): 0.3481570780277252\n",
      "Epoch: 0, Iteration: 197\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.6427125334739685\n",
      "LC Training Loss (Full): 0.2094823122024536\n",
      "Epoch: 0, Iteration: 198\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.49284324049949646\n",
      "LC Training Loss (Full): 0.19404061138629913\n",
      "Epoch: 0, Iteration: 199\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_19\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_19\n",
      "LoRA+LC Training Loss (Decomposed): 0.5710681080818176\n",
      "LC Training Loss (Full): 0.20714403688907623\n",
      "Epoch: 0, Iteration: 200\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.8275395035743713\n",
      "LC Training Loss (Full): 0.3753442168235779\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.90625\n",
      "Full accuracy (w/o dLoRA+LC): 0.9352, LC accuracy: 0.9355, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8217, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8205\n",
      "Epoch: 0, Iteration: 201\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6527107954025269\n",
      "LC Training Loss (Full): 0.19020971655845642\n",
      "Epoch: 0, Iteration: 202\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.564602792263031\n",
      "LC Training Loss (Full): 0.2595483362674713\n",
      "Epoch: 0, Iteration: 203\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.5862953662872314\n",
      "LC Training Loss (Full): 0.1775393933057785\n",
      "Epoch: 0, Iteration: 204\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.477804034948349\n",
      "LC Training Loss (Full): 0.17424632608890533\n",
      "Epoch: 0, Iteration: 205\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.455517053604126\n",
      "LC Training Loss (Full): 0.09303457289934158\n",
      "Full accuracy (w/o dLoRA+LC): 0.9352, LC accuracy: 0.9355, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8218, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8213\n",
      "Epoch: 0, Iteration: 206\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6751511693000793\n",
      "LC Training Loss (Full): 0.24536176025867462\n",
      "Epoch: 0, Iteration: 207\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.686023473739624\n",
      "LC Training Loss (Full): 0.26258382201194763\n",
      "Epoch: 0, Iteration: 208\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.6480597853660583\n",
      "LC Training Loss (Full): 0.30677926540374756\n",
      "Epoch: 0, Iteration: 209\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_20\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_20\n",
      "LoRA+LC Training Loss (Decomposed): 0.48019057512283325\n",
      "LC Training Loss (Full): 0.1847122460603714\n",
      "Epoch: 0, Iteration: 210\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5493532419204712\n",
      "LC Training Loss (Full): 0.23577526211738586\n",
      "Full accuracy (w/o dLoRA+LC): 0.935, LC accuracy: 0.9352, Decomposed-Full (w/dLoRA+LC) accuracy: 0.822, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8209\n",
      "Epoch: 0, Iteration: 211\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6096175909042358\n",
      "LC Training Loss (Full): 0.23921722173690796\n",
      "Epoch: 0, Iteration: 212\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.569255530834198\n",
      "LC Training Loss (Full): 0.3038814067840576\n",
      "Epoch: 0, Iteration: 213\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6613633036613464\n",
      "LC Training Loss (Full): 0.1718466728925705\n",
      "Epoch: 0, Iteration: 214\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6452779769897461\n",
      "LC Training Loss (Full): 0.23109139502048492\n",
      "Epoch: 0, Iteration: 215\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.5141423940658569\n",
      "LC Training Loss (Full): 0.19591975212097168\n",
      "Full accuracy (w/o dLoRA+LC): 0.9354, LC accuracy: 0.9351, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8217, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.822\n",
      "Epoch: 0, Iteration: 216\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6776737570762634\n",
      "LC Training Loss (Full): 0.2473834902048111\n",
      "Epoch: 0, Iteration: 217\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.7902839779853821\n",
      "LC Training Loss (Full): 0.23725223541259766\n",
      "Epoch: 0, Iteration: 218\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6440527439117432\n",
      "LC Training Loss (Full): 0.2191198617219925\n",
      "Epoch: 0, Iteration: 219\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_21\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_21\n",
      "LoRA+LC Training Loss (Decomposed): 0.6440921425819397\n",
      "LC Training Loss (Full): 0.22307009994983673\n",
      "Epoch: 0, Iteration: 220\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5109851360321045\n",
      "LC Training Loss (Full): 0.2491772621870041\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9347, LC accuracy: 0.9355, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8219, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8211\n",
      "Epoch: 0, Iteration: 221\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.40970689058303833\n",
      "LC Training Loss (Full): 0.10234536230564117\n",
      "Epoch: 0, Iteration: 222\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.679603099822998\n",
      "LC Training Loss (Full): 0.2500022351741791\n",
      "Epoch: 0, Iteration: 223\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6605678796768188\n",
      "LC Training Loss (Full): 0.19279146194458008\n",
      "Epoch: 0, Iteration: 224\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.48663076758384705\n",
      "LC Training Loss (Full): 0.15462221205234528\n",
      "Epoch: 0, Iteration: 225\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.5229573845863342\n",
      "LC Training Loss (Full): 0.15300725400447845\n",
      "Full accuracy (w/o dLoRA+LC): 0.9347, LC accuracy: 0.9356, Decomposed-Full (w/dLoRA+LC) accuracy: 0.823, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8212\n",
      "Epoch: 0, Iteration: 226\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.3956189751625061\n",
      "LC Training Loss (Full): 0.10894479602575302\n",
      "Epoch: 0, Iteration: 227\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.6257146596908569\n",
      "LC Training Loss (Full): 0.20393849909305573\n",
      "Epoch: 0, Iteration: 228\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.5044073462486267\n",
      "LC Training Loss (Full): 0.12147292494773865\n",
      "Epoch: 0, Iteration: 229\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_22\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_22\n",
      "LoRA+LC Training Loss (Decomposed): 0.7020966410636902\n",
      "LC Training Loss (Full): 0.2555921971797943\n",
      "Epoch: 0, Iteration: 230\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_23\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7707505822181702\n",
      "LC Training Loss (Full): 0.2361571192741394\n",
      "Full accuracy (w/o dLoRA+LC): 0.9347, LC accuracy: 0.9338, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8214, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8207\n",
      "Epoch: 0, Iteration: 231\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.5486747026443481\n",
      "LC Training Loss (Full): 0.152308389544487\n",
      "Epoch: 0, Iteration: 232\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.45219701528549194\n",
      "LC Training Loss (Full): 0.1995130181312561\n",
      "Epoch: 0, Iteration: 233\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.4453965723514557\n",
      "LC Training Loss (Full): 0.16302378475666046\n",
      "Epoch: 0, Iteration: 234\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_23\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_23\n",
      "LoRA+LC Training Loss (Decomposed): 0.48993366956710815\n",
      "LC Training Loss (Full): 0.1327293962240219\n",
      "Epoch: 1, Iteration: 0\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.548072338104248\n",
      "LC Training Loss (Full): 0.1208982914686203\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 1.0\n",
      "Epoch: 1, Iteration: 1\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7711454629898071\n",
      "LC Training Loss (Full): 0.30673086643218994\n",
      "Epoch: 1, Iteration: 2\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7257269024848938\n",
      "LC Training Loss (Full): 0.3221481442451477\n",
      "Epoch: 1, Iteration: 3\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.599651575088501\n",
      "LC Training Loss (Full): 0.17766936123371124\n",
      "Epoch: 1, Iteration: 4\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7266764640808105\n",
      "LC Training Loss (Full): 0.28904789686203003\n",
      "Epoch: 1, Iteration: 5\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6123457551002502\n",
      "LC Training Loss (Full): 0.27557602524757385\n",
      "Full accuracy (w/o dLoRA+LC): 0.9357, LC accuracy: 0.9361, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8228, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8218\n",
      "Epoch: 1, Iteration: 6\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6300378441810608\n",
      "LC Training Loss (Full): 0.33817464113235474\n",
      "Epoch: 1, Iteration: 7\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.7735391855239868\n",
      "LC Training Loss (Full): 0.3232438564300537\n",
      "Epoch: 1, Iteration: 8\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.5525887608528137\n",
      "LC Training Loss (Full): 0.14284776151180267\n",
      "Epoch: 1, Iteration: 9\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_24\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_24\n",
      "LoRA+LC Training Loss (Decomposed): 0.6316524147987366\n",
      "LC Training Loss (Full): 0.22061091661453247\n",
      "Epoch: 1, Iteration: 10\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5516709089279175\n",
      "LC Training Loss (Full): 0.14990676939487457\n",
      "Full accuracy (w/o dLoRA+LC): 0.9365, LC accuracy: 0.9356, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8229, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8218\n",
      "Epoch: 1, Iteration: 11\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.40768513083457947\n",
      "LC Training Loss (Full): 0.09551925957202911\n",
      "Epoch: 1, Iteration: 12\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.6467149257659912\n",
      "LC Training Loss (Full): 0.22712688148021698\n",
      "Epoch: 1, Iteration: 13\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.5775235891342163\n",
      "LC Training Loss (Full): 0.17552611231803894\n",
      "Epoch: 1, Iteration: 14\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.5479456782341003\n",
      "LC Training Loss (Full): 0.15303806960582733\n",
      "Epoch: 1, Iteration: 15\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.603708028793335\n",
      "LC Training Loss (Full): 0.28456419706344604\n",
      "Full accuracy (w/o dLoRA+LC): 0.9366, LC accuracy: 0.9355, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8217, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8211\n",
      "Epoch: 1, Iteration: 16\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.6597861051559448\n",
      "LC Training Loss (Full): 0.2733854055404663\n",
      "Epoch: 1, Iteration: 17\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.5793874859809875\n",
      "LC Training Loss (Full): 0.1794191300868988\n",
      "Epoch: 1, Iteration: 18\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.4829295873641968\n",
      "LC Training Loss (Full): 0.12698078155517578\n",
      "Epoch: 1, Iteration: 19\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_25\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_25\n",
      "LoRA+LC Training Loss (Decomposed): 0.7274244427680969\n",
      "LC Training Loss (Full): 0.3431873917579651\n",
      "Epoch: 1, Iteration: 20\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5056594014167786\n",
      "LC Training Loss (Full): 0.16119547188282013\n",
      "Training Accuracy | Decomposed: 0.875, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9364, LC accuracy: 0.9361, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8204, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8206\n",
      "Epoch: 1, Iteration: 21\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.7229353785514832\n",
      "LC Training Loss (Full): 0.41160356998443604\n",
      "Epoch: 1, Iteration: 22\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.7294532060623169\n",
      "LC Training Loss (Full): 0.2806796729564667\n",
      "Epoch: 1, Iteration: 23\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.5604476928710938\n",
      "LC Training Loss (Full): 0.16218839585781097\n",
      "Epoch: 1, Iteration: 24\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.7202205657958984\n",
      "LC Training Loss (Full): 0.2988693118095398\n",
      "Epoch: 1, Iteration: 25\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.4976803660392761\n",
      "LC Training Loss (Full): 0.21908456087112427\n",
      "Full accuracy (w/o dLoRA+LC): 0.9366, LC accuracy: 0.9362, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8224, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8213\n",
      "Epoch: 1, Iteration: 26\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.775568962097168\n",
      "LC Training Loss (Full): 0.4631868004798889\n",
      "Epoch: 1, Iteration: 27\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.4013734459877014\n",
      "LC Training Loss (Full): 0.12669983506202698\n",
      "Epoch: 1, Iteration: 28\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.40977030992507935\n",
      "LC Training Loss (Full): 0.1188802421092987\n",
      "Epoch: 1, Iteration: 29\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_26\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_26\n",
      "LoRA+LC Training Loss (Decomposed): 0.6698864698410034\n",
      "LC Training Loss (Full): 0.3180810809135437\n",
      "Epoch: 1, Iteration: 30\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5763176679611206\n",
      "LC Training Loss (Full): 0.21850818395614624\n",
      "Full accuracy (w/o dLoRA+LC): 0.9365, LC accuracy: 0.9367, Decomposed-Full (w/dLoRA+LC) accuracy: 0.821, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8215\n",
      "Epoch: 1, Iteration: 31\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.5661595463752747\n",
      "LC Training Loss (Full): 0.21313562989234924\n",
      "Epoch: 1, Iteration: 32\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6977835893630981\n",
      "LC Training Loss (Full): 0.18013224005699158\n",
      "Epoch: 1, Iteration: 33\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6550238132476807\n",
      "LC Training Loss (Full): 0.27160272002220154\n",
      "Epoch: 1, Iteration: 34\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6208657622337341\n",
      "LC Training Loss (Full): 0.2463349997997284\n",
      "Epoch: 1, Iteration: 35\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.6577419638633728\n",
      "LC Training Loss (Full): 0.3437931537628174\n",
      "Full accuracy (w/o dLoRA+LC): 0.9363, LC accuracy: 0.9367, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8227, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8215\n",
      "Epoch: 1, Iteration: 36\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.586909294128418\n",
      "LC Training Loss (Full): 0.19433511793613434\n",
      "Epoch: 1, Iteration: 37\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.5663030743598938\n",
      "LC Training Loss (Full): 0.17744410037994385\n",
      "Epoch: 1, Iteration: 38\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.5500839948654175\n",
      "LC Training Loss (Full): 0.21023081243038177\n",
      "Epoch: 1, Iteration: 39\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_27\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_27\n",
      "LoRA+LC Training Loss (Decomposed): 0.4943898022174835\n",
      "LC Training Loss (Full): 0.1520477682352066\n",
      "Epoch: 1, Iteration: 40\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6389787197113037\n",
      "LC Training Loss (Full): 0.2321130484342575\n",
      "Training Accuracy | Decomposed: 0.78125, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.937, LC accuracy: 0.9371, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8219, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8219\n",
      "Epoch: 1, Iteration: 41\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.7120408415794373\n",
      "LC Training Loss (Full): 0.4239935278892517\n",
      "Epoch: 1, Iteration: 42\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5651583075523376\n",
      "LC Training Loss (Full): 0.14167943596839905\n",
      "Epoch: 1, Iteration: 43\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5307773351669312\n",
      "LC Training Loss (Full): 0.27099505066871643\n",
      "Epoch: 1, Iteration: 44\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5245936512947083\n",
      "LC Training Loss (Full): 0.13994218409061432\n",
      "Epoch: 1, Iteration: 45\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5455920696258545\n",
      "LC Training Loss (Full): 0.1909954696893692\n",
      "Full accuracy (w/o dLoRA+LC): 0.9363, LC accuracy: 0.9372, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8216, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8206\n",
      "Epoch: 1, Iteration: 46\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6109485030174255\n",
      "LC Training Loss (Full): 0.1684480607509613\n",
      "Epoch: 1, Iteration: 47\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.45839017629623413\n",
      "LC Training Loss (Full): 0.19721530377864838\n",
      "Epoch: 1, Iteration: 48\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.6199970245361328\n",
      "LC Training Loss (Full): 0.22737464308738708\n",
      "Epoch: 1, Iteration: 49\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_28\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_28\n",
      "LoRA+LC Training Loss (Decomposed): 0.5543537139892578\n",
      "LC Training Loss (Full): 0.11786538362503052\n",
      "Epoch: 1, Iteration: 50\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6947941780090332\n",
      "LC Training Loss (Full): 0.16127115488052368\n",
      "Full accuracy (w/o dLoRA+LC): 0.9361, LC accuracy: 0.9363, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8216, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8209\n",
      "Epoch: 1, Iteration: 51\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6112087368965149\n",
      "LC Training Loss (Full): 0.14886605739593506\n",
      "Epoch: 1, Iteration: 52\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.5264955163002014\n",
      "LC Training Loss (Full): 0.20682640373706818\n",
      "Epoch: 1, Iteration: 53\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6602099537849426\n",
      "LC Training Loss (Full): 0.2114149034023285\n",
      "Epoch: 1, Iteration: 54\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6266129612922668\n",
      "LC Training Loss (Full): 0.17838552594184875\n",
      "Epoch: 1, Iteration: 55\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6034575700759888\n",
      "LC Training Loss (Full): 0.17391210794448853\n",
      "Full accuracy (w/o dLoRA+LC): 0.9365, LC accuracy: 0.9362, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8222, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8214\n",
      "Epoch: 1, Iteration: 56\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.5129266977310181\n",
      "LC Training Loss (Full): 0.20224781334400177\n",
      "Epoch: 1, Iteration: 57\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.8014368414878845\n",
      "LC Training Loss (Full): 0.296315997838974\n",
      "Epoch: 1, Iteration: 58\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6055998206138611\n",
      "LC Training Loss (Full): 0.21643869578838348\n",
      "Epoch: 1, Iteration: 59\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_29\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_29\n",
      "LoRA+LC Training Loss (Decomposed): 0.6762204170227051\n",
      "LC Training Loss (Full): 0.3104326128959656\n",
      "Epoch: 1, Iteration: 60\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5585870742797852\n",
      "LC Training Loss (Full): 0.19257119297981262\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9384, LC accuracy: 0.9369, Decomposed-Full (w/dLoRA+LC) accuracy: 0.822, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8214\n",
      "Epoch: 1, Iteration: 61\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5831952691078186\n",
      "LC Training Loss (Full): 0.268564909696579\n",
      "Epoch: 1, Iteration: 62\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5939698219299316\n",
      "LC Training Loss (Full): 0.16832444071769714\n",
      "Epoch: 1, Iteration: 63\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.49487051367759705\n",
      "LC Training Loss (Full): 0.18146690726280212\n",
      "Epoch: 1, Iteration: 64\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5964491367340088\n",
      "LC Training Loss (Full): 0.3142065107822418\n",
      "Epoch: 1, Iteration: 65\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7073604464530945\n",
      "LC Training Loss (Full): 0.3909432291984558\n",
      "Full accuracy (w/o dLoRA+LC): 0.9362, LC accuracy: 0.937, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8235, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8218\n",
      "Epoch: 1, Iteration: 66\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.7092687487602234\n",
      "LC Training Loss (Full): 0.4229164123535156\n",
      "Epoch: 1, Iteration: 67\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5976303815841675\n",
      "LC Training Loss (Full): 0.24711285531520844\n",
      "Epoch: 1, Iteration: 68\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5998828411102295\n",
      "LC Training Loss (Full): 0.19607838988304138\n",
      "Epoch: 1, Iteration: 69\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_30\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_30\n",
      "LoRA+LC Training Loss (Decomposed): 0.5018157958984375\n",
      "LC Training Loss (Full): 0.15706317126750946\n",
      "Epoch: 1, Iteration: 70\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5978735685348511\n",
      "LC Training Loss (Full): 0.13663169741630554\n",
      "Full accuracy (w/o dLoRA+LC): 0.9361, LC accuracy: 0.9357, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8237, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8221\n",
      "Epoch: 1, Iteration: 71\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.48095548152923584\n",
      "LC Training Loss (Full): 0.1446298062801361\n",
      "Epoch: 1, Iteration: 72\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.4610145390033722\n",
      "LC Training Loss (Full): 0.15130141377449036\n",
      "Epoch: 1, Iteration: 73\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.5245623588562012\n",
      "LC Training Loss (Full): 0.12669174373149872\n",
      "Epoch: 1, Iteration: 74\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.6254180073738098\n",
      "LC Training Loss (Full): 0.16368868947029114\n",
      "Epoch: 1, Iteration: 75\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.551049530506134\n",
      "LC Training Loss (Full): 0.1356942504644394\n",
      "Full accuracy (w/o dLoRA+LC): 0.9361, LC accuracy: 0.9358, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8238, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.822\n",
      "Epoch: 1, Iteration: 76\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.6876463294029236\n",
      "LC Training Loss (Full): 0.22907988727092743\n",
      "Epoch: 1, Iteration: 77\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.5974419713020325\n",
      "LC Training Loss (Full): 0.1828702837228775\n",
      "Epoch: 1, Iteration: 78\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.5559431910514832\n",
      "LC Training Loss (Full): 0.26395338773727417\n",
      "Epoch: 1, Iteration: 79\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_31\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_31\n",
      "LoRA+LC Training Loss (Decomposed): 0.6683198809623718\n",
      "LC Training Loss (Full): 0.2501499354839325\n",
      "Epoch: 1, Iteration: 80\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.388201504945755\n",
      "LC Training Loss (Full): 0.07736466079950333\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.984375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9355, LC accuracy: 0.9364, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8225, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8227\n",
      "Epoch: 1, Iteration: 81\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5975778102874756\n",
      "LC Training Loss (Full): 0.2420782446861267\n",
      "Epoch: 1, Iteration: 82\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5419267416000366\n",
      "LC Training Loss (Full): 0.14636078476905823\n",
      "Epoch: 1, Iteration: 83\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.6038464903831482\n",
      "LC Training Loss (Full): 0.22707048058509827\n",
      "Epoch: 1, Iteration: 84\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5184569358825684\n",
      "LC Training Loss (Full): 0.24855610728263855\n",
      "Epoch: 1, Iteration: 85\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5449901223182678\n",
      "LC Training Loss (Full): 0.1267654299736023\n",
      "Full accuracy (w/o dLoRA+LC): 0.9365, LC accuracy: 0.9362, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8244, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8224\n",
      "Epoch: 1, Iteration: 86\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.557877242565155\n",
      "LC Training Loss (Full): 0.15315738320350647\n",
      "Epoch: 1, Iteration: 87\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.5642940998077393\n",
      "LC Training Loss (Full): 0.217736154794693\n",
      "Epoch: 1, Iteration: 88\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.9336332082748413\n",
      "LC Training Loss (Full): 0.4719695746898651\n",
      "Epoch: 1, Iteration: 89\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_32\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_32\n",
      "LoRA+LC Training Loss (Decomposed): 0.8092304468154907\n",
      "LC Training Loss (Full): 0.36915433406829834\n",
      "Epoch: 1, Iteration: 90\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6616493463516235\n",
      "LC Training Loss (Full): 0.20107419788837433\n",
      "Full accuracy (w/o dLoRA+LC): 0.9366, LC accuracy: 0.9361, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8225, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8221\n",
      "Epoch: 1, Iteration: 91\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.541861891746521\n",
      "LC Training Loss (Full): 0.22259923815727234\n",
      "Epoch: 1, Iteration: 92\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.7128952145576477\n",
      "LC Training Loss (Full): 0.22486454248428345\n",
      "Epoch: 1, Iteration: 93\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.5192290544509888\n",
      "LC Training Loss (Full): 0.09166121482849121\n",
      "Epoch: 1, Iteration: 94\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.717553973197937\n",
      "LC Training Loss (Full): 0.2378709316253662\n",
      "Epoch: 1, Iteration: 95\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.495419442653656\n",
      "LC Training Loss (Full): 0.14849355816841125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9358, LC accuracy: 0.9362, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8238, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8221\n",
      "Epoch: 1, Iteration: 96\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.4568972587585449\n",
      "LC Training Loss (Full): 0.1364751011133194\n",
      "Epoch: 1, Iteration: 97\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6115493774414062\n",
      "LC Training Loss (Full): 0.21443864703178406\n",
      "Epoch: 1, Iteration: 98\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.5696333050727844\n",
      "LC Training Loss (Full): 0.17657123506069183\n",
      "Epoch: 1, Iteration: 99\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_33\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_33\n",
      "LoRA+LC Training Loss (Decomposed): 0.6512349247932434\n",
      "LC Training Loss (Full): 0.25330644845962524\n",
      "Epoch: 1, Iteration: 100\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5784504413604736\n",
      "LC Training Loss (Full): 0.20121945440769196\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.9375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9359, LC accuracy: 0.9359, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8213, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8219\n",
      "Epoch: 1, Iteration: 101\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.5584558248519897\n",
      "LC Training Loss (Full): 0.15317432582378387\n",
      "Epoch: 1, Iteration: 102\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.37015265226364136\n",
      "LC Training Loss (Full): 0.13556084036827087\n",
      "Epoch: 1, Iteration: 103\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7473852634429932\n",
      "LC Training Loss (Full): 0.2807873785495758\n",
      "Epoch: 1, Iteration: 104\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.5391334295272827\n",
      "LC Training Loss (Full): 0.1921483278274536\n",
      "Epoch: 1, Iteration: 105\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.7913985848426819\n",
      "LC Training Loss (Full): 0.4562850594520569\n",
      "Full accuracy (w/o dLoRA+LC): 0.9373, LC accuracy: 0.9359, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8232, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8221\n",
      "Epoch: 1, Iteration: 106\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.6165925860404968\n",
      "LC Training Loss (Full): 0.2441510260105133\n",
      "Epoch: 1, Iteration: 107\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.5441997051239014\n",
      "LC Training Loss (Full): 0.15099669992923737\n",
      "Epoch: 1, Iteration: 108\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.5098753571510315\n",
      "LC Training Loss (Full): 0.24413882195949554\n",
      "Epoch: 1, Iteration: 109\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_34\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_34\n",
      "LoRA+LC Training Loss (Decomposed): 0.48662787675857544\n",
      "LC Training Loss (Full): 0.10278131812810898\n",
      "Epoch: 1, Iteration: 110\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6256376504898071\n",
      "LC Training Loss (Full): 0.25256067514419556\n",
      "Full accuracy (w/o dLoRA+LC): 0.9356, LC accuracy: 0.936, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8228, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8222\n",
      "Epoch: 1, Iteration: 111\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.499228835105896\n",
      "LC Training Loss (Full): 0.09428523480892181\n",
      "Epoch: 1, Iteration: 112\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.5080671906471252\n",
      "LC Training Loss (Full): 0.1191212385892868\n",
      "Epoch: 1, Iteration: 113\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.7087925672531128\n",
      "LC Training Loss (Full): 0.31762948632240295\n",
      "Epoch: 1, Iteration: 114\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.6802181601524353\n",
      "LC Training Loss (Full): 0.32209116220474243\n",
      "Epoch: 1, Iteration: 115\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.47704681754112244\n",
      "LC Training Loss (Full): 0.09769419580698013\n",
      "Full accuracy (w/o dLoRA+LC): 0.9369, LC accuracy: 0.9361, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8229, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8219\n",
      "Epoch: 1, Iteration: 116\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.44663310050964355\n",
      "LC Training Loss (Full): 0.14127106964588165\n",
      "Epoch: 1, Iteration: 117\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.6516674160957336\n",
      "LC Training Loss (Full): 0.27885547280311584\n",
      "Epoch: 1, Iteration: 118\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.5218424201011658\n",
      "LC Training Loss (Full): 0.22893482446670532\n",
      "Epoch: 1, Iteration: 119\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_35\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_35\n",
      "LoRA+LC Training Loss (Decomposed): 0.505250096321106\n",
      "LC Training Loss (Full): 0.0935044214129448\n",
      "Epoch: 1, Iteration: 120\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7408497929573059\n",
      "LC Training Loss (Full): 0.34670981764793396\n",
      "Training Accuracy | Decomposed: 0.84375, Full : 0.875\n",
      "Full accuracy (w/o dLoRA+LC): 0.937, LC accuracy: 0.9375, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8227, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.822\n",
      "Epoch: 1, Iteration: 121\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5422315001487732\n",
      "LC Training Loss (Full): 0.18367964029312134\n",
      "Epoch: 1, Iteration: 122\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7242735028266907\n",
      "LC Training Loss (Full): 0.356427401304245\n",
      "Epoch: 1, Iteration: 123\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5223758816719055\n",
      "LC Training Loss (Full): 0.13886070251464844\n",
      "Epoch: 1, Iteration: 124\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5742523670196533\n",
      "LC Training Loss (Full): 0.17967632412910461\n",
      "Epoch: 1, Iteration: 125\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5692076683044434\n",
      "LC Training Loss (Full): 0.14912976324558258\n",
      "Full accuracy (w/o dLoRA+LC): 0.9362, LC accuracy: 0.9374, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8244, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8218\n",
      "Epoch: 1, Iteration: 126\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.4634067714214325\n",
      "LC Training Loss (Full): 0.14683420956134796\n",
      "Epoch: 1, Iteration: 127\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.5451231598854065\n",
      "LC Training Loss (Full): 0.15976375341415405\n",
      "Epoch: 1, Iteration: 128\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.7310925126075745\n",
      "LC Training Loss (Full): 0.2993566393852234\n",
      "Epoch: 1, Iteration: 129\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_36\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_36\n",
      "LoRA+LC Training Loss (Decomposed): 0.6950768828392029\n",
      "LC Training Loss (Full): 0.287539541721344\n",
      "Epoch: 1, Iteration: 130\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.4177619218826294\n",
      "LC Training Loss (Full): 0.15738800168037415\n",
      "Full accuracy (w/o dLoRA+LC): 0.9363, LC accuracy: 0.9364, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8221, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.822\n",
      "Epoch: 1, Iteration: 131\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.48187726736068726\n",
      "LC Training Loss (Full): 0.20296728610992432\n",
      "Epoch: 1, Iteration: 132\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.48728662729263306\n",
      "LC Training Loss (Full): 0.15742681920528412\n",
      "Epoch: 1, Iteration: 133\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6723157167434692\n",
      "LC Training Loss (Full): 0.2831806242465973\n",
      "Epoch: 1, Iteration: 134\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6158409714698792\n",
      "LC Training Loss (Full): 0.23197825253009796\n",
      "Epoch: 1, Iteration: 135\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.5954883694648743\n",
      "LC Training Loss (Full): 0.27713412046432495\n",
      "Full accuracy (w/o dLoRA+LC): 0.9373, LC accuracy: 0.9365, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8231, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.822\n",
      "Epoch: 1, Iteration: 136\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.5985390543937683\n",
      "LC Training Loss (Full): 0.24669767916202545\n",
      "Epoch: 1, Iteration: 137\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.5775805711746216\n",
      "LC Training Loss (Full): 0.21152983605861664\n",
      "Epoch: 1, Iteration: 138\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.6417028903961182\n",
      "LC Training Loss (Full): 0.2727510929107666\n",
      "Epoch: 1, Iteration: 139\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_37\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_37\n",
      "LoRA+LC Training Loss (Decomposed): 0.713664710521698\n",
      "LC Training Loss (Full): 0.42655712366104126\n",
      "Epoch: 1, Iteration: 140\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.6812987327575684\n",
      "LC Training Loss (Full): 0.2082226276397705\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.984375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9382, LC accuracy: 0.9385, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8229, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.823\n",
      "Epoch: 1, Iteration: 141\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.41705235838890076\n",
      "LC Training Loss (Full): 0.12909658253192902\n",
      "Epoch: 1, Iteration: 142\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5610866546630859\n",
      "LC Training Loss (Full): 0.18503151834011078\n",
      "Epoch: 1, Iteration: 143\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5152307152748108\n",
      "LC Training Loss (Full): 0.12275436520576477\n",
      "Epoch: 1, Iteration: 144\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5602416396141052\n",
      "LC Training Loss (Full): 0.1514388918876648\n",
      "Epoch: 1, Iteration: 145\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5741836428642273\n",
      "LC Training Loss (Full): 0.1690545529127121\n",
      "Full accuracy (w/o dLoRA+LC): 0.9378, LC accuracy: 0.9384, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8247, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8231\n",
      "Epoch: 1, Iteration: 146\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5285173654556274\n",
      "LC Training Loss (Full): 0.0886305570602417\n",
      "Epoch: 1, Iteration: 147\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.48655635118484497\n",
      "LC Training Loss (Full): 0.12789729237556458\n",
      "Epoch: 1, Iteration: 148\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.5329667925834656\n",
      "LC Training Loss (Full): 0.2004186362028122\n",
      "Epoch: 1, Iteration: 149\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_38\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_38\n",
      "LoRA+LC Training Loss (Decomposed): 0.525800347328186\n",
      "LC Training Loss (Full): 0.17416632175445557\n",
      "Epoch: 1, Iteration: 150\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5240857005119324\n",
      "LC Training Loss (Full): 0.14321085810661316\n",
      "Full accuracy (w/o dLoRA+LC): 0.9371, LC accuracy: 0.9362, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8231, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8241\n",
      "Epoch: 1, Iteration: 151\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.39995643496513367\n",
      "LC Training Loss (Full): 0.09846044331789017\n",
      "Epoch: 1, Iteration: 152\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.5089819431304932\n",
      "LC Training Loss (Full): 0.11462707072496414\n",
      "Epoch: 1, Iteration: 153\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.6953524351119995\n",
      "LC Training Loss (Full): 0.21581415832042694\n",
      "Epoch: 1, Iteration: 154\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.4483887553215027\n",
      "LC Training Loss (Full): 0.13414639234542847\n",
      "Epoch: 1, Iteration: 155\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.6631505489349365\n",
      "LC Training Loss (Full): 0.23651351034641266\n",
      "Full accuracy (w/o dLoRA+LC): 0.9368, LC accuracy: 0.9362, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8254, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8242\n",
      "Epoch: 1, Iteration: 156\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.5670428276062012\n",
      "LC Training Loss (Full): 0.157562255859375\n",
      "Epoch: 1, Iteration: 157\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.605901837348938\n",
      "LC Training Loss (Full): 0.3452921509742737\n",
      "Epoch: 1, Iteration: 158\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.39832669496536255\n",
      "LC Training Loss (Full): 0.09818752110004425\n",
      "Epoch: 1, Iteration: 159\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_39\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_39\n",
      "LoRA+LC Training Loss (Decomposed): 0.4214388132095337\n",
      "LC Training Loss (Full): 0.1077006608247757\n",
      "Epoch: 1, Iteration: 160\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5070418119430542\n",
      "LC Training Loss (Full): 0.14048050343990326\n",
      "Training Accuracy | Decomposed: 0.921875, Full : 0.96875\n",
      "Full accuracy (w/o dLoRA+LC): 0.9372, LC accuracy: 0.9376, Decomposed-Full (w/dLoRA+LC) accuracy: 0.825, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8249\n",
      "Epoch: 1, Iteration: 161\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.548456609249115\n",
      "LC Training Loss (Full): 0.17959147691726685\n",
      "Epoch: 1, Iteration: 162\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.8581696152687073\n",
      "LC Training Loss (Full): 0.36681127548217773\n",
      "Epoch: 1, Iteration: 163\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.621344804763794\n",
      "LC Training Loss (Full): 0.25243163108825684\n",
      "Epoch: 1, Iteration: 164\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5149385333061218\n",
      "LC Training Loss (Full): 0.1198120266199112\n",
      "Epoch: 1, Iteration: 165\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.6913223266601562\n",
      "LC Training Loss (Full): 0.25951045751571655\n",
      "Full accuracy (w/o dLoRA+LC): 0.9389, LC accuracy: 0.9376, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8267, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8253\n",
      "Epoch: 1, Iteration: 166\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.7634773850440979\n",
      "LC Training Loss (Full): 0.31697890162467957\n",
      "Epoch: 1, Iteration: 167\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.43136826157569885\n",
      "LC Training Loss (Full): 0.11284080147743225\n",
      "Epoch: 1, Iteration: 168\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.4895760416984558\n",
      "LC Training Loss (Full): 0.21298134326934814\n",
      "Epoch: 1, Iteration: 169\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_40\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_40\n",
      "LoRA+LC Training Loss (Decomposed): 0.5926507711410522\n",
      "LC Training Loss (Full): 0.2241477519273758\n",
      "Epoch: 1, Iteration: 170\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5045683979988098\n",
      "LC Training Loss (Full): 0.13427665829658508\n",
      "Full accuracy (w/o dLoRA+LC): 0.938, LC accuracy: 0.9394, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8245, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8253\n",
      "Epoch: 1, Iteration: 171\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5553646087646484\n",
      "LC Training Loss (Full): 0.1261148750782013\n",
      "Epoch: 1, Iteration: 172\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5433804988861084\n",
      "LC Training Loss (Full): 0.16089345514774323\n",
      "Epoch: 1, Iteration: 173\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.6278709769248962\n",
      "LC Training Loss (Full): 0.24245376884937286\n",
      "Epoch: 1, Iteration: 174\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.6541000604629517\n",
      "LC Training Loss (Full): 0.2754605710506439\n",
      "Epoch: 1, Iteration: 175\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5018617510795593\n",
      "LC Training Loss (Full): 0.15830354392528534\n",
      "Full accuracy (w/o dLoRA+LC): 0.9392, LC accuracy: 0.9396, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8246, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8245\n",
      "Epoch: 1, Iteration: 176\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.6192052960395813\n",
      "LC Training Loss (Full): 0.2085639089345932\n",
      "Epoch: 1, Iteration: 177\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5426588654518127\n",
      "LC Training Loss (Full): 0.21765853464603424\n",
      "Epoch: 1, Iteration: 178\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.6227937936782837\n",
      "LC Training Loss (Full): 0.1633835732936859\n",
      "Epoch: 1, Iteration: 179\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_41\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_41\n",
      "LoRA+LC Training Loss (Decomposed): 0.5836021304130554\n",
      "LC Training Loss (Full): 0.3034273087978363\n",
      "Epoch: 1, Iteration: 180\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.47170624136924744\n",
      "LC Training Loss (Full): 0.14423991739749908\n",
      "Training Accuracy | Decomposed: 0.859375, Full : 0.953125\n",
      "Full accuracy (w/o dLoRA+LC): 0.9391, LC accuracy: 0.9388, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8244, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8249\n",
      "Epoch: 1, Iteration: 181\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5871334671974182\n",
      "LC Training Loss (Full): 0.30012309551239014\n",
      "Epoch: 1, Iteration: 182\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.523184597492218\n",
      "LC Training Loss (Full): 0.18747548758983612\n",
      "Epoch: 1, Iteration: 183\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5015363097190857\n",
      "LC Training Loss (Full): 0.10510141402482986\n",
      "Epoch: 1, Iteration: 184\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6443582773208618\n",
      "LC Training Loss (Full): 0.1565803438425064\n",
      "Epoch: 1, Iteration: 185\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.8363230228424072\n",
      "LC Training Loss (Full): 0.3334488868713379\n",
      "Full accuracy (w/o dLoRA+LC): 0.9397, LC accuracy: 0.9388, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8252, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8246\n",
      "Epoch: 1, Iteration: 186\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6124356985092163\n",
      "LC Training Loss (Full): 0.19133269786834717\n",
      "Epoch: 1, Iteration: 187\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.6397027373313904\n",
      "LC Training Loss (Full): 0.24693429470062256\n",
      "Epoch: 1, Iteration: 188\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5576199889183044\n",
      "LC Training Loss (Full): 0.27105024456977844\n",
      "Epoch: 1, Iteration: 189\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_42\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_42\n",
      "LoRA+LC Training Loss (Decomposed): 0.5454522371292114\n",
      "LC Training Loss (Full): 0.20111477375030518\n",
      "Epoch: 1, Iteration: 190\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.5695632100105286\n",
      "LC Training Loss (Full): 0.22096295654773712\n",
      "Full accuracy (w/o dLoRA+LC): 0.9391, LC accuracy: 0.9395, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8253, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.825\n",
      "Epoch: 1, Iteration: 191\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.4665496051311493\n",
      "LC Training Loss (Full): 0.17120100557804108\n",
      "Epoch: 1, Iteration: 192\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5433562994003296\n",
      "LC Training Loss (Full): 0.16454125940799713\n",
      "Epoch: 1, Iteration: 193\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.403581440448761\n",
      "LC Training Loss (Full): 0.1515112668275833\n",
      "Epoch: 1, Iteration: 194\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5823184847831726\n",
      "LC Training Loss (Full): 0.16114047169685364\n",
      "Epoch: 1, Iteration: 195\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5199967622756958\n",
      "LC Training Loss (Full): 0.12282554060220718\n",
      "Full accuracy (w/o dLoRA+LC): 0.9394, LC accuracy: 0.9396, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8239, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8242\n",
      "Epoch: 1, Iteration: 196\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.4550285041332245\n",
      "LC Training Loss (Full): 0.11951334029436111\n",
      "Epoch: 1, Iteration: 197\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6076529622077942\n",
      "LC Training Loss (Full): 0.16952760517597198\n",
      "Epoch: 1, Iteration: 198\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.6535803079605103\n",
      "LC Training Loss (Full): 0.21022097766399384\n",
      "Epoch: 1, Iteration: 199\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_43\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_43\n",
      "LoRA+LC Training Loss (Decomposed): 0.5300683379173279\n",
      "LC Training Loss (Full): 0.2560601532459259\n",
      "Epoch: 1, Iteration: 200\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7573311924934387\n",
      "LC Training Loss (Full): 0.2929966449737549\n",
      "Training Accuracy | Decomposed: 0.8125, Full : 0.921875\n",
      "Full accuracy (w/o dLoRA+LC): 0.939, LC accuracy: 0.9393, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8258, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8247\n",
      "Epoch: 1, Iteration: 201\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.4832814633846283\n",
      "LC Training Loss (Full): 0.18049845099449158\n",
      "Epoch: 1, Iteration: 202\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.4178566336631775\n",
      "LC Training Loss (Full): 0.12580536305904388\n",
      "Epoch: 1, Iteration: 203\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5262117385864258\n",
      "LC Training Loss (Full): 0.17046888172626495\n",
      "Epoch: 1, Iteration: 204\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5000301599502563\n",
      "LC Training Loss (Full): 0.1535521149635315\n",
      "Epoch: 1, Iteration: 205\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.43126899003982544\n",
      "LC Training Loss (Full): 0.10114723443984985\n",
      "Full accuracy (w/o dLoRA+LC): 0.939, LC accuracy: 0.9392, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8266, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.824\n",
      "Epoch: 1, Iteration: 206\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.6036565899848938\n",
      "LC Training Loss (Full): 0.1923362761735916\n",
      "Epoch: 1, Iteration: 207\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5428766012191772\n",
      "LC Training Loss (Full): 0.26390010118484497\n",
      "Epoch: 1, Iteration: 208\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5628282427787781\n",
      "LC Training Loss (Full): 0.16652745008468628\n",
      "Epoch: 1, Iteration: 209\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_44\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_44\n",
      "LoRA+LC Training Loss (Decomposed): 0.5952258706092834\n",
      "LC Training Loss (Full): 0.24758903682231903\n",
      "Epoch: 1, Iteration: 210\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.7370738387107849\n",
      "LC Training Loss (Full): 0.3781472444534302\n",
      "Full accuracy (w/o dLoRA+LC): 0.9387, LC accuracy: 0.9385, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8255, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8249\n",
      "Epoch: 1, Iteration: 211\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5256903171539307\n",
      "LC Training Loss (Full): 0.14111323654651642\n",
      "Epoch: 1, Iteration: 212\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5524981021881104\n",
      "LC Training Loss (Full): 0.15052670240402222\n",
      "Epoch: 1, Iteration: 213\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5306151509284973\n",
      "LC Training Loss (Full): 0.14421343803405762\n",
      "Epoch: 1, Iteration: 214\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5875139236450195\n",
      "LC Training Loss (Full): 0.144528329372406\n",
      "Epoch: 1, Iteration: 215\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.5922162532806396\n",
      "LC Training Loss (Full): 0.21563738584518433\n",
      "Full accuracy (w/o dLoRA+LC): 0.9387, LC accuracy: 0.9382, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8267, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8247\n",
      "Epoch: 1, Iteration: 216\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6331416368484497\n",
      "LC Training Loss (Full): 0.17919409275054932\n",
      "Epoch: 1, Iteration: 217\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.7604538202285767\n",
      "LC Training Loss (Full): 0.23292814195156097\n",
      "Epoch: 1, Iteration: 218\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6872554421424866\n",
      "LC Training Loss (Full): 0.2810502052307129\n",
      "Epoch: 1, Iteration: 219\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_45\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_45\n",
      "LoRA+LC Training Loss (Decomposed): 0.6604527235031128\n",
      "LC Training Loss (Full): 0.2683163285255432\n",
      "Epoch: 1, Iteration: 220\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.48347434401512146\n",
      "LC Training Loss (Full): 0.10392262041568756\n",
      "Training Accuracy | Decomposed: 0.828125, Full : 0.984375\n",
      "Full accuracy (w/o dLoRA+LC): 0.9389, LC accuracy: 0.9389, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8249, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8252\n",
      "Epoch: 1, Iteration: 221\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.9115905165672302\n",
      "LC Training Loss (Full): 0.43195804953575134\n",
      "Epoch: 1, Iteration: 222\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.4649994373321533\n",
      "LC Training Loss (Full): 0.1156139224767685\n",
      "Epoch: 1, Iteration: 223\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.42837509512901306\n",
      "LC Training Loss (Full): 0.11400043964385986\n",
      "Epoch: 1, Iteration: 224\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6689018607139587\n",
      "LC Training Loss (Full): 0.1795230656862259\n",
      "Epoch: 1, Iteration: 225\n",
      "Saving Checkpoint: lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_4.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6228605508804321\n",
      "LC Training Loss (Full): 0.24376794695854187\n",
      "Full accuracy (w/o dLoRA+LC): 0.9388, LC accuracy: 0.939, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8258, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8252\n",
      "Epoch: 1, Iteration: 226\n",
      "Saving Checkpoint: lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_5.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.7289064526557922\n",
      "LC Training Loss (Full): 0.23091651499271393\n",
      "Epoch: 1, Iteration: 227\n",
      "Saving Checkpoint: lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_6.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.5937894582748413\n",
      "LC Training Loss (Full): 0.13680271804332733\n",
      "Epoch: 1, Iteration: 228\n",
      "Saving Checkpoint: lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_7.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.6639548540115356\n",
      "LC Training Loss (Full): 0.31187012791633606\n",
      "Epoch: 1, Iteration: 229\n",
      "Saving Checkpoint: lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_46\n",
      "Saving Checkpoint: old_lc_checkpoint_8.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_46\n",
      "LoRA+LC Training Loss (Decomposed): 0.8271632194519043\n",
      "LC Training Loss (Full): 0.34451451897621155\n",
      "Epoch: 1, Iteration: 230\n",
      "saving full base model @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_47\\base_model.pt\n",
      "LoRA+LC Training Loss (Decomposed): 0.45216917991638184\n",
      "LC Training Loss (Full): 0.07255230098962784\n",
      "Full accuracy (w/o dLoRA+LC): 0.9385, LC accuracy: 0.9388, Decomposed-Full (w/dLoRA+LC) accuracy: 0.8255, Decomposed-Restored (w/dLoRA+LC restored) accuracy: 0.8252\n",
      "Epoch: 1, Iteration: 231\n",
      "Saving Checkpoint: lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_0.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.5886114835739136\n",
      "LC Training Loss (Full): 0.26153361797332764\n",
      "Epoch: 1, Iteration: 232\n",
      "Saving Checkpoint: lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_1.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.6423674821853638\n",
      "LC Training Loss (Full): 0.28783297538757324\n",
      "Epoch: 1, Iteration: 233\n",
      "Saving Checkpoint: lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_2.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.6443324685096741\n",
      "LC Training Loss (Full): 0.23119130730628967\n",
      "Epoch: 1, Iteration: 234\n",
      "Saving Checkpoint: lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/lobranch/train_loader4/set_47\n",
      "Saving Checkpoint: old_lc_checkpoint_3.pt @ ./volumes/Ultra Touch/lobranch-snapshot/diffbitwidth-adaptive-rank/lenet/old-lc/train_loader4/set_47\n",
      "LoRA+LC Training Loss (Decomposed): 0.39644503593444824\n",
      "LC Training Loss (Full): 0.13775993883609772\n",
      "End of model training on train_loader4...\n",
      "Model saved at accuracy: 0.8255\n"
     ]
    }
   ],
   "source": [
    "train_loader_list = [train_loader1, train_loader2, train_loader3, train_loader4]\n",
    "\n",
    "for j in range(len(train_loader_list)):\n",
    "    train_loader_txt = \"train_loader{}\".format(j+1)\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Beginning of model training on {}...\".format(train_loader_txt))\n",
    "\n",
    "    full_accuracy_dloralc = 0\n",
    "    decomposed_full_accuracy_dloralc = 0\n",
    "    restored_accuracy_dloralc = 0\n",
    "    lc_accuracy_dloralc = 0\n",
    "\n",
    "    for epch in range(NUM_EPOCHES):\n",
    "        for i, data in enumerate(train_loader_list[j], 0):\n",
    "\n",
    "            SAVE_LOC_j = SAVE_LOC + \"/\"+train_loader_txt\n",
    "            if not os.path.exists(SAVE_LOC_j):\n",
    "                os.makedirs(SAVE_LOC_j)\n",
    "                \n",
    "            SAVE_LOC_OLC_j = SAVE_LOC_OLC + \"/\"+train_loader_txt\n",
    "            if not os.path.exists(SAVE_LOC_OLC_j):\n",
    "                os.makedirs(SAVE_LOC_OLC_j)\n",
    "            print(\"Epoch: {}, Iteration: {}\".format(epch, i))\n",
    "            \n",
    "            set_path = \"/set_{}\".format(current_set)\n",
    "            if not os.path.exists(SAVE_LOC_j + set_path):\n",
    "                os.makedirs(SAVE_LOC_j + set_path)\n",
    "\n",
    "            if i == 0 and epch == 0: # first iteration, create baseline model\n",
    "                base, base_decomp = lc.extract_weights_gpu(model, SAVE_LOC_j + \n",
    "                                                        \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "            else:\n",
    "                if i % 10 == 0: \n",
    "                    # full snapshot!\n",
    "                    new_model = lazy_restore_gpu(base, base_decomp, bias, LeNet(), \n",
    "                                            original.state_dict(), DECOMPOSED_LAYERS, rank = RANK, scaling = SCALING)\n",
    "                    original = new_model # Changing previous \"original model\" used to restore the loRA model.\n",
    "                    \n",
    "                    current_set += 1\n",
    "                    current_iter = 0\n",
    "\n",
    "                    set_path = \"/set_{}\".format(current_set)\n",
    "                    if not os.path.exists(SAVE_LOC_j + set_path):\n",
    "                        os.makedirs(SAVE_LOC_j + set_path)\n",
    "                    \n",
    "                    # Rebuilding LoRA layers => reset model!\n",
    "                    w, b = getBase(original)\n",
    "                    model = LeNet_LowRank(w, b, rank = RANK).to(device)\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "                    load_sd_decomp(original.state_dict(), model, DECOMPOSED_LAYERS)\n",
    "                    base, base_decomp = lc.extract_weights_gpu(model, SAVE_LOC_j + \n",
    "                                                        \"/set_{}\".format(current_set), DECOMPOSED_LAYERS)\n",
    "\n",
    "                else:\n",
    "                    # Delta-compression\n",
    "                    delta, decomp_delta, bias = lc.generate_delta_gpu(base, \n",
    "                                                                    base_decomp, model.state_dict(), DECOMPOSED_LAYERS)\n",
    "                    compressed_delta, full_delta, compressed_dcomp_delta, full_dcomp_delta  = lc.compress_delta(delta, \n",
    "                                                                                                                decomp_delta)\n",
    "                    \n",
    "                    # Saving checkpoint\n",
    "                    lc.save_checkpoint(compressed_delta, compressed_dcomp_delta, bias, current_iter, SAVE_LOC_j + \n",
    "                                    \"/set_{}\".format(current_set))\n",
    "        \n",
    "                    base = np.add(base, full_delta) # Replace base with latest for delta to accumulate.\n",
    "                    base_decomp = np.add(full_dcomp_delta, base_decomp)\n",
    "\n",
    "                    current_iter += 1\n",
    "                \n",
    "            # ==========================\n",
    "            # Saving using LC-Checkpoint\n",
    "            # ==========================\n",
    "                    \n",
    "            if i == 0 and epch == 0:\n",
    "                cstate = model_original.state_dict()\n",
    "                set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                if not os.path.exists(SAVE_LOC_OLC_j + set_path):\n",
    "                    os.makedirs(SAVE_LOC_OLC_j + set_path)\n",
    "                torch.save(cstate, SAVE_LOC_OLC_j + set_path + \"/initial_model.pt\")\n",
    "                prev_state = olc.extract_weights_gpu(cstate, SAVE_LOC_OLC_j + set_path, DECOMPOSED_LAYERS)\n",
    "            else:\n",
    "                if i % 10 == 0:\n",
    "                    cstate = model_original.state_dict()\n",
    "                    current_set_old_lc += 1\n",
    "                    current_iter_old_lc = 0\n",
    "                    set_path = \"/set_{}\".format(current_set_old_lc)\n",
    "                    if not os.path.exists(SAVE_LOC_OLC_j + set_path):\n",
    "                        os.makedirs(SAVE_LOC_OLC_j + set_path)\n",
    "                    torch.save(cstate, SAVE_LOC_OLC_j + set_path + \"/initial_model.pt\")\n",
    "                    prev_state = olc.extract_weights_gpu(cstate, SAVE_LOC_OLC_j + set_path, DECOMPOSED_LAYERS)\n",
    "                else:\n",
    "                    cstate = model_original.state_dict()\n",
    "                    old_lc_delta, old_lc_bias = olc.generate_delta_gpu(prev_state, cstate, DECOMPOSED_LAYERS)\n",
    "                    olc_compressed_delta, update_prev = olc.compress_data(old_lc_delta, num_bits = 3)\n",
    "                    olc.save_checkpoint(SAVE_LOC_OLC_j + \"/set_{}\".format(current_set_old_lc), olc_compressed_delta, \n",
    "                                        old_lc_bias, current_iter_old_lc)\n",
    "                    prev_state = np.add(prev_state, update_prev)\n",
    "                    current_iter_old_lc += 1\n",
    "            \n",
    "            # ==========================\n",
    "            # Training on Low-Rank Model\n",
    "            # ==========================\n",
    "\n",
    "            # Get the inputs and labels\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs,labels)\n",
    "            loss.backward()\n",
    "            print(\"LoRA+LC Training Loss (Decomposed): {}\".format(loss.item()))\n",
    "            optimizer.step()\n",
    "                \n",
    "            # ======================\n",
    "            # Training on Full Model\n",
    "            # ======================\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer_lc_only.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs_full = model_original(inputs)\n",
    "            loss_full = torch.nn.functional.cross_entropy(outputs_full,labels)\n",
    "            loss_full.backward()\n",
    "            print(\"LC Training Loss (Full): {}\".format(loss_full.item()))\n",
    "            optimizer_lc_only.step()\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print(\"Training Accuracy | Decomposed: {}, Full : {}\".format(acc(outputs, labels), \n",
    "                                                                            acc(outputs_full, labels)))\n",
    "\n",
    "            if i != 0  and i % 5 == 0: # Evaluation on testing set\n",
    "                full_accuracy_dloralc = evaluate_accuracy_gpu(model_original, test_loader, device)\n",
    "                full_accuracy.append(full_accuracy_dloralc)\n",
    "\n",
    "                decomposed_full_accuracy_dloralc = evaluate_accuracy_gpu(model, test_loader, device)\n",
    "                decomposed_full_accuracy.append(decomposed_full_accuracy_dloralc)\n",
    "                \n",
    "                restored_model = lazy_restore_gpu(base, base_decomp, bias, LeNet(), \n",
    "                                            original.state_dict(), DECOMPOSED_LAYERS, \n",
    "                                            rank = RANK, scaling = SCALING)\n",
    "                restored_accuracy_dloralc_restored = evaluate_accuracy(restored_model, test_loader)\n",
    "                restored_accuracy.append(restored_accuracy_dloralc_restored)\n",
    "\n",
    "                restored_lc_model = LeNet().to(device)\n",
    "                restored_lc_model.load_state_dict(olc.restore_state_dict(prev_state, old_lc_bias, \n",
    "                                                                    restored_model.state_dict(), DECOMPOSED_LAYERS))\n",
    "                lc_accuracy_lc = evaluate_accuracy_gpu(restored_lc_model, test_loader, device)\n",
    "                lc_accuracy.append(lc_accuracy_lc)\n",
    "                print(\"Full accuracy (w/o dLoRA+LC): {}, LC accuracy: {}, Decomposed-Full (w/dLoRA+LC) accuracy: {}, Decomposed-Restored (w/dLoRA+LC restored) accuracy: {}\".format(\n",
    "                    full_accuracy[-1], lc_accuracy[-1], decomposed_full_accuracy[-1], restored_accuracy[-1]))\n",
    "                \n",
    "                wandb.log({\n",
    "                    \"accuracy w/o dLoRALC\": full_accuracy[-1],\n",
    "                    \"accuracy w/ LC\": lc_accuracy[-1],\n",
    "                    \"accuracy w/ dLoRALC\": decomposed_full_accuracy[-1],\n",
    "                    \"accuracy w/ dLoRALC after restoration\": restored_accuracy[-1]\n",
    "                })\n",
    "                \n",
    "\n",
    "    print(\"End of model training on {}...\".format(train_loader_txt))\n",
    "\n",
    "    rounded_valid_acc = decomposed_full_accuracy_dloralc\n",
    "    torch.save(model.state_dict(), HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch/branch_{}.pt\".format(rounded_valid_acc))\n",
    "    print(\"Model saved at accuracy: {:.4f}\".format(rounded_valid_acc))\n",
    "\n",
    "    w, b = getBase(original)\n",
    "    model = LeNet_LowRank(w, b, rank = RANK).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(HDFP + \"/lobranch-snapshot/branchpoints/lenet/branch/branch_{}.pt\".format(rounded_valid_acc)))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate_dloralc)\n",
    "\n",
    "    # Initialize the current iteration and set to 0\n",
    "    current_iter = 0\n",
    "    current_set = 0\n",
    "\n",
    "    # Initialize the current iteration and set to 0 for the old LC method\n",
    "    current_iter_old_lc = 0\n",
    "    current_set_old_lc = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_original.state_dict(), './model_original.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC-Checkpoint + GZIP\n",
      "Compression Ratio: 885.525%, Space Savings: 88.70700000000001%\n",
      "LoRA + LC-Checkpoint + GZIP\n",
      "Compression Ratio: 2478.644%, Space Savings: 95.966%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def getsize(sl):\n",
    "    dir = [x for x in os.listdir(sl)]\n",
    "    csize, usize = 0, 0\n",
    "    for dataloader in dir:\n",
    "        for set in os.listdir(sl + \"/\" + dataloader):\n",
    "            # print(set)\n",
    "            for f in os.listdir(sl + \"/\" + dataloader + \"/\" + set):\n",
    "                # print(f)\n",
    "                fp = sl + \"/\" + dataloader + \"/{}/{}\".format(set, f)\n",
    "                csize += os.path.getsize(fp)\n",
    "                usize += 244.0 * math.pow(2, 10) # torch checkpoint same size\n",
    "    return csize, usize\n",
    "\n",
    "compressed_size, uncompressed_size = getsize(SAVE_LOC)\n",
    "a, b = evaluate_compression(uncompressed_size, compressed_size)\n",
    "compressed_size, uncompressed_size = getsize(SAVE_LOC_OLC)\n",
    "a1, b1 = evaluate_compression(uncompressed_size, compressed_size)\n",
    "\n",
    "print(\"LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a1, b1))\n",
    "print(\"LoRA + LC-Checkpoint + GZIP\")\n",
    "print(\"Compression Ratio: {}%, Space Savings: {}%\".format(a, b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
